@article{LI2022108173,
title = {A near effective and efficient model in recognition},
journal = {Pattern Recognition},
volume = {122},
pages = {108173},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108173},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321003605},
author = {Hongjun Li and Ze Zhou and Chaobo Li and Ching Y. Suen},
keywords = {Pattern recognition, Hierarchical structure, Fuzzy system, Cycle mechanism},
abstract = {Neuro-fuzzy models have been applied in various domains, in which the issue of long time-consumption for optimizing parameters and less innovation in fuzzy method for feature extraction remains to be solved. Here, we present a novel cycle reinforce hierarchical model (CRHM) for effective and efficient recognition. The innovative strategies of CRHM consist of the hierarchical structure, the groups of fuzzy subsystems and the cycle mechanism. The hierarchical structure is innovatively built to extract features and transform the low-level features into advanced ones semantically, in which we adopt the groups of fuzzy subsystems as feature extraction units in each hidden layer, which ensures the diversity of features, avoids the fuzzy rules explosion, and reduces the time for clustering. The cycle mechanism is first proposed to connect the hierarchical structure and the output layer directly, transferring the tuned parameters again and again, to reinforce features gradually. To demonstrate the performance of CRHM, we have conducted extensive comparison with several state-of-the-art algorithms on benchmark 1D and 2D datasets. The experimental results show that the recognition rate of CRHM is higher than convolutional neural network (CNN), while the training time is only 5% of CNN's, which confirms that our approach provides a novel model for recognition, which can simultaneously improve the effectiveness and efficiency without the need of advanced equipment. In addition, the analysis results about the contribution of the core strategies to CRHM performance indicates that the contribution of the hierarchical structure is greater than that of the groups of fuzzy subsystems, which is superior than that of the cycle mechanism.}
}
@article{ZHANG2022108217,
title = {Multi-task framework based on feature separation and reconstruction for cross-modal retrieval},
journal = {Pattern Recognition},
volume = {122},
pages = {108217},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108217},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321003988},
author = {Li Zhang and Xiangqian Wu},
keywords = {Cross-modal retrieval, Feature separation, Image reconstruction, Text reconstruction},
abstract = {Cross-modal retrieval has become a hot research topic in both computer vision and natural language processing areas. Learning intermediate common space for features of different modalities has become one of mainstream methods. In this paper, we propose a novel multi-task framework based on feature separation and reconstruction (mFSR) for cross-modal retrieval based on common space learning methods, which introduces feature separation module to deal with information asymmetry between different modalities, and introduces image and text reconstruction module to improve the quality of feature separation module. Extensive experiments on MS-COCO and Flickr30K datasets demonstrate that feature separation and specific information reconstruction can significantly improve the baseline performance of cross-modal image-caption retrieval.}
}
@article{2022108390,
title = {Editorial Board},
journal = {Pattern Recognition},
volume = {122},
pages = {108390},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/S0031-3203(21)00570-7},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321005707}
}
@article{EVANGELISTA2022108363,
title = {A new bayesian Poisson denoising algorithm based on nonlocal means and stochastic distances},
journal = {Pattern Recognition},
volume = {122},
pages = {108363},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108363},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321005434},
author = {Rodrigo C. Evangelista and Denis H.P. Salvadeo and Nelson D.A. Mascarenhas},
keywords = {Poisson denoising, Nonlocal means, Stochastic distances, Bayesian estimation, Conjugate distributions, Low dose CT},
abstract = {Poisson noise is the main cause of degradation of many imaging modalities. However, many of the proposed methods for reducing noise in images lack a formal approach. Our work develops a new, general, formal and computationally efficient bayesian Poisson denoising algorithm, based on the Nonlocal Means framework and replacing the euclidean distance by stochastic distances, which are more appropriate for the denoising problem. It takes advantage of the conjugacy of Poisson and gamma distributions to obtain its computational efficiency. When dealing with low dose CT images, the algorithm operates on the sinogram, modeling the rates of the Poisson noise by the Gamma distribution. Based on the Bayesian formulation and the conjugacy property, the likelihood follows the Poisson distribution, while the a posteriori distribution is also described by the Gamma distribution. The derived algorithm is applied to simulated and real low-dose CT images and compared to several algorithms proposed in the literature, with competitive results.}
}
@article{CHANG2022108213,
title = {Video anomaly detection with spatio-temporal dissociation},
journal = {Pattern Recognition},
volume = {122},
pages = {108213},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108213},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321003940},
author = {Yunpeng Chang and Zhigang Tu and Wei Xie and Bin Luo and Shifu Zhang and Haigang Sui and Junsong Yuan},
keywords = {Video anomaly detection, Spatio-temporal dissociation, Simulate motion of optical flow, Deep K-means cluster},
abstract = {Anomaly detection in videos remains a challenging task due to the ambiguous definition of anomaly and the complexity of visual scenes from real video data. Different from the previous work which utilizes reconstruction or prediction as an auxiliary task to learn the temporal regularity, in this work, we explore a novel convolution autoencoder architecture that can dissociate the spatio-temporal representation to separately capture the spatial and the temporal information, since abnormal events are usually different from the normality in appearance and/or motion behavior. Specifically, the spatial autoencoder models the normality on the appearance feature space by learning to reconstruct the input of the first individual frame (FIF), while the temporal part takes the first four consecutive frames as the input and the RGB difference as the output to simulate the motion of optical flow in an efficient way. The abnormal events, which are irregular in appearance or in motion behavior, lead to a large reconstruction error. To improve detection performance on fast moving outliers, we exploit a variance-based attention module and insert it into the motion autoencoder to highlight large movement areas. In addition, we propose a deep K-means cluster strategy to force the spatial and the motion encoder to extract a compact representation. Extensive experiments on some publicly available datasets have demonstrated the effectiveness of our method which achieves the state-of-the-art performance. The code is publicly released at the link11https://github.com/ChangYunPeng/VideoAnomalyDetection.}
}