@article{JI2022103967,
title = {A virtual force interaction scheme for multi-robot environment monitoring},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103967},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103967},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002384},
author = {Kang Ji and Qian Zhang and Zhi Yuan and Hui Cheng and Dingli Yu},
keywords = {Monitoring coverage, Multi-robot system, Virtual force, Benchmark},
abstract = {The autonomous multi-robot system is an emerging technology that has a wide range of potential applications, such as environmental monitoring, exploration of unknown area, battlefield surveillance, and search and rescue. One major challenge in such applications is how to deploy each robotic agent autonomously in a distributed manner. In this paper, we proposed a distributed coverage control strategy named multi-stage virtual force interaction scheme (VFIS), where the agents’ deployment process is split into stages and each agent iteratively seeks its next position according to the interaction among agents and the interaction between agents and the perceived environment. The interactions are realized via virtual repulsive forces and virtual vortex forces, where the latter are newly proposed to enhance the exploration capability of agents. We also designed a group of benchmark testing problems for the mission of monitoring coverage of complex environments with unknown obstacles. Extensive simulation experiments were conducted based on the defined benchmark configurations and the results showed a favorable performance of the invented strategy. In addition, practical experiments were carried out using a group of mobile robots, which validated the effectiveness of the proposed method.}
}
@article{KASAEI2021103900,
title = {Robust biped locomotion using deep reinforcement learning on top of an analytical control approach},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103900},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103900},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001858},
author = {Mohammadreza Kasaei and Miguel Abreu and Nuno Lau and Artur Pereira and Luis Paulo Reis},
keywords = {Humanoid robots, Modular walk engine, Linear–Quadratic–Gaussian (LQG), Genetic Algorithm (GA), Proximal Policy Optimization (PPO), Deep Reinforcement Learning (DRL)},
abstract = {This paper proposes a modular framework to generate robust biped locomotion using a tight coupling between an analytical walking approach and deep reinforcement learning. This framework is composed of six main modules which are hierarchically connected to reduce the overall complexity and increase its flexibility. The core of this framework is a specific dynamics model which abstracts a humanoid’s dynamics model into two masses for modeling upper and lower body. This dynamics model is used to design an adaptive reference trajectories planner and an optimal controller which are fully parametric. Furthermore, a learning framework is developed based on Genetic Algorithm (GA) and Proximal Policy Optimization (PPO) to find the optimum parameters and to learn how to improve the stability of the robot by moving the arms and changing its center of mass height. A set of simulations are performed to validate the performance of the framework using the official RoboCup 3D League simulation environment. The results validate the performance of the framework, not only in creating a fast and stable gait but also in learning to improve the upper body efficiency.}
}
@article{LIAO2021103876,
title = {Unsupervised fault detection and recovery for intelligent robotic rollators},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103876},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103876},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001615},
author = {Yiwen Liao and Abdullah Yeaser and Bin Yang and James Tung and Ehsan Hashemi},
keywords = {Fault detection and recovery, Robotic rollators, Deep learning, Assistive devices, Temporal finite differences},
abstract = {Fault diagnosis is a key safety component in robotic assistive technologies. Although conventional model-based methods for sensor fault diagnosis in mobile robots have been well established, they face challenges due to model parameter changes and uncertainties. On the other hand, data-driven approaches becomes more appealing in order to take advantage from available historical data in the era of Big Data. To provide a new generic unsupervised solution to the fault detection and recovery, we explicitly include kinematic relations and temporal finite differences from measured sensor signals into training a multi-task deep neural network. To evaluate the proposed fault diagnosis and recovery framework, experiments have been conducted on a robotic rollator platform. Experiments under several conditions confirm that the proposed approach, which leverages machine learning-enhanced algorithms, exhibits reliable performance. Outperforming other baselines and state-of-the-art diagnosis algorithms, the framework presents a promising solution to sensor fault recovery challenges in assistive devices.}
}
@article{EFTHYMIOU2022103975,
title = {ChildBot: Multi-robot perception and interaction with children},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103975},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103975},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002426},
author = {Niki Efthymiou and Panagiotis P. Filntisis and Petros Koutras and Antigoni Tsiami and Jack Hadfield and Gerasimos Potamianos and Petros Maragos},
keywords = {Child–Robot Interaction, Multi-robot perception, Visual activity recognition, Distant speech recognition, Audio-visual active speaker localization, 6-DoF object tracking},
abstract = {In this paper, we present an integrated robotic system capable of participating in and performing a wide range of educational and entertainment tasks collaborating with one or more children. The system, called ChildBot, features multimodal perception modules and multiple robotic agents that monitor the interaction environment and can robustly coordinate complex Child–Robot Interaction use-cases. In order to validate the effectiveness of the system and its integrated modules, we have conducted multiple experiments with a total of 52 children. Our results show improved perception capabilities in comparison to our earlier works that ChildBot was based on. In addition, we have conducted a preliminary user experience study, employing some educational/entertainment tasks, that yields encouraging results regarding the technical validity of our system and initial insights on the user experience with it.}
}
@article{ADAMIK2022103912,
title = {Fast robotic pencil drawing based on image evolution by means of genetic algorithm},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103912},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103912},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001974},
author = {Michal Adamik and Jozef Goga and Jarmila Pavlovicova and Andrej Babinec and Ivan Sekaj},
keywords = {Robotic pencil drawing, Image vectorization, Non-photorealistic rendering, Machine creativity},
abstract = {Even if pencil drawing is the basic method of human artistic expression, it remains at the forefront of scientific attention in the field of robotics, which focuses mainly on painting. Although various methods of artistic robotic drawing have been developed in the past, the results are not always satisfactory. The vast majority of existing systems focus only on sketches, and detailed pencil drawings are time-consuming. In this article, we present a novel general robotic system for creating realistic pencil drawings based on image evolution. We show that by procedural image generation approach using genetic algorithms, we can create realistic drawings with an element of machine creativity. Furthermore, we show that the image approximation using even simple line segments leads to aesthetic and fast drawings. Finally, we describe a hardware solution using an industrial robot, a software implementation, and preliminary experimental results.}
}
@article{MEHRKISH2021103860,
title = {A comprehensive grasp taxonomy of continuum robots},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103860},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103860},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001457},
author = {Ali Mehrkish and Farrokh Janabi-Sharifi},
keywords = {Continuum robots, Grasp task, Grasp configuration, Grasp family, Grasp taxonomy, Taxonomy analysis},
abstract = {Continuum robots (CRs) have been the subject of intensive research in recent years due to their wide range of potential applications. Research on grasp taxonomy plays a key role in a number of task-based problems such as grasp synthesis, motion planning, and motion control. Additionally, grasp taxonomy has been shown to reduce the complexity of the design of robotic systems and human–computer interaction operations. The main goal of this research is to present a general CR-based grasp taxonomy. For this purpose, we first overview and summarize different types of CR-based grasp tasks. Then, we compare existing CR-based grasp configurations in the CR-related literature and classify the configurations into a comprehensive taxonomy. On the basis of this survey, nine major CR-based grasp families are introduced and arranged in subgroups for more detailed research. It should be noted that we studied grasps performed by different CR types and configurations without considering the object/CR size. Finally, the work includes different analyses of CR-based grasp taxonomy, including grasp frequency, grasp adaptability, taxonomy completeness, and properties of manipulated objects and tasks enabled by the proposed taxonomy.}
}
@article{BALATTI2021103888,
title = {A flexible and collaborative approach to robotic box-filling and item sorting},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103888},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103888},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001731},
author = {Pietro Balatti and Mattia Leonori and Arash Ajoudani},
keywords = {Intelligent and flexible manufacturing, Human–robot collaboration, Autonomous agents, Manipulation planning},
abstract = {In this paper, we introduce an adaptive robotic manipulation framework to respond to the flexibility needs of common industrial tasks such as box-filling and item sorting. The proposed framework consists of a vision module and a robot control module. The vision module is responsible for the detection and tracking of the environment (e.g., box and the items), which is also capable of creating an occupancy grid in real-time, to continuously update the robot trajectory planner with the occupied portions of the detected box and their coordinates. The robot control module includes a trajectory planner and a self-tuning Cartesian impedance controller, to implement an adaptive strategy for the picking, placement, and sorting of the items in the box. The item-sorting strategy is based on our preliminary observations on human motor behavior, implementing a trade-off between the task execution accuracy and environmental perception uncertainty. The efficacy of the framework in performing a flexible box-filling task using a robot, autonomously or in collaboration with a human, is evaluated through several experiments.}
}
@article{FARID2021103836,
title = {Finite-time disturbance reconstruction and robust fractional-order controller design for hybrid port-Hamiltonian dynamics of biped robots},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103836},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103836},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001214},
author = {Yousef Farid and Fabio Ruggiero},
keywords = {Bipedal robots, Hybrid systems, Port-Hamiltonian dynamics, Fractional sliding surface, Finite-time control, Disturbance estimator},
abstract = {In this paper, disturbance reconstruction and robust trajectory tracking control of biped robots with hybrid dynamics in the port-Hamiltonian form is investigated. A new type of Hamiltonian function is introduced, which ensures the finite-time stability of the closed-loop system. The proposed control system consists of two loops: an inner and an outer loop. A fractional proportional–integral–derivative filter is used to achieve finite-time convergence for position tracking errors at the outer loop. A fractional-order sliding mode controller acts as a centralized controller at the inner-loop, ensuring the finite-time stability of the velocity tracking error. In this loop, the undesired effects of unknown external disturbance and parameter uncertainties are compensated using estimators. Two disturbance estimators are envisioned. The former is designed using fractional calculus. The latter is an adaptive estimator, and it is constructed using the general dynamic of biped robots. Stability analysis shows that the closed-loop system is finite-time stable in both contact-less and impact phases. Simulation studies on three types of biped robots (i.e., two-link walker, RABBIT biped robot, and flat-feet biped robot) demonstrate the proposed controller’s tracking performance and disturbance rejection capability.}
}
@article{CHEN2022103917,
title = {A collaborative robot for COVID-19 oropharyngeal swabbing},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103917},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103917},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002025},
author = {Yongquan Chen and Qiwen Wang and Chuliang Chi and Chengjiang Wang and Qing Gao and Heng Zhang and Zheng Li and Zonggao Mu and Ruihuan Xu and Zhenglong Sun and Huihuan Qian},
keywords = {Oropharyngeal swabbing robot, Rigid–flexible coupling manipulator, Micro-pneumatic actuator, Collaborative manipulation scheme, Evaluation metrics},
abstract = {The coronavirus disease 2019 (COVID-19) outbreak has increased mortality and morbidity world-wide. Oropharyngeal swabbing is a well-known and commonly used sampling technique for COVID-19 diagnose around the world. We developed a robot to assist with COVID-19 oropharyngeal swabbing to prevent frontline clinical staff from being infected. The robot integrates a UR5 manipulator, rigid–flexible coupling (RFC) manipulator, force-sensing and control subsystem, visual subsystem and haptic device. The robot has strength in intrinsically safe and high repeat positioning accuracy. In addition, we also achieve one-dimensional constant force control in the automatic scheme (AS). Compared with the rigid sampling robot, the developed robot can perform the oropharyngeal swabbing procedure more safely and gently, reducing risk. Alternatively, a novel robot control schemes called collaborative manipulation scheme (CMS) which combines a automatic phase and teleoperation phase is proposed. At last, comparative experiments of three schemes were conducted, including CMS, AS, and teleoperation scheme (TS). The experimental results shows that CMS obtained the highest score according to the evaluation equation. CMS has the excellent performance in quality, experience and adaption. Therefore, the proposal of CMS is meaningful which is more suitable for robot-sampling.}
}
@article{GINESI2021103844,
title = {Overcoming some drawbacks of Dynamic Movement Primitives},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103844},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103844},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001299},
author = {Michele Ginesi and Nicola Sansonetto and Paolo Fiorini},
keywords = {Learning from demonstrations, Motion and path planning, Kinematics, Dynamic Movement Primitives},
abstract = {Dynamic Movement Primitives (DMPs) is a framework for learning a point-to-point trajectory from a demonstration. Despite being widely used, DMPs still present some shortcomings that may limit their usage in real robotic applications. Firstly, at the state of the art, mainly Gaussian basis functions have been used to perform function approximation. Secondly, the adaptation of the trajectory generated by the DMP heavily depends on the choice of hyperparameters and the new desired goal position. Lastly, DMPs are a framework for ‘one-shot learning’, meaning that they are constrained to learn from a unique demonstration. In this work, we present and motivate a new set of basis functions to be used in the learning process, showing their ability to accurately approximate functions while having both analytical and numerical advantages w.r.t. Gaussian basis functions. Then, we show how to use the invariance of DMPs w.r.t. affine transformations to make the generalization of the trajectory robust against both the choice of hyperparameters and new goal position, performing both synthetic tests and experiments with real robots to show this increased robustness. Finally, we propose an algorithm to extract a common behavior from multiple observations, validating it both on a synthetic dataset and on a dataset obtained by performing a task on a real robot.}
}
@article{JING2021103872,
title = {Domain adversarial transfer for cross-domain and task-constrained grasp pose detection},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103872},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103872},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001573},
author = {Xingshuo Jing and Kun Qian and Xin Xu and Jishen Bai and Bo Zhou},
keywords = {Adversarial transfer learning, Domain adaptation, Grasp pose detection, Human–robot interaction},
abstract = {Transferring the grasping skills learned from simulated environments to the real world is favorable for many robotic applications, in which the collecting and labeling processes of real-world visual grasping datasets are often expensive or even impractical. However, the models purely trained on simulated data are often difficult to generalize well to the unseen real world due to the domain gap between the training and testing data. In this paper, we propose a novel domain adversarial transfer network to narrow the domain gap for cross-domain and task-constrained grasp pose detection. Generative adversarial training is exploited to constrain the generator to produce simulation-like data for extracting the shared features with the joint distribution. We also propose to improve the backbone by extracting task-constrained grasp candidates and constructing the grasp candidate evaluator with a lightweight structure and an embedded recalibration technique. To validate the effectiveness and superiority of our proposed method, grasping performance evaluation and task-oriented human–robot interaction experiments were investigated. The experiment results indicate that the proposed method achieves state-of-the-art performance in these experimental settings. An average task-constrained grasping success rate of 83.3% without using any real-world labels for the task-oriented human–robot interaction experiment was achieved especially.}
}
@article{SARKAR2021103848,
title = {A novel search and survey technique for unmanned aerial systems in detecting and estimating the area for wildfires},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103848},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103848},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001330},
author = {Mrinmoy Sarkar and Xuyang Yan and Berat A. Erol and Ioannis Raptis and Abdollah Homaifar},
keywords = {UAV, Multi-agent autonomous system, AMASE, Search & survey, Collaborative operation, Robotics},
abstract = {In recent years Unmanned Aerial Vehicles (UAVs) have progressively been utilized for wildfire management, and are especially in prevalent in forest fire monitoring missions. To ensure the fast detection and accurate area estimation of forest fires, a two-step search and survey algorithm for multi-UAV system is proposed to address these fire scenarios. Initially, a grid-based partition method is applied to divide the area-of-interest into several search areas. Then, an archetype search pattern is used to provide timely UAV exploration within those sub-areas. Once the fire zones are detected, a novel survey strategy is employed for UAVs to discover the boundary points of the fire zones, so that the area of the fire zones can be estimated using the sampled boundary points. In addition, the effect of wind is accounted for improving fire zone boundary estimates. The proposed search-and-survey procedure is validated on multiple simulated scenarios using the U.S. Air Force’s mission-realistic Aerospace Multi-Agent Simulation Environment (AMASE) software. Simulation results showcase that the proposed search pattern can effectively discover the seeded fire zones within 40 min of the mission. This is relatively faster than the other two well-known search patterns. Moreover, the proposed survey technique provides a coverage estimate with at least 85% accuracy for the area of interest within 90 min of the mission.}
}
@article{LI2022103965,
title = {Nonlinear ESO-based tracking control for warehouse mobile robots with detachable loads},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103965},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103965},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002372},
author = {Peng Li and Hongjiu Yang and Hongbo Li and Shiqing Liang},
keywords = {Warehouse mobile robot, Detachable load, Double closed-loop framework, Tracking control, Nonlinear extended state observer},
abstract = {It is an essential task to guarantee satisfactory tracking performance for a warehouse mobile robot with a detachable load. To this end, a nonlinear extended state observer (ESO)-based tracking control is investigated via a double closed-loop framework in this paper. A kinematics controller is designed in an outer loop to generate desired velocities for the warehouse mobile robot. A nonlinear ESO with an improved error function is proposed in an inner loop to estimate load variations and internal unmodeled dynamics. Then a nonlinear error feedback controller based on estimation values is given to track the desired velocities from the outer loop. Simulation and experiment results illustrate the effectiveness and superiority of the proposed control strategy.}
}
@article{XIE2021103831,
title = {Three-dimensional aperiodic biped walking including the double support phase using LIPM and LPM},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103831},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103831},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001160},
author = {Zhongqu Xie and Long Li and Xiang Luo},
keywords = {3D biped robot, Double support phase, LIPM, LPM, Aperiodic gaits},
abstract = {This paper presents a trajectory generation algorithm with which a three-dimensional (3D) biped robot can perform aperiodic gaits by modifying only a small set of gait parameters. In addition to the double support phase (DSP), the gait can transit smoothly from one single support phase (SSP) to another. We decouple the sagittal and coronal dynamics, firstly. In the sagittal plane, the linear inverted pendulum model (LIPM) is used to generate the walking reference trajectory during the SSP. An extra template model, linear pendulum model (LPM), is added to describe the motion in the DSP. For the coronal plane, we only utilize the LPM for trajectory generation. Thanks to linearity properties, the proposed method can obtain the biped locomotion computationally fast without the need for numerical time-integration. Herein, we also introduce the trajectory generation algorithm for different aperiodic gaits including from standing to walking, stopping walking, as well as speed switch. A full-dynamics 3D humanoid robot is used for the tests of the developed reference trajectory through simulation. The results are promising for implementations.}
}
@article{2023104519,
title = {Editorial Board},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104519},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/S0921-8890(23)00158-6},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001586}
}
@article{ZHAO2021103899,
title = {A real-time low-computation cost human-following framework in outdoor environment for legged robots},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103899},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103899},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001846},
author = {Yue Zhao and Yue Gao and Qiao Sun and Yuan Tian and Liheng Mao and Feng Gao},
keywords = {Human following, Person tracking, Hexapod robot, Legged robot, Obstacle avoidance, Gait generation},
abstract = {Legged robots have potential advantages in mobility compared with wheeled robots. Hence, legged robots are widely utilized in outdoor unstructured environments. Human-following operation is one of important tasks for outdoor robots. However, most current human-following strategies requires large amount of computation resource hence difficult to be applied to legged robots. This paper proposes real-time low-computation cost human-following framework in outdoor environment for legged robots. Our method takes a full consideration of the differences between legged robots and wheeled robots. Firstly, an on-line extrinsic calibration method is proposed to calculate the camera coordinate and the world coordinate system. Then, a real-time low-computation cost human-following method utilizing RGBD cameras and 3D LIDAR is proposed. The robot motion considers tracking the leading person while avoiding obstacles. Furthermore, a dynamic alternating tripod trotting gait is developed to control the robot to follow the leading person. Finally, the method is implemented and tested on a hexapod robot Qingzhui with indoor and outdoor experiments. The framework proposed in this paper can be a valuable reference for other legged robots when operated in outdoor environments.}
}
@article{ABDELAAL2021103847,
title = {Uncalibrated stereo vision with deep learning for 6-DOF pose estimation for a robot arm system},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103847},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103847},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001329},
author = {Mahmoud Abdelaal and Ramy M.A. Farag and Mohamed S. Saad and Ahmed Bahgat and Hassan M. Emara and Ayman El-Dessouki},
keywords = {Deep learning, Pose estimation, Robot vision, Stereo vision, Optimization techniques, Levenberg–Marquardt algorithm},
abstract = {This paper proposes a novel method for six degrees of freedom pose estimation of objects for the application of robot arm pick and place. It is based on the use of a stereo vision system, which does not require calibration. Using both cameras, four corner points of the object are detected. A deep-neural-network (DNN) is trained for the prediction of the 6 DOF pose of the object from the four detected corner points’ coordinates in each image of both cameras. The stereo vision used is a low-end vision system placed in a custom-made setup. Before the training phase of the DNN, the robot is set to auto collect data in a predefined workspace. This workspace is defined dependently on the spatial feasibility of the robot arm and the shared field of view of the stereo vision system. The collected data represent images of a 2D marker attached to the robot arm gripper. The 2D marker is used for data collection to ease the detection of the four corner points. The proposed method succeeds in estimating the six degrees of freedom pose of the object, without the need for the determination of neither the intrinsic nor the extrinsic parameters of the stereo vision system. The optimum design of the proposed DNN is obtained after comparing different activation functions and optimizers associated with the DNN. The proposed uncalibrated DNN-based method performance is compared to that of the traditional calibration-based method. In the calibration-based method, the rotational matrix relating the robot coordinates to the stereo vision coordinates is computed using two approaches. The first approach uses Singular Value Decomposition (SVD) while the second approach uses a novel proposed modification of particle swarm optimization (PSO) called Hyper particle Scouts optimization (HPSO). HPSO outperforms other metaheuristic optimization algorithms such as PSO and genetic algorithm (GA). Exhaustive tests are performed, and the proposed DNN-based method is shown to outperform all tested alternatives.}
}
@article{THALAMY2021103875,
title = {Engineering efficient and massively parallel 3D self-reconfiguration using sandboxing, scaffolding and coating},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103875},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103875},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001603},
author = {Pierre Thalamy and Benoît Piranda and Julien Bourgeois},
keywords = {Programmable matter, Distributed algorithms, Modular robotics, Self-reconfiguration, Multi-agent systems},
abstract = {Programmable matter based on modular self-reconfigurable robots could stand as the ultimate form of display system, through which humans could not only see the virtual world in 3D, but manipulate it and interact with it through touch. These systems rely on self-reconfiguration processes to reshape themselves and update their representation, using methods that we argue, are currently too slow for such applications due to a lack of parallelism in the motion of the robotic modules. Therefore, we propose a novel approach to the problem, promising faster and more efficient self-reconfigurations in programmable matter display systems. We contend that this can be achieved by using a dedicated platform supporting self-reconfiguration named a sandbox, acting as a reserve of modules, and by engineering the representation of objects using an internal scaffolding covered by a coating. This paper introduces a complete view of our framework for realizing this approach on quasi-spherical modules arranged in a face-centered cubic lattice. After thoroughly discussing the model, motivations, and making a case for our method, we synthesize results from published research highlighting its benefits and engage in an honest and critical discussion of its current state of implementation and perspectives.}
}
@article{WANG2021103870,
title = {Hybrid force/position control in workspace of robotic manipulator in uncertain environments based on adaptive fuzzy control},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103870},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103870},
url = {https://www.sciencedirect.com/science/article/pii/S092188902100155X},
author = {Ziling Wang and Lai Zou and Xiaojie Su and Guoyue Luo and Rui Li and Yun Huang},
keywords = {Hybrid force/position control, Workspace, Computed torque control, Adaptive fuzzy control, Fuzzy proportional integral},
abstract = {In this study, a novel hybrid force/position controller in workspace of robotic manipulator based on adaptive fuzzy control is developed to improve the controlling performance of force and position in contact with uncertain environments. The dynamic model of the robotic manipulator in joint space is converted to a dynamic model in workspace, which is consisted of the model of position-controlled subsystem and model of force-controlled subsystem. Furthermore, in the position-controlled subsystem, an adaptive fuzzy computed torque control is proposed by considering adaptive fuzzy control and conventional computed torque control (AFCTC), for compensating deviations caused by the presence of structured uncertainty and unstructured uncertainty. In the force-controlled subsystem, a fuzzy proportional integral control method (FPI) is proposed by fuzzy logic and conventional proportional integral method to improve the control performance. The asymptotic stability of the developed controller is proved by Lyapunov theorem. The simulation results show the preferable performance of the proposed controller (AFCTC-FPI) by comparison with adaptive fuzzy sliding mode control (AFSMC), adaptive network-based fuzzy inference system with proportion differential and integral (ANFIS-PD+I), computed torque control-proportion integral (CTC-PI), fuzzy proportional integral derivative (FPID), and proportional integral derivative (PID) in uncertain environments. Furthermore, in the experimental study, average position error with AFCTC-FPI is decreased by 87.14 % than that with PID, meanwhile, range of interaction force with AFCTC-FPI is reduced by 70.31% than that with PID. In summary, the experimental results also show the superior control accuracy of the proposed controller in real environment.}
}
@article{MONIRUZZAMAN2022103973,
title = {Teleoperation methods and enhancement techniques for mobile robots: A comprehensive survey},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103973},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103973},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002414},
author = {MD Moniruzzaman and Alexander Rassau and Douglas Chai and Syed Mohammed Shamsul Islam},
keywords = {Robot, Teleoperation, Enhancement techniques, Future video prediction, Survey, Review},
abstract = {In a world with rapidly growing levels of automation, robotics is playing an increasingly significant role in every aspect of human endeavour. In particular, many types of mobile robots are increasingly being utilised in places and for tasks that are difficult and dangerous for humans. Although the vision of fully autonomous mobile robotic platforms that can perform complex tasks without direct guidance from a human operator is compelling, the reality is that the current state of robotics technology is still a long way from being able to achieve this capability outside of very narrowly constrained contexts. Technology advancement for improved mobile robotic teleoperation and remote control is vital to enable robotic vehicles to operate with increasing autonomy levels while allowing for effective remote operation when task complexity is too great for the autonomous systems. Being motivated to bridge this gap, we present a review of existing teleoperation methods and enhancement techniques for control of mobile robots. After defining teleoperation, we provide a detailed review that analyses, categorises, and summarises existing mobile robot teleoperation methods. Next, we highlight existing enhancement techniques that have been applied to these teleoperation methods, along with their relative advantages and disadvantages. Finally, several promising future research directions are identified. The paper concludes with a discussion of research challenges and future research possibilities.}
}
@article{AYOOBI2022103911,
title = {Local-HDP: Interactive open-ended 3D object category recognition in real-time robotic scenarios},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103911},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103911},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001962},
author = {H. Ayoobi and H. Kasaei and M. Cao and R. Verbrugge and B. Verheij},
keywords = {Open-ended learning, Life-long learning, Class-incremental learning, 3D object category recognition, Local hierarchical Dirichlet process, Human–robot interaction},
abstract = {We introduce a non-parametric hierarchical Bayesian approach for open-ended 3D object categorization, named the Local Hierarchical Dirichlet Process (Local-HDP). This method allows an agent to learn independent topics for each category incrementally and to adapt to the environment in time. Each topic is a distribution of the visual words over a predefined dictionary. Using an inference algorithm, these latent variables are inferred from the dataset. Subsequently, the category of an object is determined based on the likelihood of generating a 3D object from the model. Hierarchical Bayesian approaches like Latent Dirichlet Allocation (LDA) can transform low-level features to high-level conceptual topics for 3D object categorization. However, the efficiency and accuracy of LDA-based approaches depend on the number of topics that is chosen manually. Moreover, fixing the number of topics for all categories can lead to overfitting or underfitting of the model. In contrast, the proposed Local-HDP can autonomously determine the number of topics for each category. Furthermore, the online variational inference method has been adapted for fast posterior approximation in the Local-HDP model. Experiments show that the proposed Local-HDP method outperforms other state-of-the-art approaches in terms of accuracy, scalability, and memory efficiency by a large margin. Moreover, two robotic experiments have been conducted to show the applicability of the proposed approach in real-time applications.}
}
@article{DAI2021103859,
title = {Towards a systematic computational framework for modeling multi-agent decision-making at micro level for smart vehicles in a smart world},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103859},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103859},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001445},
author = {Qi Dai and Xunnong Xu and Wen Guo and Suzhou Huang and Dimitar Filev},
keywords = {Multi-agent decision-making, Coordinated path planning, Human driving behavior modeling},
abstract = {We propose a multi-agent based computational framework for modeling decision-making and strategic interaction at micro level for smart vehicles in a smart world. The concepts of Markov game and best response dynamics are heavily leveraged. Our aim is to make the framework conceptually sound and computationally practical for a range of realistic applications, including micro path planning for autonomous vehicles. To this end, we first convert the would-be stochastic game problem into a closely related deterministic one by introducing risk premium in the utility function for each individual agent. We show how the sub-game perfect Nash equilibrium of the simplified deterministic game can be solved by an algorithm based on best response dynamics. In order to better model human driving behaviors with bounded rationality, we seek to further simplify the solution concept by replacing the Nash equilibrium condition with a heuristic and adaptive optimization with finite look-ahead anticipation. In addition, the algorithm corresponding to the new solution concept drastically improves the computational efficiency. To demonstrate how our approach can be applied to realistic traffic settings, we conduct a simulation experiment: to derive merging and yielding behaviors on a double-lane highway with an unexpected barrier. Despite assumption differences involved in the two solution concepts, the derived numerical solutions show that the endogenized driving behaviors are very similar. We also briefly comment on how the proposed framework can be further extended in a number of directions in our forthcoming work, such as behavioral calibration using real traffic video data, and computational mechanism design for traffic policy optimization.}
}
@article{JAYARATNE2021103835,
title = {Unsupervised skill transfer learning for autonomous robots using distributed Growing Self Organizing Maps},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103835},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103835},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001202},
author = {Madhura Jayaratne and Damminda Alahakoon and Daswin {de Silva}},
keywords = {Autonomous robots, Skill transfer learning, Distributed self-organizing map, Knowledge transfer, Growing Self-Organizing Map, MapReduce, Resilient Distributed Dataset, Bulk Synchronous Parallel, Developmental robotics, Unsupervised machine learning, Artificial intelligence},
abstract = {A persistent challenge in the cognitive development of autonomous robotics is the unsupervised and unstructured nature of skill transfer learning where the Self Organizing Map (SOM) has been used as the enabling technology. The Growing Self-Organizing Map (GSOM) algorithm is an unsupervised, structure-adapting machine learning algorithm conventionally used for data exploration, clustering, visualization, outlier detection and dimensionality reduction. In this paper, we present the design and development of a new distributed algorithm based on the GSOM for unsupervised skill transfer learning in autonomous robotics settings which overcomes the key limitations of the SOM in real-life scenarios. We posit this new algorithm will be directly applicable to skill transfer learning scenarios that require unsupervised, incremental and on-going self-learning of multi-tasks and knowledge transfer. The distributed and scalable properties of the proposed algorithm handle large volumes of data required for unsupervised skill transfer learning, based on data parallelization. It generates multiple maps representing diverse skill knowledge, which are then projected together to a single embedding. The new algorithm is positioned within an autonomous developmental robotics framework for knowledge acquisition and skill transfer learning. This framework was further adapted to three contemporary distributed computing platforms, Hadoop, Spark and Hama. Empirical evaluation of these three adaptations using several benchmark and real-life datasets demonstrates its practical value and computational efficiency for unsupervised skill transfer learning in autonomous robots.}
}
@article{HOU2022103949,
title = {Enhanced ant colony algorithm with communication mechanism for mobile robot path planning},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103949},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103949},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002256},
author = {Wenbin Hou and Zhihua Xiong and Changsheng Wang and Howard Chen},
keywords = {Mobile robot, Path planning, Ant colony algorithm, Communication mechanism, Roulette method, Deadlock},
abstract = {In mobile robot path planning, the ant colony algorithm has the problem that the historical paths explored by ants cannot be fully utilized. With this in mind, in this paper an enhanced ant colony algorithm with a communication mechanism is proposed. The communication mechanism is inspired by the contact of ant tentacles in nature, which can integrate historical paths to obtain a better composite path. To further improve the algorithm, an enlarged roulette method is presented to accelerate the convergence. Subsequently, an adaptive sigmoid attenuation function is designed to optimize the heuristic information at different stages. The various forms of the deadlock problem are analyzed and specific strategies formulated. Finally, parameter determination and comparison experiments are carried out. The experimental results demonstrate the efficiency of the proposed method and its considerable advantages in enhancing the performance of the ant colony algorithm.}
}
@article{LEE2022103916,
title = {Real-time adaptive impedance compensator using simultaneous perturbation stochastic approximation for enhanced physical human–robot interaction transparency},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103916},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103916},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002013},
author = {Kyeong Ha Lee and Seung Guk Baek and Hyuk Jin Lee and Seung Ho Lee and Ja Choon Koo},
keywords = {Physical human–robot interaction, Adaptive impedance compensator, SPSA},
abstract = {In the physical human–robot interaction (pHRi) system, the human and the robot are physically coupled, and it makes the human and the robot always influence each other. In engineering tasks, using a force sensor is the norm for control the robot through the interaction force between the human and the robot. However, the force measured from the force sensor contains the force intended by human motion and the natural force feedback generated by the robot movement and the human hand impedance due to the coupled dynamics. Therefore, it is necessary to characterize the human hand dynamics to improve transparency. However, it is difficult to estimate the human hand impedance, which is the primary source of natural force feedback in real-time. This paper proposes a real-time adaptive hand impedance compensator to enhance transparency in various pHRi conditions with human hand dynamics. The proposed algorithm regulates the impedance compensator’s parameters to find optimal values that minimize the energy-based cost function using Simultaneous Perturbation Stochastic Approximation (SPSA) and AMSGrad. SPSA is a useful method when the exact relationship between the parameters and the cost function is unknown. AMSGrad is a state-of-the-art technique widely used as an adaptive learning rate method in deep learning fields. The proposed real-time adaptive impedance compensator decreases the influence of natural force feedback by updating the parameter appropriately depending on the pHRi conditions, thus improving the transparency.}
}
@article{SOLTANIZARRIN2021103843,
title = {Towards autonomous ergonomic upper-limb exoskeletons: A computational approach for planning a human-like path},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103843},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103843},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001287},
author = {Rana {Soltani Zarrin} and Amin Zeiaee and Reza Langari and John J. Buchanan and Nina Robson},
keywords = {Computational models, Human-like motion, Path planning, Upper-limb exoskeletons, Scapulohumeral rhythm},
abstract = {Computational path planning approaches can enable development of autonomous rehabilitation and assistive exoskeletons. Using a human-like reference behavior for such wearable systems can ensure safe, effective, and intuitive human–robot interaction. This is of significant importance since the quality of interaction and ergonomic considerations have a substantial effect on technology usability and acceptance by the users. This paper proposes a novel framework for generating human-like paths for wearable exoskeletons in the shoulder-elbow level. The introduced method is a two-stage process where a human-like reference path is planned in the configuration space of the human arm, followed by an analytical transformation that directly maps the derived path to the configuration space of the exoskeleton. The analytical mapping presented is a function of the kinematic parameters of the system and can be adapted for other upper-limb exoskeletons. As a case study, the proposed method is used for generating human-like reference motions for a six-degree-of-freedom exoskeleton supporting scapulohumeral rhythm, glenohumeral rotations, and elbow flexion/extension. Firstly, it is shown that reaching motions associated with activities of daily living can be predicted with high accuracy in the human joint space. This is demonstrated by analyzing the experimental data collected from healthy subjects. Subsequently, it is verified through kinematic analysis that the transformation of generated paths to the exoskeleton configuration space does not alter their spatial profile in the task space.}
}
@article{CONTINI2021103871,
title = {Coordination approaches for multi-item pickup and delivery in logistic scenarios},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103871},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103871},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001561},
author = {Antonello Contini and Alessandro Farinelli},
keywords = {Multi-Robot systems, Multi-Agent Path Planning, Task allocation, Logistic applications},
abstract = {We focus on the Multi-Robot pickup and delivery problem for logistic scenarios that recently received significant attention from the research community. In particular we consider an innovative variant of the pickup and delivery problem where robots can deliver, in a single travel, multiple items. We propose a decentralized coordination algorithm based on a token passing approach. Our algorithm allocates delivery tasks (i.e., an aggregation of items to be delivered by a single robot) to the Multi-Robot System avoiding conflicts among the robots. In more detail, we show that our approach generates conflict-free paths for the Multi-Robot system requiring weaker assumptions on the operational area compared to previous approaches. We empirically evaluate the proposed method on three different scenarios, including the production line of a smart factory, comparing the performance of our decentralized method against two centralized approaches. Results show that our approach finds solutions of similar quality (in terms of makespan and travel distance) reducing the associated computational effort.}
}
@article{CAI2022103964,
title = {Multi-maneuver vertical parking path planning and control in a narrow space},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103964},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103964},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002360},
author = {Lei Cai and Hsin Guan and Hao Lun Zhang and Xin Jia and Jun Zhan},
keywords = {Autonomous parking, Motion planning, Path planning, Driver model},
abstract = {The automatic parking system can replace people to complete the parking task and reduce the burden of driving. The size of the parking space affects the number of parking operations and the time for parking planning to be completed. Parking planning in narrow space is a challenging problem, especially in crowded urban environments. This paper presents a parking path planning method in a narrow vertical parking space. First, the parking path planning method can be used in narrow corridor spaces and narrow spots. According to the size of the corridor space and the parking space obtained by the environment perception, this method can determine the number of parking maneuvers and the start parking position. Second, to allow the vehicle to generate a parking path at any position to reach the parking starting point, the system generates a target line set that considers control error factors. It will also select the optimal target line based on the current position. Third, the vehicle cannot complete the parking while traveling along the original parking path when the factual error is greater than the reserved error. Therefore, a re-planning method based on geometric planning is proposed to improve the robustness of the system. Finally, through the establishment of longitudinal and lateral driver models, the effectiveness of the path planning method is verified, and compared with other path planning methods, it proves that the method proposed in this paper performs well in the number of maneuvers and planning time in a small space.}
}
@article{MAHMOUDIKHOMAMI2021103846,
title = {A survey on soft lower limb cable-driven wearable robots without rigid links and joints},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103846},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103846},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001317},
author = {Asghar {Mahmoudi Khomami} and Farid Najafi},
keywords = {Cable-driven lower limb robots, Joint misalignment, Exosuit, Rehabilitation, Power augmentation},
abstract = {Traditional wearable robots mostly consist of rigid structures connected to the human body. Due to the inherent characteristics of human joints, it is unavoidable that the robot joints have some misalignment with the wearer’s biological joints. One solution to the joint misalignment problem in wearable robots is to use soft structures instead of traditional rigid structures as the interface between the robot and the wearer. This survey paper aims to provide an overview of the designs of wearable robots for the lower limbs that do not contain any rigid structures or joints. This study is mainly focused on robots with an electrical cable-driven actuator. The lower limb joint-less robots introduced in this paper were categorized into three main groups, namely exoskeleton-based robots, end-effector-based robots, and​ exosuits. Application of these devices can be categorized as rehabilitation of patients with gait impairments and power augmentation of healthy users. After a detailed review of the notable designs in each group, a discussion about the advantages and disadvantages indicated that the main drawback of current designs is the limitation on the amount of provided assistive loads. Because the forces are mainly applied in parallel to the human body, the amount of these forces is limited by the wearer’s comfort level. In the end, a possible research direction for future researchers is presented in an attempt to address the limitations of current designs.}
}
@article{YU2022103971,
title = {A fast robotic arm gravity compensation updating approach for industrial application using sparse selection and reconstruction},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103971},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103971},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002402},
author = {Chenglong Yu and Zhiqi Li and Dapeng Yang and Hong Liu},
keywords = {Industrial robot arm, Gravity compensation, Feature selection, Model reconstruction, ADMM},
abstract = {With the increasing complexity of robot tasks in the industrial field, sometimes the manipulator needs to change the payload or replace end-effectors frequently in a period of time, which will cause the change of gravity model. This paper presents a fast gravity compensation updating method based on sparse selection and reconstruction. Instead of using the classic model, feature sets in the formulation of dynamic motion are exploited and the gravity model learning is transformed into a sparse problem. Then, the Alternating Direction Multiplier Method (ADMM) is used to accelerate the process of solving the sparse optimization problem and reconstructing the effective features of the gravity model from the original signal. The merits of our method are that it does not depend on any kinematic and dynamic parameters, and there is no need to redesign the specific excitation trajectory in the gravity model updating. Thus, the updating process avoids heavy work of calibration and simplifies the labor complexity considerably from the conventional analytical methods. The results of various payload experiments on a real 7-DOF manipulator show that the proposed method can update the gravity compensation model efficiently and accurately.}
}
@article{DOMINGO2021103830,
title = {Visual recognition of gymnastic exercise sequences. Application to supervision and robot learning by demonstration},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103830},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103830},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001159},
author = {Jaime Duque Domingo and Jaime Gómez-García-Bermejo and Eduardo Zalama},
keywords = {Automated gymnastic activity recognition, Autonomous robot, Social robotics, Multilayer perceptron, MLP, Hidden Markov model, HMM, Viterbi, Modified Levenshtein distance, MLD, OpenPose},
abstract = {This work presents a novel software architecture to autonomously identify and evaluate the gymnastic activity that people are carrying out. It is composed of three different interconnected layers. The first corresponds to a Multilayer Perceptron (MLP) trained from a set of angular magnitudes derived from the information provided by the OpenPose library. This library works frame by frame, so some postures may be incorrectly detected due to eventual occlusions. The MLP layer makes it possible to accurately identify the posture a person is performing. A second layer, based on a Hidden Markov Model (HMM) and the Viterbi algorithm, filters the incorrect spurious postures. Thus, the accuracy of the algorithm is improved, leading to a precise sequence of postures. A third layer identifies the current exercise and evaluates whether the person is doing it at a correct speed. This layer uses an innovative Modified Levenshtein Distance (MLD), which considers not only the number of operations to transform a given sequence, but also the nature of the elements participating in the comparison. The system works in real time with little delay, thus recognizing sequences of arbitrary length and providing continuous feedback on the exercises being performed. An experiment carried out consisted in reproducing the output of the second layer on an autonomous Pepper robot that can be used in environments where physical exercise is performed, such as a residence for the elderly or others. It has reproduced different exercises previously executed by an instructor so that people can copy the robot. The article analyzes the current situation of the automated gymnastic activities recognition, presents the architecture, the different experiments carried out and the results obtained. The integration of the three components (MLP, HMM and MLD) results in a robust system that has allowed us to improve the results of previous works.}
}
@article{RODRIGUEZABREO2022103910,
title = {Backstepping control for a UAV-manipulator tuned by Cuckoo Search algorithm},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103910},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103910},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001950},
author = {Omar Rodríguez-Abreo and Francisco-Javier Ornelas-Rodríguez and Alfonso Ramírez-Pedraza and Juan B. Hurtado-Ramos and José-Joel González-Barbosa},
keywords = {Cuckoo Search algorithm, Backstepping control, Unmanned aerial vehicle, Manipulator, Optimal control},
abstract = {Manipulators coupled with an Unmanned Aerial Vehicle (UAV) have made it possible to perform aerial handling, transport, and picking maneuvers. One of the techniques used to control these systems is a backstepping controller that has shown high performance compared to a PID in the face of uncertainties and parametric disturbances. This paper presents the study of a backstepping controller for a mobile manipulator (MM–UAV) system tuned with the Cuckoo Search algorithm (CS) for trajectory tracking. Unlike other research, this study focuses on optimization using this metaheuristic algorithm that has never been applied in an MM–UAV. The system is divided in a novel way to implement the CS, considering the dependence of each rotation axis with the correspondence translation axis. Additionally, the tuning focuses on two critical points of the dynamic response, the overshoot and settling time. The results at the simulation and experimental level show that for all cases, a settling time of fewer than 0.8 s and overshoot is minor than 2%. This allows a balanced response of the system, which directly impacts energy consumption. The results are compared with a PID controller to verify the proposed work efficiency, showing a reduction of up to 8% of overshoots without exceeding in any experiment the maximum settling time of 0.8 s imposed to the system.}
}
@article{KOURANI2021103858,
title = {Marine locomotion: A tethered UAV-Buoy system with surge velocity control},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103858},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103858},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001433},
author = {Ahmad Kourani and Naseem Daher},
keywords = {Tethered UAV, Marine robotics, Motion control, Locomotive UAV, Floating buoy manipulation},
abstract = {Unmanned aerial vehicles (UAVs) are reaching offshore. In this work, we formulate the novel problem of a marine locomotive quadrotor UAV, which manipulates the surge velocity of a floating buoy by means of a cable. The proposed robotic system can have a variety of novel applications for UAVs where their high speed and maneuverability, as well as their ease of deployment and wide field of vision, give them a superior advantage. In addition, the major limitation of limited flight time of quadrotor UAVs is typically addressed through an umbilical power cable, which naturally integrates with the proposed system. A detailed high-fidelity dynamic model is presented for the buoy, UAV, and water environment. In addition, a stable control system design is proposed to manipulate the surge velocity of the buoy within certain constraints that keep the buoy in contact with the water surface. Polar coordinates are used in the controller design process since they outperform traditional Cartesian-based velocity controllers when it comes to ensuring correlated effects on the tracking performance, where each control channel independently affects one control parameter. The system model and controller design are validated in numerical simulation under different settings, configurations, and wave scenarios.}
}
@article{CHEN2022103947,
title = {The semantic PHD filter for multi-class target tracking: From theory to practice},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103947},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103947},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002244},
author = {Jun Chen and Zhanteng Xie and Philip Dames},
keywords = {Multiple target tracking, Semantic tracking, PHD filter, Robot learning},
abstract = {In order for a mobile robot to be able to effectively operate in complex, dynamic environments it must be capable of understanding both where and what the objects around them are. In this paper we introduce the semantic probability hypothesis density (SPHD) filter, which allows robots to simultaneously track multiple classes of targets despite measurement uncertainty, including false positive detections, false negative detections, measurement noise, and target misclassification. The SPHD filter is capable of incorporating a different motion model for each type of target and of functioning in situations where the number of targets is unknown and time-varying. To demonstrate the efficacy of the SPHD filter, we conduct both simulated and hardware tests with multiple target types containing both static and dynamic targets. We show that the SPHD filter allows effective tracking of multiple classes of targets even with detection error to some level, and performs better than a collection of PHD filters running in parallel, one for each target class. We also provide a detailed methodology that practitioners can use to fit the probabilistic sensor models necessary to run the SPHD filter.}
}
@article{ABIOYE2022103915,
title = {The performance and cognitive workload analysis of a multimodal speech and visual gesture (mSVG) UAV control interface},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103915},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103915},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002001},
author = {Ayodeji Opeyemi Abioye and Stephen D. Prior and Peter Saddington and Sarvapali D. Ramchurn},
keywords = {Aerobot, mSVG (multimodal speech and visual gesture), nCA (navigation control autonomy), RFDS (RealFlight Drone Simulator), Speech, Visual gesture},
abstract = {This paper conducts a comparison of the performance and cognitive workload between three UAV control interfaces on an nCA (navigation control autonomy) Tier 1-III flight navigation task. The first interface is the standard RC Joystick (RCJ) controller, the second interface is the multimodal speech and visual gesture (mSVG) interface, and the third interface is the modified version of the RCJ interface with altitude, attitude, and position (AAP) assist. The modified RCJ interface was achieved with the aid of the Keyboard (KBD). A model of the mSVG interface previously designed and tested was used in this comparison. An experiment study was designed to measure the completion time and navigation accuracy of participants using each of the three interfaces, on a developed path_v02 test flight path. Thirty-seven (37) participants volunteered. The NASA task load index (TLX) survey questionnaire was administered at the end of each interface experiment to access the participants experience and to estimate the interface cognitive workload. A commercial software, the RealFlight Drone Simulator (RFDS) was used to estimate the RCJ skill level of the participants. From the results of the experiment, it was shown that the flying hours, the number of months flying, and the RFDS Level 4 challenge performance was a good estimator for participants RCJ flying skill level. A two-way result was obtained in the comparison of the RCJ and mSVG interfaces. It was concluded that, although the mSVG was better than the standard RCJ interface, the AAP-assisted RCJ was found to be as effective as (in some cases better than) the mSVG interface. It was also shown, from the speech gesture ratio result, that the participants had a preference for gesture over speech when using the mSVG interface. Some further works such as an outdoor field test and a performance comparison at higher nCA levels were suggested.}
}
@article{ZHANG2021103842,
title = {An adaptive framework of real-time continuous gait phase variable estimation for lower-limb wearable robots},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103842},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103842},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001275},
author = {Binquan Zhang and Sun’an Wang and Min Zhou and Wanlu Xu},
keywords = {Gait phase estimation, Trajectory correlation, Gait kinematics, Wearable robotics},
abstract = {Phase-variable-based approaches are emerging in the control of lower-limb wearable robots, such as exoskeletons and prosthetic legs. However, real-time smooth estimation of the gait phase within each gait cycle remains an open problem. This paper presents a novel method for real-time continuous gait phase estimation during walking. The proposed framework consists of three subsystems: real-time kinematic data collection, gait phase variable estimation, and online adaptation of individual kinematics through backward data segmentation of completed gait strides. It is worth noting that we introduce an online learning mechanism for extracting and learning gait features from previous strides, in contrast with offline parameter tuning. The proposed basic gait model is initialized by human average data and is incrementally refined as a function of the individual gait features over different walking speeds. This provides a framework for long-term personalized control. Furthermore, the phase variable is constructed through the thigh angle measured by an inertial measurement unit. The resulting simple sensor system improves the usability of the proposed technique in wearable robotics. Validation experiments with seven healthy subjects, including treadmill walking and free level-ground walking, were conducted to evaluate the performance of the proposed method. In treadmill validation, the root-mean-square error (RMSE) of the phase estimator was 4.14 ± 1.68% for steady speeds, while it was 6.77 ± 2.29% for unsteady-speed walking. In level-ground validation, the average RMSE of the phase estimator was 4.59 ± 1.76%. Preliminary experiments were also conducted using a single-joint hip exoskeleton to demonstrate the usability of our method in lower-limb wearable robots.}
}
@article{MAHKAM2021103841,
title = {A framework for dynamic modeling of legged modular miniature robots with soft backbones},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103841},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103841},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001263},
author = {Nima Mahkam and Onur Özcan},
keywords = {Robot dynamics, Legged robots, Miniature robots, Modular robots, Soft mobile robots, Origami-inspired robots},
abstract = {In this work, the dynamics of ”n” legged modular miniature robots with a soft body is modeled. The dynamic formulation is obtained using Newton–Euler formulation that depends on the contact parameters and the feet closed-chain kinematic analysis. The dynamic model determines the locomotion parameters of each module as an individual system as well as the dynamics of the whole robot in a 3D space; i.e., the robot is modeled as one system, and modules are considered to be sets of flexible links connected within this system. Kinematic constraints among these modules are obtained by considering the type of backbone integrated into the modular robot. Various types of backbones are used that are classified into three groups: rigid, only torsional, and soft. The model is verified using SMoLBot, an origami-inspired miniature robot made of multiple modules and soft/rigid backbones. Additional to the dynamic model, the effect of different sets of design parameters on the locomotion of the legged soft-bodied modular miniature robots is studied. Analyses comparing the velocity of SMoLBot with a different number of modules and various types of backbones are presented using the proposed dynamic model. Our results show the existence of an optimum backbone torsional stiffness for legged miniature modular robots and an optimum number of legs for a given backbone stiffness that maximizes the robot’s velocity. In this research, presented results and locomotion study show that the robot’s design should be iteratively improved based on specific optimum goals for exclusively defined task to satisfy the operational needs.}
}
@article{MURPHY2022103922,
title = {An analysis of international use of robots for COVID-19},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103922},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103922},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002074},
author = {Robin R. Murphy and Vignesh B.M. Gandudi and Trisha Amin and Angela Clendenin and Jason Moats},
keywords = {Robotics and society, Field robotics, Disaster robotics, Medical robotics, Unmanned systems},
abstract = {This article analyses data collected from press reports, social media, and the scientific literature on 338 instances of robots used explicitly in response to COVID-19 from 24 Jan, 2020, to 23 Jan, 2021, in 48 countries. The analysis was guided by four overarching questions: (1) What were robots used for in the COVID-19 response? (2) When were they used? (3) How did different countries innovate? and 4) Did having a national policy on robotics influence a country’s innovation and insertion of robotics for COVID-19? The findings indicate that robots were used for six different sociotechnical work domains and 29 discrete use cases. When robots were used varied greatly on the country; although many countries did report an increase at the beginning of their first surge. To understand the findings of how innovation occurred, the data was examined through the lens of the technology’s maturity according to NASA’s Technical Readiness Assessment metrics. Through this lens, findings note that existing robots were used for more than 78% of the instances; slightly modified robots made up 10%; and truly novel robots or novel use cases constituted 12% of the instances. The findings clearly indicate that countries with a national robotics initiative were more likely to use robotics more often and for broader purposes. Finally, the dataset and analysis produces a broad set of implications that warrant further study and investigation. The results from this analysis are expected to be of value to the robotics and robotics policy community in preparing robots for rapid insertion into future disasters.}
}
@article{2023104501,
title = {Editorial Board},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104501},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/S0921-8890(23)00140-9},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001409}
}
@article{PARRANY2022103939,
title = {Introducing shell formation and a thermodynamics-inspired concept for swarm robotic systems},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103939},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103939},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002190},
author = {Ahmad Mahdian Parrany and Aria Alasty},
keywords = {Swarm robotics, Shell formation, Thermodynamic viewpoint, Swarm pressure, Passing through a narrow passage},
abstract = {In this article, a new formation for swarm robotic systems is introduced. This formation, which is made up of a portion of swarm members and encircles the whole swarm, is called the shell formation. In this regard, an effective algorithm for developing the shell formation in swarm robotic systems is established. The interaction mechanism among swarm agents is based on the method of artificial potential fields and the local rule of the nearest neighbor. Subsequently, inspired by the thermodynamic science and based on the introduced shell formation, the thermodynamic concept of pressure is generalized to swarm robotic systems. Finally, the efficacy of the introduced shell formation in solving the problem of passing through a narrow passage is studied via numerical simulations.}
}
@article{NOROUZIGHAZBI2021103856,
title = {Constrained visual predictive control of tendon-driven continuum robots},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103856},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103856},
url = {https://www.sciencedirect.com/science/article/pii/S092188902100141X},
author = {Somayeh Norouzi-Ghazbi and Ali Mehrkish and Mostafa {M.H. Fallah} and Farrokh Janabi-Sharifi},
keywords = {Continuum robot, Tendon driven, Visual servoing, Predictive control, Robustness, Steerable catheter},
abstract = {Due to their compliance, continuum robots (CRs) hold great potential for many applications. However, despite intensive recent research, their control poses significant challenges. The nonlinear kinematic behavior, limited actuation channels, and physical and environmental constraints typically associated with CRs hinder the development of effective control strategies. In this paper, a visual predictive position control method for tendon-driven continuum robots is proposed. The developed control approach integrates the advantages of image-based visual servoing and model predictive control techniques to enable direct end-point control in the presence of constraints and improve the control robustness to system uncertainties, sensing noise, and modeling errors. Both simulation and experimental results demonstrate the effectiveness of the method.}
}
@article{GUFFANTI2021103869,
title = {Development and validation of a ROS-based mobile robotic platform for human gait analysis applications},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103869},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103869},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001548},
author = {Diego Guffanti and Alberto Brunete and Miguel Hernando},
keywords = {Mobile robot, Gait analysis, Depth sensors},
abstract = {Background:
The integration of mobile robotic platforms in human gait analysis offers the potential to develop multiple medical applications and achieve new discoveries. The aim of this paper is to present a first design and validation of a ROS-based mobile robotic platform for human gait analysis.
Methods:
During the design stage, the model identification and the configuration of the control law were performed. The design of the control law required the integration of a lead compensator and a Filtered Smith Predictor (FSP). During the validation procedure, the accuracy of the system to retrieve kinematic gait data and the main descriptors of gait disorders was calculated with respect to the ground truth of a Vicon system. For this purpose, one hundred gait recordings were processed thanks to the collaboration of twenty participants. The participants walked in a one-way straight line gait.
Results:
Results showed high correlation and low error rates mainly in joint excursions from sagittal and transverse planes.
Conclusion:
This gait analysis system demonstrated several advantages compared with the current approaches. The use of a mobile robotic platform allowed gait analysis in long tracking ranges and without space limitations. Furthermore, the design of a suitable control law allowed a smooth tracking of the person. This led to optimal results when assessing joint excursions.
Significance:
This system represents a cost-effective and non-invasive alternative that could be used for human gait analysis applications.}
}
@article{AJAYKUMAR2021103845,
title = {Designing user-centric programming aids for kinesthetic teaching of collaborative robots},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103845},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103845},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001305},
author = {Gopika Ajaykumar and Maia Stiber and Chien-Ming Huang},
keywords = {Human–robot interaction, End–user development, End–user robot programming},
abstract = {Just as end-user programming has helped make computer programming accessible for a variety of users and settings, end-user robot programming has helped empower end-users without specialized knowledge or technical skills to customize robotic assistance that meets diverse environmental constraints and task requirements. While end-user robot programming methods such as kinesthetic teaching have introduced direct approaches to task demonstration that allow users to avoid working with traditional programming constructs, our formative study revealed that everyday people still have difficulties in specifying effective robot programs using these methods due to challenges in understanding robot kinematics and programming without situated context and assistive system feedback. These findings informed our development of Demoshop, an interactive robot programming tool that includes user-centric programming aids to help end-users author and edit task demonstrations. To evaluate the effectiveness of Demoshop, we conducted a user study comparing task performance and user experience associated with using Demoshop relative to a widely used commercial baseline interface. Results of our study indicate that users have greater task efficiency while authoring robot programs and maintain stronger mental models of the system when using Demoshop compared to the baseline interface. Our system implementation and study have implications for the further development of assistance in end-user robot programming.}
}
@article{YANG2021103829,
title = {Exploring relationships between design features and system usability of intelligent car human–machine interface},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103829},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103829},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001147},
author = {Hao Yang and Jitao Zhang and Yueran Wang and Ruoyu Jia},
keywords = {Instrument panel, Design features, Eye movement, System usability, BP neural network, SVM},
abstract = {In-vehicle human–machine interface (HMI) mainly refers to the T-shaped panel system with instruments, centre console, gear lever and other components installed. For intelligent vehicles, the high level of intelligent interconnection may to some extent make drivers lack situational safety awareness and reduce the usability of the system. Thus, this study attempted to establish a relationship between design features and system usability of the in-vehicle panels. From the perspective of visual ergonomics, the panels were deconstructed into design features to determine 36 samples to be studied. After dividing each sample into four areas of interest (AOI), eye movement and subjective preference data were collected to quantify the user experience. Artificial neural network (ANN) and support vector machine (SVM) were used in the study. Nevertheless, conventional learning algorithms often underwent deficiencies in accuracy and robustness in the detection of multifarious kinds of panels. Therefore, the parameters of the two models were tuned to deal with the noise common in user experience data. The determinant coefficients, mean-square errors and mean relative errors of the two models showed that the SVM model had a higher accuracy, smaller error and was more stable in the learning of user experience of HMI design features, which could provide a method for the layout design and evaluation of T-shaped instrument panel.}
}
@article{ALMEIDA2021103857,
title = {Where is my hand? Deep hand segmentation for visual self-recognition in humanoid robots},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103857},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103857},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001421},
author = {Alexandre Almeida and Pedro Vicente and Alexandre Bernardino},
keywords = {Robotic hand, Visual segmentation, Deep learning, Domain randomization, Self-recognition},
abstract = {The ability to distinguish between the self and the background is of paramount importance for robotic tasks. The particular case of hands, as the end effectors of a robotic system that more often enter into contact with other elements of the environment, must be perceived and tracked with precision to execute the intended tasks with dexterity and without colliding with obstacles. They are fundamental for several applications, from Human–Robot Interaction tasks to object manipulation. Modern humanoid robots are characterized by high number of degrees of freedom which makes their forward kinematics models very sensitive to uncertainty. Thus, resorting to vision sensing can be the only solution to endow these robots with a good perception of the self, being able to localize their body parts with precision. In this paper, we propose the use of a Convolution Neural Network (CNN) to segment the robot hand from an image in an egocentric view. It is known that CNNs require a huge amount of data to be trained. To overcome the challenge of labeling real-world images, we propose the use of simulated datasets exploiting domain randomization techniques. We fine-tuned the Mask-RCNN network for the specific task of segmenting the hand of the humanoid robot Vizzy. We focus our attention on developing a methodology that requires low amounts of data to achieve reasonable performance while giving detailed insight on how to properly generate variability in the training dataset. Moreover, we analyze the fine-tuning process within the complex model of Mask-RCNN, understanding which weights should be transferred to the new task of segmenting robot hands. Our final model was trained solely on synthetic images and achieves an average IoU of 82% on synthetic validation data and 56.3% on real test data. These results were achieved with only 1000 training images and 3 h of training time using a single GPU.}
}
@article{WANG2022103945,
title = {Visual detection and tracking algorithms for minimally invasive surgical instruments: A comprehensive review of the state-of-the-art},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103945},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103945},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002232},
author = {Yan Wang and Qiyuan Sun and Zhenzhong Liu and Lin Gu},
keywords = {Surgical robots, Machine vision, Detection and tracking of surgical instruments, Deep learning, Feature extraction},
abstract = {Minimally invasive surgical instrument visual detection and tracking is one of the core algorithms of minimally invasive surgical robots. With the development of machine vision and robotics, related technologies such as virtual reality, three-dimensional reconstruction, path planning, and human–machine collaboration can be applied to surgical operations to assist clinicians or use surgical robots to complete clinical operations. The minimally invasive surgical instrument vision detection and tracking algorithm analyzes the image transmitted by the surgical robot endoscope, extracting the position of the surgical instrument tip in the image, so as to provide the surgical navigation. This technology can greatly improve the accuracy and success rate of surgical operations. The purpose of this paper is to further study the visual detection and tracking technology of minimally invasive surgical instruments, summarize the existing research results, and apply it to the surgical robot project. By reading the literature, the author summarized the theoretical basis and related algorithms of this technology in recent years. Finally, the author compares the accuracy, speed and application scenario of each algorithm, and analyzes the advantages and disadvantages of each algorithm. The papers included in the review were selected through Web of Science, Google Scholar, PubMed and CNKI searches using the keywords: “object detection”, “object tracking”, “surgical tool detection”, “surgical tool tracking”, “surgical instrument detection” and “surgical instrument tracking” limiting results to the year range 1985–2021. Our study shows that this technology will have a great development prospect in the aspects of accuracy and real-time improvement in the future.}
}
@article{ZOU2022103943,
title = {Towards robot modularity — A review of international modularity standardization for service robots},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103943},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103943},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002220},
author = {Yibo Zou and Donghan Kim and Philip Norman and Jose Espinosa and Jen-Chieh Wang and Gurvinder S. Virk},
keywords = {Modularity, Service robots, ISO standardization, Use cases},
abstract = {The paper presents ISO standardization work carried out to formulate guidelines for service robot modularity for assisting the development of open plug-n-play modules that can be easily assembled to create application specific robots and robot systems. Although robot modularity has been an active research field for many years, the developments have had little impact on advancing robot markets due to their individualist nature and the results not having sufficiently wide relevance or appeal. The paper initially provides an overview of the new ISO 22166-1 service robot modularity standard and aims to illustrate how to implement it with several use cases. Specific innovations produced in realizing robot modules under the guidance of ISO are introduced and two simple approaches based on block diagram approaches (the line and circle diagrams) are proposed for implementing and designing modular robots. Finally, the paper presents several use cases as examples where the new ISO robot modular approach can be used to good effect.}
}
@article{ELZAATARI2021103864,
title = {Ring Gaussian Mixture Modelling and Regression for collaborative robots},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103864},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103864},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001494},
author = {Shirine {El Zaatari} and Weidong Li and Zahid Usman},
keywords = {Learning from demonstration, Gaussian Mixture Model, Gaussian Mixture Regression, Collaborative robots (cobots)},
abstract = {Task Parametrised Gaussian Mixture Modelling and Regression (TP-GMM/R) is an eminent algorithm to enable collaborative robots (cobots) to adapt to new environments intuitively by learning robotic paths demonstrated by humans. Task parameters in the TP-GMM/R algorithm, i.e., frames associated with demonstration paths, are considered to have orientations by default. This requirement, however, limits the range of applications that TP-GMM/R can support. To address the issue, in this paper, a novel ring Gaussian (rGaussian) is defined to cater for orientation-less frames, and an improved TP-GMM/R algorithm based on rGaussians is developed to improve the adaptability and robustness of the algorithm. In the improved algorithm, firstly, kernels are incorporated to enable Gaussians encoding points from all demonstrations, and criteria are devised to judge a frame to be oriented or orientation-less. Then, improved Gaussian mixture regression that caters for rGaussians and orientation-less frames is developed to generate regression paths adaptable to complex environments. Finally, a series of case studies are used to benchmark the improved TP-GMM/R algorithm with the conventional TP-GMM/R algorithm under different conditions. Quantitative analyses are conducted in terms of smoothness, efficiency and reachability. Results show that the improved algorithm outperformed the conventional algorithm on all the cases.}
}
@article{LOPES2021103840,
title = {Evolutionary Tabu Inverted Ant Cellular Automata with Elitist Inertia for swarm robotics as surrogate method in surveillance task using e-Puck architecture},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103840},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103840},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001251},
author = {Hamilton J.M. Lopes and Danielli A. Lima},
keywords = {Cellular automata, Swarm robotics, Bio-inspired controller, Ant colony optimization, Genetic algorithms, Surveillance task, Tabu search},
abstract = {The area of swarm robotics has grown widely in recent years, precisely because its formulation is based on the use of various techniques, ranging from computer networks to controllers. We can employ different types of techniques to carry out the control of a robots team. In this work we will focus on creating techniques based on bio-inspired computing. Within this theme, we will be focused on using cellular automata with synchronous and asynchronous rules and ant colonies optimization. Additionally, we will consider greedy approaches to select the next robot’s state cell and a local Tabu search with a queue of robot movement restrictions. Thus, we have a surrogate model capable of providing the team robot navigation in the surveillance task. We developed two different controllers, a simpler first, based on a precursor model and a second optimized model, based on the previous controller refinement. At the end, we used a genetic algorithm, which received the surrogate model as input for the improvement of our proposed models parameters. In addition, a survey with the evolution of surveillance models using cellular automata in a systematic review of literature will be shown. Experiments were performed to demonstrate the degree of robot team coverage by different environments. We accomplished statistical analysis with the intention of presenting different sizes of robot teams and amounts of pheromone deposited into the environment. In the end, we fulfilled experiments using the empirical simulation methodology of a robots team using the Webots simulator with e-Puck architecture. The results were promising, the robot team performed this task efficiently and the system is highly scalable.}
}
@article{GONZALEZSIERRA2022103921,
title = {Formation control of distance and orientation based-model of an omnidirectional robot and a quadrotor UAV},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103921},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103921},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002062},
author = {Jaime González-Sierra and Alejandro Dzul and Edgar Martínez},
keywords = {Backstepping, Omnidirectional robot, Quadrotor UAV, Sliding-mode control},
abstract = {This article proposes a dynamic model based on distance and orientation between an omnidirectional mobile robot and a quadrotor Unmanned Aerial Vehicle (UAV), both under the leader–follower scheme. It is assumed that the omnidirectional robot is already controlled in order to follow a desired trajectory. On the other hand, a backstepping with a Continuous Sliding-Mode Control (C-SMC) are designed for the quadrotor with the objective of keeping a distance and formation angle with respect to the omnidirectional robot. Numerical simulations and real-time experiments show the performance of the proposed control strategy.}
}
@article{LIU2021103868,
title = {Precise hand–eye calibration method based on spatial distance and epipolar constraints},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103868},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103868},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001536},
author = {Zhenyu Liu and Xia Liu and Guifang Duan and Jianrong Tan},
keywords = {Hand-eye calibration, Kronecker product, Nonlinear optimization, 3D constraints},
abstract = {In this paper, a new hand–eye calibration method based on spatial distance and epipolar constraints is proposed to obtain the transformation X between the end effector (hand) of the robotic arm and the camera (eye) fixed on the end effector. Most of the current effective hand–eye calibration methods utilize the classical identity, AX=XB, to obtain the analytical solution of X, and then apply various constraints to iteratively optimize the initial X, but these constraints are often at the 2D level. However, the result of hand–eye​ calibration needs to ensure the accuracy of the vision-guided robot arm system operating in 3D space, which leads to inconsistency between optimization goals and the actual requirements. Therefore, the proposed method introduces 3D constraints into the iterative optimization of X and takes 3D error as an evaluation indicator of the calibration quality. There are two main steps in the proposed method. Firstly, the initial value of hand–eye transformation matrix is calculated by utilizing Kronecker product, which avoids the error propagation from rotation parameters to translation parameters. Then, the inherent epipolar constraints and the spatial distance constraints between feature points are combined to optimize hand–eye calibration parameters iteratively. To evaluate the precision and robustness of the proposed method, both simulation experiment and real experiment are carried out. The experimental results show that compared with conventional methods, the proposed method has higher accuracy and stronger robustness.}
}
@article{DOSREIS2021103839,
title = {An arrovian analysis on the multi-robot task allocation problem: Analyzing a behavior-based architecture},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103839},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103839},
url = {https://www.sciencedirect.com/science/article/pii/S092188902100124X},
author = {Wallace Pereira Neves {dos Reis} and Gustavo Leite Lopes and Guilherme Sousa Bastos},
keywords = {Multi-robot system, Task allocation, Social choice, Arrow’s theorem, Preference aggregation},
abstract = {Research in multi-robot systems is a rich field that has attracted much attention in recent decades. However, robot coordination and task allocation to a correct mission accomplishment are still challenging even with technological advances. Despite many proposals presented in the literature, the applications and theories about the task allocation problem are not yet exhausted. Thus, this work proposes an axiomatic framework based on Social Choice Theory to analyze the task allocation problem in intentional cooperation multi-robot systems. It uses Kenneth J. Arrow’s framework of his famous Impossibility Theorem. The conditions imposed by Arrow aim to create an ideal for preference aggregation mechanisms through axiomatic analysis. This paper aims to transport this analysis to the multi-robot domain. A behavior-based Multi-robot Task Allocation architecture is used to present simulation results and discuss two cases in the ordinal preference domain. The analysis results show that using the proposed framework to analyze, under the Arrovian perspective, implemented MRTA architectures is feasible.}
}
@article{NAAB2022103904,
title = {Application of the unscented Kalman filter in position estimation a case study on a robot for precise positioning},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103904},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103904},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001895},
author = {Christoph Naab and Zhuoxun Zheng},
keywords = {Kalman filter, Sensor fusion, Tracking},
abstract = {High-precision measurement is a common task in many engineering applications. In these cases, sensor fusion algorithms represented by Kalman filter and its variants are effective and practical. It is introduced in the article, how to use this sensor fusion algorithm in a high-precision tracking task, where only one sensor (tacheometer) is used in the project. It is also discussed in the article how to build estimation models, including measurement model and motion model, for specific robot positioning problems. A variety of related models are compared in this article. The best model that utilize the prior knowledge of robot motion is proposed, which can not only meet the high precision requirements, but also have robustness to the robot operating environment.}
}
@article{MORENOSANJUAN2021103828,
title = {Design and characterization of a lightweight underactuated RACA hand exoskeleton for neurorehabilitation},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103828},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103828},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001135},
author = {Victor Moreno-SanJuan and Ana Cisnal and Juan-Carlos Fraile and Javier Pérez-Turiel and Eusebio de-la-Fuente},
keywords = {RACA robots, Hand exoskeleton, Stroke rehabilitation, Underactuated mechanisms, Mechanical design, Kinematic model},
abstract = {The spread of the use of robotic devices in neuro-rehabilitation therapies requires the availability of lightweight, easy-to-use, cost-effective and versatile systems. RobHand has been designed with these goals in mind. It is a hand exoskeleton especially suitable for patients suffering from spasticity in the fingers since it is easy to place in the hand and, from an underactuated design, allows both flexion and extension of the fingers. In this work, the structural characteristics, the mechanical design and the development and validation of the kinematic model of the device are presented, all of which has been carried out taking into account the recommendations of the new IEC 80601-2-78 standard, which formalizes the concept of RACA (Rehabilitation, Assessment, Compensation, Alleviation) robot and addresses aspects of efficiency and safety, essential in this type of equipment.}
}
@article{WU2022103935,
title = {An adaptive learning and control framework based on dynamic movement primitives with application to human–robot handovers},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103935},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103935},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002189},
author = {Min Wu and Bertram Taetz and Yanhao He and Gabriele Bleser and Steven Liu},
keywords = {Dynamic movement primitives, Human–robot handovers, Adaptive control, Interaction model},
abstract = {Object handover is a fundamental skill needed in many human–robot collaboration tasks ranging from industrial manipulation to daily service. It remains challenging for robots to perform a handover as flexibly and fluently as a human. This article proposes a framework based on Dynamic Movement Primitives (DMP) that enables robot to learn from human demonstrations and transfer the skill into human–robot handovers. In particular, we focus on the problem of dealing with time varying handover locations. Compared to the conventional DMP formalism, the proposed method contains the following extensions: (1) uncertainty-aware learning with Gaussian Process, (2) a weighting function to control the transition of the shape and goal attraction terms, (3) an orientation-based spatial scaling, (4) online parameter adaption with human feedback. Moreover, inspired by the principle of cooperative DMPs, we present an equivalent model to study the interactive dynamics in human–robot handovers. The proposed framework has been validated in experiments and evaluated by both subjective and objective metrics. Results show an enhancement of success rate, fluency and human comfort.}
}
@article{LI2022103983,
title = {Bio-inspired origamic pouch motors with a high contraction ratio and enhanced force output},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103983},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103983},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002463},
author = {Shanjun Li and Jiahao Lin and Hanwen Kang and Yunjiang Cheng and Yaohui Chen},
keywords = {Soft actuators, Hydraulic/pneumatic actuators, Soft robotics, Large motion range},
abstract = {The range of motion and force output of soft actuators are important characteristics that determine the capacities of soft robots. Pouch motors are a family of soft fluidic actuators featuring a simple mechanical structure and easy fabrication process, but their relatively small contraction ratio constrains their potential applications. Inspired by the origami membrane in the lobster leg joint, we propose two types of origamic pouch motors in which origami structures are integrated into the longitudinal edges of traditional pouches. As a uniform and large degree of transverse expansion can be facilitated by unfolding the origami structures, a significantly larger contraction ratio and enhanced force output can be achieved. The complete workflow of origamic pouch motors is presented including the design principles, fabrication process, theoretical modeling, and experimental characterization, and multiple pouches can be conveniently assembled to realize different motion profiles with a larger range of motion as well. For application demonstrations, we develop different grippers based on origamic pouch motors for safe and forceful grasping. The results of this study can provide guidance for the development of robotic systems featuring easy fabrication, safe actuation, lightweight, a large motion range, and high force output.}
}
@article{MELLO2022103981,
title = {The PoundCloud framework for ROS-based cloud robotics: Case studies on autonomous navigation and human–robot interaction},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103981},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103981},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002451},
author = {Ricardo C. Mello and Sergio D. {Sierra M.} and Wandercleyson M. Scheidegger and Marcela C. Múnera and Carlos A. Cifuentes and Moises R.N. Ribeiro and Anselmo Frizera-Neto},
keywords = {Cloud robotics, ROS, Human–robot interaction, Navigation, Mobile robots},
abstract = {Despite the increasing popularity of the cloud robotics paradigm, the literature on the field still lacks comprehensive analysis on several aspects of the technology. Therefore, the adoption of common standards and frameworks is fundamental for developing the field and allowing practical works to be reproduced and compared. This work presents a ROS-based open framework for robot-cloud communication, easing the integration of robotics and remote cloud platforms, and discusses the implementation of the overall cloud robotics stack over open source software and commercial off-the-shelf devices. Additionally, we present two practical implementations in which most of the computation is carried out remotely and perform a series of experiments to demonstrate our technique. Our results indicate that task times can be reduced up to 15% when using remote cloud platforms even under 150 ms average communication latency over the public Internet while observing figures as low as 2% on throughput loss in sensor data transmission. In general, such results point to the feasibility of the presented approach in different classes of applications, even under non-ideal network and cloud settings.}
}
@article{CASTAMAN2021103863,
title = {Receding Horizon Task and Motion Planning in Changing Environments},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103863},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103863},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001482},
author = {Nicola Castaman and Enrico Pagello and Emanuele Menegatti and Alberto Pretto},
keywords = {Task and Motion Planning, Robot manipulation, Non-static Environments},
abstract = {Complex manipulation tasks require careful integration of symbolic reasoning and motion planning. This problem, commonly referred to as Task and Motion Planning (TAMP), is even more challenging if the workspace is non-static, e.g. due to human interventions and perceived with noisy non-ideal sensors. This work proposes an online approximated TAMP method that combines a geometric reasoning module and a motion planner with a standard task planner in a receding horizon fashion. Our approach iteratively solves a reduced planning problem over a receding window of a limited number of future actions during the implementation of the actions. Thus, only the first action of the horizon is actually scheduled at each iteration, then the window is moved forward, and the problem is solved again. This procedure allows to naturally take into account potential changes in the scene while ensuring good runtime performance. We validate our approach within extensive experiments in a simulated environment. We showed that our approach is able to deal with unexpected changes in the environment while ensuring comparable performance with respect to other recent TAMP approaches in solving traditional static benchmarks. We release with this paper the open-source implementation of our method.}
}
@article{THAKAR2022103920,
title = {Area-Coverage Planning for Spray-based Surface Disinfection with a Mobile Manipulator},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103920},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103920},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002050},
author = {Shantanu Thakar and Rishi K. Malhan and Prahar M. Bhatt and Satyandra K. Gupta},
abstract = {The use of robots has significantly increased to fight highly contagious diseases like SARS-COV-2, Ebola, MERS, and others. One of the important applications of robots to fight such infectious diseases is disinfection. Manual disinfection can be a time-consuming, risky, labor-intensive, and mundane, and humans may fail to disinfect critical areas due to the resulting fatigue. Autonomous or semi-autonomous mobile manipulators mounted with a spray nozzle at the end-effector can be very effective in spraying disinfectant liquid for deep disinfection of objects and surfaces. In this paper, we present an area-coverage planning algorithm to compute a path that the nozzle follows to disinfect surfaces represented by their point clouds. We project the point cloud on a plane and produce a polygon on which we generate multiple spray paths using our branch and bound-based tree search area-coverage algorithm such that the spray paths cover the entire area of the polygon. An appropriate spray path is chosen using a robot capability map-based selection criterion. We generate mobile manipulator trajectories using successive refinement-based parametric optimization so that the paths for the nozzle are followed accurately. Thereafter, we need to make sure that the joint velocities of the mobile manipulator are regulated appropriately such that each point on the surface receives enough disinfectant spray. To this end, we compute the time intervals between the robot path waypoints such that enough disinfectant liquid is sprayed on all points of the point cloud that results in thorough disinfection of the surface, and the particular robot path is executed in the minimum possible time. We have implemented the area-coverage planning and mobile manipulator motion planning on five test scenarios in simulation using our ADAMMS-SD (Agile Dexterous Autonomous Mobile Manipulation System for Surface Disinfection) robot. We benchmark our spray path generation algorithm with three competing methods by showing that the generated paths are significantly more efficient in terms of area coverage and reducing disinfectant wastage. We also show the time interval computation between successive waypoints results in thorough disinfection of surfaces.}
}
@article{MA2021103823,
title = {Temporal sampling annealing schemes for receding horizon multi-agent planning},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103823},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103823},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001081},
author = {Aaron Ma and Mike Ouimet and Jorge Cortés},
keywords = {Multi-agent planning, Potential games, Reinforcement learning, Simulated annealing},
abstract = {This paper deals with multi-agent scenarios where individual agents must coordinate their plans in order to efficiently complete a set of tasks. Our strategy formulates the task planning problem as a potential game and uses decentralized stochastic sampling policies to reach a consensus on which sequences of actions agents should take. We execute this over a receding finite time horizon and take special care to discourage agents from breaking promises in the near future, which may cause other agents to unsuccessfully attempt a joint action. At the same time, we allow agents to change plans in the distant future, as this gives time for other agents to adapt their plans, allowing the team to escape locally optimal solutions. To do this we introduce two sampling schemes for new actions: a geometric-based scheme, where the probability of sampling a new action increases geometrically in time, and an inference-based sampling scheme, where a convolutional neural network provides recommendations for joint actions. We test the proposed schemes in a cooperative orienteering environment to illustrate their performance and validate the intuition behind their design.}
}
@article{HU2022103907,
title = {A magnetic crawler wall-climbing robot with capacity of high payload on the convex surface},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103907},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103907},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001925},
author = {Junyu Hu and Xu Han and Yourui Tao and Shizhe Feng},
keywords = {Wall-climbing robot, Magnetic crawler, High payload, Curved surface adaptivity},
abstract = {There are two challenges for wall-climbing robots in the maintenance and inspection of large vertical ferromagnetic structures: the requirement of high load capacity and the curved appearance of the wall. An improved magnetic crawler wall-climbing robot is presented in this paper. Without increasing the adhesion force, a load dispersion mechanism (LDM) is proposed to enhance the payload capacity of the crawler wall-climbing robot, through making full use of the magnetic adhesion force for resisting the overturning moment. Based on the passive independent suspension, a flexible connection scheme of the robot skeleton is proposed, that renders the wall-climbing robot move on the convex surface. Experiment results show that the magnetic crawler wall-climbing robot can move on the cylindrical wall whose curvature radius is 3000 mm. In motion, the robot can carry 75 kg payload. In the static state, the robot can afford 150 kg payload.}
}
@article{AGARWAL2022103941,
title = {A feedback-based manoeuvre planner for nonprehensile magnetic micromanipulation of large microscopic biological objects},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103941},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103941},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002219},
author = {Dharmveer Agarwal and Ajay D. Thakur and Atul Thakur},
keywords = {Nonprehensile manipulation, Micromanipulation, Magnetic manipulation, Feedback planner, Path planner, Cell manipulation},
abstract = {This paper reports a feedback-based manoeuvre planning approach for automated nonprehensile selective micromanipulation of large, microscopic biological objects (∼100μm). We employ ferromagnetic micro-particles as microrobots actuated via a global magnetic field produced by electromagnetic coils placed in quadrupole configuration. The microrobot motion is programmed to push the target object to the goal location. We employ a three-step approach comprising: (a) generate a collision-free optimal path between the initial and the commanded goal location, (b) generate a manoeuvre planning algorithm that invokes one of the three motion manoeuvres, namely, ‘approach’, ‘push’, and ‘align’ depending upon the instantaneous locations of the microrobot, target object, and the desired waypoint, and (c) deploy a simple proportional controller that determines the currents required in the electromagnetic coils that can produce a suitable magnetic field for executing the manoeuvre invoked by the manoeuvre planner. This paper reports a number of validation experiments conducted on both zebrafish, i.e., Danio rerio embryos and silica beads as target objects. We envisage that the developed inexpensive approach can be useful in robotic manipulation of biological objects with sizes in hundreds of microns including large biological cells, polyploid giant cancer cells (PGCC), multicellular spheroids, Dictyostelium slug, human oocytes, and autophagy candidates. We also believe that functionalizing the microrobots with living cells or suitable chemicals will make it possible to perform on-chip biological experiments in future.}
}
@article{KOUPPAS2021103891,
title = {Hybrid autonomous controller for bipedal robot balance with deep reinforcement learning and pattern generators},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103891},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103891},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001767},
author = {Christos Kouppas and Mohamad Saada and Qinggang Meng and Mark King and Dennis Majoe},
keywords = {Bipedal robot, Pattern generator, Reinforcement learning, Hybrid controller},
abstract = {Recovering after an abrupt push is essential for bipedal robots in real-world applications within environments where humans must collaborate closely with robots. There are several balancing algorithms for bipedal robots in the literature, however most of them either rely on hard coding or power-hungry algorithms. We propose a hybrid autonomous controller that hierarchically combines two separate, efficient systems, to address this problem. The lower-level system is a reliable, high-speed, full state controller that was hardcoded on a microcontroller to be power efficient. The higher-level system is a low-speed reinforcement learning controller implemented on a low-power onboard computer. While one controller offers speed, the other provides trainability and adaptability. An efficient control is then formed without sacrificing adaptability to new dynamic environments. Additionally, as the higher-level system is trained via deep reinforcement learning, the robot could learn after deployment, which is ideal for real-world applications. The system’s performance is validated with a real robot recovering after a random push in less than 5 s, with minimal steps from its initial positions. The training was conducted using simulated data.}
}
@article{BOLDRER2022103979,
title = {Multi-agent navigation in human-shared environments: A safe and socially-aware approach},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103979},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103979},
url = {https://www.sciencedirect.com/science/article/pii/S092188902100244X},
author = {Manuel Boldrer and Alessandro Antonucci and Paolo Bevilacqua and Luigi Palopoli and Daniele Fontanelli},
keywords = {Multi-robot navigation, Socially-aware navigation, Distributed systems},
abstract = {The paper addresses the problem of multi-robot navigation in human shared spaces. We propose a hierarchical framework that combines global path planning, local path planning and reactive strategies, ensuring a safe and socially-aware navigation. We show through several tests and extensive experiments with a real robotic implementation that our combination of solutions delivers excellent results in terms of robustness and performance even in challenging natural scenarios.}
}
@article{VANDERHAEGEN2021103867,
title = {Heuristic-based method for conflict discovery of shared control between humans and autonomous systems - A driving automation case study},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103867},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103867},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001524},
author = {Frédéric Vanderhaegen},
keywords = {Shared control, Level of autonomy, Conflicting decision, Autonomous system, Car driving, Heuristics},
abstract = {The paper proposes a heuristic-based prospective method to discover possible conflicts of shared control between humans and autonomous systems. This method adapts the triplet Competence-Availability-Possibility-to-act (CAP) that represents the autonomy characteristics of decision-makers such as humans or autonomous systems. The CAP-based autonomy is decomposed into several scenarios of shared control in a workspace or between workspaces. Conflicting decisions between humans and autonomous systems are conflicts of autonomy relating to competence, availability, or possibility to act and are determined by applying heuristics adapted from deductive, inductive, abductive, and counterfactual reasoning principles. This heuristic-based method comprises four main steps: verification of shared control, identification of discovery parameters, discovery of possible conflicting decisions, and validation of these conflicts. It was applied to a driving automation case study involving two autonomous systems: Lane Keeping Assist (LKA) and Automated Cruise Control (ACC). The conflicts of autonomy identified determine possible confusions between the reasoning of a driver and that of an autonomous system, sometimes resulting in dangerous situations. These were validated and analyzed in two ways by drivers with at least two years of driving experience: during an investigation to obtain qualitative feedback from 43 drivers and during a tutorial on human reliability assessment involving 17 people. The results demonstrate the advantage of the heuristic-based method to detect possible conflicting decisions or sources of conflicts between humans and machines. The approach proposed will consequently be of assistance in the design of shared control processes between humans and autonomous systems through the implementation of technical learning or pedagogical abilities, the improvement of alarm systems to control human attention or avoid confusion between the intentions of humans and machines, or the development of training programs or driving lessons to increase user awareness of such conflicts.}
}
@article{MOHSENI2021103815,
title = {Adaptation in a variable parallel elastic actuator for rotary mechanisms towards energy efficiency},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103815},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103815},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001007},
author = {Omid Mohseni and Majid Abedinzadeh Shahri and Ayoob Davoodi and Majid Nili Ahmadabadi},
keywords = {Compliant actuation, Variable elastic actuator, Adaptation, Energy efficiency, Legged locomotion},
abstract = {This paper is concerned with the presentation of a parallel compliance adaptation method for systems equipped with rotary motion mechanisms towards obtaining energy efficiency in cyclic tasks over a reasonable range of task frequency variations. In this work, we first introduce a variable parallel elastic actuator (VPEA) design for implementation on uni-directional joints that can respond in line with the torque requirements caused by frequency variations in rotary mechanisms. Then, in the next step, we propose two design approaches namely “general method” and “frequency-based method” for the VPEA along with the stiffness adjustment approaches both in offline and online manners. The optimality and convergence of the adaptation method for the proposed rotary VPEA are also analytically proved in general to be globally exponentially stable in the sense of Lyapunov. Finally, to demonstrate the applicability and efficiency of our VPEA, we deployed it in a robotic leg model as the case study. The simulation results demonstrate the stability and convergence of our adaptation rule and highlight the performance of the proposed VPEA in increasing energy efficiency over a wide range of task frequency variations.}
}
@article{KHAN2022103903,
title = {Design and experimental validation of a robust model predictive control for the optimal trajectory tracking of a small-scale autonomous bulldozer},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103903},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103903},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001883},
author = {Subhan Khan and Jose Guivant and Xuesong Li},
keywords = {Small-scale autonomous bulldozer, Optimal control, Model predictive control, Trajectory tracking, Unmanned ground vehicle},
abstract = {Trajectory tracking of an unmanned ground vehicle (UGV) is essential due to its extensive construction, agriculture, and military applications. In this paper, we propose an efficient, robust model predictive control (RMPC) for the trajectory tracking of a small-scale autonomous bulldozer in the presence of perturbations by unknown but bounded disturbances. The proposed RMPC is designed by considering a linearised tracking error-based model combined with a feed-forward and optimal control action to achieve the proposed trajectory. The presence of a corrective feedback controller as a time-varying finite-time linear quadratic regulator (LQR) suppresses the uncertainties acting on the real system by regulating around the nominal system. Pose estimation, required for control feedback, is based on sensor data fusion performed by an extended Kalman filter (EKF) map-based localiser, which processes inertial measurement unit (IMU) and light detection and ranging (LiDAR) measurements. Experiments are performed using a real robot (Husky A200) to validate the proposed control scheme’s performance. The experimental results show that the proposed controller can safely track target trajectories with low processing time, small tracking errors, and smooth control actions. Finally, the proposed control scheme is compared with related techniques and outperforms them in tracking accuracy.}
}
@article{YERLIKAYA2021103827,
title = {End control damping algorithm for a stabilized gun turret system for the satisfaction of the collision avoidance requirement},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103827},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103827},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001123},
author = {Ümit Yerlikaya and R. Tuna Balkan},
keywords = {Collision avoidance, End control damping algorithm, Path planning, Stabilized gun turrets, Autonomous turrets, C-space},
abstract = {This paper presents a collision avoidance algorithm for stabilized gun turrets and its real-time implementation. With the help of new collision avoidance algorithm, all types of turrets can be driven more efficiently and safely according to the specified speed, acceleration and jerk limits. Even in situations such as avoiding obstacles, deceleration/acceleration, if the user issues new commands which does not cause a collision, the algorithm starts to apply the new commands providing flexibility to the user. Since all possible worst scenarios are examined one by one, it is guaranteed that the algorithm provides collision free motion in both simulations and real-time tests. A configuration space where worst scenarios can occur is created for the performance measurement of the algorithm, and the same space is used in all tests. By giving different speed commands in the specified configuration space, the performance of the algorithm at different speeds is observed on the stabilized gun turret. For the measurement of the performance under the noisy speed commands, a custom noisy speed command of about 1000 s is created and both simulation and real-time tests are performed. As a result of these tests, it is shown that there is no collision. Finally, by adding cascade position control loop, the departure from the starting point to the desired target point is achieved without any collision. The most important feature that distinguishes this algorithm from others is both speed and position can be controlled and during transition phase, the target point can be changed instantly. In addition, no target position is required for the system to move collision-free, only axis speed commands are sufficient. Since the algorithm does not intervene in the speed and torque loops in contrast to potential field-based methods, it can be added to ready-to-use systems by manipulating only the speed references.}
}
@article{GANDOLLA2021103822,
title = {An assistive upper-limb exoskeleton controlled by multi-modal interfaces for severely impaired patients: development and experimental assessment},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103822},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103822},
url = {https://www.sciencedirect.com/science/article/pii/S092188902100107X},
author = {Marta Gandolla and Stefano Dalla Gasperina and Valeria Longatelli and Alessandro Manti and Lorenzo Aquilante and Maria Grazia D’Angelo and Emilia Biffi and Eleonora Diella and Franco Molteni and Mauro Rossini and Margit Gföhler and Markus Puchinger and Marco Bocciolone and Francesco Braghin and Alessandra Pedrocchi},
keywords = {Exoskeleton, Assistive devices, Robotics, Biomechatronics, Multi-modal interfaces, Joystick, Upper limbs, Muscular dystrophy, Neuromuscular disease},
abstract = {Active exoskeletons can help adults with muscular dystrophy regain independence and self-esteem, which have been limited due to their severe and progressive muscular weakness. A four degrees-of-freedom fully actuated upper limb exoskeleton, equipped with a spring-based anti-gravity system, has been designed, prototyped, and tested on end-users. While wearing the exoskeleton, the user directly controls the system by actively driving the end-effector position (i.e., the hand) using a joystick or vocal control. The exoskeleton’s kinematic model has been determined so that, given a desired user’s position in the task-space, a differential inverse kinematics algorithm computes the desired joint-space motion trajectories. The dynamic model was investigated in the vertical plane, demonstrating that gravity torques were considerably higher than velocity-induced and inertia torques, which have been therefore neglected. A pilot study on 14 Muscular Dystrophy patients was conducted. Outcome measures included: (i) externally-assessed functional benefit evaluated through the Performance of Upper Limbs module, (ii) self-perceived functional benefit assessed through the ABILHAND questionnaire, and (iii) usability of the system assessed through the System Usability Scale. All participants strongly increased their range of motion, and they were able to perform activities that were not possible without the exoskeleton, such as feeding. The externally-assessed and self-perceived functional improvements were statistically improved when wearing the exoskeleton (PUL p-value=0.001, ABILHAND p-value=0.005). System usability was evaluated to be excellent. Patients’ feedbacks were encouraging and outlined future development steps.}
}
@article{DUBOIS2022103933,
title = {Sharing visual-inertial data for collaborative decentralized simultaneous localization and mapping},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103933},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103933},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002177},
author = {Rodolphe Dubois and Alexandre Eudes and Vincent Frémont},
keywords = {Robotics, Visual-inertial collaborative SLAM},
abstract = {Building on the maturity of single-robot SLAM algorithms, collaborative SLAM has brought significant gains in terms of efficiency and robustness, but has also raised new challenges to cope with like informational, network and resource constraints. Several multi-robot frameworks have been coined for visual SLAM, ranging from highly-integrated and fully-centralized architectures to fully distributed and decentralized methods. However, many proposed architectures compromise the autonomy of the robots in fusing the data processed by the other agents to enhance their own estimation accuracy. In this paper, we propose three methods to share visual-inertial information, based on rigid, condensed and pruned visual-inertial packets. We also propose a common collaborative SLAM architecture to organize the computation, exchange and integration of such packets. We evaluated those methods on the EuRoC (Burri et al. 2016) dataset and on our custom dataset AirMuseum (Dubois et al. 2020). Experiments showed that the proposed methods allow the agents to build, exchange and integrate consistent visual-inertial packets, and improve their trajectory estimation accuracy up to several centimeters.}
}
@article{YANG2022103931,
title = {PTPGC: Pedestrian trajectory prediction by graph attention network with ConvLSTM},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103931},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103931},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002165},
author = {Juan Yang and Xu Sun and Rong Gui Wang and Li Xia Xue},
keywords = {Trajectory prediction, Graph attention, ConvLSTM, Multimodal},
abstract = {With the rapid development of intelligent systems, such as self-driving vehicles, service robots and surveillance systems, pedestrian trajectory prediction has become a very challenging problem. How to perceive, understand and predict the motion patterns of pedestrians in a highly crowded and chaotic environment in order to prevent future collisions becomes a top priority. The motion of pedestrians is not only affected by their own factors, but also by surrounding neighbors. To solve the above problems, we propose a model named PTPGC based on graph attention and convolutional long short-term memory (ConvLSTM) network to predict multiple reasonable pedestrian trajectories. Firstly, the pedestrians are represented in a dynamic graph by setting a Euclidean distance threshold. Then, a graph attention network is used to learn the spatial interaction relationship of all pedestrians in each time step, and a temporal convolutional network (TCN) is used to encode the pedestrians’ own factors. Finally, we use the ConvLSTM to iteratively predict the multiple reasonable and feasible future trajectories of pedestrians. Experiments show that our model has a higher prediction accuracy on two public pedestrian data sets (ETH and UCY) compared with the existing baselines for pedestrian trajectory prediction, and the generated trajectories are more in line with social rationality and physical constraints.}
}
@article{ROJASQUINTERO2021103834,
title = {A literature review of sensor heads for humanoid robots},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103834},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103834},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001196},
author = {J.A. Rojas-Quintero and M.C. Rodríguez-Liñán},
keywords = {Humanoid robot heads, Human–robot interaction, Review, Control of robotic systems, Active vision},
abstract = {We conducted a literature review on sensor heads for humanoid robots. A strong case is made on topics involved in human–robot interaction. Having found that vision is the most abundant perception system among sensor heads for humanoid robots, we included a review of control techniques for humanoid active vision. We provide historical insight and inform on current robotic head design and applications. Information is chronologically organized whenever possible and exposes trends in control techniques, mechanical design, periodical advances and overall philosophy. We found that there are two main types of humanoid robot heads which we propose to classify as either non-expressive face robot heads or expressive face robot heads. We expose their respective characteristics and provide some ideas on design and vision control considerations for humanoid robot heads involved in human–robot interactions.}
}
@article{TERRERAN2021103862,
title = {Light deep learning models enriched with Entangled features for RGB-D semantic segmentation},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103862},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103862},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001470},
author = {Matteo Terreran and Stefano Ghidoni},
keywords = {Semantic segmentation, Scene understanding, Deep learning},
abstract = {Semantic segmentation is a crucial task in emerging robotic applications like autonomous driving and social robotics. State-of-the-art methods in this field rely on deep learning, with several works in the literature following the trend of using larger networks to achieve higher performance. However, this leads to greater model complexity and higher computational costs, which make it difficult to integrate such models on mobile robots. In this work we investigate how it is possible to obtain lighter performing deep models introducing additional data at a very low computational cost, instead of increasing the network complexity. We consider the features used in the 3D Entangled Forests algorithm, proposing different strategies to integrate such additional information into different deep networks. The new features allow to obtain lighter and performing segmentation models, either by shrinking the network size or improving existing networks proposed for real-time segmentation. Such result represents an interesting alternative in mobile robotics application, where computational power and energy are limited.}
}
@article{LIU2021103878,
title = {A multi-finger robot system for adaptive landing gear and aerial manipulation},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103878},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103878},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001639},
author = {Jian Liu and Dan Zhang and Chenwei Wu and Hongyan Tang and Chunxu Tian},
keywords = {Multi-finger robot system, Bioinspired design, Rotary-wing UAV, Adaptive landing},
abstract = {In this study, a bioinspired multi-finger robot system (MFRS) is designed based on the characteristics of eagle claws. The MFRS is attached to a rotary-wing unmanned aerial vehicle (RUAV), which can be enabled to land on uneven terrain. In addition, the robot can also grab target objects or perch on a cylinder. The finger of the robot can simultaneously rotate three revolute joints only relying on one motor, to achieve an action similar to the grip of the eagle claw. The hardware structure and control system architecture of the MFRS are established. Based on depth vision, an adaptive landing algorithm that can achieve real-time optimal landing point selection is proposed. The outdoor experiments show that the robot can effectively land the RUAV on the slopes, steps, and unstructured terrains.}
}
@article{WANG2022103906,
title = {Design, development and evaluation of latex harvesting robot based on flexible Toggle},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103906},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103906},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001913},
author = {Song Wang and Hang Zhou and Chunlong Zhang and Luzhen Ge and Wei Li and Ting Yuan and Wenqiang Zhang and Junxiong Zhang},
keywords = {Agricultural robotics, Natural rubber, Spillage-free harvesting, Latex harvesting, Dynamic model},
abstract = {Natural rubber latex is an important energy material. However, the harvest of latex is still manual, and there are few researches on automatic work. This paper proposed a method for robot to harvest from each rubber tree without stopping. The robot toggled the collection cup through the flexible actuator, the cup poured out the latex and rotated to the next collection position. In this way, it not only completed the harvest work, but also prepared for the next collection. Aiming at the problem of latex splashing during rapid toggle, the structural parameters of the collection cup and the flexible actuator were modeled and studied. This method made the rotation speed of the collection cup smoother and avoids splashing. To enable the robot to accurately complete the harvesting work, this paper used two-dimensional Light Detection and Ranging (LiDAR) and ranging sensor to locate the space position of the collection cup. The results show that when the toggle speed is 0.5 m/s and the latex volume is 300 ml, the average shaking height is 3.58 mm. In the field test, the lateral error of positioning is less than 8.86 mm, and the height error is less than 0.72 mm; the average harvest rate is 98.18%. The robot has high efficiency and good stability, and can be applied to the rubber plantation to harvest automatically.}
}
@article{LIU2022103901,
title = {Robotic picking in dense clutter via domain invariant learning from synthetic dense cluttered rendering},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103901},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103901},
url = {https://www.sciencedirect.com/science/article/pii/S092188902100186X},
author = {Wenhai Liu and Weiming Wang and Yang You and Teng Xue and Zhenyu Pan and Jin Qi and Jie Hu},
keywords = {Robotic picking, Sim2real, Dense clutter, Domain invariant, Deep learning},
abstract = {Robotic picking of diverse range of novel objects is a great challenge in dense clutter, in which objects are stacked together tightly. However, collecting large-scale dataset with dense grasp labels is extremely time-consuming, and there is a huge gap between synthetic and real images. In this paper, we explore suction based grasping from synthetic multi object rendering. To avoid tedious human labeling, we present a pipeline to model stacked objects in simulation and generate photorealistic rendering RGB-D images with dense suction point labels. To reduce simulation-to-reality gap from synthetic images to low-quality RGB-D camera, we propose a novel domain-invariant Suction Quality Neural Network (diSQNN) by training on labeled synthetic dataset with unlabeled real dataset. Specifically, diSQNN fuses photorealistic color feature and adversarial depth feature, and uses a domain discriminator on depth extractor to align depth feature distribution from synthetic and real images. We evaluate our proposed method by comparing with other baseline and suction detection method. The results demonstrate the effectiveness of our synthetic dense cluttered rendering. And through feature alignment, our domain invariant learning method can learn grasp related features, while ignoring domain related disturbing features, which maintains a high transfer performance on real RGB-D images. On a physical robot with vacuum-based gripper, the proposed method achieves average picking success rate of 91% and 88% for known objects and novel objects in a tote without using any manual labels.}
}
@article{GRASSI2022103938,
title = {Knowledge triggering, extraction and storage via human–robot verbal interaction},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103938},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103938},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002207},
author = {Lucrezia Grassi and Carmine Tommaso Recchiuto and Antonio Sgorbissa},
keywords = {Social robotics, Human–robot interaction, Knowledge-grounded conversation, Knowledge extraction},
abstract = {This article describes a novel approach to expand in run-time the knowledge base of an Artificial Conversational Agent. A technique for automatic knowledge extraction from the user’s sentence and four methods to insert the new acquired concepts in the knowledge base have been developed and integrated into a system that has already been tested for knowledge-based conversation between a social humanoid robot and residents of care homes. The run-time addition of new knowledge allows overcoming some limitations that affect most robots and chatbots: the incapability of engaging the user for a long time due to the restricted number of conversation topics. The insertion in the knowledge base of new concepts recognized in the user’s sentence is expected to result in a wider range of topics that can be covered during an interaction, making the conversation less repetitive. Two experiments are presented to assess the performance of the knowledge extraction technique, and the efficiency of the developed insertion methods when adding several concepts in the Ontology.}
}
@article{WANG2022103914,
title = {Robotic odor source localization via adaptive bio-inspired navigation using fuzzy inference methods},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103914},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103914},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001998},
author = {Lingxiao Wang and Shuo Pang},
keywords = {Odor source localization, Behavior-based navigation methods, Fuzzy-inference theories},
abstract = {Robotic odor source localization (OSL) has been viewed as a challenging task due to the turbulent nature of airflows and the resulting odor plume characteristics. The key to solving an OSL problem is designing an effective olfactory-based navigation algorithm, which guides a plume-tracing robot to find the odor source via tracing emitted plumes. Inspired by the mate-seeking behaviors of male moths, this article presents a behavior-based navigation algorithm for using on a mobile robot to locate an odor source in an unknown environment. Unlike traditional bio-inspired algorithms, which use fixed parameters to formulate robot search trajectories, we design a fuzzy controller to perceive the environment and adjust trajectory parameters based on the current search situation. Therefore, the robot can automatically adapt the scale of search trajectories to fit environmental changes and balance the exploration and exploitation of the search. Simulation and on-vehicle results show that compared to two classical olfactory-based navigation algorithms, the proposed algorithm is more efficient and outperforms them in terms of the averaged search time and success rate.}
}
@article{DAS2021103890,
title = {Delay compensated state estimation for Telepresence robot navigation},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103890},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103890},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001755},
author = {Barnali Das and Gordon Dobie},
keywords = {State estimation, Delay compensation, Telepresence, Robot navigation, AS-EKF},
abstract = {Telepresence robots empower human operators to navigate remote environments. However, operating and navigating the robot in an unknown environment is challenging due to delay in the communication network (e.g., distance, bandwidth, communication drop-outs etc.), processing delays and slow dynamics of the mobile robots resulting in time-lagged in the system. Also, erroneous sensor data measurement which is important to estimate the robot’s true state (positional information) in the remote environment, often create complications and make it harder for the system to control the robot. In this paper, we propose a new approach for state estimation assuming uncertain delayed sensor measurements of a Telepresence robot during navigation. A new real world experimental model, based on Augmented State Extended Kalman Filter (AS-EKF), is proposed to estimate the true position of the Telepresence robot. The uncertainty of the delayed sensor measurements have been modelled using probabilistic density functions (PDF). The proposed model was successfully verified in our proposed experimental framework which consists of a state-of-the-art differential-drive Telepresence robot and a motion tracking multi-camera system. The results show significant improvements compared to the traditional EKF that does not consider uncertain delays in sensor measurements. The proposed model will be beneficial to build a real time predictive display by reducing the effect of visual delay to navigate the robot under the operator’s control command, without waiting for delayed sensor measurements.}
}
@article{PIPITONE2021103838,
title = {Robot passes the mirror test by inner speech},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103838},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103838},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001238},
author = {Arianna Pipitone and Antonio Chella},
keywords = {Inner speech, Cognitive architecture, Robot mirror test, Conceptual reasoning},
abstract = {The mirror test is a well-known task in Robotics. The existing strategies are based on kinesthetic-visual matching techniques and manipulate perceptual and motion data. The proposed work attempts to demonstrate that it is possible to implement a robust robotic self-recognition method by the inner speech, i.e. the self-dialogue that enables reasoning on symbolic information. The robot self-talks and conceptually reasons on the symbolic forms of signals, and infers if the robot it sees in the mirror is itself or not. The idea is supported by the existing literature in psychology, where the importance of inner speech in self-reflection and self-concept emergence for solving the mirror test was empirically demonstrated.}
}
@article{SCHILLINGER2021103866,
title = {Adaptive heterogeneous multi-robot collaboration from formal task specifications},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103866},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103866},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001512},
author = {Philipp Schillinger and Sergio García and Alexandros Makris and Konstantinos Roditakis and Michalis Logothetis and Konstantinos Alevizos and Wei Ren and Pouria Tajvar and Patrizio Pelliccione and Antonis Argyros and Kostas J. Kyriakopoulos and Dimos V. Dimarogonas},
keywords = {Robotics, Multi-robot, Temporal logic, HRI, Heterogeneous robots, Task decomposition, Task allocation, Abstraction},
abstract = {Efficiently coordinating different types of robots is an important enabler for many commercial and industrial automation tasks. Here, we present a distributed framework that enables a team of heterogeneous robots to dynamically generate actions from a common, user-defined goal specification. In particular, we discuss the integration of various robotic capabilities into a common task allocation and planning formalism, as well as the specification of expressive, temporally-extended goals by non-expert users. Models for task allocation and execution both consider non-deterministic outcomes of actions and thus, are suitable for a wide range of real-world tasks including formally specified reactions to online observations. One main focus of our paper is to evaluate the framework and its integration of software modules through a number of experiments. These experiments comprise industry-inspired scenarios as motivated by future real-world applications. Finally, we discuss the results and learnings for motivating practically relevant, future research questions.}
}
@article{YANG2022103919,
title = {Occupant-centric robotic air filtration and planning for classrooms for Safer school reopening amid respiratory pandemics},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103919},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103919},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002049},
author = {Haoguang Yang and Mythra V. Balakuntala and Jhon J. Quiñones and Upinder Kaur and Abigayle E. Moser and Ali Doosttalab and Antonio Esquivel-Puentes and Tanya Purwar and Luciano Castillo and Xin Ma and Lucy T. Zhang and Richard M. Voyles},
keywords = {Robotic air filtration, Socially-distanced classrooms, Approximation of computational fluid dynamics, Trajectory and speed optimization},
abstract = {Coexisting with the current COVID-19 pandemic is a global reality that comes with unique challenges impacting daily interactions, business, and facility maintenance. A monumental challenge accompanied is continuous and effective disinfection of shared spaces, such as office/school buildings, elevators, classrooms, and cafeterias. Although ultraviolet light and chemical sprays are routines for indoor disinfection, they irritate humans, hence can only be used when the facility is unoccupied. Stationary air filtration systems, while being irritation-free and commonly available, fail to protect all occupants due to limitations in air circulation and diffusion. Hence, we present a novel collaborative robot (cobot) disinfection system equipped with a Bernoulli Air Filtration Module, with a design that minimizes disturbance to the surrounding airflow and maneuverability among occupants for maximum coverage. The influence of robotic air filtration on dosage at neighbors of a coughing source is analyzed with derivations from a Computational Fluid Dynamics (CFD) simulation. Based on the analysis, the novel occupant-centric online rerouting algorithm decides the path of the robot. The rerouting ensures effective air filtration that minimizes the risk of occupants under their detected layout. The proposed system was tested on a 2 × 3 seating grid (empty seats allowed) in a classroom, and the worst-case dosage for all occupants was chosen as the metric. The system reduced the worst-case dosage among all occupants by 26% and 19% compared to a stationary air filtration system with the same flow rate, and a robotic air filtration system that traverses all the seats but without occupant-centric planning of its path, respectively. Hence, we validated the effectiveness of the proposed robotic air filtration system.}
}
@article{FILOTHEOU2022103957,
title = {Correspondenceless scan-to-map-scan matching of homoriented 2D scans for mobile robot localisation},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103957},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103957},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002323},
author = {Alexandros Filotheou},
keywords = {Robot localisation, Scan-to-map-scan matching},
abstract = {The objective of this study is improving the location estimate of a mobile robot capable of motion on a plane and mounted with a conventional 2D LIDAR sensor, given an initial guess for its location on a 2D map of its surroundings. Documented herein is the theoretical reasoning behind solving a matching problem between two homoriented 2D scans, one derived from the robot’s physical sensor and one derived by simulating its operation within the map, in a manner that does not require the establishing of correspondences between their constituting rays. Two results are proved and subsequently shown through experiments. The first is that the true position of the sensor can be recovered with arbitrary precision when the physical sensor reports faultless measurements and there is no discrepancy between the environment the robot operates in and its perception of it by the robot. The second is that when either is affected by disturbance, the location estimate is bound in a neighbourhood of the true location whose radius is proportional to the affecting disturbance.}
}
@article{SHEN2021103874,
title = {Multi-modal feature fusion for better understanding of human personality traits in social human–robot interaction},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103874},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103874},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001597},
author = {Zhihao Shen and Armagan Elibol and Nak Young Chong},
keywords = {Human–robot interaction, Human personality traits, Multi-modal feature fusion, Machine learning},
abstract = {Since the dynamic nature of human–robot interaction becomes increasingly prevalent in our daily life, there is a great demand for enabling the robot to better understand human personality traits and inspiring humans to be more engaged in the interaction with the robot. Therefore, in this work, as we design the paradigm of human–robot interaction as close to the real situation as possible, the following three main problems are addressed: (1) fusion of visual and audio features of human interaction modalities, (2) integration of variable length feature vectors, and (3) compensation of shaky camera motion caused by movements of the robot’s communicative gesture. Specifically, the three most important visual features of humans including head motion, gaze, and body motion were extracted from a camera mounted on the robot performing verbal and body gestures during the interaction. Then, our system was geared to fuse the aforementioned visual features and different types of vocal features, such as voice pitch, voice energy, and Mel-Frequency Cepstral Coefficient, dealing with variable length multiple feature vectors. Lastly, considering unknown patterns and sequential characteristics of human communicative behavior, we proposed a multi-layer Hidden Markov Model that improved the classification accuracy of personality traits and offered notable advantages of fusing the multiple features. The results were thoroughly analyzed and supported by psychological studies. The proposed multi-modal fusion approach is expected to deepen the communicative competence of social robots interacting with humans from different cultures and backgrounds.}
}
@article{SARKER2021103902,
title = {Robotics and artificial intelligence in healthcare during COVID-19 pandemic: A systematic review},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103902},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103902},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001871},
author = {Sujan Sarker and Lafifa Jamal and Syeda Faiza Ahmed and Niloy Irtisam},
keywords = {COVID-19, SARS-coV-2, Robotics, Artificial intelligence, Healthcare, Autonomous system},
abstract = {The outbreak of the COVID-19 pandemic is unarguably the biggest catastrophe of the 21st century, probably the most significant global crisis after the second world war. The rapid spreading capability of the virus has compelled the world population to maintain strict preventive measures. The outrage of the virus has rampaged through the healthcare sector tremendously. This pandemic created a huge demand for necessary healthcare equipment, medicines along with the requirement for advanced robotics and artificial intelligence-based applications. The intelligent robot systems have great potential to render service in diagnosis, risk assessment, monitoring, telehealthcare, disinfection, and several other operations during this pandemic which has helped reduce the workload of the frontline workers remarkably. The long-awaited vaccine discovery of this deadly virus has also been greatly accelerated with AI-empowered tools. In addition to that, many robotics and Robotics Process Automation platforms have substantially facilitated the distribution of the vaccine in many arrangements pertaining to it. These forefront technologies have also aided in giving comfort to the people dealing with less addressed mental health complicacies. This paper investigates the use of robotics and artificial intelligence-based technologies and their applications in healthcare to fight against the COVID-19 pandemic. A systematic search following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) method is conducted to accumulate such literature, and an extensive review on 147 selected records is performed.}
}
@article{PETAVRATZIS2021103826,
title = {A chaotic path planning generator enhanced by a memory technique},
journal = {Robotics and Autonomous Systems},
volume = {143},
pages = {103826},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103826},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001111},
author = {Eleftherios Petavratzis and Lazaros Moysis and Christos Volos and Ioannis Stouboulos and Hector Nistazakis and Kimon Valavanis},
keywords = {Autonomous mobile robot, Path planning, Terrain coverage, Chaos, PRBG, Memory, Optimization},
abstract = {This work considers the problem of chaotic path planning, using an improved memory technique to boost performance. In this application, the dynamics of two simple chaotic maps are first used to generate a pseudo-random bit generator. Using this as a source, a series of navigation commands are generated and used by an autonomous robot to explore an area, while maintaining a random and unpredictable motion. This navigation strategy can bring overall area coverage, but also yields numerous revisits to previous cells. Here, a memory technique is applied to limit the chaotic motion of the robot to adjacent cells with the least number of visits, leading to overall improvement in performance. Numerical simulations are performed to evaluate the path planning strategy. The simulation results showcase a major improvement in coverage performance compared to the memory-free technique and also compared to an inverse pheromone technique previously developed by the authors. Also, the number of multiple visits to previous cells is significantly reduced with the proposed technique.}
}
@article{VRBA2022103970,
title = {Autonomous capture of agile flying objects using UAVs: The MBZIRC 2020 challenge},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103970},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103970},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002396},
author = {Matouš Vrba and Yurii Stasinchuk and Tomáš Báča and Vojtěch Spurný and Matěj Petrlík and Daniel Heřt and David Žaitlík and Martin Saska},
keywords = {Unmanned aerial systems, Machine perception, Mobile robotics, Aerial safety},
abstract = {In this paper, a novel approach for autonomously catching fast flying objects is presented, as inspired by the Mohamed Bin Zayed International Robotics Challenge (MBZIRC) 2020. In this competition, an autonomous Unmanned Aerial Vehicle (UAV) was used to intercept a ball carried by a fast flying drone. The presented solution utilizes a 3D LiDAR sensor for quick and robust target detection. The trajectory of the target is estimated and predicted to select a suitable interception position. The interceptor UAV is navigated into the interception position to safely approach the target. The interception position is frequently being adjusted based on the updated estimation and prediction of the target’s motion to ensure that the ball is caught in the dedicated onboard net. After a successful interception is detected, the UAV lands in a designated landing area. The proposed concept was intensively tested and refined in demanding outdoor conditions with strong winds and varying perception conditions to achieve the robustness required by both the demanding application and the competition. In the MBZIRC 2020 competition, our solution scored second place in Challenge 1 and first place in a combined Grand Challenge. This manuscript will provide a detailed description of the applied methods and an evaluation of our approach with data collected from real-world experiments. In addition, we present achievements of our R&D towards the transition from the MBZIRC competition to an autonomous drone interceptor, which was the main motivation of this challenge.}
}
@article{GERBL2022103930,
title = {Self-reconfiguration of shape-shifting modular robots with triangular structure},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103930},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103930},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002153},
author = {Michael Gerbl and Johannes Gerstmayr},
keywords = {Extended binary trees, Self-reconfiguration, Modular robots, Triangular modules},
abstract = {In this paper, we present a reconfiguration algorithm for shape-shifting modular robots with a triangular structure. The algorithm is derived from a novel description of the configuration space based on extended binary trees. Extended binary trees representing the same configuration are grouped into equivalence classes, which allows for a one-to-one correspondence between a configuration and its mathematical representation. Reconfiguration is then accomplished by a successive construction of the goal configuration, realized by moving individual modules along the surface of the robot and building up the binary tree of the goal configuration by populating unoccupied binary tree indices in ascending order with new modules. The algorithm is capable of solving the self-reconfiguration problem for modular robots with a triangular structure in O(n2) reconfiguration steps and is demonstrated on two reconfiguration examples. We then discuss the limits of the proposed methods, regarding constraints on the implementation and the lack of efficient collision avoidance, and outline possible resolutions.}
}
@article{SANTOS2021103833,
title = {A systematic mapping study of robotics in human care},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103833},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103833},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001184},
author = {Nícolas B. Santos and Rodrigo S. Bavaresco and João E.R. Tavares and Gabriel de O. Ramos and Jorge L.V. Barbosa},
keywords = {Caregiver robot, Human caregiver, Assistive robot, Service robot, Cognitive impairment, Systematic mapping study},
abstract = {The World Health Organization (WHO) reported that more than 1 billion people live with some form of disability. Moreover, the number of elderly is increasing in recent years. According to the United Nations (UN), in 2050, there will be 2.1 billion people above 60 years of age worldwide. Many of these people live alone in their homes or clinics and rely on some kind of help to fulfill their specific needs. In this context, emerging opportunities for the application of robotics to support ubiquitous healthcare may reflect in reducing medical costs and increasing the convenience of patients and people in general. This paper presents a systematic mapping study to identify the application of service robots in the assistance of human care, focusing on the employment of computational technologies and unexplored research gaps in the literature. The study conducted searches in eight scientific repositories in the area of service robots through a systematic filtering process to remove bias. Afterward, the filtering process allowed to reduce from an initial sample of 9372 to 69 studies. As a result, these studies were reviewed entirely, analyzed, and categorized to answer six research questions. In addition, the study proposed four taxonomies illustrating the state-of-the-art of robotics in human care. The results highlight therapy and entertainment as the most common categories of the usage of robotics in human care. The most widely-used technologies to integrate with smart environments are smartphone sensors, smart device integration, wearables, and cloud services. The most frequently used mean of human–robot interaction is verbal communication, which is useful to help the elderly, children, and people with a mental health disorder. The most commonly cited diseases were cognition impairment, autism spectrum disorder, and motor impairment. Finally, we observed a trend in the growth of the use of service robots to improve the intelligence of the environment supporting human care. The scientific contribution of this article are four taxonomies that classify and group caregiver robots according to the application, integration with a smart environment, human–robot interaction, and target audience. This study also allowed the learning of 11 lessons on methodological and technological aspects based on the profound research performed.}
}
@article{LIU2021103877,
title = {PC-SD-VIO: A constant intensity semi-direct monocular visual-inertial odometry with online photometric calibration},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103877},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103877},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001627},
author = {Quanpan Liu and Zhengjie Wang and Huan Wang},
keywords = {The brightness constancy assumption, Semi-direct VIO, Online photometric calibration},
abstract = {The brightness constancy assumption is the cornerstone of direct or semi-direct visual odometry (VO) and visual simultaneous localization and mapping (SLAM). However, due to the existence of automatic exposure time, nonlinear camera response function, and vignetting, this assumption is difficult to hold in practical applications. Therefore, the corresponding algorithm performs poorly on arbitrary video sequences and uncalibrated cameras. Hence, we propose a novel constant intensity semi-direct visual-inertial odometry (VIO) integrated with online photometric calibration, which combines the exactness of the feature-based method and the quickness of the direct method. We combine gain-adaptive direct image alignment and gain-adaptive Kanade–Lucas–Tomasi (KLT) optical flow tracking to complete the feature matching and use it as the input for the back-end optimization and online photometric calibration. Our photometric calibration module can complete the estimation of all photometric parameters without any prior knowledge and cooperate with the front-end to complete the real-time photometric calibration of the latest frame. Experiments on the TUM Mono VO dataset, EuRoC dataset, and real environments prove that the algorithm can reliably calibrate the photometric parameters of an arbitrary video sequence. The semi-direct VIO algorithm integrated with the photometric calibration algorithm achieves a good balance between speed, accuracy, and robustness.}
}
@article{GHASSEMI2022103905,
title = {Multi-robot task allocation in disaster response: Addressing dynamic tasks with deadlines and robots with range and payload constraints},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103905},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103905},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001901},
author = {Payam Ghassemi and Souma Chowdhury},
keywords = {Bipartite graph, Integer linear programming, Multi-UAV flood response, Multi-robot task allocation, Unmanned aerial vehicles},
abstract = {This paper tackles a class of multi-robot task allocation (MRTA) problems called “Single-Task Robots and Single-Robot Tasks” or SR–ST problems, subject to the following additional characteristics: tasks with deadlines, tasks that are generated during the mission, and robots with range and payload constraints (thus requiring multiple tours per robot). While these characteristics are typical of various disaster response and commercial applications, there is a lack of online MRTA solutions to address them. To solve this class of complex MRTA problems, an efficient online method (which is also suitable for decentralized deployment) is developed based on the construction and weighted matching of bipartite graphs. An exact integer linear programming (ILP) formulation of this class of MRTA problems is also developed, the solution of which serves both as an offline MRTA approach and as a provably optimal benchmark against which the online method is compared. The new methods are applied to a flood response problem where multiple unmanned aerial vehicles must respond to victims spread out over a large area. The results show that the new online algorithm closely trails the offline ILP method in terms of task completion performance, while being >103 times more computationally efficient compared to the ILP method. Dedicated case studies provide further insights into the favorable scalability of the online method with an increasing number of UAVs — offering up to 46% higher task completion compared to a random walk baseline in huge 1000-task problems. Lastly, application to a slightly different class of SR–ST problems and comparison of the ensuing results with that of corresponding state-of-the-art methods demonstrate the potential wider applicability of the proposed online MRTA method.}
}
@article{BAKIRCIOGLU2022103977,
title = {Experimental comparison of the effect of the number of redundant rotors on the fault tolerance performance for the proposed multilayer UAV},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103977},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103977},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002438},
author = {Veli Bakırcıoğlu and Nihat Çabuk and Şahin Yıldırım},
keywords = {Actuator redundancy, Fault-tolerance, Flight safety, Multi-layer UAV, Universal UAV},
abstract = {In this paper, experimental investigation of the flight performance of the proposed universal Unmanned Aerial Vehicle (UAV) in case of rotor failures is presented. In the experimental flight tests, proposed universal UAV that can be converted to many different configurations due to its non-standard multi-layer structure was used in two different configurations as a standard octorotor and a multi-layer dodecarotor. Multiple outdoor experiments are conducted to show flight safety and reliability of the proposed UAV in terms of rotor failure tolerance. In order to evaluate flight safety and reliability of the proposed UAV, take-off, hovering and landing flight performance analyzes were performed in cases where one or two motors/propellers were completely lost. As performance criteria, errors in the UAV’s roll, pitch and yaw angles, altitude error and vibration in three axes were determined. The flight test results are presented both numerically and graphically. According to the results, multi-layer dodecarotor type has shown a more stable flight performance in terms of angular position errors. In addition, in both types of UAVs, in the case of failure of two rotors rotating in the opposite direction, it has been observed that the error in yaw angle is less than a rotor failure, as expected. Likewise, in the case of failure of two rotors rotating in the same direction, performance loss was observed in the control of yaw angle.}
}
@article{THALAMY2022103913,
title = {VisibleSim: A behavioral simulation framework for lattice modular robots},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103913},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103913},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001986},
author = {Pierre Thalamy and Benoît Piranda and André Naz and Julien Bourgeois},
keywords = {Discrete-event simulator, Modular robotic systems, Programmable matter, Distributed algorithms, Robotic simulation},
abstract = {Simulation is one of the most important tools for robotics research, as it serves several crucial purposes such as prototyping, learning, avoiding dispensable hardware costs, or studying future systems that cannot be fabricated yet. Large scale self-reconfiguring modular robotic systems are an instance of such systems. Yet, current modular robotic simulators are overwhelmingly physics-based, which are good for real-world simulation but can be superfluous and sacrifice scalability when studying such systems through a behavioral lens. This paper introduces VisibleSim, an open-source behavioral simulator for lattice-based modular robots that uses discrete-event simulation. We describe the principles behind the simulator and introduce its features and usage from a user standpoint. VisibleSim has unique features like extensibility, versatility, and flexibility, it can also be used as a powerful visualization tool and has already a proven track record with several modular robotic architectures. We present a stress test composed of, ultimately, 32 million simulated robots, a new record in the field of modular robotic simulation.}
}
@article{FAWAKHERJI2021103861,
title = {Multi-Spectral Image Synthesis for Crop/Weed Segmentation in Precision Farming},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103861},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103861},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001469},
author = {Mulham Fawakherji and Ciro Potena and Alberto Pretto and Domenico D. Bloisi and Daniele Nardi},
keywords = {Agricultural robotics, Crop/weed detection, cGANs, Semantic segmentation},
abstract = {An effective perception system is a fundamental component for farming robots, as it enables them to properly perceive the surrounding environment and to carry out targeted operations. The most recent methods make use of state-of-the-art machine learning techniques to learn a valid model for the target task. However, those techniques need a large amount of labeled data for training. A recent approach to deal with this issue is data augmentation through Generative Adversarial Networks (GANs), where entire synthetic scenes are added to the training data, thus enlarging and diversifying their informative content. In this work, we propose an alternative solution with respect to the common data augmentation methods, applying it to the fundamental problem of crop/weed segmentation in precision farming. Starting from real images, we create semi-artificial samples by replacing the most relevant object classes (i.e., crop and weeds) with their synthesized counterparts. To do that, we employ a conditional GAN (cGAN), where the generative model is trained by conditioning the shape of the generated object. Moreover, in addition to RGB data, we take into account also near-infrared (NIR) information, generating four channel multi-spectral synthetic images. Quantitative experiments, carried out on three publicly available datasets, show that (i) our model is capable of generating realistic multi-spectral images of plants and (ii) the usage of such synthetic images in the training process improves the segmentation performance of state-of-the-art semantic segmentation convolutional networks.}
}
@article{KIM2021103889,
title = {Distributed herding of multiple robots in cluttered environments},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103889},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103889},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001743},
author = {Jonghoek Kim},
keywords = {Networked system, Bearing measurements, Distributed herding, Network connectivity, Cluttered environments},
abstract = {This article introduces distributed herding controllers to make multiple robots (agents) follow a leader in environments with many unknown obstacles. The proposed herding controllers are developed considering agents which can only measure the bearing of a nearby agent using bearing sensors, such as camera. In addition, an agent uses Received Signal Strength Indicator (RSSI) sensors to detect the moment when it meets another agent. Every agent, except for the leader, is not equipped with sensors to localize itself. Every agent can only detect nearby agents and moves utilizing local sensing measurements. Since every agent moves in an unknown cluttered environment, communication or sensing between agents may be lost blocked by obstacles. Therefore, this article presents distributed herding controllers so that multiple agents follow a leader while maintaining network connectivity in unknown cluttered environments. The leader changes its velocity adaptively so that it can reach the goal while maintaining network connectivity with its followers. The proposed herding controllers are developed to overcome a network faulty situation. As far as we know, this paper is novel in presenting distributed herding controls of multiple agents, such that the network connectivity is maintained while agents move in cluttered environments. Under MATLAB simulations, we verify the effectiveness of the proposed herding approach in cluttered environments.}
}
@article{MOLLER2021103837,
title = {A survey on human-aware robot navigation},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103837},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103837},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001226},
author = {Ronja Möller and Antonino Furnari and Sebastiano Battiato and Aki Härmä and Giovanni Maria Farinella},
keywords = {Robot navigation, Human robot interaction, Active vision, Activity recognition},
abstract = {Intelligent systems are increasingly part of our everyday lives and have been integrated seamlessly to the point where it is difficult to imagine a world without them. Physical manifestations of those systems on the other hand, in the form of embodied agents or robots, have so far been used only for specific applications and are often limited to functional roles (e.g. in the industry, entertainment and military fields). Given the current growth and innovation in the research communities concerned with the topics of robot navigation, human–robot-interaction and human activity recognition, it seems like this might soon change. Robots are increasingly easy to obtain and use and the acceptance of them in general is growing. However, the design of a socially compliant robot that can function as a companion needs to take various areas of research into account. This paper is concerned with the navigation aspect of a socially-compliant robot and provides a survey of existing solutions for the relevant areas of research as well as an outlook on possible future directions.}
}
@article{MARIC2021103865,
title = {A Riemannian metric for geometry-aware singularity avoidance by articulated robots},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103865},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103865},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001500},
author = {Filip Marić and Luka Petrović and Marko Guberina and Jonathan Kelly and Ivan Petrović},
keywords = {Manipulation, Manipulability ellipsoid, Kinematics, Differential geometry},
abstract = {Articulated robots such as manipulators increasingly must operate in uncertain and dynamic environments where interaction (with human coworkers, for example) is necessary. In these situations, the capacity to quickly adapt to unexpected changes in operational space constraints is essential. At certain points in a manipulator’s configuration space, termed singularities, the robot loses one or more degrees of freedom (DoF) and is unable to move in specific operational space directions. The inability to move in arbitrary directions in operational space compromises adaptivity and, potentially, safety. We introduce a geometry-aware singularity index, defined using a Riemannian metric on the manifold of symmetric positive definite matrices, to provide a measure of proximity to singular configurations. We demonstrate that our index avoids some of the failure modes and difficulties inherent to other common indices. Further, we show that our index can be differentiated easily, making it compatible with local optimization approaches used for operational space control. Our experimental results establish that, for reaching and path following tasks, optimization based on our index outperforms a common manipulability maximization technique and ensures singularity-robust motions.}
}
@article{WAN2022103918,
title = {Arranging test tubes in racks using combined task and motion planning},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103918},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103918},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002037},
author = {Weiwei Wan and Takeyuki Kotaka and Kensuke Harada},
keywords = {Grasping, Manipulation, Motion planning, Lab automation},
abstract = {The paper develops a robotic manipulation system to meet the pressing needs for handling a large number of test tubes in clinical examination and replace or reduce human labor. It presents the technical details of the system, which separates and arranges test tubes in racks with the help of 3D vision and artificial intelligence (AI) planning. The developed system only requires a person to put a rack with mixed and non-arranged tubes in front of a robot. The robot autonomously performs recognition, reasoning, planning, manipulation, etc., and returns a rack with separated and arranged tubes. The system is simple-to-use, and there are no requests for expert knowledge in robotics. We expect such a system to play an important role in helping managing bulky examination samples. We also hope similar systems could be extended to other clinical manipulation like handling mixers and pipettes in the future.}
}
@article{CALDERITA2021103873,
title = {A new human-aware robot navigation framework based on time-dependent social interaction spaces: An application to assistive robots in caregiving centers},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103873},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103873},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001585},
author = {L.V. Calderita and A. Vega and P. Bustos and P. Núñez},
keywords = {Social robot navigation, Human-aware navigation, Social mapping},
abstract = {One of the most critical problems to be addressed by future generation socially-assistive robots working in semi-organized social environments, such as shopping centers, nursing homes, airports, hospitals, or assisted living centers, is the capability of human-aware navigation. Autonomous navigation in a complex environment with people, staff with different roles, timetables, and restrictions to access, among others, requires adapting to socially accepted rules. Consequently, the path-planner must consider concepts related to proxemics and personal spaces of interaction that include human–human, human–robot, or human–object combinations. Likewise, the speed of approaching people, both to initiate communication or to navigate nearby, must be adapted to social conventions. Some of these situations have already been studied in the literature with varying degrees of success. However, the concept of time dependency or chronemics in the robot social navigation has been poorly explored. Current algorithms do not take into account the social complexity of real environments and their relationship with the time of day or the activities performed in these scenarios. This article presents a new framework for robot social navigation in human environments, introducing the concept of time-dependent social mapping. The main novelty is that the social route planned by the robot considers variables that depend on the time and the scheduled center activities. The article describes how the areas of interaction vary over time and how they affect human-aware navigation. To this end, the proposed navigation stack defines a new function for time-dependent social interaction space that takes continuous values and is configurable by the center’s staff. The global path-planner uses this function to choose dynamically a socially accepted path to the target. Then, the framework uses an elastic band path optimizer as a local planner, adapting the robot’s navigation to possible changes during the trajectory. Several use cases in simulated caregiving centers have been explored to validate the robot’s social navigation improvements using these temporal variables.}
}
@article{BAUMANN2021103849,
title = {A modular functional framework for the design and evaluation of multi-robot navigation},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103849},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103849},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001342},
author = {Cyrill Baumann and Alcherio Martinoli},
keywords = {Distributed control algorithms, Multi-robot systems, Benchmarking, Performance evaluation, Control software design},
abstract = {In this work, we address the design of tightly integrated control, estimation, and allocation algorithms allowing a group of robots to move collectively. For doing so, we leverage a modular framework that allows us to define precisely the needed functional components and thus consider and compare multiple algorithmic solutions for the same module. We demonstrate the effectiveness of such a framework through multiple spatial coordination challenges carried out both in simulation and reality and leveraging different distributed control laws (graph-based and behavior-based controllers). Moreover, we investigate the impact of different localization and communication constraints as well as that of real-time switching of control laws on selected coordination metrics. Finally, we also introduce additional algorithmic components for demonstrating further the modularity of the framework. We find that defining the modularity based on functionality is a very effective way to enable algorithm benchmarking and discover possible improvements of the overall software stack while at the same time being agnostic to the underlying hardware and middleware resources. This is an especially welcome feature in case of severely resource-constrained multi-robot systems. Moreover, an important benefit of such design process is that the resulting distributed control algorithms are very robust to the considered noise sources and amplitudes as well as to the diverse types of challenges considered.}
}