@article{WU2023104484,
title = {A fast and accurate compound collision detector for RRT motion planning},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104484},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104484},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001239},
author = {Shangliang Wu and Guangyu Liu and Yanxin Zhang and Anke Xue},
keywords = {Collision detection, Rapidly-exploring random tree, Motion planning, Manipulator, Machine learning},
abstract = {The application of artificial intelligence tools has led to newly developed collision detectors which have better computational efficiency than the kinematics-and-geometry based collision detectors (KCD) to improve robot motion planning strategies. However, new detectors are not very accurate in some cases. To improve the accuracy, a trade-off between efficiency and accuracy is required. We propose a novel compound collision detector (CCD) for collision queries that modifies the planners of rapidly-exploring random tree (RRT) to improve the classical probabilistic collision detector (PCD). It is composed of an exact collision detector (ECD), an inference collision detector (ICD) and a strategy to determine ECD or ICD based on some conditions. In our CCD, we use a sphere-ellipsoidal pseudo distance (SEPD) in the determination strategy to alleviate the problem of highly-frequent outputs of false-positive in narrow passages of PCD, and a node based bounding method (NBB) to increase the speed of data storage and loading for the sub-algorithm ICD. Experiments on a Kinova Jaco assistive robotic arm are taken to evaluate the performance of our CCD, which show an improved accuracy with a small reduction of speed in comparison with PCD. So, it is a promising tool in robot motion planning.}
}
@article{HADDELER2023104512,
title = {Real-time terrain anomaly perception for safe robot locomotion using a digital double framework},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104512},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104512},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001513},
author = {Garen Haddeler and Hari P. Palanivelu and Fabien Colonnier and Yung Chuen Ng and Albertus H. Adiwahono and Zhibin Li and Chee-Meng Chew and Meng Yee Michael Chuah},
keywords = {Robot sensing, Legged robot locomotion, Digital twins, Field robotics},
abstract = {Digital twinning systems are effective tools to test and develop new robotic capabilities before applying them in the real world. This work presents a real-time digital double framework that improves and facilitates robot perception of the environment. Soft or non-rigid terrains can cause locomotion failures, while visual perception alone is often insufficient to assess the physical properties of such surfaces. To tackle this problem we employ the proposed framework to estimate ground collapsibility through physical interactions while the robot is dynamically walking on challenging terrains. We extract discrepancy information between the two systems, a simulated digital double that is synchronized with a real robot, both using exactly the same physical model and locomotion controller. The discrepancy in sensor measurements between the real robot and its digital double serves as a critical indicator of anomalies between expected and actual motion and is utilized as input to a learning-based model for terrain collapsibility analysis. The performance of the collapsibility estimation was evaluated in a variety of real-world scenarios involving flat, inclined, elevated, and outdoor terrains. Our results demonstrate the generality and efficacy of our real-time digital double architecture for estimating terrain collapsibility.}
}
@article{BRUNS2023104507,
title = {RGB-D-based categorical object pose and shape estimation: Methods, datasets, and evaluation},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104507},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104507},
url = {https://www.sciencedirect.com/science/article/pii/S092188902300146X},
author = {Leonard Bruns and Patric Jensfelt},
keywords = {Pose estimation, Shape estimation, Shape reconstruction, RGB-D-based perception},
abstract = {Recently, various methods for 6D pose and shape estimation of objects at a per-category level have been proposed. This work provides an overview of the field in terms of methods, datasets, and evaluation protocols. First, an overview of existing works and their commonalities and differences is provided. Second, we take a critical look at the predominant evaluation protocol, including metrics and datasets. Based on the findings, we propose a new set of metrics, contribute new annotations for the Redwood dataset, and evaluate state-of-the-art methods in a fair comparison. The results indicate that existing methods do not generalize well to unconstrained orientations and are actually heavily biased towards objects being upright. We provide an easy-to-use evaluation toolbox with well-defined metrics, methods, and dataset interfaces, which allows evaluation and comparison with various state-of-the-art approaches (https://github.com/roym899/pose_and_shape_evaluation).}
}
@article{PELLERKONRAD2023104415,
title = {A memory system of a robot cognitive architecture and its implementation in ArmarX},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104415},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104415},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000544},
author = {Fabian Peller-Konrad and Rainer Kartmann and Christian R.G. Dreher and Andre Meixner and Fabian Reister and Markus Grotz and Tamim Asfour},
keywords = {Humanoid robotics, Memory-driven cognitive architecture, Working memory, Episodic memory, Long-term memory, Knowledge representation},
abstract = {Cognitive agents such as humans and robots perceive their environment through an abundance of sensors producing streams of data that need to be processed to generate intelligent behavior. A key question of cognition-enabled and AI-driven robotics is how to organize and manage such data and knowledge efficiently in a cognitive robot control architecture. We argue, that memory is a central active component of such architectures that mediates between semantic and sensorimotor representations, orchestrates the flow of data streams and events between different processes and provides the components of a cognitive architecture with data-driven services for learning semantics from sensorimotor data, the parametrization of symbolic plans for execution and prediction of action effects. Based on related work, and the experience gained in developing our ARMAR humanoid robot systems, we identified conceptual and technical requirements of a memory system as central component of cognitive robot control architecture that facilitate the realization of high-level cognitive abilities such as explaining, reasoning, prospection, simulation and augmentation. Conceptually, a memory should be active, support multi-modal data representations, associate knowledge, be introspective, and have an inherently episodic structure. Technically, the memory should support a distributed design, be access-efficient and capable of long-term data storage. We introduce the memory system for our cognitive robot control architecture and its implementation in the robot software framework ArmarX. We evaluate the efficiency of the memory system with respect to transfer speeds, compression, reproduction and prediction capabilities.}
}
@article{WANG2023104552,
title = {Task parse tree: Learning task policy from videos with task-irrelevant components},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104552},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104552},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001914},
author = {Weihao Wang and Mingyu You and Hongjun Zhou and Bin He},
keywords = {Learning from video demonstration, Task planning, Video understanding},
abstract = {A good task policy should explicitly interpret the preconditions of actions and the composition structure of task. We aim to automatically learn such a task policy from videos which remains challenging at present. This issue can be further aggravated when task-irrelevant components are involved in videos, such as unoperated objects and small actions. Task-irrelevant objects may introduce disruptive visual relations, and task-irrelevant actions would lead to misleading and even failed task planning. Solving both issues simultaneously is beyond the scope of existing methods. To this end, we propose Task Parse Tree (TPT) as a novel task policy representation, distinguishing task-relevant actions with definite preconditions and clear execution order. The automatic generation of TPT relies on two core designs, where spatio-temporal graph (STG) seizes the vital changes in visual relations of objects and their attributes both spatially and temporally, and conjugate action graph (CAG) models the execution logic of actions in a graph. We collect a dataset of a real-world task, Make Tea, and experiment results on the dataset show that TPT realizes both accurate and interpretable task planning in two different scenarios.}
}
@article{BANERJEE2023104403,
title = {Lifelong mapping in the wild: Novel strategies for ensuring map stability and accuracy over time evaluated on thousands of robots},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104403},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104403},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000428},
author = {Nandan Banerjee and Dimitri Lisin and Scott R. Lenser and Jimmy Briggs and Rodrigo Baravalle and Victoria Albanese and Yao Chen and Arman Karimian and Tyagaraja Ramaswamy and Pablo Pilotti and Martin Llofriu Alonso and Lucio Nardelli and Veronica Lane and Renaud Moser and Andrea Okerholm Huttlin and Justin Shriver and Phil Fong},
keywords = {Lifelong mapping, SLAM, Semantic mapping, Correction, Prevention},
abstract = {Lifelong mapping presents unique challenges to household robots which operate in the same environment over long durations. One is the growth of redundant information in the map as it evolves over time, which can easily overwhelm the limited computation resources of a household robot. Another is the possibility of mapping errors. An error in robot pose estimate, which if not corrected fast enough, will result in incorrect occupancy and semantic representation, rendering the map unusable. Finally, for a lifelong mapping system where the map is updated continuously, avoiding these errors altogether is infeasible. In this paper, we present a comprehensive overview of novel strategies for eliminating redundant information from the map and preventing and correcting mapping errors. We also present a detailed evaluation of these novel strategies on 10,000 robots running in indoor environments across different geographic locations of the world to demonstrate map stability and accuracy over time.}
}
@article{HANINGER2023104431,
title = {Model predictive impedance control with Gaussian processes for human and environment interaction},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104431},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104431},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000702},
author = {Kevin Haninger and Christian Hegeler and Luka Peternel},
keywords = {Impedance control, Model predictive control, Human–robot interaction, Gaussian processes, Intention detection},
abstract = {Robotic tasks which involve uncertainty – due to variation in goal, environment configuration, or confidence in task model – may require human input to instruct or adapt the robot. In tasks with physical contact, several existing methods for adapting robot trajectory or impedance according to individual uncertainties have been proposed, e.g., realizing intention detection or uncertainty-aware learning from demonstration. However, isolated methods cannot address the wide range of uncertainties jointly present in many tasks. To improve generality, this paper proposes a model predictive control (MPC) framework which plans both trajectory and impedance online, can consider discrete and continuous uncertainties, includes safety constraints, and can be efficiently applied to a new task. This framework can consider uncertainty from: contact constraint variation, uncertainty in human goals, or task disturbances. An uncertainty-aware task model is learned from a few (≤3) demonstrations using Gaussian Processes. This task model is used in a nonlinear MPC problem to optimize robot trajectory and impedance according to belief in discrete human goals, human kinematics, safety constraints, contact stability, and frequency-domain disturbance rejection. This MPC formulation is introduced, analyzed with respect to convexity, and validated in co-manipulation with multiple goals, a collaborative polishing task, and a collaborative assembly task.}
}
@article{AUDDY2023104427,
title = {Continual learning from demonstration of robotics skills},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104427},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104427},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000660},
author = {Sayantan Auddy and Jakob Hollenstein and Matteo Saveriano and Antonio Rodríguez-Sánchez and Justus Piater},
keywords = {Learning from demonstration, Continual learning, Hypernetwork, Neural ordinary differential equation solver},
abstract = {Methods for teaching motion skills to robots focus on training for a single skill at a time. Robots capable of learning from demonstration can considerably benefit from the added ability to learn new movement skills without forgetting what was learned in the past. To this end, we propose an approach for continual learning from demonstration using hypernetworks and neural ordinary differential equation solvers. We empirically demonstrate the effectiveness of this approach in remembering long sequences of trajectory learning tasks without the need to store any data from past demonstrations. Our results show that hypernetworks outperform other state-of-the-art continual learning approaches for learning from demonstration. In our experiments, we use the popular LASA benchmark, and two new datasets of kinesthetic demonstrations collected with a real robot that we introduce in this paper called the HelloWorld and RoboTasks datasets. We evaluate our approach on a physical robot and demonstrate its effectiveness in learning real-world robotic tasks involving changing positions as well as orientations. We report both trajectory error metrics and continual learning metrics, and we propose two new continual learning metrics. Our code, along with the newly collected datasets, is available at https://github.com/sayantanauddy/clfd.}
}
@article{CHEN2023104480,
title = {Multi-agent planning and coordination for automated aircraft ground handling},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104480},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104480},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001197},
author = {Szu-Tung Chen and Gülçin Ermiş and Alexei Sharpanskykh},
keywords = {Automated aircraft ground handling, Task allocation, Multi-agent path planning, Vehicle routing with pick up and deliveries},
abstract = {Inspired by the vision of fully autonomous airside operations at Schiphol airport, this study aims to contribute to the short-term goal of automated aircraft ground handling. In this research, we design and evaluate a multi-agent system for planning of automated ground handling. There are two main components in the system: task allocation optimization and multi-agent path planning. To allocate tasks to ground support equipment (GSE) vehicles, an auction mechanism inspired by temporal sequential single item (TeSSI) auction is proposed. Ground handling tasks scheduling for GSE vehicles is modeled as several single-vehicle pickup and delivery optimization problems (SPDP), and the values of the objective functions are used to generate bids for GSE vehicle agents in the auction. Prioritized safe interval path planning for large agents (LA-SIPP) is used to plan collision-free paths for GSE vehicle agents in the model to execute tasks. The aim is to increase the success rates of allocating tasks and finding collision free paths without causing flight delays, given the limited resources such as a small number of available GSE vehicles, time windows constraints and conflicting interests of different agents. Due to the results, even for the instances with frequent flights and the most limited resources, the success rates of allocation and path planning were higher than 81% and 98%, respectively. Furthermore, periodic task allocation and path planning of the ground handling tasks for flights in three aircraft stands during a planning time window of the day, as well as replanning in case of disruptions were performed in a short CPU time. There is a lack of research dealing with the complete process of ground handling, since existing studies concerning the automation of ground handling operations involve fleet assignment or task scheduling models without an integration of detailed path planning. Our main contribution is to present a framework that combines task allocation and path planning for automation of ground handling operations and provides solutions using a multi-agent perspective.}
}
@article{YAZDANI2023104508,
title = {Perception-aware online trajectory generation for a prescribed manoeuvre of unmanned surface vehicle in cluttered unstructured environment},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104508},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104508},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001471},
author = {Amirmehdi Yazdani and Somaiyeh MahmoudZadeh and Oleg Yakimenko and Hai Wang},
keywords = {Unmanned surface vehicle, Dynamic unstructured operating environment, Online trajectory generation, Event-triggered receding horizon control mechanism},
abstract = {This paper proposes a perception-aware online trajectory generation system that facilitates prescribed manoeuvres of an unmanned surface vehicle (USV) in a dynamic unstructured environment. The proposed system is developed based on the principles of the inverse dynamics in the virtual domain (IDVD) method and an event-triggered receding horizon control (ETRHC) mechanism. This approach transforms the underlying nonconvex constrained optimization problem into a virtual space with a differentially flat dynamics and uses relatively few decision variables to prototype feasible quasi-optimal trajectories. The closed-loop configuration is provided by a computationally efficient ETRHC mechanism that uses situational awareness of operating environment to trigger trajectory replanning if/when required. This addresses the challenge of continuously updating a closed-loop trajectory which imposes unnecessary computational burden on a system with the limited onboard resources. To investigate the performance of the proposed trajectory generating system, a dynamic unstructured environment including variable and uncertain no-fly zone areas as well as variable current vector fields are modeled. Further, different operating conditions incorporating the uncertainties of environment and sudden failure on the USV propulsion system are introduced to examine the effectiveness, agility, and robustness of the proposed trajectory generating system. A comparative study with benchmark solutions generated by the hp-adaptive Radau pseudo-spectral method is conducted to provide a detailed statistical analysis of the proposed approach robustness, computational complexity, and effectiveness. The simulation results confirm the effectiveness of the proposed trajectory generator and ability to produce a solution for online realization.}
}
@article{ALKHATIB2023104496,
title = {Feedback control of millimeter scale pivot walkers using magnetic actuation},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104496},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104496},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001355},
author = {Ehab {Al Khatib} and Pouria Razzaghi and Yildirim Hurmuzlu},
keywords = {Small-scaled robots, Electromagnetic, Locomotion, Trajectory tracking},
abstract = {An external magnetic field can be used to remotely control small-scaled robots, making them promising candidates for diverse biomedical and engineering applications. In a previous study, we showed that our magnetically actuated millirobot is highly agile and can perform a variety of locomotive tasks such as pivot walking, tumbling, and tapping in a horizontal plane. In this study, we focus on controlling the locomotion outcomes of this millirobot in the pivot walking mode. A mathematical model of the system is developed and the kinematic model is derived. The role of the sweep and tilt angles in the robot’s motion is also investigated. We study two controllers to regulate the gait of the pivot walker. The first one is a proportional-geometric-based controller, which determines the correct pivot point that the millirobot should use. Then, it regulates the angular velocity proportionally based on the error between the center of the millirobot and the reference trajectory. The second controller is based on a gradient descent optimization technique, which expresses the control action as an optimization problem. These control algorithms enable the millirobot to generate a stable gait while tracking the desired trajectory. A low-cost high-performance magnetic actuator is built to validate the proposed controllers. We conduct a set of different experiments and simulation runs to establish the effectiveness of proposed controllers for different sweep and tilt angles in terms of tracking error. The two controllers exhibit an appropriate performance, but it is observed that the gradient descent-based controller yields faster convergence time, smaller tracking error, and fewer number of steps. Finally, we perform an extensive experimentally parametric analysis of the effect of sweep and tilt angles and step time on the tracking error. As we expect, the optimization-based controller outperforms the geometric-based one.}
}
@article{YAO2023104468,
title = {Adaptive legged manipulation: Versatile disturbance predictive control for quadruped robots with robotic arms},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104468},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104468},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001070},
author = {Qingfeng Yao and Cong Wang and Jilong Wang and Linghan Meng and Shuyu Yang and Qifeng Zhang and Donglin Wang},
keywords = {Reinforcement learning, Quadruped robot, Forward model},
abstract = {Equipping a legged robot with a manipulator enables versatile mobile manipulation, significantly improving its performance in various tasks. However, developing a unified framework for diverse robotic arms and legged robots presents a challenge. This study proposes a disturbance predictive control framework where a high-level estimator cooperates with a disturbance-based low-level controller. Further, a transportable latent dynamic adapter is introduced to enable the model to migrate rapidly to different robotic arms. Our method can adapt well to other manipulators with a few samples. Further, the effectiveness of our method was demonstrated via simulation and real experiments.}
}
@article{CHOUR2023104442,
title = {An agent-based modeling framework for the multi-UAV rendezvous recharging problem},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104442},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104442},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000817},
author = {Kenny Chour and Jean-Paul Reddinger and James Dotterweich and Marshal Childers and James Humann and Sivakumar Rathinam and Swaroop Darbha},
keywords = {Behavior trees, Hierarchical finite state machines, Agent-based modeling, Multi-UAV systems},
abstract = {In this work, we aim to model the multi-UAV rendezvous recharging problem, which consists of energy-limited aerial vehicles that rendezvous with a mobile or fixed charging station. The motivation for such a problem is to tackle persistent surveillance missions, where the modeling of related problems often rely on heavy mathematical formulations, such as mixed integer linear programming (MILP). The major drawback of such approaches is great difficulty in capturing constraints and adjusting the model for changes. Additionally, MILP solvers are not guaranteed to yield a feasible solution in a timely manner. As a result, we chose to create an agent-based model (ABM). To the best of our knowledge, the presented problem has not been modeled before using ABM. Additionally, we sought to use a custom framework incorporating Behavior Trees (BTs) and Hierarchical Finite State Machines (HFSMs), two commonly used tools in the video game and robotics industry. We verify the model’s correctness through numerical simulations and show that it is highly modular and extensible.}
}
@article{ZACCHINI2023104449,
title = {Informed expansion for informative path planning via online distribution learning},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104449},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104449},
url = {https://www.sciencedirect.com/science/article/pii/S092188902300088X},
author = {Leonardo Zacchini and Alessandro Ridolfi and Benedetto Allotta},
keywords = {Informative Path Planning, Informed expansion, Mobile robots, Autonomous Underwater Vehicles},
abstract = {Mobile robots are essential tools for gathering knowledge of the environment and monitoring areas of interest as well as industrial assets. Informative Path Planning methodologies have been successfully applied making robots able to autonomously acquire information and explore unknown surroundings. Rapidly-exploring Information Gathering approaches have been validated in real-world applications, proving they are the way to go when aiming for Information Gathering tasks. In fact, RIG can plan paths for robots with several degrees of freedom and rapidly explore complex workspaces by using the state-of-the-art Voronoi-biased expansion. Nevertheless, it is an efficient solution when most of the area is unknown but its effectiveness decreases as the exploration/gathering evolves. This paper introduces an innovative informed expansion for IG tasks that combines the Kernel Density Estimation technique and a rejection sampling algorithm. By learning online the distribution of the acquired information (i.e., the discovered map), the proposed methodology generates samples in the unexplored regions of the workspace, and thus steers the tree toward the most promising areas. Realistic simulations and an experimental campaign, conducted in the underwater robotics domain, provide a proof-of-concept validation for the developed informed expansion methodology and demonstrate that it enhances the performance of the RIG algorithm.}
}
@article{HUSEMANN2023104559,
title = {On demand ride sharing: Scheduling of an autonomous bus fleet for last mile travel},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104559},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104559},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001987},
author = {Jörg Husemann and Simon Kunz and Karsten Berns},
keywords = {Mobility-on-demand, Bus fleet scheduling, Shared mobility},
abstract = {Autonomous buses are expected to expand the mobility-on-demand options in cities in the next 10 years. An essential aspect of ensuring optimal usage of fleets of autonomous buses is the task of scheduling. This paper presents a scheduling approach based on the construction of all possible trips used to formulate an optimization problem. While in the past most research is focused on the scheduling of taxi trips, there is an increasing interest in the research for the scheduling of last-mile travel options. A street network has been generated based on open street map data as a basis for the scheduling. All possible combinations of buses and requests are calculated, and for each of those trips, a close to optimal order of requests is created. These are used to formulate the optimization problem, calculating a close to optimal assignment of requests on the buses. The approach has considered constraints such as maximum waiting time, travel delay, and targets to exploit shared trips for higher efficiency. Experiments have been carried out in a simulated environment of a university campus area with fleets of up to 10 vehicles. By performing various trials with changing parameters, the influence of the constraints on waiting time and travel delay to the scheduling is determined. Depending on the setup, service rates above 90%, while trails with strict constraints show that the approach can handle short-term requests. Based on the results, a use case-specific composition of the autonomous bus fleet can be done.}
}
@article{SARTORI2023104483,
title = {Near-optimal 3D trajectory design in presence of obstacles: A convolutional neural network approach},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104483},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104483},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001227},
author = {Daniele Sartori and Danping Zou and Ling Pei and Wenxian Yu},
keywords = {Path planning, Trajectory design, Convolutional neural network, UAV},
abstract = {This paper proposes an approach based on neural networks for designing near-optimal 3D trajectories connecting two points separated by obstacles. A reference path is first built with a novel Theta* algorithm implementation, upgraded to reduce the number of waypoints and the angular variations. Starting from the path, a trajectory based on piecewise Bézier curves is designed with an algorithm relying on two design parameters. The optimal value of these parameters is estimated with a Convolutional Neural Network (CNN) architecture receiving as inputs an image of the path and its properties. The CNN training is performed on a synthetic dataset of optimal parameters built with Differential Evolution optimization for a variety of randomly generated paths. The parameters from CNN are refined with an algorithm capable of providing with high success rate near-optimal trajectories within minimum computation time.}
}
@article{WANG2023104511,
title = {Autonomous agent-based simulation modelling—A case study on a flexible GPU-card final assembly line},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104511},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104511},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001501},
author = {Kung-Jeng Wang and Agustina Eunike and Ivan Kurniawan and Romadhani Ardi and Jing-Ming Chiu},
keywords = {Agent based system, Flexible assembly line, Graphic processing unit, Simulation modelling},
abstract = {Market demands for high-tech products constantly evolve by product specification. To be competitive, a production system must be flexible and reconfigurable when facing mass customization. Flexible assembly line (FAL) enables mixed production with high efficiency. One example is graphic processing unit (GPU) cards. FAL requires comprehensive system design and scheduling to fully utilize the resources. This study adopts agent-based simulation (ABS) modelling for a FAL because of the abilities of ABS in flexibility and scalability. The proposed framework consists of three parts: real environment, virtual environment, and evaluation and analysis. This study uses agent-based simulation modelling to elaborate on sequencing and scheduling performances in the GPU-card assembly line. The Pareto frontier analysis is conducted to resolve conflicts between part tardiness and throughput.}
}
@article{TERRERAN2023104523,
title = {A general skeleton-based action and gesture recognition framework for human–robot collaboration},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104523},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104523},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001628},
author = {Matteo Terreran and Leonardo Barcellona and Stefano Ghidoni},
keywords = {Human action recognition, Gesture recognition, 3D pose estimation, Ensemble learning, Human–robot collaboration},
abstract = {Recognizing human actions is crucial for an effective and safe collaboration between humans and robots. For example, in a collaborative assembly task, human workers can use gestures to communicate with the robot, and the robot can use the recognized actions to anticipate the next steps in the assembly process, leading to improved safety and productivity. In this work, we propose a general framework for human action recognition based on 3D pose estimation and ensemble techniques, which allows to recognize both body actions and hand gestures. The framework relies on OpenPose and 2D to 3D lifting methods to estimate 3D joints for the human body and the hands, feeding then these joints into a set of graph convolutional networks based on the Shift-GCN architecture. The output scores of all networks are combined using an ensemble approach to predict the final human action. The proposed framework was evaluated on a custom dataset designed for human–robot collaboration tasks, named IAS-Lab Collaborative HAR dataset. The results showed that using an ensemble of action recognition models improves the accuracy and robustness of the overall system; moreover, the proposed framework can be easily specialized on different scenarios and achieve state-of-the-art results on the HRI30 dataset when coupled with an object detector or classifier.}
}
@article{PACHOURI2023104551,
title = {Design and modeling of a planar-to-spatial tendon-driven continuum manipulator subjected to uncertain forces},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104551},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104551},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001902},
author = {Vipin Pachouri and Pushparaj Mani Pathak},
keywords = {Continuum manipulator, Flexible robots, Redundant robots, Tendon-driven, Kinematic analysis, Kineto-static analysis, Agricultural applications},
abstract = {Continuum Manipulators (CMs) have gained popularity as a promising solution for exploring unstructured environments due to their dexterity, compliance, and redundancy. Studies on CMs have focused individually on planar and spatial configurations, ranging from single to multi-section constructions. Planar CMs are easier to design, have simpler kinematics equations and possesses less number of tendons with reduced dexterity, redundancy, and reach. Whereas spatial CMs, offer a larger workspace with improved dexterity and redundancy while computationally expensive. This paper introduces a novel two-section tendon-driven continuum manipulator (TDCM) design that uses two planar sections to manipulate the distal end of the manipulator in three-dimensional space to handle external interaction from the environment. The proposed solution offers improved performance in terms of handling payloads and tip deflection under external interactions. This design is intended for agricultural applications such as vegetable harvesting and requires larger workspace and fewer actuators. We demonstrate the effectiveness of our design through kinematic and static analysis. The kineto-static model estimates the profile of the proposed TDCM under external interaction acting at the manipulator's distal end. Finally, the proposed design is experimentally validated by an in-housed prototype of an two-section TDCM, actuated by two tendons/section.}
}
@article{NUNEZ2023104426,
title = {Implementation relations and testing for cyclic systems: Adding probabilities},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104426},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104426},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000659},
author = {Manuel Núñez and Robert M. Hierons and Raluca Lefticaru},
keywords = {Probabilistic systems, Cyclic systems, Model-based testing, Implementation relations},
abstract = {This paper concerns the systematic testing of robotic control software based on state-based models. We focus on cyclic systems that typically receive inputs (values from sensors), perform computations, produce outputs (sent to actuators) and possibly change state. We provide a testing theory for such cyclic systems where time can be represented and probabilities are used to quantify non-deterministic choices, making it possible to model probabilistic algorithms. In addition, refusals, the inability of a system to perform a set of actions, are taken into account. We consider several possible testing scenarios. For example, a tester might only be able to passively observe a sequence of events and so cannot check probabilities, while in another scenario a tester might be able to repeatedly apply a test case and so estimate the probabilities of sequences of events. These different testing scenarios lead to a range of implementation relations (notions of correctness). As a consequence, this paper provides formal definitions of implementation relations that can form the basis of sound automated testing in a range of testing scenarios. We also validate the implementation relations by showing how observers can be used to provide an alternative but equivalent characterisation.}
}
@article{LI2023104402,
title = {A telerobotic system enabling online switching among various architectures and controllers},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104402},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104402},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000416},
author = {Gaofeng Li and Fernando Caponetto and Vasiliki Katsageorgiou and Nikos G. Tsagarakis and Ioannis Sagakoglou},
keywords = {Teleoperation, Multilateral architecture, Online switching, SLSF, MLMF, SLMF, MLSF},
abstract = {With the increasing complexity of teleoperation tasks, various teleoperation architectures, including the Single-Leader/Single-Follower (SLSF), Multiple-Leader/Multiple-Follower (MLMF), Single-Leader/Multiple-Follower (SLMF), and Multiple-Leader/Single-Follower (MLSF) systems, are emerging. Although numerous works have focused on the control strategies or a specific architecture, the study on online switching among different architectures is not equally prolific. However, the online switching among different architectures/controllers is required in a wide spectrum of robotic applications to perform complex tasks. This feature can also promote the development of shared autonomy robotic systems, including the seamless adaption of the autonomy level, the better co-adaption between human and robot, and so on. Here a generic, flexible, and expandable telerobotic system is developed. Instead of focusing on the control strategy of a specific architecture, the physical topology, the software design, and the switching strategy during transitions are all considered to enable the online switching among various architectures and/or controllers. The experimental results of several scenarios validate the main features of the proposed system and demonstrate the benefits of these features.}
}
@article{PERIYASAMY2023104490,
title = {YOLOPose V2: Understanding and improving transformer-based 6D pose estimation},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104490},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104490},
url = {https://www.sciencedirect.com/science/article/pii/S092188902300129X},
author = {Arul Selvam Periyasamy and Arash Amini and Vladimir Tsaturyan and Sven Behnke},
keywords = {Vision transformers, Object pose estimation, Object detection},
abstract = {6D object pose estimation is a crucial prerequisite for autonomous robot manipulation applications. The state-of-the-art models for pose estimation are convolutional neural network (CNN)-based. Lately, Transformers, an architecture originally proposed for natural language processing, is achieving state-of-the-art results in many computer vision tasks as well. Equipped with the multi-head self-attention mechanism, Transformers enable simple single-stage end-to-end architectures for learning object detection and 6D object pose estimation jointly. In this work, we propose YOLOPose (short form for You Only Look Once Pose estimation), a Transformer-based multi-object 6D pose estimation method based on keypoint regression and an improved variant of the YOLOPose model. In contrast to the standard heatmaps for predicting keypoints in an image, we directly regress the keypoints. Additionally, we employ a learnable orientation estimation module to predict the orientation from the keypoints. Along with a separate translation estimation module, our model is end-to-end differentiable. Our method is suitable for real-time applications and achieves results comparable to state-of-the-art methods. We analyze the role of object queries in our architecture and reveal that the object queries specialize in detecting objects in specific image regions. Furthermore, we quantify the accuracy trade-off of using datasets of smaller sizes to train our model.}
}
@article{BABA2023104471,
title = {A fuzzy logic-based stabilization system for a flying robot, with an embedded energy harvester and a visual decision-making system},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104471},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104471},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001100},
author = {Abdullatif Baba and Basil Alothman},
keywords = {Flying robot, Fuzzy logic-based stabilizer, Energy harvester, Computer vision, Smart decision},
abstract = {“Smart cities” is a popular concept in modern urban development that demands innovative solutions to enhance various aspects of our lives. This paper introduces a novel application that aims to improve public road maintenance by utilizing a flying robot to repaint partially erased sections of the sidewalks’ edges that are typically marked with black and white colors. The first contribution of this paper is the development of a fuzzy-logic-based stabilization system for an octocopter, which can serve as a liquids transporter and be equipped with a robot arm. The second contribution is the design of an embedded energy harvester for the flying robot, which optimizes the management of available power sources. Additionally, this project includes a complementary heuristic study that clarifies fundamental concepts related to a computer vision-based decision-making system.}
}
@article{FINEAN2023104450,
title = {Motion planning in dynamic environments using context-aware human trajectory prediction},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104450},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104450},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000891},
author = {Mark Nicholas Finean and Luka Petrović and Wolfgang Merkt and Ivan Marković and Ioannis Havoutis},
keywords = {Motion planning, Trajectory optimisation, Trajectory prediction, Dynamic environments, RGB-D perception},
abstract = {Over the years, the separate fields of motion planning, mapping, and human trajectory prediction have advanced considerably. However, the literature is still sparse in providing practical frameworks that enable mobile manipulators to perform whole-body movements and account for the predicted motion of moving obstacles. Previous optimisation-based motion planning approaches that use distance fields have suffered from the high computational cost required to update the environment representation. We demonstrate that GPU-accelerated predicted composite distance fields significantly reduce the computation time compared to calculating distance fields from scratch. We integrate this technique with a complete motion planning and perception framework that accounts for the predicted motion of humans in dynamic environments, enabling reactive and pre-emptive motion planning that incorporates predicted motions. To achieve this, we propose and implement a novel human trajectory prediction method that combines intention recognition with trajectory optimisation-based motion planning. We validate our resultant framework on a real-world Toyota Human Support Robot (HSR) using live RGB-D sensor data from the onboard camera. In addition to providing analysis on a publicly available dataset, we release the Oxford Indoor Human Motion (Oxford-IHM) dataset and demonstrate state-of-the-art performance in human trajectory prediction. The Oxford-IHM dataset is a human trajectory prediction dataset in which people walk between regions of interest in an indoor environment. Both static and robot-mounted RGB-D cameras observe the people while tracked with a motion-capture system.}
}
@article{LUO2023104414,
title = {A vision-based virtual fixture with robot learning for teleoperation},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104414},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104414},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000532},
author = {Jing Luo and Weibin Liu and Wen Qi and Jianwen Hu and Junming Chen and Chenguang Yang},
keywords = {Teleoperation, Robot learning, Vision-based virtual fixture, Force guidance, Control performance},
abstract = {Teleoperation plays a key role for semi-automated tasks with high complexity in remote working environment. By integrating the interaction information and control strategy, the control performance can be guaranteed by the skilled operator manipulation in terms of stability and precision. However, due to a lack of prolonged specialized training, the manipulation characteristics, such as operation habits and tremor for green hands, the control performance of teleoperation cannot be guaranteed, especially for complicated and refined tasks. To this end, a vision-based virtual fixture with robot learning approach is proposed for teleoperation. In the proposed method, a dynamic movement primitives method is utilized to learn the human tutor or skilled operator manipulation skill and then generates the expert trajectories for training of green hands. Additionally, considering the instantaneity of manipulation, a vision-based virtual fixture is utilized to generate a force selector based on position error and provides a force guidance to the green hands in order to enhance the precision of control with expert level and reduce the operation pressure. Comparative experimental results demonstrated the performance of the developed approach for teleoperation.}
}
@article{TIGARD2023104467,
title = {Toward best practices in embedded ethics: Suggestions for interdisciplinary technology development},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104467},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104467},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001069},
author = {Daniel W. Tigard and Maximilian Braun and Svenja Breuer and Konstantin Ritt and Amelia Fiske and Stuart McLennan and Alena Buyx},
keywords = {Interdisciplinary collaboration, Embedded ethics, AI ethics, Artificial intelligence, Robotics, Responsible robotics},
abstract = {With current developments in robotics and artificial intelligence (AI) comes an increased focus on the ethical production and use of such novel technologies. Accordingly, a trend toward “embedded ethics” is seen in recent research, reflecting an increase in efforts to integrate social and ethical considerations in computer science education and early in the development phases of AI and robotics. What remains to be established, however, is a more concrete understanding of the best working modalities for such interdisciplinary collaborations. In this brief discussion paper, we provide reflections derived from our interdisciplinary Responsible Robotics project which integrates ethicists and social scientists at early stages of development. We put forward several suggestions on how to integrate ethics and social science within technological development. We believe these suggestions can serve as a working taxonomy of best practices for embedded ethics.}
}
@article{CIPRIANO2023104495,
title = {Humanoid motion generation in a world of stairs},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104495},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104495},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001343},
author = {Michele Cipriano and Paolo Ferrari and Nicola Scianca and Leonardo Lanari and Giuseppe Oriolo},
keywords = {Humanoid robot, Footstep Planning, Gait Generation, MPC, Uneven ground, Sensor-based},
abstract = {Consider the problem of generating humanoid motions in an environment consisting of horizontal patches located at different heights (world of stairs). To this end, the paper proposes an integrated scheme which combines footstep planning and gait generation. In particular, footsteps are produced by a randomized algorithm that guarantees both feasibility and quality of the plan according to a chosen criterion; whereas for 3D gait generation we devise an ad hoc extension of the Intrinsically Stable MPC scheme. In its basic form, the proposed scheme addresses the off-line case (known environments), but a sensor-based adaptation is developed for the on-line case (unknown environments) based on an anytime version of the footstep planner. In order to validate the proposed approach, we present simulations in CoppeliaSim for the HRP-4 humanoid robot navigating scenarios of different complexity, both in the on-line and off-line case.}
}
@article{CAI2023104410,
title = {Cooperative Artificial Intelligence for underwater robotic swarm},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104410},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104410},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000490},
author = {Wenyu Cai and Ziqiang Liu and Meiyan Zhang and Chengcai Wang},
keywords = {Underwater robots, Artificial Intelligence, Swarm cooperation, Heuristic algorithms, Cooperative communication and navigation},
abstract = {Underwater Robots such as Autonomous Underwater Vehicles (AUVs) and Remotely Operated Vehicles (ROVs) has played an important role in many tasks, such as marine environmental monitoring, underwater resource exploration, oil and gas industries, hydrographic surveys, military missions, etc. Underwater robotic swarm is a team of cooperative underwater robots which focuses on controlling multiple underwater robots to work in an organic group. In contrast to a single underwater robot, underwater robotic swarm represents higher operation efficiency and better stability while executing complex tasks. However, it needs higher intelligence to realize complementary cooperation than a single robot. It is beneficial to researchers to present a comprehensive survey of the state of the art of cooperative research for underwater robotic swarm. We observe that the research of Artificial Intelligence (AI) for multiple underwater robots is still in an early stage. In this paper, we study different collaborative operation mode in detail, such as formation control, task allocation, path planning, obstacle avoidance, flocking control etc. We propose different classification frameworks for these research topics and it also can be used to compare different methods and help engineers choose suitable methods for various applications. To achieve better cooperative performance of underwater robots, there are several key factors, including multi-source heterogeneous sensing, cooperative communication and navigation, information fusion and decision. Moreover, cooperative AI for underwater robotic swarm has different kinds of interesting and helpful applications. Finally, several possible applied AI methods including meta-heuristic algorithms, deep learning method and distributed learning method are accomplishing to cooperation of underwater robotic swarm.}
}
@article{ZANCHETTIN2023104452,
title = {Symbolic representation of what robots are taught in one demonstration},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104452},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104452},
url = {https://www.sciencedirect.com/science/article/pii/S092188902300091X},
author = {Andrea Maria Zanchettin},
keywords = {Programming by demonstration, Semantic skill representation, Semantic scene description},
abstract = {To facilitate the use of robots in small and medium-sized enterprises (SMEs), they have to be easily and quickly deployed by non-expert users. Programming by Demonstration (PbD) is considered a fast and intuitive approach to handle this requirement. However, one of the major drawbacks of pure PbD is that it may suffer from poor generalisation capabilities, as it is mainly capable of motion-level representations. This work proposes a method to semantically represent a demonstrated skill, so as to identify the elements of the workspace that are relevant for the characterisation of the skill itself, as well as its preconditions and effects. This way, the robot can automatically abstract from the demonstration and memorise the skill in a more general way. An experimental case study consisting in a manipulation task is reported to validate the approach.}
}
@article{TIOZZOFASIOLO2023104514,
title = {Towards autonomous mapping in agriculture: A review of supportive technologies for ground robotics},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104514},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104514},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001537},
author = {Diego {Tiozzo Fasiolo} and Lorenzo Scalera and Eleonora Maset and Alessandro Gasparetto},
keywords = {Mobile robotics, Agriculture, Localization, Mapping, Path planning, Artificial intelligence},
abstract = {This paper surveys the supportive technologies currently available for ground mobile robots used for autonomous mapping in agriculture. Unlike previous reviews, we describe state-of-the-art approaches and technologies aimed at extracting information from agricultural environments, not only for navigation purposes but especially for mapping and monitoring. The state-of-the-art platforms and sensors, the modern localization techniques, the navigation and path planning approaches, as well as the potentialities of artificial intelligence towards autonomous mapping in agriculture are analyzed. According to the findings of this review, many examples of recent mobile robots provide full navigation and autonomous mapping capability. Significant resources are currently devoted to this research area, in order to further improve mobile robot capabilities in this complex and challenging field.}
}
@article{GERBL2023104417,
title = {Self-reconfiguration of PARTS: A parallel reconfiguration algorithm based on surface flow},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104417},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104417},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000568},
author = {Michael Gerbl and Johannes Gerstmayr},
keywords = {Extended binary trees, Self-reconfiguration, Modular robots, Triangular modules, Collision detection, Collision avoidance, Parallelization},
abstract = {In this paper, we present a parallel reconfiguration algorithm for shape-shifting modular robots with a triangular structure. The reconfiguration planning is based on partitioning the robot’s surface into source and sink sections for modules, using the largest common topology as a reference. Reconfiguration is realized by a synchronous surface flow of modules guided by the prior determination of module sources and sinks. Individual reconfiguration steps are carried out by a multi-step optimization framework, ensuring that intermediate configurations required for topology changes are valid and collision-free. With a configuration containing n modules, the algorithm completes the reconfiguration in O(n) reconfiguration steps and allows for a distributed and asynchronous hardware implementation. We demonstrate the performance of the proposed algorithm on multiple example configurations and compare the results to other reconfiguration approaches.}
}
@article{LI2023104445,
title = {TMG: A topology-based motion generalization method with spatial relationship preservation},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104445},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104445},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000842},
author = {Yihui Li and Jiajun Wu and Xiaohan Chen and Yisheng Guan and Haifei Zhu},
keywords = {Motion generalization, Topology representation, Spatial relationship preservation, Learning from demonstration, Imitation learning},
abstract = {As an important requirement, human-friendly motion in human–robot interaction (HRI) is increasingly attracting attention. In many scenarios, the ability to generalize a similar motion from demonstration is essential for a robot, and the similarity is generally captured by the spatial relationship between the different joints of the robot. Though a lot of investigation for motion generalization has been conducted and good progress achieved, they share limitations in leaving the relationship out of consideration and being difficult to apply the generalization between different robots. In this paper, we propose a novel topology-based motion generalization (TMG) method that abstracts the motion generalization problem to a mesh deformation optimization, and the spatial relationship between different parts of the robot is captured with a topology-based representation. Instead of only taking into account a single joint position, the relationship semantic with Laplacian coordinates is modeled, and the motion generalization from demonstration to reproduction is realized by preserving the semantic as a Laplacian deformation, and even the robot or target position is changed. Furthermore, motion generalization between single or multiple different robots can be achieved with spatial relationship preservation and transfer. Our experimental results show that the reproduction based on topology-based representation outperforms the mapping methods by training with end-effector pose or joint angles, and ensures robust motion with spatial relationship preservation.}
}
@article{GONZALEZSIERRA2023104433,
title = {Smooth collision avoidance for the formation control of first order multi-agent systems},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104433},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104433},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000726},
author = {Jaime González-Sierra and E.G. Hernandez-Martinez and Mario Ramírez-Neria and Guillermo Fernandez-Anaya},
keywords = {Collision avoidance, First-order agents, Multi-agent system, Observer, Formation control},
abstract = {This work addresses collision avoidance in the formation control of a group of mobile robots with first-order dynamics perturbed by lateral and longitudinal slipping parameters. A Generalized Proportional–Integral Observer (GPIO) is designed to estimate these perturbations. Then, an Active Disturbance Rejection Control (ADRC) is proposed to solve the well-known formation control avoiding collisions among the agents. The control strategy only depends on the agents’ position measurements. On the other hand, Continuous Repulsive Vector Fields (C-RVFs) are developed to avoid collisions among the agents. For this purpose, a parameter depending on the inter-robot distance is developed to scale the RVFs properly. By proposing C-RVFs, the chattering is eliminated when using Discontinuous RVFs (D-RVFs). Numerical simulations and real-time experiments illustrate the agents’ performance when they are at risk of collision.}
}
@article{PECKERMARCOSIG2023104404,
title = {Correct and efficient UAV missions based on temporal planning and in-flight hybrid simulations},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104404},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104404},
url = {https://www.sciencedirect.com/science/article/pii/S092188902300043X},
author = {Ezequiel Pecker-Marcosig and Sebastián Zudaire and Rodrigo Castro and Sebastián Uchitel},
keywords = {Controller synthesis, Hybrid simulation, Cyber–physical systems, LTL, DEVS},
abstract = {Controller synthesis has been successfully applied in UAV applications, to construct a mission plan that is guaranteed to be correct with respect to a user-provided specification. Albeit being correct, these plans may not be optimal in the vehicle’s trajectory, battery consumption, or other criteria which the user may consider relevant. A possibility would be to apply a quantitative synthesis approach where the target is to compute efficient plans before the mission, at a higher cost of complexity and potential limitations in the optimization goals to achieve. As an alternative, in this paper we propose doing the plan optimization in-flight. For this, we use available tools that synthesize controllers with multiple controllable choices and later select among these choices in-flight using hybrid simulations ranking them according to the optimization objective. We present the advantages of our approach and validate them using software-in-the-loop simulation with typical UAV mission scenarios.}
}
@article{SAVERIANO2023104510,
title = {Learning stable robotic skills on Riemannian manifolds},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104510},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104510},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001495},
author = {Matteo Saveriano and Fares J. Abu-Dakka and Ville Kyrki},
keywords = {Learning from Demonstration, Learning stable dynamical systems, Riemannian manifold learning},
abstract = {In this paper, we propose an approach to learn stable dynamical systems that evolve on Riemannian manifolds. Our approach leverages a data-efficient procedure to learn a diffeomorphic transformation, enabling the mapping of simple stable dynamical systems onto complex robotic skills. By harnessing mathematical techniques derived from differential geometry, our method guarantees that the learned skills fulfill the geometric constraints imposed by the underlying manifolds, such as unit quaternions (UQ) for orientation and symmetric positive definite (SPD) matrices for impedance. Additionally, the method preserves convergence towards a given target. Initially, the proposed methodology is evaluated through simulation on a widely recognized benchmark, which involves projecting Cartesian data onto UQ and SPD manifolds. The performance of our proposed approach is then compared with existing methodologies. Apart from that, a series of experiments were performed to evaluate the proposed approach in real-world scenarios. These experiments involved a physical robot tasked with bottle stacking under various conditions and a drilling task performed in collaboration with a human operator. The evaluation results demonstrate encouraging outcomes in terms of learning accuracy and the ability to adapt to different situations.}
}
@article{GOLMISHEH2023104486,
title = {Distributed safe formation maneuver control of Euler–Lagrange multi-agent systems in a partially unknown environment by safe reinforcement learning},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104486},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104486},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001252},
author = {Fatemeh Mahdavi Golmisheh and Saeed Shamaghdari},
keywords = {Control barrier function, Euler–Lagrange multi-agent system, Formation maneuver control, Multi-layer approach, Off-policy reinforcement learning, Safe reinforcement learning},
abstract = {This paper describes a multi-layer approach to the problem of safe formation control. The agents’ and the leader’s dynamics are considered unknown Euler–Lagrange (E-L) systems. In addition, the environment is partially unknown. We propose a novel layered approach to reach the predefined target while preserving a designed, safe, optimal formation pattern along a planned optimal path. By satisfying the safety constraints, safe reinforcement learning (RL) is introduced to ensure the leader reaches the desired destination without collision. Maintaining a constant formation pattern is unsafe for followers since they are not familiar with the surroundings. Thus, we define the formation maneuver control problem, which can adjust formation geomatical patterns dynamically depending on the environment. A proposed algorithm based on the leader’s designed path is defined to solve the problem. Using off-policy RL, the model-free distributed control law is presented to generate a designed formation pattern in a determined optimal path. Finally, we demonstrate that the proposed approach can be applied to the safe formation maneuver problem in an environment with convex obstacles. This paper presents a safe formation control strategy that addresses practical issues, such as model uncertainty, without requiring sensor measurements in an unknown, static environment without uncertainty. Simulation demonstrates the effectiveness of the suggested approaches for a group of Uncrewed Surface Vehicles (USVs).}
}
@article{JIANG2023104550,
title = {Stable skill improvement of quadruped robot based on privileged information and curriculum guidance},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104550},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104550},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001896},
author = {Han Jiang and Teng Chen and Jingxuan Cao and Jian Bi and Guanglin Lu and Guoteng Zhang and Xuewen Rong and Yibin Li},
keywords = {Deep reinforcement learning, Quadruped robots, Teacher–student policy, Synthetic terrain-command curriculum, Self-correction mechanism},
abstract = {Quadruped robots have attracted many researchers due to their unique advantages. In the field of control, deep reinforcement learning (DRL) saves the complex and tedious design of traditional control algorithms and motivates the robot to learn the motion patterns by itself, which is a promising alternative approach. However, due to the lack of prior information that is difficult to obtain in the physical world, policy usually exhibits a single motion state when faced with multiple scenarios. In this paper, we adopt a teacher–student policy architecture that uses the student policy to implicitly identify the teacher policy containing a privileged information, enabling the robot to adjust its motion depending on the environment it is in. We propose the synthetic terrain-command curriculum that assigns different levels of command curriculum depending on the difficulty of the terrain, which is useful for improving policy adaptation and stability. Policy is often trapped in local optima due to the nonlinearity of the robot system and unreasonable parameters. We propose a self-correction mechanism to jump out of this state in time, so that the policy can be steadily improved. We demonstrate our policy on the real quadruped platform named SDUQuad-48, and the results show that the learned policy exhibits state-of-the-art performance in both high-speed locomotion and complex terrain adaptation.}
}
@article{GHODSIAN2023104526,
title = {A framework to integrate mobile manipulators as cyber–physical systems into existing production systems in the context of industry 4.0},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104526},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104526},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001653},
author = {Nooshin Ghodsian and Khaled Benfriha and Adel Olabi and Varun Gopinath and Esma Talhi and Lucas A. Hof and Aurélien Arnou},
keywords = {Cyber–physical systems, Industry 4.0, Mobile manipulators, Integration framework},
abstract = {With the emergence of the Cyber–Physical Systems (CPSs) along with the fourth industrial revolution, the discussion of distributed architecture and coordination and extensive communication between all components of a system was raised. On the other hand, Modern industrial manufacturing relies heavily on flexible production. Autonomous mobile manipulators (MMs) have the potential to improve the flexibility of existing manufacturing environments. With the advantages associated with this technology, there is an upsurge in the demand for MMs. Thus, adding a new MM as a new CPS into a system following industry 4.0 requires a framework to help taking all the advantages from it. In this article, we proposed a framework to integrating MMs as CPSs into an existing production system. This integration requires comprehensive knowledge of the existing production process and control, which is a view to improve the performance of the existing production systems via new functionalities due to MMs. The next step of the framework is to make new MM operations compatible with the existing production control system. For this purpose, we define different parametric blocks to perform new operations and thus contribute to making the production line more autonomous. Considering all of these issues simultaneously is necessary for an efficient integration in smart production context. For a successful integration, we presented four principal dimensions of integration: Physical integration, communicational integration, functional and operational integration, and digital integration. Furthermore, the framework has been applied to a research production line called Platform 4.0 at Arts et Métiers. An MM from OMRON Company (called MoMa) has been integrated into the existing production system. Results from this real-world demonstration show that MoMa is capable of successfully increasing flexibility, autonomy, and efficiency of a production system using command signals from Manufacturing Execution System (MES).}
}
@article{HUANG2023104429,
title = {Quasi-static balancing for biped robot to perform extreme postures using ducted-fan propulsion system},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104429},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104429},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000684},
author = {Zhifeng Huang and Zijun Wang and Jinglun Zhou and Kairong Wu and Shunjie Zhu and Lei Nie and Yuwei Liang and Liang Yang and Yun Zhang},
keywords = {Biped robot, Ducted-fan propulsion system, Quasi-static balancing},
abstract = {Quasi-static balancing is important for enabling humanoid robots to move through extremely rugged terrain, e.g., stepping over a ditch whose width exceeds the robot’s leg length. In this study, to overcome such challenges, an innovative solution was developed, in which external thrust is utilized to maintain the robot’s balance. Initially, a model of the robot’s balance was established for analyzing the factors affecting the balance and the means to maintain it. Subsequently, a new controller combining a thrust controller and a center-of-mass controller was developed to compensate for errors in the thrust output and mass distribution. Finally, a new motion-planning method based on line search regression (LSR) and grid search optimization (GSO) was developed. A series of experiments were conducted using a prototype robot (Jet-HR3), including an error compensation test, an external force disturbance test, a comprehensive motion test, and an active sliding steering test. The results indicated the effectiveness and efficiency of the proposed method. The robot successfully crossed a ditch 695 mm wide, i.e., 147% of the robot’s leg length.}
}
@article{AOKI2023104405,
title = {Teleoperation by seamless transitions in real and virtual world environments},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104405},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104405},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000441},
author = {Junki Aoki and Fumihiro Sasaki and Ryota Yamashina and Ryo Kurazume},
keywords = {Teleoperation, Shared autonomy, Human–robot interaction, Virtual reality},
abstract = {This study investigates operability and acceptability issues in the teleoperation of robots. Prior studies have proposed efficient approaches to increase human perceptual ability and robot autonomy but with reduced operability and acceptance. We propose a novel teleoperation method that overcomes the weaknesses of existing approaches while inheriting their strengths. The key feature of our method is switching the teleoperated robot world from real to virtual. The user study results showed that the proposed method offered an improved user experience compared to the conventional methods, while task efficiency was equivalent in all methods. The contributions of this paper include the proposal of the teleoperation method by seamless switching between real and virtual space, the proposal of an image transformation method and visual effect to achieve seamless switching, and verification of the practicality of the proposed system through experiments on actual mobile robots.}
}
@article{BRUGALI2023104470,
title = {Modeling variability in self-adapting robotic systems},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104470},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104470},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001094},
author = {Davide Brugali},
keywords = {Robot architectures, Software variability, ROS},
abstract = {Autonomous robots operating in everyday environments, such as hospitals, private houses, and public roads, are context-aware self-adaptive systems, i.e. they exploit knowledge about their resources and the environment to trigger runtime adaptation, so that they exhibit a behavior adequate to the current context. For these systems, context-aware self-adaptation requires to design the robot control application as a dynamically reconfigurable software architecture and to specify the adaptation logic for reconfiguring its variable aspects (e.g. the modules that implement various obstacle detection algorithms or control different distance sensors) according to specific criteria (e.g. enhancing robustness against variable illumination conditions). Despite self-adaptation is an intrinsic capability of autonomous robots, ad-hoc approaches are used in practice to design reconfigurable robot architectures. In order to enhance system maintainability, the control logic and the adaptation logic should be loosely coupled. For this purpose, the adaptation logic should be defined against an explicit representation of software variability in the robot control architecture. In this paper we propose a modeling approach, which consists in explicitly representing robot software variability with the MARTE::ARM-Variability metamodel, which has been designed as an extension of the UML MARTE profile. We evaluate the applicability of the proposed approach by exemplifying the software architecture design of a robot navigation framework and by analyzing the support provided by the ROS infrastructure for runtime reconfiguration of its variable aspects.}
}
@article{KHADIVAR2023104461,
title = {Online active and dynamic object shape exploration with a multi-fingered robotic hand},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104461},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104461},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001008},
author = {Farshad Khadivar and Kunpeng Yao and Xiao Gao and Aude Billard},
keywords = {Active exploration, Multi-fingered robotic hand, Gaussian process implicit surface, Dynamic hand pose adaptation},
abstract = {The sense of touch can provide a robot with a wealth of information about the contact region when interacting with an unknown environment. Nevertheless, utilizing touch information to plan exploration paths and adjust robot posture to improve task efficiency remains challenging. This paper presents a novel approach for the online tactile surface exploration of unknown objects with a multi-degree of freedom robotic hand. We propose an exploration strategy that actively maximizes the entropy of the acquired data while dynamically balancing the exploration’s global knowledge and local complexity. We demonstrate that our method can efficiently control a multi-fingered robotic hand to explore objects of arbitrary shapes (e.g., with a handle, hole, or sharp edges). To facilitate efficient multi-contact exploration with a robotic hand, we offer an optimization-based planning algorithm that adapts the hand pose to the local surface geometry online and increases the kinematic configuration of each finger during exploration. Ultimately, we compared our approach to state of the art in a simulated environment. Experimental results indicate that our proposed methods can guide a multi-finger robotic hand to explore efficiently and smoothly, thereby reconstructing the unknown geometry of a variety of everyday objects, with significant improvements in data efficiency and finger compliance when compared to state-of-the-art approaches.}
}
@article{LI2023104416,
title = {Pose accuracy improvement in robotic machining by visually-guided method and experimental investigation},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104416},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104416},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000556},
author = {Bo Li and Yufei Li and Wei Tian and Wenhe Liao},
keywords = {Industrial robot, Pose accuracy, Robotic drilling and milling, Visual guidance},
abstract = {Industrial robots have been widely used in the industries of automotive, machining, electrical and electronic, rubber and plastics, aerospace, food, etc., owing to their high efficiency and flexibility in contrast to large scaled machining centers. However, the poor accuracy resulted from the serial configuration of industrial robots has restricted their applications to high-precision machining for several decades. In this paper, an error compensation technique is proposed using the visual guidance to effectively improve the pose accuracy of industrial robots. Firstly, the effect of the establishment method of tracking coordinate system for a visual sensor on the pose measurement error is analyzed and the establishment method is optimized. Next, a fuzzy PID controller is designed and integrated with a KUKA robot controller KRC via the KUKA robot sensor interface to guide the robot to the desired pose in real-time. Finally, experimental tests are implemented to validate the effectiveness of the proposed approach.}
}
@article{YANG2023104444,
title = {A lumen-adapted navigation scheme with spatial awareness from monocular vision for autonomous robotic endoscopy},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104444},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104444},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000830},
author = {Tao Yang and Yongming Yang and Peng Wang and Yang Cao and Zhuo Yang and Hao Liu},
keywords = {Autonomous navigation, Robotic endoscopy, Spatial awareness, Digital topology},
abstract = {Lumen is a common anatomical condition in endoscopic therapy or diagnostics. The navigation of autonomous robotic endoscopy usually involves vision techniques such as detection of lumen center or anatomically specific contour features. However, these methods may fail to achieve smooth interventions and result in large conveying force without spatial awareness of the tissue state. In this paper, a novel navigation pipeline based on a spatial-aware monocular vision is proposed. The spatial awareness pipeline starts with a data-driven depth estimation technique for reconstructing real-time approximate tissue surface. The spatial shape of the lumen described by the skeleton is then extracted using digital topology. We modify the skeleton to get a smooth pathway, and design an adaptive autonomous control strategy using geometric information from the pathway. We conduct experiments on a colon phantom and ex vivo pig intestines. We test turning performance of several bending segments with different angles in phantom, as well as the overall performance of a long-range intervention task in the phantom and pig intestines. The results show our navigation scheme achieve smoother intervention with lower conveying force. The proposed navigation method with spatial awareness can effectively improve the fluency of autonomous robotic endoscopy.}
}
@article{FENG2023104553,
title = {Measurement of mobile manipulator chassis pose change caused by suspension deformation and end-effector accuracy improvement based on multi-sensor fusion},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104553},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104553},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001926},
author = {Yixiao Feng and Xiangyu Tian and Tiemin Li and Yao Jiang},
keywords = {Mobile manipulator, Suspension, Data fusion, Error compensation},
abstract = {In order to expand the application of mobile manipulators in high-precision scenarios, researchers have focused on improving their accuracy. However, it is challenging to eliminate the impact of reference movement on manipulator accuracy during operation. Therefore, real-time measurement of manipulator reference and compensation of end pose are necessary. To address the inflexibility of global measurement schemes, this study proposes a method for obtaining the pose change of the chassis by fusing an inertial measurement unit (IMU) array and suspension displacement sensors. The IMU array is used to remove acceleration interference from the accelerometer and obtain the attitude of the chassis, while the kinematic analysis of the suspension is used to obtain the 6-degree-of-freedom (DoF) pose of the chassis. These two measurements are fused to improve attitude accuracy. The pose change of the chassis is filtered and used to generate a compensated manipulator pose through pose transformation. Finally, the inverse kinematics of the manipulator is used to compensate each joint. An experiment was conducted on a mobile manipulator, and the end position error was found to be less than 0.5 mm after chassis disturbance, demonstrating promising results.}
}
@article{FUSARO2023104524,
title = {Pyramidal 3D feature fusion on polar grids for fast and robust traversability analysis on CPU},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104524},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104524},
url = {https://www.sciencedirect.com/science/article/pii/S092188902300163X},
author = {Daniel Fusaro and Emilio Olivastri and Ivano Donadi and Daniele Evangelista and Emanuele Menegatti and Alberto Pretto},
keywords = {Traversability analysis, 3D LiDAR semantic segmentation, Autonomous driving, Machine learning},
abstract = {Self-driving vehicles and autonomous ground robots require a reliable and accurate method to analyze the traversability of the surrounding environment for safe navigation. This paper proposes and evaluates a real-time machine learning-based traversability analysis method that combines geometric features with a pyramid-polar space representation based on SVM classifiers. In particular, we show that by fusing geometric features with information stemming from coarser pyramid levels that account for a broader space portion, as well as integrating important implementation details, allows for a noticeable boost in performance and reliability. The main goal of this work is to demonstrate that traversability analysis is possible with effective results and in real-time even on cheaper hardware than expensive GPUs, e.g. CPU-only PCs. The proposed approach has been compared with state-of-the-art deep learning approaches on publicly available datasets of outdoor driving scenarios, running such algorithms both on GPU and CPU to compare runtimes. Our method can be fully executed on CPU and achieves results close to the best-in-class methods, runs faster, and requires fewer and less expensive hardware resources, consuming less than 30% electrical power with respect to deep learning models on embedded processing units. We release with this paper the open-source implementation of our method.}
}
@article{TIBONI2023104432,
title = {DROPO: Sim-to-real transfer with offline domain randomization},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104432},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104432},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000714},
author = {Gabriele Tiboni and Karol Arndt and Ville Kyrki},
keywords = {Robot learning, Transfer learning, Reinforcement learning, Domain randomization},
abstract = {In recent years, domain randomization over dynamics parameters has gained a lot of traction as a method for sim-to-real transfer of reinforcement learning policies in robotic manipulation; however, finding optimal randomization distributions can be difficult. In this paper, we introduce DROPO, a novel method for estimating domain randomization distributions for safe sim-to-real transfer. Unlike prior work, DROPO only requires a limited, precollected offline dataset of trajectories, and explicitly models parameter uncertainty to match real data using a likelihood-based approach. We demonstrate that DROPO is capable of recovering dynamic parameter distributions in simulation and finding a distribution capable of compensating for an unmodeled phenomenon. We also evaluate the method in two zero-shot sim-to-real transfer scenarios, showing successful domain transfer and improved performance over prior methods.}
}
@article{LAMPERTI2023104509,
title = {Distributed strategy for communication between multiple robots during formation navigation task},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104509},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104509},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001483},
author = {Rubisson Duarte Lamperti and Lucia Valéria Ramos {de Arruda}},
keywords = {Swarm robotics, Communication message, Formation control, Robot localization, Swarm intelligence},
abstract = {Swarm robotics involves the study of the behavior of a set of robots in carrying out collective tasks, such as alignment, navigation and formation. During cooperative tasks execution, the communication among robots can contribute to successfully performing tasks through an efficient messages exchange. This paper proposes a communication strategy for swarm robots, the so-called Double-Wave Swarm, aiming at alignment and navigation tasks. The Double-Wave Swarm is an improvement of a prior Wave Swarm communication approach that uses the concept of wave propagation for message exchange between neighbors. Double-Wave Swarm provides better communication network connectivity when compared to the former approach. Experiments with the robot simulator CoppeliaSim (V-REP) validate the proposed communication and highlight its efficiency and robustness while running alignment and navigation tasks. Also, the Double-Wave Swarm proved to be superior during swarm formation navigation into environments with obstacles in different scenarios if compared with Wave Swarm.}
}
@article{MULLER2023104485,
title = {Map point selection for visual SLAM},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104485},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104485},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001240},
author = {Christiaan J. Müller and Corné E. {van Daalen}},
keywords = {Visual SLAM, Submodular maximisation, Subset selection},
abstract = {Simultaneous localisation and mapping (SLAM) play a vital role in autonomous robotics. Robotic platforms are often resource-constrained, and this limitation motivates resource-efficient SLAM implementations. While sparse visual SLAM algorithms offer good accuracy for modest hardware requirements, even these more scalable sparse approaches face limitations when applied to large-scale and long-term scenarios. A contributing factor is that the point clouds resulting from SLAM are inefficient to use and contain significant redundancy. This paper proposes the use of subset selection algorithms to reduce the map produced by sparse visual SLAM algorithms. Information-theoretic techniques have been applied to simpler related problems before, but they do not scale if applied to the full visual SLAM problem. This paper proposes a number of novel information-theoretic utility functions for map point selection and optimises these functions using greedy algorithms. The reduced maps are evaluated using practical data alongside an existing visual SLAM implementation (ORB-SLAM 2). Approximate selection techniques proposed in this paper achieve trajectory accuracy comparable to an offline baseline while being suitable for online use. These techniques enable the practical reduction of maps for visual SLAM with competitive trajectory accuracy. Results also demonstrate that SLAM front-end performance can significantly impact the performance of map point selection. This shows the importance of testing map point selection with a front-end implementation. To exploit this, this paper proposes an approach that includes a model of the front-end in the utility function when additional information is available. This approach outperforms alternatives on applicable datasets and highlights future research directions.}
}
@article{CRISAFULLI2023104549,
title = {Modeling and analysing Cyber–Physical Systems in HOL-CSP},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104549},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104549},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001884},
author = {Paolo Crisafulli and Safouan Taha and Burkhart Wolff},
keywords = {Cyber–Physical Systems, Autonomous cars, Safety-critical systems, Process-algebra, Concurrency, Proof-based verification},
abstract = {Modelling and Analysing Cyber–Physical Systems (CPS) is a challenge for Formal Methods and therefore a field of active research. It is characteristic of CPSs that models comprise aspects of Newtonian Physics appearing in system environments, the difficulties of their discretization, the problems of communication and interaction between actors in this environment as well as calculations respecting time-bounds. We present a novel framework to address these problems developed with industrial partners involved in the Autonomous Car domain. Based on HOL-CSP, we model time, physical evolution, “scenes” (global states) and “scenarios” (traces) as well as the interaction of “actors” (vehicles, pedestrians, traffic lights) inside this framework. In particular, discrete samplings are modelled by infinite internal choices. For several instances of the modelling framework, we give formal proofs of a particular safety property for Autonomous Cars: if each car follows the same driving strategy defined by the so-called Responsibility-Sensitive Safety (RSS), no collision will occur. The proofs give rise to a number of variants of RSS and optimizations as well as a test-case partitioning of abstract test cases and a test-strategy for integration tests.}
}
@article{KINNARI2023104497,
title = {LSVL: Large-scale season-invariant visual localization for UAVs},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104497},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104497},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001367},
author = {Jouko Kinnari and Riccardo Renzulli and Francesco Verdoja and Ville Kyrki},
keywords = {UAV, Localization, Wake-up robot problem, Seasonal appearance change},
abstract = {Localization of autonomous unmanned aerial vehicles (UAVs) relies heavily on Global Navigation Satellite Systems (GNSS), which are susceptible to interference. Especially in security applications, robust localization algorithms independent of GNSS are needed to provide dependable operations of autonomous UAVs also in interfered conditions. Typical non-GNSS visual localization approaches rely on known starting pose, work only on a small-sized map, or require known flight paths before a mission starts. We consider the problem of localization with no information on initial pose or planned flight path. We propose a solution for global visual localization on large maps, based on matching orthoprojected UAV images to satellite imagery using learned season-invariant descriptors, and test with environment sizes up to 100 km2. We show that the method is able to determine heading, latitude and longitude of the UAV at 12.6–18.7 m lateral translation error in as few as 23.2–44.4 updates from an uninformed initialization, also in situations of significant seasonal appearance difference (winter–summer) between the UAV image and the map. We evaluate the characteristics of multiple neural network architectures for generating the descriptors, and likelihood estimation methods that are able to provide fast convergence and low localization error. We also evaluate the operation of the algorithm using real UAV data and evaluate running time on a real-time embedded platform. We believe this is the first work that is able to recover the pose of an UAV at this scale and rate of convergence, while allowing significant seasonal difference between camera observations and map.}
}
@article{REYES2023104525,
title = {Visual-RRT: Integrating IBVS as a steering method in an RRT planner},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104525},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104525},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001641},
author = {Ramses Reyes and Israel Becerra and Rafael Murrieta-Cid and Seth Hutchinson},
keywords = {Feedback-based motion planning, Image-based visual servo control, Nonholonomic constraints, Rapidly exploring random trees},
abstract = {In this paper, we present a new approach to robot motion planning that anticipates the use of vision-based feedback control during task execution. We accomplish this by incorporating an image-based visual servo (IBVS) controller directly into the steering function used by a Rapidly Exploring Random Tree (RRT) planner. Our approach requires a number of extensions to traditional RRT-style planning. First, we derive a new sampling strategy that augments the usual state information by including image features that will be used by the IBVS control law. These augmented samples are then used by our new IBVS steering function, which simulates an IBVS control law to generate local trajectories that extend the current tree. These trajectories must be validated to ensure that they are collision-free and that all image features remain unoccluded and within the camera field of view throughout the local trajectory. We also provide a formal proof showing that the proposed approach is probabilistically complete. We have applied our approach to the problem of planning trajectories for three different systems: a robotic arm, an unmanned aerial vehicle (UAV) and a car-like robot, which are equipped with an IBVS control law. We explore performance trade-offs in the control design via simulation studies and demonstrate real-world effectiveness via experiments in which a small-scale car-like robot uses IBVS to navigate a track that includes a number of obstacles and potential occlusions. By exploring performance trade-offs, we mean that several elements, such as the metric used to identify nearest neighbors in the RRT and the steering method used to generate nodes, are tested and compared.}
}
@article{FORSTER2023104428,
title = {Automatic extension of a symbolic mobile manipulation skill set},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104428},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104428},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000672},
author = {Julian Förster and Lionel Ott and Juan Nieto and Nicholas Lawrance and Roland Siegwart and Jen Jen Chung},
keywords = {Skill representation learning, Learning to plan, Task and motion planning},
abstract = {Symbolic planning can provide an intuitive interface for non-expert users to operate autonomous robots by abstracting away much of the low-level programming. However, symbolic planners assume that the initially provided abstract domain and problem descriptions are closed and complete. This means that they are fundamentally unable to adapt to changes in the environment or tasks that are not captured by the initial description. We propose a method that allows an agent to automatically extend the abstract description of its skill set upon encountering such a situation. We introduce strategies for generalizing from previous experience, completing sequences of key actions and discovering preconditions to ensure computational efficiency. The resulting system is evaluated on a symbolic planning benchmark task and on object rearrangement tasks in simulation. Compared to a Monte Carlo Tree Search baseline, our strategies for efficient search have on average a 25% higher success rate at a 67% faster runtime. Code is available at https://github.com/ethz-asl/high_level_planning.}
}
@article{COSTA2023104469,
title = {Online learning of MPC for autonomous racing},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104469},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104469},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001082},
author = {Gabriel Costa and João Pinho and Miguel Ayala Botto and Pedro U. Lima},
keywords = {Learning Model Predictive Control, Model learning, Motion and path planning, Autonomous racing},
abstract = {A Learning-based Model Predictive Control (LMPC) algorithm is proposed for a Formula Student (FS) autonomous vehicle. The online learning algorithm has two distinct roles: to improve the dynamic model accuracy of the vehicle used in the MPC, while performing online tuning of the model predictive controller parameters. The developed controller is shown to reduce the total lap time through an iterative learning process as the vehicle progresses on track. To capture the full complexity of the nonlinear higher order dynamics, an Artificial Neural Network (ANN) complements the vehicle’s nominal model. The ANN is trained using an online supervised learning scheme based on past model prediction errors. Additionally, a Genetic Algorithm (GA) is used to iteratively find the optimal set of controller parameters that maximizes a reward function. Several simulation tests performed on real examples of competition tracks demonstrate the effectiveness of the approach. Moreover, it is shown that the combination of both online learning methods is able to significantly improve tracking performance of the FS vehicle, eventually reducing the total lap time by over 16%.}
}
@article{SUBBURAMAN2023104443,
title = {A survey on control of humanoid fall over},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104443},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104443},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000829},
author = {Rajesh Subburaman and Dimitrios Kanoulas and Nikos Tsagarakis and Jinoh Lee},
keywords = {Humanoid fall, Legged robot fall, Fall detection, Controlled fall, Fall recovery},
abstract = {Humanoid robot operation requires balancing to prevent failures, such as fall over. This is a crucial task in legged robots and thus several researchers are working on this topic. Fall prediction, controlled fall, and fall recovery become important topics in understanding robot control and allow legged robots to function in challenging real-world environments. This paper aims at setting up methodically the problem definition of humanoid falling and further identifying and surveying working techniques in the literature. The focus is to categorize all methods that were used in the community, identify the solved and open questions, as well as propose directions of research in the field. The paper is based on experimental research that has been done on a full-size humanoid robot.}
}
@article{LEE2023104447,
title = {Design of 9-DOF humanoid arms inspired by the human’s inner shoulder to enhance versatility and workspace},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104447},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104447},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000866},
author = {Jaesoon Lee and Baek-Kyu Cho},
keywords = {Humanoid design, Manipulator, Kinematic analysis, Redundant manipulator control, Null space projection},
abstract = {Many humanoid arms have six degrees-of-freedom (DOFs), similar to the human joint configuration. Moreover, humanoid arms with 7-DOF or 8-DOF have been designed to enhance the range of motion or structural versatility. Notably, these arms exhibit structural limitations and thus cannot effectively implement versatile and complex motions such as valve closing motion. To address this problem, this paper proposes a novel 9-DOF humanoid arm, named RoK-Arm9, inspired by the human inner shoulder. Two additional joints are introduced inside the shoulder to increase the versatility and workspace. To demonstrate the superiority of RoK-Arm9 over the existing robots for complex dual-arm manipulation, we analyzed the corresponding manipulability measure, bimanual task areas, and dual-arm manipulability measure. Finally, we confirmed that the actual RoK-Arm9 can conduct the same motion as the simulation.}
}
@article{LI2023104528,
title = {Online trajectory optimization for safe autonomous overtaking with active obstacle avoidance},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104528},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104528},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001677},
author = {Guoqiang Li and Hongliang Guo and Zhenpo Wang and Meng Wang},
keywords = {Autonomous overtaking, Trajectory optimization, Object avoidance, Receding horizon, Dual optimization},
abstract = {Autonomous driving with active obstacle avoidance in dynamic urban environment has attracted significant attention to improve road safety and traffic efficiency. In this paper, an online optimization-based trajectory planning method for autonomous overtaking is developed to prevent collision and realize safe efficient driving. Unlike traditional methods which solve the overtaking problem with segmented reference path in multi-stages with integer variables, this paper proposes a novel dual-variable trajectory planning framework to get the optimal trajectory for active collision avoidance. First, the nonlinear non-differentiable collision-free constraint between vehicles is reformulated using dual problem optimization. Then, the optimal trajectory for longitudinal and lateral movement is obtained jointly in a receding horizon optimization framework based on the optimized dual variable considering the safety and dynamic performance. The key novelty lies in the reformulation of the nonlinear optimal trajectory planning problem and the formulated whole optimization framework can be solved using efficient open-source solvers for online computation. Simulation studies in different dynamic cases are provided to show the efficiency and robustness for safe driving. The method reaches safe overtaking performance with much less calculation time. Real-world experiment with a static obstacle demonstrates its capability for the safe efficient trajectory planning and online implementation in autonomous driving.}
}
@article{XIE2023104411,
title = {A robust and compliant framework for legged mobile manipulators using virtual model control and whole-body control},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104411},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104411},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000507},
author = {Aizhen Xie and Teng Chen and Xuewen Rong and Guoteng Zhang and Yibin Li and Yong Fan},
keywords = {Dynamic manipulation, Virtual model control, Whole-body control, Quadruped robot},
abstract = {Quadruped robots can mimic animal locomotion mode and have great potential usage in unstructured environments. However, as mobile platforms, quadruped robots often lack manipulation capabilities. In this project, we equipped the quadruped robot SDU-ADog with a torque-controlled 6-DOF arm. A novel control framework which combines virtual model control (VMC) and prioritized whole-body control (WBC) for the whole system is proposed in this paper. VMC finds optimal target ground reaction forces while compensating the arm’s inertia, and then makes the robot compliant to external disturbance. Prioritized WBC deals with multiple tasks in an optimal fashion and achieves efficiency and robustness of robot’s locomotion and manipulation. The effectiveness of our framework has been evaluated through a set of robot dynamic simulations conducted in Webots. The robot can finish balance maintaining with moving arm, fixed point tracking while trotting, and locomotion over different obstacles with an end-point task.}
}
@article{ZHANG2023104544,
title = {Simultaneous search and monitoring by multiple aerial robots},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104544},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104544},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001835},
author = {Haoyu Zhang and Sandor Veres and Andreas Kolling},
keywords = {Search, Monitoring, POMDP, semi-Dec-POMDP, Multi-agent cooperation, Heuristic reactive policy planning},
abstract = {This paper studies simultaneous search and monitoring (SSM) between multiple unmanned aerial vehicles (UAVs) and multiple moving ground targets. Searching for unknown targets and monitoring known ones are two intrinsically related problems, but they have mostly been addressed in isolation. We combine the two tasks and exploit their interconnection as a synergy rather than a trade-off. We construct the single-robot SSM as a partially observable Markov decision process (POMDP) and the multi-robot SSM as a semi-decentralised POMDP (semi-Dec-POMDP). A novel heuristic reactive policy planning is proposed to solve the POMDP. It is then extended for semi-Dec-POMDP with game-theoretical methods. In simulations and experiments, the searchers will successfully locate unknown targets without losing known ones and cooperate by partitioning their tasks. With theoretical proofs, simulations, and experiments, we demonstrate that our method can perform better than conventional approaches and the state-of-the-art.}
}
@article{CHAKRAA2023104492,
title = {Optimization techniques for Multi-Robot Task Allocation problems: Review on the state-of-the-art},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104492},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104492},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001318},
author = {Hamza Chakraa and François Guérin and Edouard Leclercq and Dimitri Lefebvre},
keywords = {Multi-Robot System (MRS), Multi-Robot Task Allocation (MRTA), Dynamic task allocation, Optimization-based techniques},
abstract = {In the last years, Multi-Robot Systems (MRS) have experienced considerable recognition due to various possible real-world applications. Multi-Robot Task Allocation (MRTA) is among the most interesting MRS problems. This problem concerns the situation when a set of given tasks must be performed by a team of mobile robots with the intention of optimizing an objective function (e.g., minimizing the mission time). This paper aims to present MRTA applications and categorizes methods into market-based, behavior-based, and optimization-based approaches. The paper focus on the latter and review several works in order to point out their advantages and limitations and to identify possible future research opportunities. Furthermore, a statistical analysis is provided to identify the most used methods and the evolution of the topic over the years.}
}
@article{NENCHEV2023104488,
title = {Model checking embedded adaptive cruise controllers},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104488},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104488},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001276},
author = {Vladislav Nenchev},
keywords = {Automated driving, Autonomous vehicles, Adaptive cruise control, Model checking, Software verification},
abstract = {While checking functional correctness for automated driving is often achieved through vast amounts of automated and manual field testing, automating specification verification is essential for developing and releasing fully self-driving vehicles. This paper presents an automatic bounded model checking approach for functional specifications over longitudinal vehicle controller implementations. The proposed method checks the actual embedded program, rather than an extracted abstract model. The specification is converted into a monitor that is interleaved with the execution of the program over a finite time horizon in closed-loop simulation. A decomposition is proposed to tackle the verification complexity. This allows verifying the program for whole parameter sets using a software model checker as opposed to testing only individual samples. The approach is capable of identifying functional flaws in several exemplary longitudinal controllers with variable complexity.}
}
@article{SABET2023104464,
title = {Scalable modular synthetic data generation for advancing aerial autonomy},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104464},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104464},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001033},
author = {Mehrnaz Sabet and Praveen Palanisamy and Sakshi Mishra},
keywords = {Aerial autonomy, Drone, Synthetic data, Sim-to-real, Domain randomization},
abstract = {One major barrier to advancing aerial autonomy has been collecting large-scale aerial datasets for training machine learning models. Due to costly and time-consuming real-world data collection through deploying drones, there has been an increasing shift towards using synthetic data for training models in drone applications. However, to increase widespread generalization and transferring models to real-world, increasing the diversity of simulation environments to train a model over all the varieties and augmenting the training data, has been proved to be essential. Current synthetic aerial data generation tools either lack data augmentation or rely heavily on manual workload or real samples for configuring and generating diverse realistic simulation scenes for data collection. These dependencies limit scalability of the data generation workflow. Accordingly, there is a major challenge in balancing generalizability and scalability in synthetic data generation. To address these gaps, we introduce a scalable Aerial Synthetic Data Augmentation (ASDA) framework tailored to aerial autonomy applications. ASDA extends a central data collection engine with two scriptable pipelines that automatically perform scene and data augmentations to generate diverse aerial datasets for different training tasks. ASDA improves data generation workflow efficiency by providing a unified prompt-based interface over integrated pipelines for flexible control. The procedural generative approach of our data augmentation is performant and adaptable to different simulation environments, training tasks and data collection needs. We demonstrate the effectiveness of our method in automatically generating diverse datasets and show its potential for downstream performance optimization. Our work contributes to generating enhanced benchmark datasets for training models that can generalize better to real-world situations. Video: youtube.com/watch?v=eKpOh-K-NfQ}
}
@article{MALVIDOFRESNILLO2023104556,
title = {A method for understanding and digitizing manipulation activities using programming by demonstration in robotic applications},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104556},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104556},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001951},
author = {Pablo {Malvido Fresnillo} and Saigopal Vasudevan and Wael M. Mohammed and Jose L. {Martinez Lastra} and José A. {Pérez García}},
keywords = {Robot Programming by Demonstration, Motion intention recognition, Markov Models, Knowledge based systems, Automatic process segmentation},
abstract = {Robots are flexible machines, where the flexibility is achieved, mainly, by the re-programming of the robotic system. To fully exploit the potential of robotic systems, an easy, fast, and intuitive programming methodology is desired. By applying such methodology, robots will be open to a wider audience of potential users (i.e. SMEs, etc.) since the need for a robotic expert in charge of programming the robot will not be needed anymore. This paper presents a Programming by Demonstration approach dealing with high-level tasks taking advantage of the ROS standard. The system identifies the different processes associated to a single-arm human manipulation activity and generates an action plan for future interpretation by the robot. The system is composed of five modules, all of them containerized and interconnected by ROS. Three of these modules are in charge of processing the manipulation data gathered by the sensors system, and converting it from the lowest level to the highest manipulation processes. In order to do this transformation, a module is used to train the system. This module generates, for each operation, an Optimized Multiorder Multivariate Markov Model, that later will be used for the operations recognition and process segmentation. Finally, the fifth module is used to interface and calibrate the system. The system was implemented and tested using a dataglove and a hand position tracker to capture the operator’s data during the manipulation. Four users and five different object types were used to train and test the system both for operations recognition and process segmentation and classification, including also the detection of the locations where the operations are performed.}
}
@article{YANG2023104504,
title = {A multi-locomotion clustered tensegrity mobile robot with fewer actuators},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104504},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104504},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001434},
author = {Qi Yang and Xinyu Liu and Panfeng Wang and Yimin Song and Tao Sun},
keywords = {Multi-locomotion bionic robot, Fewer actuators, Tensegrity, High load-to-mass ratio, Low energy consumption},
abstract = {Mobile robots with multi locomotion modes have excellent terrain adaptability. However, traditional multi-locomotion mobile robots are usually actuated by a large number of motors, making their structures heavy and bulky. As a result, the controls become complex, the load-to-mass ratio is low, and the energy consumption is high. Inspired by the bio-mechanism of worms, a novel tensegrity-based multi-locomotion mobile robot, named TJUBot, has been designed. It is actuated by only two motors, yet it has the potential to realize three locomotion modes: earthworm-like, inchworm-like, and tumbling locomotion. The design of these three locomotion modes has been implemented based on kinematic and dynamic models, and the driving law of the two motors under each locomotion mode has been established. Notably, the robot’s locomotion has been analyzed under five different terrains. A laboratory prototype of TJUBot has been developed, and experiments demonstrate that the robot can adjust to five types of terrains using the three locomotion modes. For instance, on flat ground, it achieves a maximum velocity of 2.34 BL/min, and it can pass through confined spaces with a minimum height of 1.26 BH. Moreover, the robot can climb slopes with a maximum angle of 7°, overcome obstacles with a maximum height of 0.52 BH, and traverse gaps with a maximum width as 0.35 BL. Herein, BL and BH represent the body length and body height of the robot, respectively. In addition, TJUBot exhibits outstanding performance in terms of its load-to-mass ratio, which is measured at 5.56, and its low energy consumption of 0.69J/m, as observed in experiments. The promising results obtained from these experiments indicate that TJUBot holds significant potential for applications in multi-terrain environments.}
}
@article{CALANCA2023104407,
title = {Force control of lightweight series elastic systems using enhanced disturbance observers},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104407},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104407},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000465},
author = {Andrea Calanca and Enrico Sartori and Bogdan Maris},
keywords = {Force control, Series elastic actuators, Disturbance observers},
abstract = {This paper analyzes the control challenges associated to lightweight series elastic systems in force control applications, showing that a low end-point inertia can lead to high sensitivity to environment uncertainties. Where mainstream force control methods fail, this paper proposes a control methodology to enhance the performance robustness of existing disturbance observers (DOBs). The approach is validated experimentally and successfully compared to basic control solutions and state of the art DOB approaches.}
}
@article{ANAND2023104531,
title = {Model-based variable impedance learning control for robotic manipulation},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104531},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104531},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001707},
author = {Akhil S. Anand and Jan Tommy Gravdahl and Fares J. Abu-Dakka},
keywords = {Variable impedance control, Model predictive control, Robot learning},
abstract = {The capability to adapt compliance by varying muscle stiffness is crucial for dexterous manipulation skills in humans. Incorporating compliance in robot motor control is crucial for enabling real-world force interaction tasks with human-like dexterity. In this study, we introduce a novel approach, we call “deep Model Predictive Variable Impedance Controller (MPVIC)” for compliant robotic manipulation, which combines Variable Impedance Control with Model Predictive Control (MPC). The method involves learning a generalized Cartesian impedance model of a robot manipulator through an exploration strategy to maximize information gain. Within the MPC framework, this learned model is utilized to adapt the impedance parameters of a low-level variable impedance controller, thereby achieving the desired compliance behavior for various manipulation tasks without requiring retraining or finetuning. We assess the efficacy of the proposed deep MPVIC approach using a Franka Emika Panda robotic manipulator in simulations and real-world experiments involving diverse manipulation tasks. Comparative evaluations against model-free and model-based reinforcement learning approaches in variable impedance control are conducted, considering aspects such as transferability between tasks and performance. The results demonstrate the effectiveness and potential of the presented approach for advancing robotic manipulation capabilities.}
}
@article{ZHAO2023104491,
title = {Towards One Shot & Pick All: 3D-OAS, an end-to-end framework for vision guided top-down parcel bin-picking using 3D-overlapping-aware instance segmentation and GNN},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104491},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104491},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001306},
author = {Yi Zhao and Jiacheng Yang and Shaocong Wang and Xiaohui Li},
keywords = {Parcel bin-picking, Vision guided robotic grasping, 3D overlapping-aware instance segmentation},
abstract = {Robotic Grasping and sorting is acknowledged as the most fundamental and significant manipulation task in industry. An ultimate goal of a Vision guided Robotic grasping system is to precisely and efficiently sort maximum objects with minimum inference time of vision system. So far, applicable end-to-end perception and autonomously picking of hierarchically stacked objects has not been intensively reported in previous works. Especially, in the scenario of top-down parcel bin-picking where robots are required to perceive and pick up parcels from random stacks. In this work, we focus on this challenging task by putting forward a novel end-to-end parcel bin-picking model termed 3D-OAS. Our proposal combines a 3D overlapping-aware instance segmentation and directed graph to describe the hierarchical structure of stacked objects from a top-down angle and a graph-neural-network is introduced to solve the optimal sorting orders. The experiment was conducted via a set of Vision guided Delta-Parallel robotic grasping system with a top-down RGB-D camera. Experimental Results proved the feasibility of our proposal, it could hierarchically segment stacked objects and solve sorting sequence with minimum one shot.}
}
@article{CHGHAF2023104446,
title = {A multimodal loop closure fusion for autonomous vehicles SLAM},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104446},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104446},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000854},
author = {Mohammed Chghaf and Sergio Rodríguez Flórez and Abdelhafid El Ouardi},
keywords = {SLAM, Camera, LiDAR, Localization, Loop closure, Mapping, Fusion, Multimodal},
abstract = {Place recognition and loop closure detection are critical steps in the process of Simultaneous Localization and Mapping (SLAM). Indeed, the ability to determine whether an Autonomous Ground Vehicle (AGV) has returned to a previously visited place is highly important in the context of building a reliable SLAM system. In order to build a consistent global map and to localize the AGV with high confidence in an unknown environment, it is crucial to reduce the cumulative error generated by pose estimation. Although multiple approaches using various data sources have been proposed in order to provide an accurate pose estimation, fewer studies have focused on the integration of a multimodal process to detect loop closure. In this work, we present a novel approach to leverage multiple modalities for a robust and reliable loop closure detection. Our method is based on Similarity-Guided Particle Filtering (SGPF) for the search and validation of Loop Closure Candidates (LCCs). We validate the proposed Multimodal Loop Closure (MMLC) by using two perception modalities based on Bag-of-Words and Scan Context techniques for camera-based and LiDAR-based place recognition, respectively. The efficiency of our method has been evaluated on both KITTI and a self-collected dataset. Compared to the classical loop closure used in ORB-SLAM2, the suggested approach reduces the Absolute Trajectory Error (ATE) by up to 54% and the cumulative error during run-time by up to 62.63%. Finally, 100% of the loops are accurately detected and the ground truth distance between the current pose and the LC is less than 3 m in 98% of the cases.}
}
@article{SANGEETHA2023104515,
title = {Performance analysis of buck converter with fractional PID controller using hybrid technique},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104515},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104515},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001549},
author = {S. Sangeetha and B. Sri Revathi and K. Balamurugan and Suresh G.},
keywords = {PID controller, Buck converter, Fractional order PID, Switching source, Pulse width modulation, Error signal},
abstract = {In this paper, a hybrid technique is proposed for analyzing the performance of buck converters with fractional-order proportional integral derivative (FOPID) controllers. The hybrid approach is a combination of Capuchin Search Algorithm (CapSA) and Golden Jackal Optimization (GJO). The update behavior of Golden Jackal Optimization2 is enhanced with Capuchin Search Algorithm (CapSA) therefore it is called the improved GJO (IGJO) technique. The power converters are hard to manage based on their nonlinear nature and therefore the search for smart and effectual controllers is ongoing and continual. In current years, fractional order controllers have shown greater efficiency in power electronic systems. The IGJO technique is used to establish the optimum design of a fractional-order proportional integral derivative (PID) controller for the buck converter. The FOPID controller parameters are considered to diminish several performance metrics, with a particular focus on the Integral Squared Error (ISE). The proposed method is performed in the MATLAB, and its execution is analyzed by using the existing methods. From the simulation result, the proposed method reduces the error more effectively than existing methods.}
}
@article{LUKYANENKO2023104487,
title = {Probabilistic motion planning for non-Euclidean and multi-vehicle problems},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104487},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104487},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001264},
author = {Anton Lukyanenko and Damoon Soudbakhsh},
keywords = {Nonholonomic motion planning, Motion and trajectory planning, Trajectory planning for multiple mobile robots, Cooperative robots and multi-robot systems},
abstract = {Trajectory planning tasks for non-holonomic or collaborative systems are naturally modeled by state spaces with non-Euclidean metrics. However, existing proofs of convergence for sample-based motion planners only consider the setting of Euclidean state spaces. We resolve this issue by formulating a flexible framework and set of assumptions for which the widely-used PRM*, RRT, and RRT* algorithms remain asymptotically optimal in the non-Euclidean setting. The framework is compatible with collaborative trajectory planning: given a fleet of robotic systems that individually satisfy our assumptions, we show that the corresponding collaborative system again satisfies the assumptions and therefore has guaranteed convergence for the trajectory-finding methods. Our joint state space construction builds in a coupling parameter 1≤p≤∞, which interpolates between a preference for minimizing total energy at one extreme and a preference for minimizing the travel time at the opposite extreme. We illustrate our theory with trajectory planning for simple coupled systems, fleets of Reeds–Shepp vehicles, and a highly non-Euclidean fractal space.}
}
@article{EYUBOGLU2023104527,
title = {A novel collaborative path planning algorithm for 3-wheel omnidirectional Autonomous Mobile Robot},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104527},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104527},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001665},
author = {Meltem Eyuboglu and Gokhan Atali},
keywords = {Path planning, Obstacle avoidance, Collaborative AMRs, Three-wheel omnidirectional mobile robot, Simultaneously motion},
abstract = {Collaboration of multiple mobile robots becomes important in situations where collaborative tasks are required. For this purpose, a method including obstacle detection based on collaborative path planning of multiple Autonomous Mobile Robots (AMRs) has been developed. This study ensures the usability of collaborative omnidirectional AMRs technologies in various fields. In the study, novel path planning and obstacle avoidance algorithms are developed for collaborative mobile robots with omnidirectional mobility. Essentially, these algorithms include motion planning performed by obstacle avoidance with two identical 3-wheel omnidirectional mobile robots (TWOMR). Numerical calculations of the collaborative algorithm have been performed after the kinematic calculations, and tested algorithms developed for the proposed model. As a result, it has been observed that the path planning and obstacle avoidance algorithms developed for collaborative omnidirectional AMRs successfully follow the Master robot in the most efficient trajectory without collision and it has been observed that the developed method works with high accuracy.}
}
@article{CHEN2023104430,
title = {Direction constraints adaptive extended bidirectional A* algorithm based on random two-dimensional map environments},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104430},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104430},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000696},
author = {Jiqing Chen and Mingyu Li and Yousheng Su and Wenqu Li and Yizhong Lin},
keywords = {Path planning, Bidirectional A* algorithm, Adaptive extension, Constraint expansion},
abstract = {This paper focuses on the mobile robot path planning problem of optimizing the performance metrics of bidirectional A* algorithm in randomized two-dimensional map environments. An algorithm called direction constraints adaptive extended bidirectional A* (DCAE-BA*), which is an improvement of the traditional target dynamic bidirectional A* algorithm (TTD-BA*), is proposed to improve the performance metrics of the algorithm. Regarding the improvement, we propose the adaptive extension method and the direction-constrained optimal node extension method (DCONE). Simulation experiments were conducted for DCAE-BA*, TTD-BA* and traditional A* algorithm (A*) in a large number of random two-dimensional map environments. The simulation experimental scenarios consider four types of start and end point relative directions and three obstacle proportions to objectively and comprehensively evaluate the performance of the proposed algorithms. The results show that different scenarios have a significant impact on the algorithm performance metrics. Finally, the overall performance of the proposed algorithm is evaluated with a large number of experiments in “random” scenarios, and the results show that DCAE-BA* obtains significantly better search time for all three obstacle proportions, and better path length and number of expanded nodes for 10% and 25% obstacle proportions. The effectiveness of the proposed DCAE-BA* algorithm is demonstrated, which provides an essential reference for the path planning of mobile robots in a random 2D map environment.}
}
@article{TENG2023104406,
title = {Fuzzy dynamical system for robot learning motion skills from human demonstration},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104406},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104406},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000453},
author = {Tao Teng and Matteo Gatti and Stefano Poni and Darwin Caldwell and Fei Chen},
keywords = {Learning from demonstration, Motion planning, Fuzzy inference system, Fuzzy rules},
abstract = {Learning from demonstration (LfD) is an intuitive strategy for transferring human motion skills to robots in an agile and adaptable manner. The major goal of LfD is to identify significant movement primitives (MPs) from human demonstrations and then recompose those intrinsic primitives to adapt to a variety of new situations. However, maintaining the simplicity of MPs representation while guaranteeing their adaptability is not an easy undertaking. To achieve these two goals, two approaches are possible: (1) learning models that can capture and utilize the inherent patterns and main characteristics of the human demonstrations, and (2) dynamical systems that can respond to perturbations online without requiring to re-plan the entire trajectory. In this paper, we present a novel and efficient model that combines these two benefits to formulate MPs using a fuzzy dynamical system (Fuzzy-DS), which enables robots to adaptively alter the learned motion skills to meet various additional constraints in the process of performing tasks. Due to the joint use of a fuzzy inference system and a dynamic system, Fuzzy-DS is well-suited to human inputs and intuitive fuzzy rules, resulting in a computationally efficient model. To verify the effectiveness of the proposed method, experiments have been designed where the robot learned a plant pruning task and a pick-and-place task, subsequently, it can replicate and generalize these tasks to novel situations.}
}
@article{MACENSKI2023104493,
title = {From the desks of ROS maintainers: A survey of modern & capable mobile robotics algorithms in the robot operating system 2},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104493},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104493},
url = {https://www.sciencedirect.com/science/article/pii/S092188902300132X},
author = {Steve Macenski and Tom Moore and David V. Lu and Alexey Merzlyakov and Michael Ferguson},
keywords = {Navigation, Robot operating system, Nav2, Mobile robotics, Planning, Costmap, ROS, Control, Localization, Perception, SLAM, State estimation},
abstract = {The Robot Operating System 2 (ROS 2) is rapidly impacting the intelligent machines sector — on space missions, large agriculture equipment, multi-robot fleets, and more. Its success derives from its focused design and improved capabilities targeting product-grade and modern robotic systems. Following ROS 2’s example, the mobile robotics ecosystem has been fully redesigned based on the transformed needs of modern robots and is experiencing active development not seen since its inception. This paper comes from the desks of the key ROS Navigation maintainers to review and analyze the state of the art of robotics navigation in ROS 2. This includes new systems without parallel in ROS 1 or other similar mobile robotics frameworks. We discuss current research products and historically robust methods that provide differing behaviors and support for most every robot type. This survey consists of overviews, comparisons, and expert insights organized by the fundamental problems in the field. Some of these implementations have yet to be described in literature and many have not been benchmarked relative to others. We end by providing a glimpse into the future of the ROS 2 mobile robotics ecosystem.}
}
@article{CAI2023104453,
title = {LWDNet-A lightweight water-obstacles detection network for unmanned surface vehicles},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104453},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104453},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000921},
author = {Qilie Cai and Qiang Wang and Yulong Zhang and Zhibo He and Yuhong Zhang},
keywords = {Unmanned surface vehicle, Computer vision, Semantic segmentation, LWDNet, Obstacle detection, Artificial intelligence},
abstract = {Water-obstacles detection based on semantic segmentation is an essential part of autonomous navigation of unmanned surface vehicles (USV). However, it is difficult for existing methods to ensure the real-time of water-obstacles recognition and high detection accuracy. To address this issue, we proposed novel network architecture, a lightweight water-obstacles detection network (LWDNet). In LWDNet, we adopt a novel backbone, bottleneck structure with attention block, the former decrease the model size, the latter obtain more semantic information, and then the dilated convolution has been used in depthwise separable (DW) convolution to enforce the extraction of feature information. Additionally, by using improved focal loss (weight the main and auxiliary focal loss), the water-obstacles detection accuracy increased. In order to test the real-time performance and detection accuracy of LWDNet, we use the most challenging dataset, Multi-modal Marine Obstacle Detection Dataset 2 (MODD2) dataset, for experimental validation. The experimental results show that, compared with the state-of-the-art detection methods, such as WasR and ShorelineNet, the LWDNet maintains a much faster speed of images inference (62 frames-per-second on an NVIDIA RTX 2080Ti), and at the same time, the obstacles detection performance is equally high (87.5% F-measure, 77.8% IOU). Therefore, the LWDNet is an efficient network in water-obstacles detection, making the autonomous navigation of USV more reliable.}
}
@article{SHEHAWY2023104506,
title = {Flattening and folding towels with a single-arm robot based on reinforcement learning},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104506},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104506},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001458},
author = {Hassan Shehawy and Daniele Pareyson and Virginia Caruso and Stefano {De Bernardi} and Andrea Maria Zanchettin and Paolo Rocco},
keywords = {Reinforcement learning, Robotics, Deformable objects},
abstract = {Robots can learn how to complete a variety of tasks without explicit instructions thanks to reinforcement learning. In this work, a piece of cloth is placed on a table and manipulated using a single-arm robot. We consider 2 forms of manipulation: flattening a crumpled towel and folding a flat one. To learn a policy that will allow the robot to select the optimum course of action based on observations of the environment, we construct a simulation environment using a gripper and a piece of cloth. After that, the policy is applied to a real robot and put to the test. Additionally, we present our method for identifying the corners of a garment using computer vision, which includes a comparison between a traditional computer vision approach with a deep learning one. We use an ABB robot and a 2D camera for the experiments and PyBullet software for the simulation.}
}
@article{RIBOLI2023104534,
title = {Collision-free and smooth motion planning of dual-arm Cartesian robot based on B-spline representation},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104534},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104534},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001732},
author = {Marco Riboli and Matthieu Jaccard and Marco Silvestri and Alessandra Aimi and Cesare Malara},
keywords = {Collision-free path planning, Dual-arm cartesian robot, Pick-and-place application, B-spline curves, Quadratic programming, Minimizing curvature, Iso-parametric trajectory planning},
abstract = {This paper discusses a new approach to motion planning of dual-arm gantry kinematic that solves the self-collision problem while ensuring G2-continuity and low curvatures. Starting from collision-free start and target points, the proposed method defines the geometric path of the end-effectors with classical five-segment planar trajectories, described by fifth-degree B-splines. The rototranslation of the loaded parts is evaluated in frames to define sampled overlapping curves, used to compute splines that act as deviation curves being added on the previously defined geometric paths in order to prevent collisions. Here, a quadratic programming minimization is employed to reduce the curvature of these spline and preserve the kinematics properties of the initial path. The kinematic constraints of the axes are ensured by iso-parametric trajectory planning, which results in an optimized motion profile to reduce the task execution time. Finally, the proposed approach is applied to a sorting system for laser machine (LST) having a dual-arm 7-d.o.f. gantry kinematic. The results of a case study of a typical sorting operation are presented and discussed to illustrate and clarify the method. The approach presented in this work can be applied to other robotic systems with similar kinematic structures, providing a useful tool for motion planning in pick-and-place applications.}
}
@article{BACA2023104482,
title = {Autonomous cooperative wall building by a team of Unmanned Aerial Vehicles in the MBZIRC 2020 competition},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104482},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104482},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001215},
author = {Tomas Baca and Robert Penicka and Petr Stepan and Matej Petrlik and Vojtech Spurny and Daniel Hert and Martin Saska},
keywords = {Unmanned Aerial Vehicles, Aerial manipulation, Visual servoing, Multi-robot systems},
abstract = {This paper presents a system for autonomous cooperative wall building with a team of Unmanned Aerial Vehicles (UAVs). The system was developed for Challenge 2 of the Mohamed Bin Zayed International Robotics Challenge (MBZIRC) 2020. The wall-building scenario of Challenge 2 featured an initial stack of bricks and wall structure where the individual bricks had to be placed by a team of three UAVs. The objective of the task was to maximize collected points for placing the bricks within the restricted construction time while following the prescribed wall pattern. The proposed approach uses initial scanning to find a priori unknown locations of the bricks and the wall structure. Each UAV is then assigned to individual bricks and wall placing locations and further performs grasping and placement using onboard resources only. The developed system consists of methods for scanning a given area, RGB-D detection of bricks and wall placement locations, precise grasping and placing of bricks, and coordination of multiple UAVs. The paper describes the overall system, individual components, experimental verification in demanding outdoor conditions, the achieved results in the competition, and lessons learned. The presented CTU-UPenn-NYU approach achieved the overall best performance among all participants to win the MBZIRC competition by collecting the highest number of points by correct placement of a high number of bricks.}
}
@article{AYYASAMY2023104409,
title = {SAR optimization and Convolutional Neural Network based fault estimations and for auto-landing control model},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104409},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104409},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000489},
author = {T. Ayyasamy and S. Nirmala and A. Saravanakumar},
keywords = {CNN, LSTM, SAR, Fault estimation, Auto-landing, Pitch, Altitude, Roll, Yaw angle},
abstract = {During auto landing, the aircraft flies at a significantly low altitude and low speed. So the consequent accidents and flight crashes are highly possible. Several constrained space and foremost external interruption while landing is considered as one of the most complex phases of the aircraft. Therefore it is necessary to recover the aircraft from various major disturbances and to estimate the rate of fault during aircraft landing. In addition to this, for the effective design of an aircraft, it is essential in determining the fault that affects the aircraft. To overcome the issues, this article aim to propose a novel CNNLSTM-SAR-based fault estimation approach to estimate the fault rate from various state trajectories of the aircraft. Here we employed a Convolution Neural Network (CNN) and Long Short-Term Memory (LSTM) model integrated with the Search and Rescue (SAR) optimization algorithm to react instantaneously to the broad range of failures such as actuator failure and failure due to the wind. Then the performances of the proposed CNNLSTM-SAR based fault estimation approach are compared and the results demonstrated that the proposed approach provide a smooth landing with minimum fault and error.}
}
@article{ALTINPINAR2023104546,
title = {A novel indoor localization algorithm based on a modified EKF using virtual dynamic point landmarks for 2D grid maps},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104546},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104546},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001859},
author = {Ozan Vahit Altınpınar and Volkan Sezer},
keywords = {Localization, Self-position tracking, Landmark extraction algorithm, Extended kalman filter, Autonomous mobile robots},
abstract = {Summary
Localization is a self-position estimation problem and is one of the most critical research areas in autonomous mobile robots. This study presents novel solutions to two significant practical challenges in localization. The initial challenge pertains to the lack of distinct features within the environment, while the second involves the imperfectness of the map. Many studies are based on Extended Kalman Filter (EKF) and they need specific features from the environment for localization. The edges and corners are the popular natural feature types to be used in grid maps. The proposed study promises accurate and fast position tracking in the grid maps which have very few corners and edges. To achieve high performance in such a challenging map, we propose the virtual dynamic point landmark (VDPL) approach in this paper. VDPL does not need specific features such as edges and corners, and any part of the map can be used as a landmark. Since the real-world applications are based on imperfect maps, mostly generated by SLAM (Simultaneous Localization and Mapping) algorithm, the probabilistic distribution of the measurement model and measurement predictions are incorrect. In this study, the position errors that occur as a result of this incorrectness are alleviated by modifying the EKF algorithm. The modified equations of EKF for taking into account the map errors are clearly shown in the paper. The efficiency of the proposed solution is demonstrated in multiple simulations which are performed in randomly generated maps. Moreover, the benefits and real-time performance of the proposed approach are provided by real-world tests using an autonomous wheelchair platform. We believe that the methods developed in this study will improve the localization performance of autonomous robots that operate in challenging environments in terms of feature structure.}
}
@article{KADOKAWA2023104425,
title = {Cyclic policy distillation: Sample-efficient sim-to-real reinforcement learning with domain randomization},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104425},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104425},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000647},
author = {Yuki Kadokawa and Lingwei Zhu and Yoshihisa Tsurumine and Takamitsu Matsubara},
keywords = {Domain randomization, Sim-to-real, Deep reinforcement learning},
abstract = {Deep reinforcement learning with domain randomization learns a control policy in various simulations with randomized physical and sensor model parameters to become transferable to the real world in a zero-shot setting. However, a huge number of samples are often required to learn an effective policy when the range of randomized parameters is extensive due to the instability of policy updates. To alleviate this problem, we propose a sample-efficient method named cyclic policy distillation (CPD). CPD divides the range of randomized parameters into several small sub-domains and assigns a local policy to each one. Then local policies are learned while cyclically transitioning to sub-domains. CPD accelerates learning through knowledge transfer based on expected performance improvements. Finally, all of the learned local policies are distilled into a global policy for sim-to-real transfers. CPD’s effectiveness and sample efficiency are demonstrated through simulations with four tasks (Pendulum from OpenAIGym and Pusher, Swimmer, and HalfCheetah from Mujoco), and a real-robot, ball-dispersal task. We published code and videos from our experiments at https://github.com/yuki-kadokawa/cyclic-policy-distillation.}
}
@article{EDER2023104494,
title = {Traversability analysis for off-road environments using locomotion experiments and earth observation data},
journal = {Robotics and Autonomous Systems},
volume = {168},
pages = {104494},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104494},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001331},
author = {Matthias Eder and Raphael Prinz and Florian Schöggl and Gerald Steinbauer-Wagner},
keywords = {Traversability analysis, Locomotion, Mobile robots, Cost map, Off-road navigation, Earth observation, Data-driven},
abstract = {In recent years, the navigation capabilities of mobile robots in off-road environments have increased significantly, opening up new potential applications in a variety of settings. By accurately identifying different types of terrain in unstructured environments, safe automated navigation can be supported. However, to enable safe path planning and execution, the traversability costs of the terrain types need to be accurately estimated. Such estimations are often performed manually by experts who possess information about the environment and are familiar with the capabilities of the robotic system or using simplified experiments. In this paper, we present an automated pipeline for generating traversability costs that use recorded locomotion data from a realistic experiment and descriptive information on the terrain obtained from earth observation data. The main contribution is that the cost estimation for different terrain types is based on locomotion data obtained in realistic standardized experiments. Moreover, by repeating the experiments with different robot systems we are easily able to reflect the actual capabilities of the systems. Experiments were conducted in an alpine off-road environment to record locomotion data of four different robot systems and to investigate the performance and validity of the proposed pipeline. The recorded locomotion data for the different robots are publicly available at https://robonav.ist.tugraz.at/data/}
}
@article{FRENCH2023104397,
title = {Super Intendo: Semantic Robot Programming from Multiple Demonstrations for taskable robots},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104397},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104397},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000362},
author = {Kevin David French and Ji Hwang Kim and Yidong Du and Elizabeth Mamantov Goeddel and Zhen Zeng and Odest Chadwicke Jenkins},
keywords = {Programming by demonstration, Learning from demonstration, Task learning, Goal inference, Taskable robots},
abstract = {When an end-user instructs a taskable robot on a new task, it is important for the robot to learn the user’s intention for the task. Knowing the user’s intention, represented as desired goal conditions, allows the robot to generalize across variations of the learned task seen at execution time. However, it has proven challenging to learn goal conditions due to the large, noisy, and complex space of goal conditions expressed by human users. This paper introduces Semantic Robot Programming with Multiple Demonstrations (SRP-MD) to learn a generative model of latent end-user task goal conditions from multiple end-user demonstrations in a shared workspace. By learning a generative model of the goal conditions, SRP-MD generalizes to task instances even when the quantity of objects to be arranged is not in the training set or novel object instances are included. At test time, a new goal is pulled from the learned generative model given the objects present in the initial scene. The efficacy of SRP-MD as a step toward taskable robots is shown on a Fetch robot learning and executing bin packing tasks in a simulated environment with grocery items.}
}
@article{TI2023104413,
title = {A geometric optimal control approach for imitation and generalization of manipulation skills},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104413},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104413},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000520},
author = {Boyang Ti and Amirreza Razmjoo and Yongsheng Gao and Jie Zhao and Sylvain Calinon},
keywords = {Learning from demonstration, Riemannian geometry, Model-based optimization, Optimal control},
abstract = {Daily manipulation tasks are characterized by regular features associated with the task structure, which can be described by multiple geometric primitives related to actions and object shapes. Only using Cartesian coordinate systems cannot fully represent such geometric descriptors. In this article, we consider other candidate coordinate systems and propose a learning approach to extract the optimal representation of an observed movement/behavior from these coordinates. This is achieved by using an extension of Gaussian distributions on Riemannian manifolds, which is used to analyze a small set of user demonstrations statistically represented in different coordinate systems. We formulate the skill generalization as a general optimal control problem based on the (iterative) linear quadratic regulator ((i)LQR), where the Gaussian distribution in the proper coordinate systems is used to define the cost function. We apply our approach to object grasping and box-opening tasks in simulation and on a 7-axis Franka Emika robot using open-loop and feedback control, where precision matrices result in the automatic determination of feedback gains for the controller from very few demonstrations represented in multiple coordinate systems. The results show that the robot can exploit several geometries to execute the manipulation task and generalize it to new situations. The results show high variation along the do-not-matter direction, while maintaining the invariant characteristics of the task in the coordinate system(s) of interest. We then tested the approach in a human–robot shared control task. Results show that the robot can modify its grasping strategy based on the geometry of the object that the user decides to grasp.}
}
@article{QIAN2023104466,
title = {Robot learning from human demonstrations with inconsistent contexts},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104466},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104466},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001057},
author = {Zhifeng Qian and Mingyu You and Hongjun Zhou and Xuanhui Xu and Bin He},
keywords = {Robot learning from inconsistent contexts, Viewpoint transformation, Meta learning},
abstract = {Visual imitation learning is a promising approach that promotes robots to learn skills from visual demonstrations. However, current visual imitation learning approaches introduce unreasonable assumptions that the contexts of the visual demonstrations and the robot observations are consistent, which affects the flexibility and scalability of the approaches. It is a key challenge for robots to learn from visual demonstrations with inconsistent contexts. Inconsistent contexts may cause a serious difference in the pixel distribution of the operator and the environment, which makes vision-based control policies hardly effective. In this paper, we propose a novel imitation learning framework to enable robots to reproduce behavior by watching human demonstrations with inconsistent contexts, such as different viewpoints, operators, backgrounds, object appearances and positions. Specifically, our framework consists of three networks: flow-based viewpoint transformation network (FVTrans), robot2human alignment network (RANet) and inverse dynamics network (IDNet). First, FVTrans transforms various third-person demonstrations into the fixed robot execution view. With a meta learning strategy, FVTrans can quickly adapt to novel contexts with few samples. Then, RANet aligns the human and the robot at the feature level. Therefore, the demonstration feature can be used as a subgoal of the current moment. Finally, IDNet predicts the joint angles of the robot. We collect a multi-context dataset on the real robot (UR5) for three tasks, including grasping cups, sweeping garbage and placing objects. We empirically demonstrate that our framework can perform three tasks with a high success rate and be effectively generalized to different contexts.}
}
@article{HUANG2023104530,
title = {Sampling-based time-optimal path parameterization with jerk constraints for robotic manipulation},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104530},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104530},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001690},
author = {Huanhuan Huang and Houde Liu and Chongkun Xia and Hongwei Mei and Xuehai Gao and Bin Liang},
keywords = {Time optimization, Path parameterization, Sampling, Constraint-checking, Jerk-bounded trajectory},
abstract = {In this paper, a sampling-based time-optimal path parameterization (S-TOPP) method is proposed to address time-optimal trajectory planning problems with bounded jerks. The key insight of S-TOPP is that a tree of feasible nodes connected by edges is established to find a time-optimal trajectory on the temporal dimension. The tree establishment process includes two major phases at each stage, namely sampling and one-step backtracking. In the sampling phase, a new sampling strategy integrating historical information is proposed to obtain superior samples whereby fewer samples can be controlled automatically, reducing the calculation loss. In one-step backtracking phase, a “lazy” strategy is used to lazily skip constraint-checking when evaluating local connections, enabling S-TOPP to avoid checking the vast majority of nodes that have no chance of being in an optimal trajectory. Simulations and real-world experiments validate the feasibility and practicability of S-TOPP. Results show that S-TOPP is an effective solution to jerk-bounded time-optimal trajectory planning, with features that are more in line with the needs of the practical tasks compared with other methods.}
}
@article{STOLFI2023104412,
title = {Design and analysis of an E-Puck2 robot plug-in for the ARGoS simulator},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104412},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104412},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000519},
author = {Daniel H. Stolfi and Grégoire Danoy},
keywords = {E-puck2, ARGoS, Computer simulations, Sensors, Swarm robotic},
abstract = {In this article we present a new plug-in for the ARGoS swarm robotic simulator to implement the E-Puck2 robot model, including its graphical representation, sensors and actuators. We have based our development on the former E-Puck robot model (version 1) by upgrading the existing sensors (proximity, light, ground, camera, and battery) and adding new ones (time of flight and simulated encoders) implemented from scratch. We have adapted the values produced by the proximity, light and ground sensors, including the E-Puck2’s onboard camera according to its resolution, and proposed four new discharge models for the battery. We have evaluated this new plug-in in terms of accuracy and efficiency through comparisons with real robots and extensive simulations. In all our experiments the proposed plug-in has worked well showing high levels of accuracy. The observed increment of execution times when using the studied sensors varies according to the number of robots and types of sensors included in the simulation, ranging from a negligible impact to 53% longer simulations in the most demanding cases.}
}
@article{AHONEN2023104424,
title = {An exploratory study of software engineering in heavy-duty mobile machine automation},
journal = {Robotics and Autonomous Systems},
volume = {165},
pages = {104424},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104424},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000635},
author = {Andrei Ahonen and Marea {de Koning} and Tyrone Machado and Reza Ghabcheloo and Outi Sievi-Korte},
keywords = {Machines, Heavy equipment, Cyber–physical systems, Software engineering, Robotics, Industry},
abstract = {As the amount and complexity of software for automating heavy-duty mobile machinery is increasing, software engineering in this domain is becoming more important. To characterize the industry’s current state of software engineering and its issues to guide future research, we performed an empirical exploratory study. We interviewed 16 software engineering professionals from 13 different companies conducting business in heavy-duty mobile machines and their automation. The interviews were analyzed qualitatively, and quantification of the analysis results is presented. We first create an overview of software engineering in the heavy-duty mobile machinery industry. We then identify problem areas affecting software development and discuss some of the possible solutions found in literature. Our findings indicate that the major problem areas faced in the industry that require more research are its digital transformation, autonomous machine functional safety, low availability of workforce for developing software for robotic mobile machines and the lack of established software standards.}
}
@article{BAI2023104529,
title = {A study of robotic search strategy for multi-radiation sources in unknown environments},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104529},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104529},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001689},
author = {Hua Bai and Wenrui Gao and Haofei Ma and Pengchao Ding and Gongcheng Wang and Wenda Xu and Weidong Wang and Zhijiang Du},
keywords = {Particle filter, Information gain, RRT, Receding horizon, Differential evolution},
abstract = {This paper focuses on the multiple radiation source search problems, where the mobile robot identifies the number and parameters of sources online while exploring an unknown environment. The radiation superposition and the limited observations improve the difficulty of estimation, and the exploration trajectory is also associated with estimation. A novel search strategy based on receding horizon planning is proposed, which includes the observation, estimation, and exploration modules. The observation module filters and records the radiation intensity for estimation. In the estimation module, an adaptive differential evolution algorithm is integrated into the peak suppression particle filter to avoid the local optimum. The multi-source radiation gain model is conceived to determine the observation position in the exploration module. The strategy trades off exploration of unknown areas and exploitation of known radiation fields. The results of simulations and experiments demonstrate that the proposed strategy can identify the parameters and quantities of all sources in multi-modal radiation fields. Furthermore, our strategy exhibits superior performance in searching for multi-radiation sources in unknown environments compared with the boustrophedon path and the Next-Best-View planner.}
}
@article{ELHAJJAMI2023104557,
title = {A novel robust adaptive neuro-sliding mode steering controller for autonomous ground vehicles},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104557},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104557},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001963},
author = {Lhoussain {El Hajjami} and El Mehdi Mellouli and Vidas Žuraulis and Mohammed Berrada},
keywords = {Autonomous vehicle, Vehicle dynamics, Adas systems, Steering control, Robust adaptive, Neuro-sliding Mode, Neural-network Optimization},
abstract = {This paper intends to harness recent advances in intelligent commands to develop a novel steering control strategy for autonomous ground vehicles (AGVs) maneuvering problems. In this research, the vehicle is embodied by a single track-model (ST) taking into consideration its lateral dynamics. Besides, it is subject to unknown disturbances and uncertainties, associated with the tire/road adhesion coefficient, which are upper bounded by a positive limit. An on-line Radial Basis-function Neural-Networks (RBNN) adaptive mechanism is designed to estimate this upper limit in the sense of Lyapunov. On this basis, a novel robust adaptive neuro-sliding mode steering angle controller (AN-SMC) is introduced. Whilst the effectiveness of the controller is impacted by its parameters, a new neural-network optimization algorithm (NNA) is employed to provide optimal values for these settings. The proposed approach is evaluated through a single lane-change-maneuver planned out by a new methodology. The steering controller revealed a powerful path-tracking via the comparisons carried out in support of the developed strategy.}
}
@article{WANG2023104505,
title = {Driving line-based two-stage path planning in the AGV sorting system},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104505},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104505},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001446},
author = {Ke Wang and Wei Liang and Huaguang Shi and Jialin Zhang and Qi Wang},
keywords = {Path planning, Automated guided vehicle (AGV), Sorting system, Mesh topology},
abstract = {The path planning problem is the core issue in the automatic guided vehicle (AGV) sorting system. The current AGV sorting system has the following characteristics: (1) a great number of AGVs; (2) dynamic sorting of tasks; and (3) two-stage tasks involving transporting express packages and then leaving the sorting area. Therefore, existing path planning methods face challenges in terms of achieving timeliness and optimality. In this paper, the path planning problem of the AGV sorting system in a mesh topology area is modeled. A Driving Line-based Two-Stage (DLTS) path planning algorithm is proposed. First, to avoid conflicts among AGVs with different driving directions, time–space resources are divided according to the driving line mechanism, which specifies the driving direction, possible planned locations and specific driving rules. Second, we propose an incremental search method to plan continuous paths for two-stage tasks while simultaneously avoiding conflicts among AGVs moving in the same direction. Finally, we verify the effectiveness of our method in terms of real-time and optimal performance through simulation experiments.}
}
@article{LUO2023104545,
title = {Reinforcement learning in robotic motion planning by combined experience-based planning and self-imitation learning},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104545},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104545},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001847},
author = {Sha Luo and Lambert Schomaker},
keywords = {Self-imitation learning, Reinforcement learning, Robotics, Motion planning, Obstacle avoidance},
abstract = {High-quality and representative data is essential for both Imitation Learning (IL)- and Reinforcement Learning (RL)-based motion planning tasks. For real robots, it is challenging to collect enough qualified data either as demonstrations for IL or experiences for RL due to safety consideration in environments with obstacles. We target this challenge by proposing the self-imitation learning by planning plus (SILP+) algorithm, which efficiently embeds experience-based planning into the learning architecture to mitigate the data-collection problem. The planner generates demonstrations based on successfully visited states from the current RL policy, and the policy improves by learning from these demonstrations. In this way, we relieve the demand for human expert operators to collect demonstrations required by IL and improve the RL performance as well. Various experimental results shows that SILP+ achieves better training efficiency, higher and more stable success rate in complex motion planning tasks compared to several other methods. Extensive tests on physical robots illustrate the effectiveness of SILP+ in a physical setting, retaining a success rate of 90% where the next-best contender drops from 87% to 75% in the Sim2Real transition.}
}
@article{FERRARI2023104448,
title = {Multi-contact planning and control for humanoid robots: Design and validation of a complete framework},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104448},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104448},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000878},
author = {Paolo Ferrari and Luca Rossini and Francesco Ruscelli and Arturo Laurenzi and Giuseppe Oriolo and Nikos G. Tsagarakis and Enrico {Mingo Hoffman}},
keywords = {Multi-contact framework, Motion planning, Torque-controlled humanoid robots, Loco-manipulation},
abstract = {In this paper, we consider the problem of generating appropriate motions for a torque-controlled humanoid robot that is assigned a multi-contact loco-manipulation task, i.e., a task that requires the robot to move within the environment by repeatedly establishing and breaking multiple, non-coplanar contacts. To this end, we present a complete multi-contact planning and control framework for multi-limbed robotic systems, such as humanoids. The planning layer works offline and consists of two sequential modules: first, a stance planner computes a sequence of feasible contact combinations; then, a whole-body planner finds the sequence of collision-free humanoid motions that realize them while respecting the physical limitations of the robot. For the challenging problem posed by the first stage, we propose a novel randomized approach that does not require the specification of pre-designed potential contacts or any kind of pre-computation. The control layer produces online torque commands that enable the humanoid to execute the planned motions while guaranteeing closed-loop balance. It relies on two modules, i.e., the stance switching and reactive balancing module; their combined action allows it to withstand possible execution inaccuracies, external disturbances, and modeling uncertainties. Numerical and experimental results obtained on COMAN+, a torque-controlled humanoid robot designed at Istituto Italiano di Tecnologia, validate our framework for loco-manipulation tasks of different complexity.}
}
@article{WANG2023104465,
title = {Ultrasound-guide prostate biopsy robot and calibration based on dynamic kinematic error model with POE formula},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104465},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104465},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001045},
author = {Weirong Wang and Bo Pan and Yue Ai and Yili Fu and Gonghui Li and Yanjie Liu},
keywords = {Prostate biopsy robot, Clinical, Dynamic error, POE, Linear kinematic model, Calibration},
abstract = {In the transrectal ultrasound-guided transperineal prostate biopsy, the application of robots can effectively reduce the interference of low-quality ultrasound images on the physician to determine the biopsy route and improve the positive detection rate. In this paper, an 8-degree-of-freedom (DOF) prostate biopsy robot for clinical is developed to realize the operation of ultrasonic probe scanning, the inserting point and target lesion point positioning, and the needle insertion. Considering the dynamic errors caused by different motions of robot joints, a dynamic product-of-exponentials (POE) based kinematic model that can reflect non-geometric errors is proposed by integrating the errors into each joint. Moreover, the parameters in the model are identified by linearizing the dynamic POE-based kinematic model. Finally, the experiment shows the maximum errors can be limited to 0.60 and 1.16 mm for inserting point and needle endpoint after compensation, and the maximum inserting angle error is limited to 1.381°. It proves the feasibility of the kinematic model proposed in this paper and indicates that the robot system can meet the requirements of clinical biopsy.}
}
@article{CHANG2023104533,
title = {A review of UAV autonomous navigation in GPS-denied environments},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104533},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104533},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001720},
author = {Yingxiu Chang and Yongqiang Cheng and Umar Manzoor and John Murray},
keywords = {UAV, GPS-denied navigation, Self-exploration, Performance evaluation metrics},
abstract = {Unmanned aerial vehicles (UAVs) have drawn increased research interest in recent years, leading to a vast number of applications, such as, terrain exploration, disaster assistance and industrial inspection. Unlike UAV navigation in outdoor environments that rely on GPS (Global Positioning System) for localization, indoor navigation cannot rely on GPS due to the poor quality or lack of signal. Although some reviewing papers particularly summarized indoor navigation strategies (e.g., Visual-based Navigation) or their specific sub-components (e.g., localization and path planning) in detail, there still lacks a comprehensive survey for the complete navigation strategies that cover different technologies. This paper proposes a taxonomy which firstly classifies the navigation strategies into Mapless and Map-based ones based on map usage and then, respectively categorizes the Mapless navigation into Integrated, Direct and Indirect approaches via common characteristics. The Map-based navigation is then split into Known Map/Spaces and Map-building via prior knowledge. In order to analyze these navigation strategies, this paper uses three evaluation metrics (Path Length, Deviation Rate and Exploration Efficiency) according to the common purposes of navigation to show how well they can perform. Furthermore, three representative strategies were selected and 120 flying experiments conducted in two reality-like simulated indoor environments to show their performances against the evaluation metrics proposed in this paper, i.e., the ratio of Successful Flight, the Mean time of Successful Flight, the Mean Length of Successful Flight, the Mean time of Flight, and the Mean Length of Flight. In comparison to the CNN-based Supervised Learning (directly maps visual observations to UAV controls) and the Frontier-based navigation (necessitates continuous global map generation), the experiments show that the CNN-based Distance Estimation for navigation trades off the ratio of Successful Flight and the required time and path length. Moreover, this paper identifies the current challenges and opportunities which will drive UAV navigation research in GPS-denied environments.}
}
@article{BOMBILE2023104481,
title = {Bimanual dynamic grabbing and tossing of objects onto a moving target},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104481},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104481},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001203},
author = {Michael Bombile and Aude Billard},
keywords = {Dual-arm systems, Grabbing and tossing, Moving target, Dynamical systems},
abstract = {Bimanual grabbing and tossing of packages onto trays or conveyor belts remains a human activity in the industry. For robots, such a dynamic task requires coordination between two arms and fast adaptation abilities when the tossing target is moving and subject to perturbations. Thus, this paper proposes a control framework that enables a bimanual robotic system to grab and toss objects onto a moving target. We develop a mixed learning-optimization method that computes the tossing parameters necessary to achieve accurate tossing tasks. Hence, we learn an inverse throwing map (a closed-form solution of the inverse non-linear throwing problem) that provides minimum release velocities of the object for given relative release positions. This map is embedded into a kinematics-based bi-level optimization that determines the associated feasible release states (positions and velocities) of the dual-arm robot. Additionally, we propose a closed-form modeling approach of the robot’s tossable workspace (set of all positions reachable by an object if tossed by the robot) and use the model to predict intercept or landing locations that yield high probabilities of task success. Furthermore, we employ dynamical systems to generate the coordinated motion of the dual-arm system and design an adaptation strategy to ensure robustness of the interception in the face of target’s perturbations in speed or location. Finally, we validate experimentally the framework on two 7-DoF robotic arms. We demonstrate the accuracy and robustness of the proposed approach. We also show its speed and energy advantages when compared to the traditional pick-and-place strategy.}
}
@article{YU2023104408,
title = {TRUSTS: A novel treadmill-based multifunctional testing system for performance evaluation of wheeled planetary exploration rover},
journal = {Robotics and Autonomous Systems},
volume = {164},
pages = {104408},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104408},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000477},
author = {Haitao Yu and Jian Chen and Dong Pan and Haibo Gao},
keywords = {Wheeled planetary exploration rover, Trafficability and maneuverability, Performance evaluation},
abstract = {This paper presents a novel treadmill-based multifunctional testing system (TRUSTS) to execute ground testing for wheeled planetary exploration rover (WPER) in both regular and extreme physical conditions before launching. The TRUSTS with specially-made components featuring compact structure and multifunctional testing items comprises a traction loading subsystem (TLS) and a treadmill-based resistance torque loading subsystem (TRTLS). The former offers the working modes including traction loading, position holding, and range limiting. The latter offers working modes including resistance torque loading and leader–follower tracking. By appropriately allocating the working modes of two subsystems, the TRUSTS is capable of conducting diverse testing items. The customized controllers for the TLS and the TRTLS are proposed to guarantee the operation performance of the TRUSTS in all testing items. Extensive experimental results on a Mars rover prototype in both regular and extreme physical conditions demonstrate that the devised TRUSTS could effectively executing trafficability and maneuverability as well as adaptability tests with reliable scenarios and satisfactory precisions of motion tracking and traction/torque loading, which makes the TRUSTS a favorable choice for comprehensive performance assessment of rover in simulant extraterrestrial environment.}
}
@article{CHEN2023104489,
title = {A deep multi-agent reinforcement learning framework for autonomous aerial navigation to grasping points on loads},
journal = {Robotics and Autonomous Systems},
volume = {167},
pages = {104489},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104489},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001288},
author = {Jingyu Chen and Ruidong Ma and John Oyekan},
keywords = {Cooperative navigation, Multi-agent reinforcement learning, Learning from demonstration, Curriculum learning},
abstract = {Deep reinforcement learning, by taking advantage of neural networks, has made great strides in the continuous control of robots. However, in scenarios where multiple robots are required to collaborate with each other to accomplish a task, it is still challenging to build an efficient and scalable multi-agent control system due to increasing complexity. In this paper, we regard each unmanned aerial vehicle (UAV) with its manipulator as one agent, and leverage the power of multi-agent deep deterministic policy gradient (MADDPG) for the cooperative navigation and manipulation of a load. We propose solutions for addressing navigation to grasping point problem in targeted and flexible scenarios, and mainly focus on how to develop model-free policies for the UAVs without relying on a trajectory planner. To overcome the challenges of learning in scenarios with an increasing number of grasping points, we incorporate the demonstrations from an Optimal Reciprocal Collision Avoidance (ORCA) algorithm into our framework to guide the policy training and adapt two novel techniques into the architecture of MADDPG. Furthermore, curriculum learning with the attention mechanism is utilized by reusing knowledge from fewer grasping points to facilitate the training of a load with more points. Our experiments were validated by a load with three, four and six grasping points respectively in Coppeliasim simulator and then transferred into the real world with Crazyflie quadrotors. Our results show that the average tracking deviations from the desirable grasping point to the final position of the UAV can be less than 10 cm in some real-world experiments. Compared with state-of-the-art model-free reinforcement learning and swarm optimization algorithms, results show that our proposed methods outperform other baselines with a reasonable success rate especially in the scenarios with more grasping points. Furthermore, the learned optimal policies enable UAVs to reach and hover over all the grasping points before manipulation without any collision. We conducted a comprehensive analysis of both targeted and flexible navigation, highlighting their respective advantages and disadvantages.}
}
@article{ALQUDSI2023104532,
title = {A numerically-stable trajectory generation and optimization algorithm for autonomous quadrotor UAVs},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104532},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104532},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001719},
author = {Yunes Alqudsi and Murat Makaraci and Ayman Kassem and Gamal El-Bayoumi},
keywords = {Trajectory optimization, Minimum snap trajectories, Quadrotor trajectory generation, Motion path planning, Autonomous motion control},
abstract = {This paper introduces a novel trajectory generation and optimization algorithm (TGO) that enables agile and aggressive flight of quadrotor UAVs while considering various constraints associated with robot dynamics, actuator inputs, and flight environment. The TGO algorithm employs time-parametrized polynomial trajectories based on a predetermined sequence of waypoints to produce dynamically feasible and collision-free trajectories. This approach extends previous work that utilized differential flatness property and polynomial based trajectories by eliminating the need for iterative searching and computationally intensive sampling. One of the significant advantages of the TGO algorithm is its numerical stability for large number of waypoints and high-order polynomials. To address the ill-conditioned problem of Quadratic Programming (QP) based methods, the TGO algorithm reformulates the trajectory generation and optimization problem into an unconstrained quadratic programming (UCP) using the numerically stable null-space factorization method. The TGO algorithm produces minimum derivative trajectories and minimum waypoints arrival times, generating a wide range of aggressive trajectories that can leverage the full maneuvering capabilities of quadrotor robots. The proposed algorithm’s numerical stability and computational advantages are demonstrated through various scenarios and comparisons. An animated simulation of the TGO algorithm is available at: https://youtu.be/MvvhBG14iIg.}
}
@article{HOU2023104451,
title = {Learning 6-DoF grasping with dual-agent deep reinforcement learning},
journal = {Robotics and Autonomous Systems},
volume = {166},
pages = {104451},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104451},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023000908},
author = {Yanxu Hou and Jun Li},
keywords = {Robotic grasp, Cluttered objects, Multi-agent reinforcement learning, Grasp representation, Grasp quality},
abstract = {Self-supervised grasp learning (SGL) is one of the most promising approaches to challenging robotic grasping. However, most existing SGL-based methods are restricted to in 4-DoF planar grasps due to limited grasp representations and inadequate learning rewards. This paper proposes 6-DoF grasp learning (6DGL). It represents a 6-DoF grasp by exploiting both planar and spherical grasp affordance in the image space. Its underlying network is called Q Mixing Network with Planar and Spherical Affordances (QMIX-PSA). In QMIX-PSA, two agent networks, i.e., a planar affordance network (PA-Net) and a spherical affordance network (SA-Net), are used to predict grasp position and orientation. Then, the two networks’ joint action value is estimated by a QMIX to reconstruct their connection. Again, an augmented reward is presented to evaluate the quality of a 6-DoF grasp by measuring the incurred disturbance to the surroundings with scene images. Finally, extensive experiments are conducted on grasping metal workpieces and daily items. The results show that 6DGL outperforms its peers regarding grasp success rate and quality, especially in clutter where existing SGL methods are incompetent.}
}