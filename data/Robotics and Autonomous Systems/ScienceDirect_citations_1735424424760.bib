@article{RATHI2022104222,
title = {Stackelberg game approach for resource allocation in device-to-device communication with heterogeneous networks},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104222},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104222},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001300},
author = {Roopsi Rathi and Saurav Dixit and Shweta Bansal and Kaushal Kumar and Natalia Taskaeva and Tumanov A.Yu. and Vinod John},
keywords = {Resource management, Base station, Leader, Follower, D2D, Price, Power},
abstract = {Device-to-device communication is an enabling technology for direct connection between two or more devices/users without the intermediation of a base station (BS). In heterogeneous device-to-device networks, technology such as femtocell suggests advantages such as improving coverage area, spectral efficiency, and increased capacity. However, several challenging issues like interference, resource allocation, and power control strategies need to be addressed in the macrocell–femtocell-D2D heterogeneous network. This research presents a solution for resource allocation in D2D networks by proposing a Stackelberg game approach to increase network performance and throughput. The proposed study examines a framework for a two-leader multiple-followers Stackelberg game in which the leaders are macrocell base station (MBS) and femtocell base station (FBS), and the numerous followers are D2D pairings. Based on their mobility in the cell zone, D2D users are divided into three types Each leader and follower are designed with a different utility function. The paper is focused to minimize the interference in the system and maximize the system throughput. The game is solved to a Stackelberg equilibrium and ensures D2D communication continues with optimal transmit power. The assignment of resources among various contending users using the Hungarian algorithm. The proposed model is validated through simulations in MATLAB. The results show that the proposed model reduced the interference in the network and increased the throughput of the system in terms of price, transmit power and D2D rate.}
}
@article{ELHAKI2022104106,
title = {Output-feedback robust saturated actor–critic multi-layer neural network controller for multi-body electrically driven tractors with n-trailer guaranteeing prescribed output constraints},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104106},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104106},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000574},
author = {Omid Elhaki and Khoshnam Shojaei},
keywords = {Actuator saturation, Actuator dynamics, Reinforcement learning control, High-gain observer, Prescribed performance, Tractor with -trailer},
abstract = {This paper proposes a novel robust saturated actor–critic multi-layer neural network controller for electrically-driven tractors with n-trailer with unmeasurable linear and angular velocities, uncertain complex dynamics and actuator saturation while guaranteeing a prescribed performance with employing the motor dynamics. The proposed controller consists of four control loops. In the first loop, tracking errors are transformed into constraint errors via prescribed performance bounds. Then, a kinematic controller is designed. In the second loop, an output feedback robust dynamic controller is proposed via multi-layer actor–critic neural networks to approximate model uncertainties, a high-gain observer (HGO) to estimate velocities, and an adaptive robust controller to compensate external dynamic disturbances. Afterwards, a robust actuator controller is designed in third loop by employing multi-layer actor–critic neural networks to deeply diminish unknown nonlinear functions effects, and an adaptive robust controller to handle the bounded actuator disturbances. An auxiliary subsystem is considered in the final loop to reduce the danger of actuator saturation by designing an auxiliary intermediate controller. The stability under the proposed controller is studied by the Lyapunov stability synthesis, and it is proven that tracking errors remain uniformly ultimately bounded. Finally, the validity, reliability, and effectiveness of the proposed reinforcement learning-based controller is shown by means of multiple simulations and some comparisons with a quantitative study.}
}
@article{CACCAVALE2022104238,
title = {A rapidly-exploring random trees approach to combined task and motion planning},
journal = {Robotics and Autonomous Systems},
volume = {157},
pages = {104238},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104238},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001385},
author = {Riccardo Caccavale and Alberto Finzi},
keywords = {Robot planning, Sampling-based planning, Rapidly-exploring random trees, Mobile robotics},
abstract = {Task and motion planning in robotics are typically addressed by separated intertwined methods. Task planners generate abstract high-level actions to be executed, while motion planners provide the associated discrete movements in the configuration space satisfying kinodynamic constraints. However, these two planning processes are strictly dependent, therefore the problem of combining task and motion planning with a uniform approach is very relevant. In this work, we tackle this issue by proposing a RRT-based method that addresses combined task and motion planning. Our approach relies on a combined metric space where both symbolic (task) and sub-symbolic (motion) spaces are represented. The associated notion of distance is then exploited by a RRT-based planner to generate a plan that includes both symbolic actions and feasible movements in the configuration space. The proposed method is assessed in several case studies provided by a real-world hospital logistic scenario, where an omni-directional mobile robot is involved in navigation and transportation tasks.}
}
@article{LECHAU2022104199,
title = {Structural optimization of a rotary joint by hybrid method of FEM, neural-fuzzy and water cycle–moth flame algorithm for robotics and automation manufacturing},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104199},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104199},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001142},
author = {Ngoc {Le Chau} and Minh Phung Dang and Chander Prakash and Dharam Buddhi and Thanh-Phong Dao},
keywords = {Rotary joint, Topology-size optimization, Finite element method, Neural-fuzzy, Water cycle moth-flame optimization algorithm, Robotics, Automation manufacturing},
abstract = {Rotary joint is used in robotic arm for mobility aids and rehabilitation device. The rotary joint often requires a compactness, a lightness, and a large load capacity in robotics as well as automation manufacturing. However, the experience-based design methods take a lot of time, finances, and human resources to achieve the mentioned multiple functions. To overcome the above difficulties, the article proposes a new design technique to solve the structural optimization for the rotary joint. The proposed optimization technique is formed by topology method, analysis of variance, finite element method, adaptive neuro-fuzzy inference system model, and water cycle moth-flame optimization algorithm. A new rotary joint is designed via the topology optimization. The adaptive neuro-fuzzy inference system is optimized by Taguchi technique to enhance the modeling accuracy. The geometry of the joint is optimized by the water cycle moth-flame optimization algorithm. The results found that the rotary joint can stand a torque of 357.46 N.mm with the equivalent stress up to 489.98 MPa. The difference between the optimal prediction results and simulations are 0.27% and 0.58% for the moment reaction and the equivalent stress, respectively. The small error proves the developed hybrid method has a high reliability.}
}
@article{KAWAHARAZUKA2022104067,
title = {Robust continuous motion strategy against muscle rupture using online learning of redundant intersensory networks for musculoskeletal humanoids},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104067},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104067},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000331},
author = {Kento Kawaharazuka and Manabu Nishiura and Yasunori Toshimitsu and Yusuke Omura and Yuya Koga and Yuki Asano and Kei Okada and Koji Kawasaki and Masayuki Inaba},
keywords = {Musculoskeletal humanoid, Redundancy, Neural networks},
abstract = {Musculoskeletal humanoids have various biomimetic advantages, of which redundant muscle arrangement is one of the most important features. This feature enables variable stiffness control and allows the robot to keep moving its joints even if one of the redundant muscles breaks, but this has been rarely explored. In this study, we construct a neural network that represents the relationship among sensors in the flexible and difficult-to-modelize body of the musculoskeletal humanoid, and by learning this neural network, accurate motions can be achieved. In order to take advantage of the redundancy of muscles, we discuss the use of this network for muscle rupture detection, online update of the intersensory relationship considering the muscle rupture, and body control and state estimation using the muscle rupture information. This study explains a method of constructing a musculoskeletal humanoid that continues to move and perform tasks robustly even when one muscle breaks.}
}
@article{JO2022104148,
title = {Robust walking stabilization strategy of humanoid robots on uneven terrain via QP-based impedance/admittance control},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104148},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104148},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000859},
author = {Joonhee Jo and Gyunghoon Park and Yonghwan Oh},
keywords = {Humanoid, Hybrid landing control, QP impedance control, Walking stabilization},
abstract = {A robust walking stabilization strategy of humanoids on uneven terrain via a QP-based impedance/ admittance control is addressed in this paper. The core idea is combining the following two strategies. The first is to reduce the effect of an unexpected contact force on the centroidal momentum dynamics, and the second is to adjust post-contact reference for the swing foot with which its pose is regulated on the obstacle. The former can be achieved by replacing the task of the trajectory tracking control for the swing foot with its task-space impedance control, and the latter follows by employing the hybrid admittance control combining the admittance control with resetting the post-contact reference. In addition, an optimal set of parameters used for the admittance control is computed via the Taguchi optimal design method. The proposed algorithm is embedded into the momentum-based whole-body control (WBC) framework and verified its validity by multiple simulations with the physics engine.}
}
@article{TUGAL2022104130,
title = {Hand-impedance measurements with robots during laparoscopy training},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104130},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104130},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000732},
author = {Harun Tugal and Benjamin Gautier and Benjie Tang and Ghulam Nabi and Mustafa Suphi Erden},
keywords = {Human-robot interaction, Hand-impedance, Laparoscopy training},
abstract = {This paper presents hand-impedance measurements during laparoscopic training with physically interactive manipulators. We develop a co-manipulated robotic system allowing hand-impedance measurements in an active manipulation task with occasional environmental contact. Six professional, four trainee surgeons, and ten novice subjects participated in our experimental program for a suturing activity where the novice subjects were involved in a five weeks training practice. Variable admittance controlled robots, attached to the tools with force sensors, applied step vice velocity disturbances while subjects were trying to set the needle perpendicular to the surgical driver. Hereby, impedances of the left and right hands were computed in four different directions. Then, the measured impedance parameters across all subjects were compared with respect to the participants’ level of proficiency and skill progression via statistical analyses to demonstrate effectiveness of the system. Results indicate that hand-impedance in the direction of the suturing-line demonstrates a consistent change throughout training and across different levels of expertise in laparoscopy. Therefore, hand-impedance information, proposed here, can pave the way for future development of robotic assessment or assistance in laparoscopy training programs.}
}
@article{BENLAKHAL2022104065,
title = {Safe and adaptive autonomous navigation under uncertainty based on sequential waypoints and reachability analysis},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104065},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104065},
url = {https://www.sciencedirect.com/science/article/pii/S092188902200032X},
author = {Nadhir Mansour {Ben Lakhal} and Lounis Adouane and Othman Nasri and Jaleleddine {Ben Hadj Slama}},
keywords = {Autonomous navigation, Sequential waypoint-based navigation, Risk assessment and management, Reachability analysis, Interval Taylor models},
abstract = {This paper presents a new approach for a safe autonomous navigation based on reliable state space reachability analysis. This latter improves an already proposed flexible Navigation Strategy based on Sequential Waypoint Reaching (NSbSWR) framework (Vilca et al., 2015), while considering explicitly different uncertainties in modeling and/or perception. Indeed, NSbSWR is an emergent concept that exploits its flexibility and genericity to avoid frequent complex trajectories’ planning/re-planning. The paper’s main contribution is to introduce a reachability analysis scheme as a reliable risk assessment and management policy ensuring safe autonomous navigation between the successive assigned waypoints. For this aim, interval analysis is employed to propagate uncertainties influencing the vehicle’s dynamics into the navigation system states. By solving an ordinary differential equation with uncertain variables and parameters via an interval Taylor series expansion method, all the vehicle potential reachable state-space is revealed. According to the obtained bounds of the reachable sets, a decision about the navigation safety is made. Once a collision risk is captured, the risk management layer acts to update the control parameters to master the critical situation and guarantee a proper reaching of waypoint, while avoiding any risky state. Several simulation results prove the safety, efficiency and robustness of the overall navigation under uncertainties.}
}
@article{ZHOU2022104017,
title = {The role of pre-tensioned springs in 3 pneumatic artificial muscles driven joint mechanisms with sliding mode controllers},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104017},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.104017},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002669},
author = {Zhongchao Zhou and Yuanyuan Wang and Wenwei Yu},
keywords = {Pneumatic artificial muscles (PAMs), Three types of joint spring-PAMs​ structures, Sliding mode control},
abstract = {During the past decade, soft robotics has become a growing new field, and researchers have developed different kinds of soft robots with different actuation technologies and mechanisms. Pneumatic artificial muscles (PAMs), as one kind of the most popular soft actuators, have been widely applied to robotic systems that assist persons. However, PAMs are highly nonlinear, which makes it difficult to achieve accurate force and motion control. Another major problem is their slow response. Efforts have been made to improve the accuracy and responses of PAMs. Adding pre-tensioned springs is one efficient way to improve responses of mechatronic systems. However, the role of pre-tensioned springs in different PAMs-driven mechanical structures has not been sufficiently investigated. In this study, two joint structures combining pre-tensioned springs and PAMs were modeled and their sliding mode controllers (SMC) were designed. The control results were compared with canonical antagonistic PAMs structure in simulation experiments. Moreover, a one-joint prototype actuated by 3 PAMs connected in series with two series-connected springs, was built and used to validate the simulated model. The results with both simulation models and the prototype mechanism showed that, one of joint structure with pre-tensioned springs could achieve better step response and control accuracy than the canonical antagonistic PAMs structure.}
}
@article{GAO2022104121,
title = {An intelligent master–slave collaborative robot system for cafeteria service},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104121},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104121},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000690},
author = {Mingyu Gao and Haiping Zhou and Yuxiang Yang and Zhekang Dong and Zhiwei He},
keywords = {Master–slave collaborative robot, Point cloud segmentation network, Master–slave motion planning},
abstract = {In order to improve the efficiency and reduce the labor cost of cafeterias, an intelligent master–slave collaborative robot system is developed for cafeteria service in this paper. The developed system can automatically complete the tasks of scooping dishes, taking bowls and pouring dishes into the bowl based on master–slave collaboration. Specifically, a dynamic geometry feature graph convolution network (DGG) is devised using the 3D point cloud of the dish, which can efficiently predict the scooping positions of the different dishes. Moreover, a master–slave motion planning control method is proposed to achieve fast and smooth trajectories for both arms, which can accomplish the cafeteria service tasks collaboratively. Furthermore, we establish a dataset containing point clouds and color images of various Chinese food. Experiments demonstrate that the DGG network can achieve superior performance over other state-of-the-art point cloud segmentation networks. Besides, the designed robot system can well meet the requirements of operation accuracy and speed, confirming its practicality in cafeteria services.}
}
@article{RUBAGOTTI2022104047,
title = {Perceived safety in physical human–robot interaction—A survey},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104047},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104047},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000173},
author = {Matteo Rubagotti and Inara Tusseyeva and Sara Baltabayeva and Danna Summers and Anara Sandygulova},
keywords = {Physical human robot interaction, Perceived safety, Trust, Comfort, UAVs, Self-driving cars},
abstract = {This review paper focuses on different aspects of perceived safety for a number of autonomous physical systems. This is a major aspect of robotics research, as more and more applications allow humans and autonomous systems to share their space, with crucial implications both on safety and on its perception. The alternative terms used to express related concepts (e.g., psychological safety, trust, comfort, stress, fear, and anxiety) are listed and explained. Then, the available methods to assess perceived safety (i.e., questionnaires, physiological measurements, behavioral assessment, and direct input devices) are described. Six categories of autonomous systems are considered (industrial poly-articulated manipulators, indoor mobile robots, mobile manipulators, humanoid robots, drones, and autonomous vehicles), providing an overview of the main themes related to perceived safety in the specific domain, a description of selected works, and an analysis of how motion and characteristics of the system influence the perception of safety. The survey also discusses experimental duration and location of the reviewed papers, and the connection between perceived safety and safety standards.}
}
@article{LI2022103999,
title = {Dual-view 3D object recognition and detection via Lidar point cloud and camera image},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103999},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103999},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002542},
author = {Jing Li and Rui Li and Jiehao Li and Junzheng Wang and Qingbin Wu and Xu Liu},
keywords = {Object detection, Lidar point cloud, RGB image, Sensor fusion, Autonomous system},
abstract = {When it comes to the accuracy of autonomous motion, it is necessary to consider object detection and recognition, especially for the robot application of the complex environment. This paper investigates novel dual-view 3D object detection networks combined with the Lidar point cloud and RGB image in engineering scenarios. The developed system is applied for autonomous vehicles that the detected objects are cars, cyclists, and pedestrians. Firstly, a feature extraction network based on the residual module is presented, and the specific features are from the RGB image. The point cloud is transformed into Bird’s Eye View (BEV), and the BEV feature extraction network is built based on sparse convolution. Besides, the feature maps are input into the region proposal network (RPN) to obtain the optimal proposal so that the object classification and the bounding box regression are obtained. Finally, to evaluate the flexibility of the developed framework, extensive data sets are generated through the CARLA simulator and verified on the KITTI data set and unmanned motion platform (BIT-NAZA robot), indicating that the proposed networks can achieve satisfactory performance in the real-world scenario.}
}
@article{SUOMALAINEN2022104224,
title = {A survey of robot manipulation in contact},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104224},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104224},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001312},
author = {Markku Suomalainen and Yiannis Karayiannidis and Ville Kyrki},
keywords = {Robotic manipulation, Manipulation in contact, Compliance, In-contact tasks, Impedance control},
abstract = {In this survey, we present the current status on robots performing manipulation tasks that require varying contact with the environment, such that the robot must either implicitly or explicitly control the contact force with the environment to complete the task. Robots can perform more and more manipulation tasks that are still done by humans, and there is a growing number of publications on the topics of (1) performing tasks that always require contact and (2) mitigating uncertainty by leveraging the environment in tasks that, under perfect information, could be performed without contact. The recent trends have seen robots perform tasks earlier left for humans, such as massage, and in the classical tasks, such as peg-in-hole, there is a more efficient generalization to other similar tasks, better error tolerance, and faster planning or learning of the tasks. Thus, in this survey we cover the current stage of robots performing such tasks, starting from surveying all the different in-contact tasks robots can perform, observing how these tasks are controlled and represented, and finally presenting the learning and planning of the skills required to complete these tasks.}
}
@article{ROBBINS2022104150,
title = {Model-free dynamic control of robotic joints with integrated elastic ligaments},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104150},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104150},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000860},
author = {A.S. Robbins and M. Ho and M. Teodorescu},
keywords = {Robot dynamics, Deep reinforcement learning, Soft robots, Robotic manipulator, Biomimetics},
abstract = {The combination of elasticity and rigidity found within mammalian limbs enables dexterous manipulation, agile, and versatile behavior, yet most modern robots are either primarily soft or rigid. Hybrid robots, composed of both soft and rigid parts, promote compliance to external forces while maintaining strength and stability provided by rigid robots. Most mammals have ligaments which connect bone to bone, enabling joints to passively redirect forces and softly constrain the range of motion. We present an approach to constructing a new class of hybrid joints through parametric design choices that adjust dynamic properties of the system. The inherent modularity and variability necessitate a model-free controller which can adjust to new contexts in relatively short time. Three joint examples are created along with three tasks to assess quality of the controllers, creating 9 total cases. We show the Soft Actor Critic (SAC) reinforcement learning algorithm outperforms a proportion–integral–derivative (PID) controller in 6/9 cases, yet this changes to 9/9 with a brief re-training period. This work presents a new class of hybrid robotic joints with modifiable dynamics and employs a model-free control training technique which can be fine-tuned for specific scenarios.}
}
@article{GYAGENDA2022104069,
title = {A review of GNSS-independent UAV navigation techniques},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104069},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104069},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000343},
author = {Nasser Gyagenda and Jasper V. Hatilima and Hubert Roth and Vadim Zhmud},
keywords = {GNSS-independent navigation, Integrity monitoring},
abstract = {Application of UAVs (Unmanned Aerial Vehicles) in environments devoid of GNSS (Global Navigation Satellite System) service has motivated research into GNSS-independent navigation solutions. This paper presents an account of such solutions proposed within the last decade. Unlike most literature that abstract UAV navigation to mere localization, this work takes a bottom-up approach by assessing the navigation components namely perception, localization and motion planning presented in the selected literature. The review results indicate that only 16% of the research presented full navigation solutions, while the rest present one or several components thereof. Besides the account of navigation solutions, our other contributions include an adapted MTOW-based (Maximum Take-Off Weight) UAV classification scheme incorporating a nano-sized UAV class, technology maturity assessment of the reviewed GNSS-independent navigation solutions and analysis of integrity monitoring frameworks.}
}
@article{PELLOIS2022104201,
title = {An inertial human upper limb motion tracking method for robot programming by demonstration},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104201},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104201},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001154},
author = {Robin Pellois and Olivier Brüls},
keywords = {Robotics, Programming by demonstration, Inertial human motion tracking},
abstract = {This paper proposes an inertial human motion tracking for robot programming by demonstration (PbD). An original element called heading reset is proposed to catch the drift around gravity direction. It is based on a hypothesis made on the human arm motion during a task demonstration. It is used to overcome the non-use of the magnetometer due to magnetic disturbances from robotic environment. This element is implemented in an orientation estimation algorithm and compared with three other IMU algorithms and a commercial MARG algorithm. The human arm trajectory is estimated through three IMUs sensors directly set on the arm to estimate the segment orientation (hand, forearm and arm). A specific inertial-2-segment procedure is presented as well as a procedure to estimate the transformation from human reference frame to task frame, necessary for a PbD process. Experimental tests, using a robot as a reference, have been conducted to validate the different part of the method. The heading reset and the orientation algorithm show good results. The inertial-2-segment procedure is shown to be robust. Finally, experimental tests on a human arm and physical robot validate the complete method.}
}
@article{QIAN2022104046,
title = {Environment-adaptive learning from demonstration for proactive assistance in human–robot collaborative tasks},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104046},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104046},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000185},
author = {Kun Qian and Xin Xu and Huan Liu and Jishen Bai and Shan Luo},
keywords = {Learning-from-demonstration, Interactive movement primitives, Human–robot collaboration, Proactivity, Robot grasping},
abstract = {Proactive assistance in human–robot collaboration remains a challenging objective, as the spatial–temporal coordination of the human–robot motion must be considered in conjunction with the object and environmental context. In this paper, we propose an environment-adaptive probabilistic interaction primitive method using learning-from-demonstration. In particular, we propose a novel phase estimation algorithm called Single-axis Uniform Interval Interpolation, which alleviates the restriction of Gaussian or uniform distribution of phase variables. In addition, the environmental constraints in human–robot interactive skills are learned via the regression between environmental parameters and the weight vectors. The proposed method is implemented in a proactive robotic system for typical industrial-motivated human–robot collaborative scenarios, such as assistive push-button assembly and human–robot collaborative object covering. The experimental result validates the effectiveness of the proposed approach.}
}
@article{PROUDMAN2022104240,
title = {Towards real-time forest inventory using handheld LiDAR},
journal = {Robotics and Autonomous Systems},
volume = {157},
pages = {104240},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104240},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001397},
author = {Alexander Proudman and Milad Ramezani and Sundara Tejaswi Digumarti and Nived Chebrolu and Maurice Fallon},
keywords = {Forestry, SLAM, Real-time Operation, Automated forest inventory},
abstract = {While mobile LiDAR sensors are increasingly used to scan in ecology and forestry applications, reconstruction and characterization are typically carried out offline. Motivated by this, we present an online LiDAR system which is capable of running on a handheld device. Our system is capable of creating 3D point cloud reconstructions of large forest areas, segment and track individual trees, and create an inventory for the detected trees. Segments relating to each tree are accumulated over time, and tree models are completed as more scans are captured from different perspectives. The LiDAR scans are processed in an online fashion, and feedback can be provided to the operator via a screen mounted on the device. This allows the operator to ensure the desired area is mapped satisfactorily without any gaps or missing sections. We employ a pose-graph based SLAM system with loop closures to correct for drift errors allowing us to map large areas accurately. Our mapping system also provides multi-session capability where data captured during different runs can be automatically merged in a post-processing step. In this work, we estimate the Diameter at Breast Height (DBH) of individual trees as an example parameter for the forest inventory. The DBH is estimated online by fitting a cylinder to each tree trunk through a least-squares optimization within a RANSAC loop. We demonstrate our mapping approach operating in two different forests (both ecological and commercial) with the total travel distance spanning several kilometres. Further, we also provide experimental results comparing our DBH estimation to ground-truth measurements recorded manually in an ecological forest (Wytham Woods, Oxford). We demonstrate that our DBH estimates are within ∼7 cm accuracy for 90% of individual trees detected in the dataset.}
}
@article{VINOD2022104158,
title = {Development of an autonomous fog computing platform using control-theoretic approach for robot-vision applications},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104158},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104158},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000902},
author = {Dinsha Vinod and P.S. SaiKrishna},
keywords = {Fog computing, LPV modelling, LMI based control, Deep learning for object detection, Mobile robot, SLAM},
abstract = {This paper presents the dynamic modelling and linear matrix inequality (LMI) based controller design of a distributed fog computing framework for real-time robot vision applications. A mobile robot vision system acquires the images from an application environment such as a warehouse, where articles are stacked in numerous racks. We characterise the mobile robot vision data (MRVD) using frames per second (FPS) and the image resolution. From the MRVD, object detection is performed by an open-source deep learning (DL) platform for detecting and localising various objects. However, with higher FPS together with high-resolution images, the processing time by the DL algorithm increases significantly. This necessitates the deployment of a distributed computing platform with several computing nodes. In this work, we deploy a distributed fog computing environment (DFCE) for the real-time object detection in an application environment. The processing time required to handle the MRVD is called the service time. However, for efficient auto-scaling performance, the mathematical model of the DFCE, taking into consideration the characteristics of the MRVD is necessary. In this context, we envisage the application of control theory to build the dynamic model of the DFCE. A Linear Parameter Varying (LPV) model is proposed for the DFCE with the service time as the output, the number of fog nodes as the input, and the characteristics of MRVD as the time-varying parameters. At first, an LPV model for the DFCE is derived using system identification, and the model is validated using the real-time test data. The LPV model is converted to a Polytopic LPV (PLPV) model for LMI based controller design. Finally, we develop and validate a Linear Matrix Inequality (LMI) based LPV controller to meet the service time constraints for a given application environment. For localisation and trajectory tracking with obstacle avoidance in the application environment, the mobile robot implements an Extended Kalman Filter (EKF) based simultaneous localisation and mapping (SLAM) and a bug-based path planning algorithm respectively. Finally, we present, detailed controller validation results illustrating the mobile robot navigation together with the auto-scaling control for the fog computing platform to modulate the service time.}
}
@article{XIAO2022104132,
title = {APPL: Adaptive Planner Parameter Learning},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104132},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104132},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000744},
author = {Xuesu Xiao and Zizhao Wang and Zifan Xu and Bo Liu and Garrett Warnell and Gauraang Dhamankar and Anirudh Nair and Peter Stone},
keywords = {Mobile robot navigation, Machine learning, Motion planning},
abstract = {While current autonomous navigation systems allow robots to successfully drive themselves from one point to another in specific environments, they typically require extensive manual parameter re-tuning by human robotics experts in order to function in new environments. Furthermore, even for just one complex environment, a single set of fine-tuned parameters may not work well in different regions of that environment. These problems prohibit reliable mobile robot deployment by non-expert users. As a remedy, we propose Adaptive Planner Parameter Learning (appl), a machine learning framework that can leverage non-expert human interaction via several modalities – including teleoperated demonstrations, corrective interventions, and evaluative feedback – and also unsupervised reinforcement learning to learn a parameter policy that can dynamically adjust the parameters of classical navigation systems in response to changes in the environment. appl inherits safety and explainability from classical navigation systems while also enjoying the benefits of machine learning, i.e., the ability to adapt and improve from experience. We present a suite of individual appl methods and also a unifying cycle-of-learning scheme that combines all the proposed methods in a framework that can improve navigation performance through continual, iterative human interaction and simulation training.}
}
@article{2023104576,
title = {Editorial Board},
journal = {Robotics and Autonomous Systems},
volume = {170},
pages = {104576},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/S0921-8890(23)00215-4},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023002154}
}
@article{WU2022104248,
title = {Adaptive ORB feature detection with a variable extraction radius in RoI for complex illumination scenes},
journal = {Robotics and Autonomous Systems},
volume = {157},
pages = {104248},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104248},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001439},
author = {Xing Wu and Chao Sun and Leisheng Chen and Ting Zou and Wei Yang and Haining Xiao},
keywords = {Image processing, Feature detection, ORB feature, RoI segmenting, Adaptive extraction},
abstract = {Feature detection is a crucial technique for a vision navigation system to estimate robot pose according to natural landmarks. It is difficult for the existing feature detection techniques to balance the feature quality, processing time and robustness for a vision-based robot in complex workspaces. An adaptive Oriented fast and Rotated Brief (ORB) feature detection method with a variable extraction radius in Region of Interest (RoI) is proposed to deal with these problems. Firstly, the original camera image is processed by means of the Laplace transform of Gaussian (LTOG) pyramid and the grayscale centroid method, in order to obtain the rotation and scale invariance for ORB features. Then, a RoI segmenting technique is developed to locate the image areas that contain potential ORB features due to obvious grayscale variation. Thirdly, the ORB features are extracted in RoIs by using a set of variable-radius templates, adaptive to different illumination conditions. Finally, a number of feature detection and robot localization experiments are conducted on a vision-based robot prototype in different scenes under complex illumination. The experimental results verify that the RoI segmenting technique can correctly preserve the grayscale-varying regions to search ORB features with scattered distribution but excluding the irrelevant areas to suppress feature noises, while the variable-radius template extraction method can detect more feature inliers in complex workspaces. Therefore, our adaptive ORB method can outperform other commonly-used algorithms in accuracy, efficiency and robustness.}
}
@article{JEON2022104014,
title = {Overtaking decision and trajectory planning in highway via hierarchical architecture of conditional state machine and chance constrained model predictive control},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104014},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.104014},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002657},
author = {Seungmin Jeon and Kibeom Lee and Dongsuk Kum},
keywords = {Autonomous vehicle, Collision avoidance, Model predictive control, Overtaking, Path planning},
abstract = {An overtaking trajectory planning algorithm is an essential part of autonomous vehicles, but maximizing trip efficiency (minimum travel time) while guaranteeing safety is non-trivial. In particular, to achieve optimal trajectory results in all situations using one algorithm is challenging because overtaking is a complex maneuver in which several behaviors are combined. In this paper, an overtaking algorithm that employs a finite state machine as a high-level decision maker and chance constrained model predictive control as a trajectory planner is proposed to optimize trip efficiency and ride comfort while guaranteeing safety. By combining two methods in a hierarchical structure, the proposed algorithm takes advantage of each method to realize optimality and real-time performance. Using the conditional state machine (CSM), algorithm classifies maneuver states that can ensure safety, and sets the optimal multi-vehicle constraints in each state. The chance constrained model predictive control (MPC) plans an optimal trajectory that considers the prediction uncertainty, safety, trip efficiency and ride comfort. To rigorously evaluate both trip efficiency and safety, the performance of the proposed overtaking algorithm is evaluated in a statistical manner for various level of service (LOS) scenarios. Simulation results show that the optimal trajectory was generated in a multi-vehicle situation while ensuring higher safety than the rule-based algorithm.}
}
@article{YAMAMOTO2022104218,
title = {Resolved viscoelasticity control for robust walking of a humanoid with knee-stretched posture considering singularity},
journal = {Robotics and Autonomous Systems},
volume = {157},
pages = {104218},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104218},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001270},
author = {Ko Yamamoto and Kazuya Murotani and Tianyi Ko and Yoshihiko Nakamura},
keywords = {Balance control, Biped locomotion, Compliance Control, Humanoid robot},
abstract = {Resolved viscoelasticity control (RVC) method resolves multiple viscoelasticities in the task-space, including the center of gravity viscoelasticity for balancing, into the joint-space viscoelasticity. We achieved robust and compliant motions using the RVC method. In previous studies, however, the conventional knee-bent posture was used to avoid kinematic singularity, suffering from large knee joint torque. In this study, we propose an extension of the RVC that can consider the kinematic singularity. Stable knee-stretched walking has been described using a humanoid with the RVC. Using simulations and experiments, we demonstrate that this RVC method allows for stable and human-like walking while considering the singularity, reducing the knee joint torque, and improving the energy efficiency.}
}
@article{CHEN2022103989,
title = {Flexible gait transition for six wheel-legged robot with unstructured terrains},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103989},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103989},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002499},
author = {Zhihua Chen and Jiehao Li and Shoukun Wang and Junzheng Wang and Liling Ma},
keywords = {Wheel-legged robot, Gait transition, Flexibly gait planner, Gait feedback regulator, Unstructured terrain},
abstract = {The flexibility of gait and trajectory planning with heavy payload are the main challenges for legged stable walking of hexapod robots in unstructured terrain, especially in time-varying and local terrain mutation conditions. To guarantee adaptability in unstructured terrain environment, the factors, including the obstacle height, terrain depth, and secure foothold as well as stability state, should be considered in the gait and trajectory planning. In this article, a novel gait transition hierarchical control framework based on a flexible gait planner (FGP), and gait feedback regulator (GFR) with behavior rules is proposed for the developed hexapod wheel-legged robot (BIT-6NAZA). The core of this gait planner is to select the optimal footholds and change gait types according to secure foothold and stability margin and kinematic margin of legs, and the GFR is applied to modify the foot-end trajectory of the selected gait according to the terrain feedback information to adapt to unstructured terrain. Finally, taking BIT-6NAZA robot as an example, the simulation and experiment are carried out under the proposed control framework. The co-simulation and experimental results show that the robot can modify the foot-end trajectory in dynamic unstructured terrain and obtain elastic gait in obstacle avoidance.}
}
@article{WEN2022103997,
title = {CL-MAPF: Multi-Agent Path Finding for Car-Like robots with kinematic and spatiotemporal constraints},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103997},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103997},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002530},
author = {Licheng Wen and Yong Liu and Hongliang Li},
keywords = {Multi-agent systems, Path planning, Mobile robots},
abstract = {Multi-Agent Path Finding has been widely studied in the past few years due to its broad application in the field of robotics and AI. However, previous solvers rely on several simplifying assumptions. This limits their applicability in numerous real-world domains that adopt nonholonomic car-like agents rather than holonomic ones. In this paper, we give a mathematical formalization of the Multi-Agent Path Finding for Car-Like robots (CL-MAPF) problem. We propose a novel hierarchical search-based solver called Car-Like Conflict-Based Search to address this problem. It applies a body conflict tree to address collisions considering the shapes of the agents. We introduce a new algorithm called Spatiotemporal Hybrid-State A* as the single-agent planner to generate agents’ paths satisfying both kinematic and spatiotemporal constraints. We also present a sequential planning version of our method, sacrificing a small amount of solution quality to achieve a significant reduction in runtime. We compare our method with two baseline algorithms on a dedicated benchmark and validate it in real-world scenarios. The experiment results show that the planning success rate of both baseline algorithms is below 50% for all six scenarios, while our algorithm maintains that of over 98%. It also gives clear evidence that our algorithm scales well to 100 agents in 300 m × 300 m scenario and is able to produce solutions that can be directly applied to Ackermann-steering robots in the real world. The benchmark and source code are released in https://github.com/APRIL-ZJU/CL-CBS. The video of the experiments can be found on YouTube.}
}
@article{KOVAL2022104168,
title = {Dataset collection from a SubT environment},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104168},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104168},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000951},
author = {Anton Koval and Samuel Karlsson and Sina Sharif Mansouri and Christoforos Kanellakis and Ilias Tevetzidis and Jakub Haluska and Ali-akbar Agha-mohammadi and George Nikolakopoulos},
keywords = {Dataset, SubT, RGB, RGB-D, Event-based and thermal cameras, 2D and 3D lidars},
abstract = {This article presents a dataset collected from the subterranean (SubT) environment with a current state-of-the-art sensors required for autonomous navigation. The dataset includes sensor measurements collected with RGB, RGB-D, event-based and thermal cameras, 2D and 3D lidars, inertial measurement unit (IMU), and ultra wideband (UWB) positioning systems which are mounted on the mobile robot. The overall sensor setup will be referred further in the article as a data collection platform. The dataset contains synchronized raw data measurements from all the sensors in the robot operating system (ROS) message format and video feeds collected with action and 360 cameras. A detailed description of the sensors embedded into the data collection platform and a data collection process are introduced. The collected dataset is aimed for evaluating navigation, localization and mapping algorithms in SubT environments. This article is accompanied with the public release of all collected datasets from the SubT environment. Link: Dataset}
}
@article{SONG2022104087,
title = {Adaptive neural fuzzy reasoning method for recognizing human movement gait phase},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104087},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104087},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000434},
author = {Jiyuan Song and Aibin Zhu and Yao Tu and Han Mao and Xiaodong Zhang},
keywords = {Human gait, Phase division, ANFIS, Signal processing},
abstract = {In response to the needs of real-time and accurate detection of the human gait phase for lower limb exoskeleton, the movement of the human foot is taken as the research object, and the human gait phase division method based on human kinematics and dynamics information is studied. This paper presents a wearable foot gait analysis system based on inertial sensors and pressure sensors, and studies the human gait phase recognition method based on plantar acceleration and plantar pressure information. Based on the analysis of the relationship between the plantar acceleration–pressure information and the gait period, the adaptive neural fuzzy reasoning system is used to integrate the information of plantar acceleration and plantar pressure information so as to realize the fast gait phase division. The three proposed methods are compared with the standard results of the Vicon motion capture system by experiments. The experimental results show that the accuracy of the ANFIS method combining the acceleration information and the plantar pressure information to the human gait phase division is 99.16%.}
}
@article{MULLER2022104187,
title = {A constraint embedding approach for dynamics modeling of parallel kinematic manipulators with hybrid limbs},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104187},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104187},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001087},
author = {Andreas Müller},
keywords = {Parallel kinematic manipulator (PKM), Complex limbs, Kinematic loop, Constraints, Constraint embedding, Redundancy, Inverse kinematics, Singularity, Dynamics, Multibody system, Model-based control, Screws, Lie group (3)},
abstract = {Parallel kinematic manipulators (PKM) are characterized by closed kinematic loops, due to the parallel arrangement of limbs but also due to the existence of kinematic loops within the limbs. Moreover, many PKM are built with limbs constructed by serially combining kinematic loops. Such limbs are called hybrid, which form a particular class of complex limbs. Design and model-based control requires accurate dynamic PKM models desirably without model simplifications. Dynamics modeling then necessitates kinematic relations of all members of the PKM, in contrast to the standard kinematics modeling of PKM, where only the forward and inverse kinematics solution for the manipulator (relating input and output motions) are computed. This becomes more involved for PKM with hybrid limbs. In this paper a modular modeling approach is employed, where limbs are treated separately, and the individual dynamic equations of motions (EOM) are subsequently assembled to the overall model. Key to the kinematic modeling is the constraint resolution for the individual loops within the limbs. This local constraint resolution is a special case of the general constraint embedding technique. The proposed method finally allows for a systematic modeling of general PKM. The method is demonstrated for the IRSBot-2, where each limb comprises two independent loops.}
}
@article{SABIHA2022104058,
title = {ROS-based trajectory tracking control for autonomous tracked vehicle using optimized backstepping and sliding mode control},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104058},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104058},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000276},
author = {Ahmed D. Sabiha and Mohamed A. Kamel and Ehab Said and Wessam M. Hussein},
keywords = {Autonomous tracked vehicles, Backstepping control, Dynamic modeling, Robot operating system (ROS), Sliding mode control (SMC)},
abstract = {This paper investigates the trajectory tracking control of an autonomous tracked vehicle. First, the desired linear and angular velocities are evaluated based on vehicle’s kinematics. An optimized backstepping controller is proposed as the kinematic controller, whereas the controller gains are optimally obtained. Next, an integral sliding mode control (SMC) is exploited based on vehicle dynamics and slipping characteristics, to obtain the desired torques that drive the vehicle and converge its trajectory to the desired one. Moreover, stability analysis of the whole system is proven based on Lyapunov theory. Finally, simulations and real-time experiments based on robot operating system (ROS) implementation are conducted to validate the effectiveness of the proposed control algorithm and compared with a hybrid backstepping-modified PID dynamic controller.}
}
@article{BONETTO2022104102,
title = {iRotate: Active Visual SLAM for Omnidirectional Robots},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104102},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104102},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000550},
author = {Elia Bonetto and Pascal Goldschmid and Michael Pabst and Michael J. Black and Aamir Ahmad},
keywords = {View planning for SLAM, Vision-based navigation, SLAM, Active Perception},
abstract = {In this paper, we present an active visual SLAM approach for omnidirectional robots. The goal is to generate control commands that allow such a robot to simultaneously localize itself and map an unknown environment while maximizing the amount of information gained and consuming as low energy as possible. Leveraging the robot’s independent translation and rotation control, we introduce a multi-layered approach for active V-SLAM. The top layer decides on informative goal locations and generates highly informative paths to them. The second and third layers actively re-plan and execute the path, exploiting the continuously updated map and local features information. Moreover, we introduce two utility formulations to account for the presence of obstacles in the field of view and the robot’s location. Through rigorous simulations, real robot experiments, and comparisons with state-of-the-art methods, we demonstrate that our approach achieves similar coverage results with lesser overall map entropy. This is obtained while keeping the traversed distance up to 39% shorter than the other methods and without increasing the wheels’ total rotation amount. Code and implementation details are provided as open-source, and all the generated data is available online for consultation.}
}
@article{ALIREZAZADEH2022104144,
title = {Optimal algorithm allocation for robotic network cloud systems},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104144},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104144},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000835},
author = {Saeid Alirezazadeh and André Correia and Luís A. Alexandre},
keywords = {Cloud robotics, Robotic networks, Cloud, Fog, Edge, Memory and time optimization, Algorithm allocation},
abstract = {A robotic network is a system with multiple robots connected by a communication network. Certain tasks that cannot be accomplished with available robotic resources are candidates for the use of cloud robotics, which overcomes the limitations of the robot network by adding to the network, either local or remote servers or cloud infrastructure, to aid in computational demanding tasks or storage. Previous studies have mainly focused on minimizing the cost of the robots in retrieving resources by knowing the resource allocation in advance. We develop a method for a robotic network cloud system that includes robots, fog and cloud nodes, to determine where each algorithm should be allocated so that the system achieves optimal performance, regardless of which robot initiates the request. We can find the minimum required memory for the robots and the optimal way to allocate the algorithms with the shortest time to complete each task. We experimentally compare our method with a state-of-the-art method, using real-world data, showing the improvements that can be obtained.}
}
@article{DO2022104063,
title = {Heat conduction combined grid-based optimization method for reconfigurable pavement sweeping robot path planning},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104063},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104063},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000318},
author = {Huy Do and Anh {Vu Le} and Lim Yi and Joel Chan Cheng Hoong and Minh Tran and Phan {Van Duc} and Minh Bui Vu and Oliver Weeger and Rajesh Elara Mohan},
keywords = {Self-reconfigurable robot, Pavement cleaning robot, Multi-objective path planning, Heat conduction, Mobile robot},
abstract = {Self-reconfigurable robots can change their morphology to expose functionality that enables them to overcome challenges that fixed shape robots are unable to overcome. A reconfigurable pavement sweeping robot, Panthera, is able to reconfigure in width by compressing and expanding. This autonomous system overcomes challenges in the pavement cleaning industry, such as access to tight and narrow pavements. Reconfigurability in width enables the robot to maximize cleaning area in an expanded state and navigate through tight spaces in the compressed state, which fixed shape robots are unable to pass through. Despite its advantages, most path planning (PP) algorithms are developed for fixed shape robots, and there are little or no works done on PP for reconfigurable robots that are able to expand and compress in width. To tackle this challenge, we present a novel PP method for pavement-sweeping reconfigurable robots by drawing similarities between heat transfer analysis and PP. Heat travels from the heat source to the heat sink and can only travel through a conductive material. Similarly, PP enables the robot to move from start to goal while accessing the feasible areas. Our proposed path planner employs a thermal gradient ascent combined grid-based optimization algorithm to generate optimal paths for best smoothness, distance, and robot footprint. The path planner is tested in four virtual environments and validated in a real-world environment.}
}
@article{YUE2022104166,
title = {Vehicle motion segmentation via combining neural networks and geometric methods},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104166},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104166},
url = {https://www.sciencedirect.com/science/article/pii/S092188902200094X},
author = {Min Yue and Guangyuan Fu and Ming Wu and Yuqing Zhao and Shaolei Zhang},
keywords = {Vehicle motion segmentation, Deep learning, Multiple moving objects, Dynamic SLAM, View re-projection},
abstract = {Motion segmentation is important for autonomous robots’ activities in dynamic scenes, which has been a challenging problem due to the dual motion caused by the camera and moving objects. The existing methods based on the optical or scene flow are sensitive to the environment, whereas deep learning-based methods commonly do not consider geometric constraints. Aiming at a vehicle, as the most common object in outdoor urban dynamic scenes because other objects, such as people, can be almost directly determined as a moving object, this paper proposes an object-level motion segmentation method for multiple moving objects combining geometric methods and deep learning. First, we choose three kinds of learned information, constructing object-level three-dimensional (3D) scene structure. And then, to infer motion segmentation results from learned information, we propose an instance cross-matching method to obtain instance correspondence and a motion segmentation extraction method based on instance reprojection residual to determine whether the objects are moving or not. The proposed approach is simple and direct, and it can obtain vehicle motion segmentation results from the original RGB images without using the optical or scene flow commonly used to extract motion information. Experiments on public motion segmentation datasets demonstrate that the proposed method can effectively improve the performance of vehicle motion segmentation and is superior to the most advanced methods in terms of accuracy.}
}
@article{MUNARO2022104195,
title = {Continuous mapping of large surfaces with a quality inspection robot},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104195},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104195},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001129},
author = {Matteo Munaro and Morris Antonello and Mauro Antonello and Emanuele Menegatti},
keywords = {Image registration, Mapping, Sensor in motion, Quality inspection, Carbon fibre, Inspection robot},
abstract = {This paper addresses the problem of mapping large surfaces with a moving sensor. In particular, it proposes image registration and mapping algorithms that enable to use in continuous motion sensors that need multiple shots to perform a measurement. These methods exploit the knowledge of the shape of the part to inspect in a both efficient and accurate fashion, thus allowing to obtain a measurement quality comparable to that of static measurements, while guaranteeing fast sensor motion and thus short scanning times. This work describes the application of these methods for the mapping of carbon fibre parts with an inspection robot equipped with a sensor estimating 3D carbon fibre orientation from multiple 2D images captured with different illumination. Experiments on carbon fibre preforms of complex 3D shape demonstrates that this system accurately reconstructs in real-time the 3D fibre orientations of the outer layer of carbon fibre parts. Accuracy assessments report small errors within the tolerances allowed by the automotive industry on flat and generic 3D surfaces. The inspection robot system presented in this paper has been demonstrated both as an in-line quality inspection robot for production of carbon fibre preforms and as a measurement device for improving the draping process in the prototyping of carbon fibre parts.}
}
@article{DOGRU2022104242,
title = {ECO-CPP: Energy constrained online coverage path planning},
journal = {Robotics and Autonomous Systems},
volume = {157},
pages = {104242},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104242},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001403},
author = {Sedat Dogru and Lino Marques},
keywords = {Coverage path planning, Energy constrained, Online},
abstract = {Some robotic platforms are expected to perform coverage path planning (CPP) on a daily basis. However, at times they may be expected to perform CPP in large unknown spaces, which are not fully coverable with the onboard limited energy supply. In these cases the platforms need to revisit the charging station multiple times, increasing mission times and the total energy needed, reducing the availability of the robots. This paper proposes a novel solution to this energy constrained online coverage path planning problem, showing effectiveness of this solution in various settings. The proposed solution is based on contour following and outperforms existing work in the literature. Additionally, this work presents a new lower bound for the minimum number of charges and energy consumed for both, offline and online, energy constrained coverage path planning problems.}
}
@article{ZHANG2022104122,
title = {Design of intelligent fire-fighting robot based on multi-sensor fusion and experimental study on fire scene patrol},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104122},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104122},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000677},
author = {Shuo Zhang and Jiantao Yao and Ruochao Wang and Zisheng Liu and Chenhao Ma and Yingbin Wang and Yongsheng Zhao},
keywords = {Intelligent fire-fighting robot, Multi-sensor fusion, Path planning, Ant Colony Optimization, Fire source identification and location},
abstract = {Based on the current situation that most fire-fighting robots are operated by humans and do not have independent planning and operation abilities, in this paper an intelligent fire-fighting robot is designed using multi-sensor fusion. The robot has the functions of automatic inspection and fire-fighting, and can integrate the information of the operational environment and make decisions based multi-sensor fusion. An improved path-planning mechanism is proposed in order to overcome some disadvantages of the ant colony optimization algorithm, such as its easy tendency to reach local optimal solutions, slow convergence speed and weak global searching ability. A comprehensive evaluation method of the improved ACO is established to quantify its relevance and effectiveness. A joint calibration scheme for the color and temperature information obtained using an infrared thermal imager and a binocular vision camera was designed, and the internal and external parameters and distortion coefficient of the camera were successfully obtained. Based on the principle of binocular vision, a fire source detection and location strategy is proposed. When a fire source is detected, the location of the fire source is determined quickly and rescue path planning can be carried out, which improves the intelligence level of the fire-fighting robot. Finally, MATLAB and ROS are used to analyze the improved algorithm, and a fire site patrolling experiment is carried out. The results showed that the improved ACO greatly improves the convergence, reduces the number of iterations and greatly shortens the length of the patrol path, while the robot can effectively determine the location of the fire source efficiently during independent patrols and sound alarms, which will save precious time for fire-fighting and emergency rescue personnel.}
}
@article{BAK2022103995,
title = {Hovering control of an underwater robot with tilting thrusters using the decomposition and compensation method based on a redundant actuation model},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103995},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103995},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002529},
author = {Jeongae Bak and Yecheol Moon and Jongwon Kim and Santhakumar Mohan and TaeWon Seo and Sangrok Jin},
keywords = {Hovering control, Underwater robot, Tilting thruster, Redundant tilting mechanism, Empirical model compensation},
abstract = {Six-degree-of-freedom (6-DOF) hovering control is important for underwater robots to perform various tasks. Our previous underwater robot study, which used tilting thrusters, could not control 6-DOF motion simultaneously owing to several mechanical and control problems. In this study, we developed a new robot with tilting thrusters and improved 6-DOF hovering performance. The maneuverability of the robot was evaluated by analyzing the force and moment of the thrust vector. Based on this, a redundant tilting mechanism without constraints was designed to solve structural problems. A proportional–integral–derivative (PID)-based control design using the decomposition and compensation method (PID-DC) that is appropriate for this mechanism, was derived. The decomposition method was used to overcome the nonlinearity of the thrust vector caused by the tilting mechanism, and the null-space projection technique was applied to minimize the thrust force and avoid the boundary of the tilting angle. A compensator based on the empirical model of the tilting thruster transferred the control input to the system with regulation. Simulation and experimental results verified the validity of the controller for the 6-DOF hovering motion of the robot, and the hovering performance was significantly improved. Furthermore, the stability of the hovering performance under tidal currents was demonstrated through disturbance experiments.}
}
@article{AN2022104011,
title = {Uncertain moving obstacles avoiding method in 3D arbitrary path planning for a spherical underwater robot},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104011},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.104011},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002645},
author = {Ruochen An and Shuxiang Guo and Liang Zheng and Hideyuki Hirata and Shuoxin Gu},
keywords = {Spherical underwater robot, Uncertain dynamic obstacles avoiding, 3D arbitrary path planning, Inertial measurement unit and depth sensor localization},
abstract = {In order to avoid the risk of obstacles collision during the spherical underwater robot (SUR) move to target points in 3D arbitrary path planning, an underwater obstacle avoiding method was studied. Considering the uncertainty of the movement of obstacles in the actual environment, we present an uncertain moving obstacle avoiding method based on the improved velocity obstacle method. In addition, to reduce the distance and time of obstacle avoidance, the concept of the time of obstacle avoiding was designed. First, the size and velocity information of obstacles are obtained through the camera, which can provide an accurate decision basis for obstacles avoidance in the next step. Then, according to the time when the robot collides with the obstacle, the time of start and end of the obstacle avoidance is determined. The movement direction and velocity of the robot are obtained based on the improved velocity obstacle method and the movement characteristics of SUR. Finally, a detailed 3D arbitrary path planning analysis based on an improved ant colony algorithm was conducted. A series of experiments were carried out in the pool that validates the proposed methods are also presented.}
}
@article{KARN2022104234,
title = {ICACIA: An Intelligent Context-Aware framework for COBOT in defense industry using ontological and deep learning models},
journal = {Robotics and Autonomous Systems},
volume = {157},
pages = {104234},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104234},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001361},
author = {Arodh Lal Karn and Sudhakar Sengan and Ketan Kotecha and Irina V. Pustokhina and Denis A. Pustokhin and V. Subramaniyaswamy and Dharam Buddhi},
keywords = {Human–Robot Collaboration, Communication system, Contextual Intelligence, Military agents, Deep Learning, Defense industry, Ontology, Mobile Robotic Systems},
abstract = {Most of the world’s most advanced defense technologies are robots, and the defence industry is slowly moving toward including AI in the military robots they build. For these smart robots to make their own decisions about where to go and what to do, they need to be limited by several algorithms that run continuously and at the same time. Autonomy is the range of automated systems that can be adapted to a specific mission, residual risk, and level of team cohesion between humans and robots. Self-driving robotic systems should be collaborative, which means they should be able to interact actively with humans in a shared space or in proximity to humans and robots. Human–Robot Collaboration (HRC) works better when these COBOTs are aware of their surroundings. Mobile Robot (MR) teams whose perceptual and cognitive abilities are very well developed can help a lot with context awareness. To work well with humans, these robots should know what is going on with their human and other robot teammates so they can make decisions on their own. Also, robots should be able to share information about their surroundings so that humans can benefit from a better understanding of the situation. At the same time, humans should be able to see what the robots are doing. In this paper, we propose a knowledge-based framework for humans and robots to work together to understand the context of Defense missions. An ontological model of contexts for missions, agents, and situations; a knowledge base comprising all the tools necessary for a sort of situation; and an efficient and reliable method of collaborative learning are some of its main contributions. The framework works well in terms of how long it takes for people to talk to each other. As the team continues to expand, it can also easily manage communication challenges and a widely differing event frequency range.}
}
@article{ZHOU2022104079,
title = {Analysis, design and preliminary evaluation of an anthropometric self-stabilization passive exoskeleton for enhancing the ability of walking with loads},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104079},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104079},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000392},
author = {Nengbing Zhou and Yali Liu and Qiuzhi Song and Zhuo Qi and Weizhi Ren and Kun Zhang},
keywords = {Passive exoskeleton, Self-stabilization mechanism, Efficient transmission, Dynamic modeling},
abstract = {This paper introduces the analysis, design and preliminary evaluation of an anthropometric self-stabilization passive exoskeleton (ASPE) with elastic band to increase the load transmission efficiency and protect and strengthen the human body during loaded walking. Firstly, we analyze the working principle of passive exoskeleton, and propose an efficient method of reducing the degrees of freedom in exoskeleton relatively, which contributes to a self-stabilization mechanism for balancing the back torque causing by the loaded backpack and assisting human hip flexion. The design of the ASPE is then introduced in detail. The novelty of the ASPE is that the human–machine interaction forces are significantly reduced by integrating the elastic band into the exoskeleton hip joint and converting load gravity into the elastic potential energy of elastic band to assist hip joint flexion. Furthermore, we analyze the dynamic modeling of the ASPE to preliminarily calculate the transmission efficiency regarding the ratio of plantar pressure of the ASPE to load gravity. Besides, we conduct the experiment of human wearing the ASPE to evaluate the performance of the ASPE regarding the ratio of the difference of human plantar pressure with and without the ASPE to load gravity. The results show that the ASPE can effectively transfer load gravity to the ground and maintain the human natural movement. The ratio of the plantar pressure of the ASPE to load gravity is more than 70% in the simulation, and when the walking speed is 4 km/h, the ASPE reduce the human plantar pressure of 68.9% compared to without wearing the ASPE during human walking with load. The results provide evidence for the efficient transmission of the newly designed ASPE during walking with loads. The application of the ASPE have benefits for subjects walking with loads, such as soldiers, to decrease their injuries and strengthen their ability.}
}
@article{FIGAT2022103987,
title = {Parameterised robotic system meta-model expressed by Hierarchical Petri nets},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103987},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103987},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002487},
author = {Maksym Figat and Cezary Zieliński},
keywords = {Embodied agent approach, Model Driven Engineering, Robotic System Hierarchical Petri Net, Meta-model parameterisation},
abstract = {The paper presents a model-based approach to developing robotic system controllers. Central to this approach is a parameterised meta-model that describes the generic robotic system from two points of view: structure and activity. By appropriate parameterisation of the meta-model one can obtain a particular model of a robotic system performing desired tasks. The meta-model is expressed using the Robotic System Hierarchical Petri Net (RSHPN), a 6-layer Petri net tailored for robotics. Each layer describes the activity of the robotic system at a completely different level of abstraction. This guarantees the separation of concerns. The required model emerges from the meta-model by appropriate parameterisation of the layers of the RSHPN. Introduction of parameterisation enables the robot designer to focus only on the concepts derived from the domain. It greatly facilitates the robotic system development process as it gives the designer clear guidance on what needs to be defined and what is imposed by the design pattern. The resulting single RSHPN model is used both to verify some properties of the system, e.g. lack of deadlocks, but also to automatically generate controller code. The presented approach is illustrated by examples of the creation of two different robotic systems.}
}
@article{KIM2022104128,
title = {Upper extremity exoskeleton system to generate customized therapy motions for stroke survivors},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104128},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104128},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000720},
author = {Beomsu Kim and Kuk-Hyun Ahn and SeungKyu Nam and Dong Jin Hyun},
keywords = {Upper extremity exoskeleton, Rehabilitation robot, Bézier polynomials},
abstract = {This paper proposes the development of a seven degree-of-freedom (DOF) upper extremity exoskeleton to provide robotic therapy solutions for stroke survivors whose number is increasing along with the trend of ‘Aging Society’. Various robotic solutions have been illuminated and advanced along with their interfacing system in order to promote motor recovery after stroke. From this point of view, the proposed exoskeleton, RearMEX, is developed to (1) achieve active-actuation for the full range of human arm motions through the compact mechanical structure, (2) perform high force transparency through the reduction of the mechanical impedance, and (3) provide a user-interface for customized arm movements in active daily life. Especially, the exoskeleton system has a minimal impedance mode where a user can choose sequential desired postures for constituting a therapy motion by the simple button on the handgrip. Then, given a desired period for the movement, a novel interpolation method named norm-based time-allocating monotone Bézier interpolation is proposed to generate the corresponding trajectory with no jerk at each instant in the operational or configurational space. Furthermore, the disturbance observer (DOB) scheme is applied to achieve a robust tracking control performance on the interpolated trajectory even with model uncertainties and unexpected physical interactions with a wearer. The experimental results verify that the consistent performance can be achieved under various load conditions using the suggested controller.}
}
@article{ALSHANOON2022104041,
title = {Robotic manipulation based on 3-D visual servoing and deep neural networks},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104041},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104041},
url = {https://www.sciencedirect.com/science/article/pii/S092188902200015X},
author = {Abdulrahman Al-Shanoon and Haoxiang Lang},
keywords = {Robot–object-interaction, Object-detection and pose estimation, Deep-learning methods, 3D visual-servoing},
abstract = {The critical challenge, for robot–object-interaction, is to estimate visually the pose of the target object in a 3D space and combine it into a vision-based control scheme in manipulation applications. This paper proposes a novel reliable framework for deep ConvNet combined with visual servoing using a single RGB camera. We introduce an extensive system called Deep-Visual-Servoing (DVS) that addresses an integration of: (I) training of deep-CNNs using synthetic dataset only and operates successfully in real-world scenario, (II) continuous 3 D object pose estimation as the sensing feedback in a 3D visual servoing control scheme, and (III) design, integration and experimentation of visual servoing approach based on Lyapunov’s theory. The proposed deep based learning approach, the kinematic modeling and controller design are experimentally verified and discussed using the 6 DOF UR5 manipulator.}
}
@article{CVISIC2022104189,
title = {Enhanced calibration of camera setups for high-performance visual odometry},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104189},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104189},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001099},
author = {Igor Cvišić and Ivan Marković and Ivan Petrović},
keywords = {Camera calibration, Visual odometry, Visual SLAM, Parametric lens models},
abstract = {For robots and autonomous system that rely on visual data for operating in the real world, camera calibration is an indispensable step as it relates image information to the geometric structure of the 3D world. Although it is convenient to consider a several decades old problem as something that is swiftly solvable with a dedicated toolbox, we should still push calibration methods to their practical limits in order to gain valuable insights, and especially when robots are operating in circumstances that concern human safety. In this paper we propose a camera setup calibration procedure with emphasis on visual odometry accuracy. We focus on target-based calibration and two popular datasets are used for evaluating visual odometry and SLAM algorithms, namely the EuRoC and KITTI datasets. Our procedure consists of: (i) introducing a novel highly accurate corner detection algorithm robust to challenging illumination conditions, (ii) investigating different lens distortion models, (iii) incorporating static and dynamic board deformation models, (iv) ex-post analysis of reprojection error sensitivity and calibration parameter uncertainty, and (v) grid search method based on odometry accuracy when board poses do not constrain calibration parameters well enough. The whole process significantly reduced the reprojection error when calibrating the camera setups of the EuRoC and KITTI datasets. We tested four different odometries, namely SOFT, ORB-SLAM2, VINS-FUSION, and VISO2—all four showed higher accuracy with the proposed calibration parameters. Moreover, with the proposed calibration method our SOFT2 scored 0.53% in translation and 0.0009 deg/m in rotation error rendering it currently the highest ranking algorithm on the KITTI scoreboard.}
}
@article{HONG2022104104,
title = {Development and application of key technologies for Guide Dog Robot: A systematic literature review},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104104},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104104},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000562},
author = {Bin Hong and Zhangxi Lin and Xin Chen and Jing Hou and Shunya Lv and Zhendong Gao},
keywords = {Guide Dog Robot, Visually impaired, Navigation, Obstacle avoidance, Human–robot​ interaction},
abstract = {In the current situation of many visually handicapped people worldwide, yet the corresponding number of guide dogs is quite rare. It activates the application of advanced technology to broaden their horizons and allow them to embrace the world. This paper will review the research state of the Guide Dog Robot (GDR) for people with visual impairment and present some views. According to the application scenes, we have divided the GDR into two categories: specific scene applicable type and universal scene applicable type, with the description of different performances under various scenes. Then the current research focuses are elaborated, including localization and navigation technology, recognition of traffic signs, human–robot interaction (HRI), speed coordination, and walking structure design. Subsequently, the studying directions and challenges of GDR are discussed, and collaborative human–robot mode is believed to become the research mainstream. Finally, we conclude this review and explain why few GDR has realized commercialization. The limitations of current studies and some recommendations for future research are presented.}
}
@article{GIMENEZ2022104146,
title = {Motion control for a differential vehicle with variable point of interest. Application: Smart cane control},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104146},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104146},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000847},
author = {Javier Gimenez and Flavio Roberti and Juan Marcos Toibero and Ricardo Carelli},
keywords = {Trajectory tracking, Path following, Extended kinematic model, Variable point of interest, Robotic cane},
abstract = {This article addresses an unified solution to the trajectory tracking and path following problems for differential drive mobile robots (DDMR) considering a point of interest (PoI) with variable location relative to the vehicle. The mobile robot is modeled with an extended kinematic model avoiding typical singularities of this kind of vehicles, and allowing a straightforward definition of the corresponding inverse kinematics controller (IKC). This classical IKC fulfills the control objective with exponential error convergence but with the shortcoming of generating backward navigation when the PoI is located behind the DDMR, which is undesirable in some practical applications where the forward navigation must be preserved. This situation is theoretically analyzed, concluding that even though both forward and backward navigations correspond to equilibrium points of the closed loop, the stability of the forward navigation requires a PoI located in front of the DDMR, and the stability of the backward navigation requires a PoI located behind the DDMR. Finally, the article presents novel alternative controllers in order to always fulfill the motion objectives with stable forward navigation. Simulation results are presented to show the performance of the proposed controllers, and a real application of a robotic cane guiding its user is experimentally developed.}
}
@article{FENG2022104244,
title = {UAV-based persistent full area coverage with dynamic priorities},
journal = {Robotics and Autonomous Systems},
volume = {157},
pages = {104244},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104244},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001415},
author = {Licheng Feng and Jay Katupitiya},
keywords = {Persistent and complete coverage, Minimum Spanning Tree, Priority function, Modified Dijkstra algorithm},
abstract = {This paper tackles the problem of performing persistent and complete coverage of a target space with a minimum number of Unmanned Aerial Vehicles (UAVs). The UAVs are required to preferentially visit subareas of interest with higher frequency than the rest of the surveillance area within a predefined time threshold. A Minimum Spanning Tree based recursive algorithm is firstly proposed to estimate the upper bound of minimum number of UAVs for area coverage with visiting frequency constraints. Then an autonomous path planning strategy is proposed for persistent coverage, where a combinatorial priority function is designed as the goal assignment strategy and a modified Dijkstra algorithm is applied as the goal planning to obtain the optimum path. Finally, computer simulations have been conducted for the evaluation of the proposed solution, and the obtained results show that these algorithms can compute valid and sound solutions under different setups for the UAVs.}
}
@article{STARKE2022104123,
title = {Semi-autonomous control of prosthetic hands based on multimodal sensing, human grasp demonstration and user intention},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104123},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104123},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000689},
author = {Julia Starke and Pascal Weiner and Markus Crell and Tamim Asfour},
keywords = {Semi-autonomous control, Prosthetic hands, Human grasping data, Context-awareness},
abstract = {Semi-autonomous control strategies for prosthetic hands provide a promising way to simplify and improve the grasping process for the user by adopting techniques usually applied in robotic grasping. Such strategies endow prosthetic hands with the ability to autonomously select and execute grasps while keeping the user in the loop to intervene at any time for triggering, accepting or rejecting decisions taken by the controller in an intuitive and easy way. In this paper, we present a semi-autonomous control strategy that allows the user to perform fluent grasping of everyday objects based on a single EMG channel and a multi-modal sensor system embedded in the hand for object perception and autonomous grasp execution. We conduct a user study with 20 subjects to assess the effectiveness and intuitiveness of our semi-autonomous control strategy and compare it to a conventional electromyography-based control strategy. The results show that the workload is reduced by 25.9% compared to conventional electromyographic control, the physical demand is reduced by 60% and the grasping process is accelerated by 19.4%.}
}
@article{LUPERTO2022104170,
title = {User feedback and remote supervision for assisted living with mobile robots: A field study in long-term autonomy},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104170},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104170},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000963},
author = {Matteo Luperto and Marta Romeo and Javier Monroy and Jennifer Renoux and Alessandro Vuono and Francisco-Angel Moreno and Javier Gonzalez-Jimenez and Nicola Basilico and N. Alberto Borghese},
keywords = {Socially Assistive Robots, Long-term autonomy, Field study},
abstract = {In an ageing society, the at-home use of Socially Assistive Robots (SARs) could provide remote monitoring of their users’ well-being, together with physical and psychological support. However, private home environments are particularly challenging for SARs, due to their unstructured and dynamic nature which often contributes to robots’ failures. For this reason, even though several prototypes of SARs for elderly care have been developed, their commercialisation and wide-spread at-home use are yet to be effective. In this paper, we analyse how including the end users’ feedback impacts the SARs reliability and acceptance. To do so, we introduce a Monitoring and Logging System (MLS) for remote supervision, which increases the explainability of SAR-based systems deployed in older adults’ apartments, while also allowing the exchange of feedback between caregivers, technicians, and older adults. We then present an extensive field study showing how long-term deployment of autonomous SARs can be accomplished by relying on such a feedback loop to address any potential issue. To this end, we provide the results obtained in a 130-week long study where autonomous SARs were deployed in the apartments of 10 older adults, with the aim of possibly serving and assisting future practitioners, with the knowledge collected from this extensive experimental campaign, to fill the gap that currently exists for the widespread adoption of SARs.}
}
@article{ROSENFELDER2022103993,
title = {Cooperative distributed nonlinear model predictive control of a formation of differentially-driven mobile robots},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103993},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103993},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002517},
author = {Mario Rosenfelder and Henrik Ebel and Peter Eberhard},
keywords = {Formation control, Model predictive control, Distributed control, Non-holonomic systems, Mobile robots, Experiments},
abstract = {Due to the increasing complexity of today’s tasks and the demand for higher performance and robustness, using a single robot is not always expedient in robotics applications. Therefore, having multiple autonomous robotic agents collaborate utilizing explicit communication is gaining more attention. The goal of this article is to develop a distributed algorithm that allows the formation control of multiple differentially-driven mobile robots. The formation control goal is formulated in a novel manner by leveraging results on the control of a single differentially-driven mobile robot, which is sophisticated due to the present non-holonomic constraint. This results in a nonlinear distributed control problem. The fundamental functionality of the developed algorithm is analyzed in simulation scenarios. The applicability to real-life scenarios is demonstrated through experiments with custom hardware. To the best of the authors’ knowledge, this is the first time that nonlinear distributed model predictive control is applied to a formation of differentially-driven mobile robots using a theoretically-founded cost function and, moreover, that the results are verified with hardware experiments.}
}
@article{WU2022103961,
title = {FEM-based trajectory tracking control of a soft trunk robot},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103961},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103961},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002359},
author = {Ke Wu and Gang Zheng and Junfeng Zhang},
keywords = {Soft robotics, Finite Element Method, Trajectory planning, Trajectory tracking control},
abstract = {As a novel class of robots, soft robots have demonstrated many desirable mechanical properties than traditional rigid robots due to their nature of being compliant, flexible and hyper-redundant, such as great adaptability to unknown environments, safe human robot interaction (HRI), energy-saving actuation and the maneuverability to display diverse mechanical properties. However, its inherent high-DoF nature would result in some complex nonlinear behaviors, and their kinematic or dynamic models are therefore harder to deduce than the ones of conventional rigid robots. In this paper, we propose a trajectory tracking control strategy for a soft trunk robot based on Finite Element Method (FEM). We first plan a feasible trajectory for the studied robot in SOFA (a FEM-based simulator) by solving a model-prediction-control (MPC)-based optimization problem. The second step is to conduct linearization around the pre-designed trajectory, based on which an associated controller can be then developed. The detailed derivation of the mentioned work is explained accordingly. In the end, the results of experimental validation is presented to prove the feasibility of the proposed method.}
}
@article{YANG2022104197,
title = {A novel stereo image self-inpainting network for autonomous robots},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104197},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104197},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001130},
author = {Xiaokang Yang and Hengyu Li and Jingyi Liu and Yonghao Xie and Huayan Pu and Shaorong Xie and Jun Luo},
keywords = {Stereo image inpainting, CNN, Feature alignment, Attention mechanism},
abstract = {Recently, vision-based methods have exhibited promising prospects in assigning autonomous robots more capabilities for better environment perception. Since visual sensors are easily affected under extreme conditions, current image inpainting methods based on CNNs jointly with generative adversarial networks (GANs) usually generate patches quite different from the ground truth (GT), which is harmful to autonomous robots. In this paper, we propose a novel multiscale feature alignment module with an early fusion strategy to align the left and right feature maps to better capture the motion cues between them. Then, the aligned features are fused to fill holes in the left image. To aggregate the multiscale feature maps dynamically, we propose a multiscale feature aggregation module based on an attention mechanism, of which the fusion module is designed as a symmetrical architecture to adaptively incorporate the complementary contextual correlations from different feature branches. In addition, a spatial attention module able to capture the correlations among pixels is introduced into our network to enhance the inpainting capacity and generate more refined details. To evaluate the effectiveness of our proposed method, many experiments are conducted on a stereo image dataset. The quantitative and qualitative results show that our method significantly outperforms the recent state-of-the-art image inpainting methods while running over 22 fps on a single NVIDIA RTX2080Ti GPU.}
}
@article{SAQIB2022104009,
title = {A framework for spatial map generation using acoustic echoes for robotic platforms},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {104009},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.104009},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002633},
author = {Usama Saqib and Jesper Rindom Jensen},
keywords = {Robot audition, TOA estimation, DOA estimation, Echolocation, Localization, Mapping},
abstract = {In this work, we present a framework for constructing a spatial map of an indoor environment using the concept of echolocation. More specifically, we propose a non-linear least squares (NLS) estimator which is combined with a spatial filtering technique, e.g., beamforming, to estimate both the time-of-arrival (TOA) and direction-of-arrival (DOA) of the acoustic echoes. The proposed framework is complemented with an echo detector to classify a spurious estimate and an acoustic reflector, i.e., a wall. Based on these estimators, we propose two algorithms that complement existing range sensors and aid robotic platforms in acoustic reflector localization and mapping: single-channel localization and mapping (ScLAM) and a multi-channel localization and mapping (McLAM). Compared to commonly used sensors, such as lidar, cameras and ultrasonic sensors, our proposed model-based approach can detect transparent surfaces that are typically found in an office environment and could work in audible frequency ranges. A proof-of-concept robotic platform was built to test our algorithms. According to our evaluation, both qualitative and quantitative experiments reveal that the proposed methods can detect an acoustic reflector up to a distance of 1.5 m at a signal-to-diffuse-noise ratio (SDNR) of 0 dB in a simulated environment and 10 dB in a real environment with an accuracy of 80%.}
}
@article{YANG2022104043,
title = {A parallel shape formation method for swarm robotics},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104043},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104043},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000161},
author = {Hong-an Yang and Yuhua Li and Xin Duan and Gaopan Shen and Shaohua Zhang},
keywords = {Swarm robotics, Shape formation, Task differentiation, Parallel forming, Artificial potential field},
abstract = {In order to cope with diversified tasks and unstructured environments, a parallel shape formation method for swarm robotics is introduced to adjust the system’s configuration autonomously and flexibly with the user-specified 2-D shape. Given the desired shape to be formed in the form of analytic functions, the forming task of the swarm system is divided into two sub-tasks: the edge robot forming task and the internal robot forming task. Then, the seed robot is selected through the generation and transmission of the gradient to establish the relative coordinate system, and the initial coordinates of robots are obtained through trilateral positioning. Based on that, using the artificial potential field method, under the action of gravitational force generated by the objective analytic functions and repulsion forces generated by other individuals in the neighborhood, edge individuals move to the target boundary; at the same time, internal individuals spread evenly in the target area under the action of the repulsion forces generated by each other. During the forming process, the two sub-tasks are executed in parallel, and the individuals continue to update their real-time positions by dead-reckoning until the desired shape is formed. We evaluate the feasibility and scalability of this novel method in simulation-based experiments, and implement the parallel shape formation algorithm on the Cilibot robot, a hardware system developed in our lab.}
}
@article{WU2022103985,
title = {Convolutionally evaluated gradient first search path planning algorithm without prior global maps},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {103985},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103985},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002475},
author = {Yizhi Wu and Fei Xie and Lei Huang and Rui Sun and Jiquan Yang and Qiang Yu},
keywords = {Path planning, Mobile robot, Gradient descent, Unknown environments},
abstract = {Most of the existing path planning algorithms require a prior global map. Although there have been some algorithms proposed for unknown environments, they can only deal with those which just have several hidden obstacles in a roughly known global map. In order to improve the efficiency of robot’s path planning without prior global maps, this paper proposes a Convolutionally Evaluated Gradient First Search (CE-GFS) path planning algorithm. It allows the robot to collect environmental information and complete path planning simultaneously. Firstly, the Gradient First Search (GFS) algorithm is proposed based on the gradient score parameter, with which the conventional cost function is replaced. The GFS can adapt to any moving direction through the environmental information surrounding the mobile robot and computing the gradient score parameter. Secondly, CE-GFS path planning algorithm is proposed based on GFS and convolutional evaluation method. The CE-GFS helps the robots to evaluate the efficiency of the global path and get global perception ability, so that they are prevented from going astray, which can significantly improve the efficiency of path planning. Finally, several simulation tests and field tests have been carried out. The test results show that convolutional evaluation improves the efficiency of CE-GFS by 86.94% on average compared with GFS at the price of 0.18% decrease in path planning success rate. Moreover, the time cost of the proposed CE-GFS algorithm is 42.18% less than that of FAR-Planner in some special cases.}
}
@article{BHARADWAJ2022104084,
title = {Synthesis of strategies for autonomous surveillance on adversarial targets},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104084},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104084},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000410},
author = {Suda Bharadwaj and Rayna Dimitrova and Jesse Quattrociocchi and Ufuk Topcu},
keywords = {Synthesis, Formal methods in robotics, Temporal logic, Surveillance, Partial-information},
abstract = {We study the problem of synthesizing a controller for an agent with imperfect sensing and a quantitative surveillance objective, that is, an agent is required to maintain knowledge of the location of a moving, possibly adversarial target. We formulate the problem as a one-sided partial-information game with a winning condition expressed as a temporal logic specification. The specification encodes the quantitative surveillance requirement as well as any additional tasks. Solving a partial-information game typically involves transforming it into a perfect-information belief game using a belief-set construction. Such a transformation leads to a state-space explosion, rendering the belief game computationally intractable to solve for most realistic settings. We present a belief-set abstraction technique to transform the partial-information game to a provably sound abstract belief game that can be solved efficiently using off-the-shelf reactive synthesis tools. We introduce a counterexample-guided refinement approach to automatically achieve the abstraction precision sufficient to synthesize a strategy that is provably winning on the original partial-information game. We evaluate the proposed method on multiple case-studies, implemented on hardware as well as high-fidelity ROS/Gazebo simulations where the agent must respond in real-time to a human-controlled adversary.}
}
@article{PALIGA2022104191,
title = {Human–cobot interaction fluency and cobot operators’ job performance. The mediating role of work engagement: A survey},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104191},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104191},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001105},
author = {Mateusz Paliga},
keywords = {Human–robot collaboration, Human–robot interaction fluency, Cobot, Cognitive ergonomics, Job performance, Work engagement},
abstract = {Advanced human–robot interaction becomes an essential resource in Industry 4.0. Specifically, the deployment of collaborative robots (cobots) has changed the game in modern smart factories. These robotic agents assist human operators, working with them side-by-side on joint task execution. Because cobots are designed to be more co-workers than tools, fluent interaction between the operators and their robotic counterparts is critical for employees’ task accomplishment and, thus, high performance. The current study investigates the relationships between four perspectives of human–robot interaction fluency (i.e., the human emotions-oriented, the human contribution-oriented, the robot-oriented, and the team-oriented fluency) and operators’ subjective job performance. It also examines the mediating role of work engagement in these relationships. The analysis carried out on 190 male and female cobot operators working on the shop floor showed positive associations between human–robot interaction (HRI) fluency and job performance. The study confirmed the mediating role of work engagement in the relationships of human contribution-oriented fluency and team-oriented fluency with job performance. The obtained results suggest that HRI fluency relates to employee job performance because of the positive affective–cognitive state experienced by the operator when cooperating with a cobot in a coordinated and well-synchronized manner. The findings of the study are discussed within the theoretical framework of cognitive ergonomics, the Job Demand-Control-Support model, the job demands-resources model, and the job design perspective. The article finishes with a conclusion of the results and implications for organizational practice.}
}
@article{MARCHIDAN2022104156,
title = {A local reactive steering law for 2D collision avoidance with curvature constraints and constant speed},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104156},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104156},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000896},
author = {Andrei Marchidan and Efstathios Bakolas},
keywords = {Real-time algorithms, Collision avoidance, Steering law, Curvature constraints, Path planning, Moving obstacles},
abstract = {Motion planning algorithms for dynamic environments that explicitly take into account actuator constraints require a lot of computational effort due to replanning or optimizing trajectories. This makes them limited in use, especially for autonomous reactive behaviors that need to be computed on-board. Motivated by this need, we present a new real-time method for reactive collision avoidance for systems with bounded curvature in static and dynamic environments. Our approach relies on the implementation of a local steering law that satisfies a predefined bound on path curvature. The steering law depends on a user-defined parametric function that determines the transition between obstacle-free motion and collision avoidance by enforcing an obstacle impenetrability constraint. As such, we propose a systematic procedure which modulates the velocity vector to enforce curvature constraints in complex 2D environments characterized by static and moving obstacles. We provide theoretical guarantees for collision avoidance and we demonstrate this methodology through simulations.}
}
@article{MONTESDEOCA2022104075,
title = {Person-Following Controller with Socially Acceptable Robot Motion},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104075},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104075},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000379},
author = {Julio Montesdeoca and J. Marcos Toibero and Julian Jordan and Andreas Zell and Ricardo Carelli},
keywords = {Person-following control, Human–robot social interaction, Socially acceptable robot motion, Motion human-aware robot navigation, Human–robot interactive communication},
abstract = {This work presents a novel stable controller for the person-following task that includes social considerations for a differential drive mobile robot equipped with an RGB-D camera and a laser range finder as main sensors. The proposed controller adapts its behavior based on the knowledge of both: a modified personal space distribution and human user velocity. Control objectives are focused hence on keeping the human user within the camera’s field-of-view while the mobile robot follows it, with a socially acceptable motion through arbitrary paths. To show the good behavior of this proposal, simulation and real experimental results are included and discussed. The asymptotic stability of the overall system is proved through the Lyapunov theory. Also, in our proposal, three state-of-the-art algorithms were integrated with the controller. In particular, a new real-time multi-person skeletal tracking system is used to obtain the relative human–robot position, a text to speech algorithm is used to confirm the commands given by the human, and also, a SLAM algorithm is used to obtain the map of the environment while the main task is being performed. Additionally, a hand gesture recognition module is included to interact with the mobile robot. This way, the robot is allowed to navigate with a socially-aware behavior in environments shared with humans. Finally, subjective and objective metrics are used as a validation method for human perception about the achieved robot motion.}
}
@article{CHEN2022104116,
title = {Reinforcement learning control for the swimming motions of a beaver-like, single-legged robot based on biological inspiration},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104116},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104116},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000653},
author = {Gang Chen and Yuwang Lu and Xin Yang and Huosheng Hu},
keywords = {Reinforcement learning control, Q-learning, Beaver-like, Swimming, Underwater bionic robots},
abstract = {Complex hydrodynamic modeling and analysis are considered as stumbling blocks in the motion study of underwater bionic robots. In recent years, reinforcement learning techniques have been applied for robot motion control in unknown environments. However, robots may act in an unconventional or dangerous manner during the learning process. These actions increase the training difficulty and decrease the training efficiency. In this study, a biological-inspired reinforcement learning control method is proposed. It realizes the self-learning movement policy of the robot with discretized swimming motions of a beaver without the need to establish motion models, such as hydrodynamics, of underwater robots. The biological-inspired model further reduces the robot’s ineffective movements during the reinforcement learning and improves training efficiency. The experiment results verify the environmental adaptation and self-learning ability of the proposed robot platform and proves the effectiveness of the reinforcement learning control method for robotic swimming based on biological inspiration. This study’s findings provide new ideas for the motion control of underwater bionic robots and further promote the application of artificial intelligence in underwater robots.}
}
@article{BENSALAH2022104037,
title = {Summarizing large scale 3D mesh for urban navigation},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104037},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104037},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000136},
author = {Imeen {Ben Salah} and Sébastien Kramm and Cédric Demonceaux and Pascal Vasseur},
keywords = {3D mapping, Summarized mapping, Localization based vision},
abstract = {Cameras have become increasingly common in vehicles, smartphones, and advanced driver assistance systems. The areas of application of these cameras in the world of intelligent transportation systems are becoming more and more varied: pedestrian detection, line crossing detection, navigation, …A major area of research currently focuses on mapping that is essential for localization and navigation. However, this step generates an important problem of memory management. Indeed, the memory space required to accommodate the map of a small city is measured in tens gigabytes. In addition, several providers today are competing to produce High-Definition (HD) maps. These maps offer a rich and detailed representation of the environment for highly accurate localization. However, they require a large storage capacity and high transmission and update costs. To overcome these problems, we propose a solution to summarize this type of map by reducing the size while maintaining the relevance of the data for navigation based on vision only. The summary consists in a set of spherical images augmented by depth and semantic information and allowing to keep the same level of visibility in every directions. These spheres are used as landmarks to offer guidance information to a distant agent. They then have to guarantee, at a lower cost, a good level of precision and speed during navigation. Some experiments on real data demonstrate the feasibility for obtaining a summarized map while maintaining a localization with interesting performances.}
}
@article{2023104540,
title = {Editorial Board},
journal = {Robotics and Autonomous Systems},
volume = {169},
pages = {104540},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/S0921-8890(23)00179-3},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023001793}
}
@article{BUCHLER2023104230,
title = {Learning to Control Highly Accelerated Ballistic Movements on Muscular Robots},
journal = {Robotics and Autonomous Systems},
volume = {159},
pages = {104230},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104230},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001348},
author = {Dieter Büchler and Roberto Calandra and Jan Peters},
keywords = {Bio-inspired, Pneumatic artificial muscles, Bayesian optimization, High accelerations, Co-contraction},
abstract = {High-speed and high-acceleration movements are inherently hard to control. Applying learning to the control of such motions on anthropomorphic robot arms can improve the control’s accuracy but might damage the system. The inherent exploration of learning approaches can lead to instabilities and the robot reaching joint limits at high speeds. Having hardware that enables safe exploration of high-speed and high-acceleration movements is therefore desirable. To address this issue, we propose to use robots actuated by pneumatic artificial muscles (PAMs). In this paper, we present a four degrees of freedom (DoFs) robot arm that reaches high joint angle accelerations of up to 28000°s-2 while avoiding dangerous joint limits thanks to the antagonistic actuation and limits on the air pressure ranges. With this robot arm, we can tune control parameters using Bayesian optimization directly on the hardware without additional safety considerations. The achieved tracking performance on a fast trajectory exceeds previous results on comparable PAM-driven robots. We also show that our system can be controlled well on slow trajectories with PID controllers due to careful construction considerations such as minimal bending of cables, lightweight kinematics, and minimal contact between PAMs and PAMs with the links. Finally, we propose a novel technique to control the co-contraction of antagonistic muscle pairs. Experimental results illustrate that choosing the optimal co-contraction level is vital to reach better tracking performance. Using PAM-driven robots and learning, we do a small step towards the future development of robots capable of more human-like motions.}
}
@article{GUTOW2022103991,
title = {AND/OR search techniques for chance constrained motion primitive path planning},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103991},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103991},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002505},
author = {Geordan Gutow and Jonathan D. Rogers},
keywords = {Motion primitives, Trajectory planning, MDP, Graph search, And/Or graphs, Parametric uncertainty, Chance constraints, Collision avoidance, Informed search},
abstract = {Motion primitive planning under parametric uncertainty may be modeled as a chance-constrained Markov Decision Process (CCMDP). Single-query solutions to CCMDPs can be obtained by searching the And/Or graph representing the state–action space of the system. The Risk-bounded AO* (RAO*) algorithm has been proposed as a solution method for this problem, but it scales poorly to MDPs resulting from a motion primitive discretization because it has no mechanism to prioritize expansion of AND nodes. This paper describes an induced heuristic for state–action pairs that can be rapidly computed by leveraging the properties of motion primitives; its value can be used to prioritize AND nodes for more efficient search. Search is further accelerated by leveraging shared symmetry in constraints and dynamics to move almost all computation necessary to enforce convex polytope constraints offline. The performance improvements are demonstrated with path planning problems involving a Dubins Car and a nonlinear aircraft model.}
}
@article{PRAMANICK2022104183,
title = {Talk-to-Resolve: Combining scene understanding and spatial dialogue to resolve granular task ambiguity for a collocated robot},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104183},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104183},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001063},
author = {Pradip Pramanick and Chayan Sarkar and Snehasis Banerjee and Brojeshwar Bhowmick},
keywords = {Human–robot interaction, Ambiguity in HRI, Spatial dialogue, Multi-level ambiguity, Language-vision grounding},
abstract = {The utility of collocating robots largely depends on the easy and intuitive interaction mechanism with the human. If a robot accepts task instruction in natural language, first, it has to understand the user’s intention by decoding the instruction. However, while executing the task, the robot may face unforeseeable circumstances due to the variations in the observed scene and therefore requires further user intervention. In this article, we present a system called Talk-to-Resolve (TTR) that enables a robot to initiate a coherent dialogue exchange with the instructor by observing the scene visually to resolve the impasse. Through dialogue, it either finds a cue to move forward in the original plan, an acceptable alternative to the original plan, or affirmation to abort the task altogether. To realize the possible stalemate, we utilize the dense captions of the observed scene and the given instruction jointly to compute the robot’s next action. We evaluate our system based on a data set of initial instruction and situational scene pairs. Our system can identify the stalemate and resolve them with appropriate dialogue exchange with 82% accuracy. Additionally, a user study reveals that the questions from our systems are more natural (4.02 on average on a scale of 1 to 5) as compared to a state-of-the-art (3.08 on average).}
}
@article{CHEN2022104124,
title = {Real-time identification and avoidance of simultaneous static and dynamic obstacles on point cloud for UAVs navigation},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104124},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104124},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000665},
author = {Han Chen and Peng Lu},
keywords = {Motion planning, UAVs, Point cloud, Dynamic environment},
abstract = {Avoiding hybrid obstacles in unknown scenarios with an efficient flight strategy is a key challenge for unmanned aerial vehicle applications. In this paper, we introduce a more robust technique to distinguish and track dynamic obstacles from static ones with only point cloud input. Then, to achieve dynamic avoidance, we propose the forbidden pyramids method to solve the desired vehicle velocity with an efficient sampling-based method in iteration. The motion primitives are generated by solving a nonlinear optimization problem with the constraint of desired velocity and the waypoint. Furthermore, we present several techniques to deal with the position estimation error for close objects, the error for deformable objects, and the time gap between different submodules. The proposed approach is implemented to run onboard in real-time and validated extensively in simulation and real hardware tests, demonstrating our superiority in tracking robustness, energy cost, and calculating time.}
}
@article{CHENG2022104039,
title = {Trajectory planning of transcranial magnetic stimulation manipulator based on time-safety collision optimization},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104039},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104039},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000148},
author = {Qiang Cheng and Xiaolong Hao and Yi Wang and Wenxiang Xu and Shijun Li},
keywords = {Multi-objective optimization, Quintic B-spline interpolation, Safety collision, Time-safety collision trajectory planning, TMS manipulator},
abstract = {In this study, an optimal time-safety collision trajectory planning method of manipulator is proposed. It optimizes the coupling and contradictory performance indexes of manipulator joint motion time and safety collision coefficient. The trajectory of the manipulator can be transformed into the position and time series in the joint space by Inverse Kinematics (IK). Among the splines, quintic B-spline used commonly for interpolating robotic trajectories is preferred also in this study. Under the constraints of the manipulator, non-dominated sorting genetic algorithms-II (NSGA-II) is used to optimize the objective function. The total optimized running time is shortened by 33.07 s. The main joints damage before and after optimization of safety collision have been reduced more than 49.4%. After quintic B-spline interpolation, the time-safety collision of manipulator trajectory are effectively optimized. In general, the execution efficiency of the manipulator is improved, the collision damage to the human head is reduced, and the motion control performance of TMS manipulator is improved to be widely used in medical clinic.}
}
@article{BAI2022104085,
title = {Hierarchical multi-robot strategies synthesis and optimization under individual and collaborative temporal logic specifications},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104085},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104085},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000422},
author = {Ruofei Bai and Ronghao Zheng and Yang Xu and Meiqin Liu and Senlin Zhang},
keywords = {Multi-robot, Task planning, Linear temporal logic},
abstract = {This paper presents a hierarchical framework for multi-robot temporal logic task planning. We assume that each robot has its individual task specification and the robots have to jointly satisfy a global collaborative task specification, both described in finite linear temporal logic. To reduce the overall computational complexity, a central server firstly extracts and decomposes a collaborative task sequence from the automaton corresponding to the collaborative task specification, and allocates the subtasks in the sequence to robots. The robots then synthesize their initial execution strategies based on locally constructed product automatons, which integrate task requirements of the assigned collaborative tasks and their individual task specifications. Further, to reduce robots’ wait time in collaborations, we propose a distributed execution strategy adjusting mechanism to iteratively improve the time efficiency of robots. Finally, we prove the completeness of the proposed framework under assumptions, and analyze its time complexity and optimality. Extensive simulation results verify the scalability and optimization efficiency of the proposed method.}
}
@article{KIM2022104023,
title = {Robust interaction control for environments having uncertainties},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104023},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104023},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000021},
author = {Sehun Kim and Jeha Ryu},
keywords = {Adaptive control, Contact stability, Impedance control, Interaction control, Robust control, Uncertain environment},
abstract = {Physical human–robot and/or robot–environment interactions require robust contact stability because an unstable interaction could harm the human or environment. Maintaining effective contact performance while preserving robust contact stability still remains a considerable challenge. This is especially true when interacting with uncertain environments, which are characterized as systems experiencing sudden impedance changes from low to high. Although many existing control methods can be useful for practical interaction controls, they may not be applicable to some uncertain environments; they require either a priori knowledge of the environments before contact or time to update parameters while assuming contact stability during adaptation. This paper proposes a new robust interaction control strategy, the stability enforcement-then-performance enhancement, to provide effective contact performance while guaranteeing robust interaction stability in uncertain environments. The proposed strategy first stabilizes the interaction system by regulating a force input command to the robot system. For robustness to uncertain environments, this regulation is based on the robot’s own stability limit only. Performance enhancement then follows by adjusting the motion commands or adapting the robot’s impedance parameters because continuous stable contact can be maintained by the stability enforcement control even in uncertain environments. Theoretical analysis and typical contact experiments demonstrate the effectiveness of the proposed control strategy.}
}
@article{BOLDRER2022104207,
title = {A unified Lloyd-based framework for multi-agent collective behaviours},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104207},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104207},
url = {https://www.sciencedirect.com/science/article/pii/S092188902200118X},
author = {Manuel Boldrer and Luigi Palopoli and Daniele Fontanelli},
keywords = {Distributed control, Collective behaviours, Lloyd-based algorithms},
abstract = {Different authors have addressed a number of problems in the area of distributed control proposing convincing solutions to specific problems such as static coverage, dynamic coverage/exploration, rendezvous, flocking, formation control. However, a major limitation of problem-specific approaches is a fundamental lack of flexibility when the group meets unexpected conditions and has to change its goal on the fly. In this paper, we show that a large class of distributed control problems can be cast into a general framework based on the adoption of the Lloyd methodology. The adoption of a unified framework enables efficient solutions for the specific problems guaranteeing at the same time important safety and functional properties and a large degree of flexibility in the execution of group tasks. The paper sets the theoretical basis for this development and proves the efficacy of the proposed solutions through extensive simulations and experimental results.}
}
@article{LI2022104100,
title = {A nonlinear state estimation framework for humanoid robots},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104100},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104100},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000549},
author = {Jingchao Li and Zhaohui Yuan and Sheng Dong and Jingqin Zhang and Jianrui Zhang},
keywords = {Humanoid robot state estimation, Dynamics of the center of mass, Dual-loop Kalman filter, Invariant extended Kalman filter},
abstract = {This article proposes a novel nonlinear state estimation framework for humanoid robots based on the dynamics of the center of mass (CoM) and dual-loop Kalman filter(DLKF). It effectively fuses the information from inertial measurement unit(IMU), joint encoders, and foot sensitive resistors (FSRs), and provides state estimates for various gait generation algorithms and dynamic balance controllers with CoM or divergence component of motion (DCM) feedback. Compared to the widely used linear models such as the linear inverted pendulum model (LIPM), the nonlinear dynamics of CoM effectively reduce the process error. However, the humanoid robot is a highly complex dynamic system with multiple links and joints, the dynamics of CoM are also a simplification of the whole body dynamics. As a result, it brings non-zero-mean, non-Gaussian, and correlated process error, which the conventional extend Kalman filter (EKF) cannot handle. To this end, the DLKF is adopted to compensate the process error, thus the estimator is robust to the modeling error caused by simplifications. Furthermore, the invariant extended Kalman filter (IEKF) is used for floating base kinematics estimation, and the force/torque (F/T) sensor which is difficult to integrate on smaller or cheaper robots due to the size and cost is not used in our framework. Finally, our nonlinear state estimation framework improves the accuracy of CoM and DCM estimation in a virtual environment simulation using our self-developed Defensor hydraulic humanoid robot.}
}
@article{BRAHMIA2022104021,
title = {Kinematic sensitivity analysis of manipulators using a novel dimensionless index},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {104021},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104021},
url = {https://www.sciencedirect.com/science/article/pii/S092188902200001X},
author = {Allaoua Brahmia and Ridha Kelaiaia and Olivier Company and Ahmed Chemori},
keywords = {Sensitivity analysis, New sensitivity index, PAR2 PKM, Position error modeling, Precision design},
abstract = {Geometric errors directly affect the position of the end-effector of a Parallel Kinematic Manipulator (PKM), thus reducing its positioning accuracy. However, the tasks that are performed by PKMs, such as high-precision machining using a kinematic model with nominal values, are affected by machine errors that are not taken into account. Therefore, it is important to make an accurate determination of a machine’s error factors to obtain an accurate error model. Identifying the most crucial geometric errors and determining a method to control them is key in improving the accuracy of PKMs. To achieve this objective, a new method of sensitivity analysis, allowing the crucial geometric errors for parallel and serial manipulators to be identified, is proposed. A new dimensionless sensitivity index, based on the definition of a Local Sensitivity Index (LSI), is used to perform this analysis. The geometric error modeling is performed by deriving the position vector of the end-effector of the PKM. To test the efficiency of the proposed method, the main sources of PAR2 PKM errors are identified. The results show that 33.3% of the error components (main errors) from all error sources can be improved, to achieve a 51.8% improvement in the accuracy of the position error. These results indicate that the error sensitivity analysis method is quite effective, and can significantly contribute to improving the accuracy of a PKM.}
}
@article{MAHDI2022104193,
title = {A survey on the design and evolution of social robots — Past, present and future},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104193},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104193},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001117},
author = {Hamza Mahdi and Sami Alperen Akgun and Shahed Saleh and Kerstin Dautenhahn},
keywords = {Assistive robots, Human–robot interaction, Robots in education, Companion robots, Domestic robots, Healthcare robots, Personal robots, Rehabilitation robots, Robot assistant, Therapy robots, Robot peers, Robot societies, Social robots, Toy robots, Evolution of social robots, History of social robots},
abstract = {Despite the relatively young age of Human–Robot Interaction (HRI) as a field, there is a large volume of research on advances in robot hardware, software and behavior. The goal of this article is to survey trends in social robot design, to provide an evidence-based approach and guidelines that can inform future social robot development. To this end, this article systematically reviews the evolution of social robots with a focus on their applications, technical features and design. In total 9920 articles from ACM Digital Library (n=4223) and IEEE Explore (n=5697) were reviewed. In order to make this review as inclusive as possible, a broad definition of social robots was used to make decisions about inclusion/exclusion of a given social robot during the review process. As a result, a total of 344 social robots were examined in the review with features being embodiment, mobility, total number of degrees of freedom, existence of a manipulator, size, weight, shell build, applications, target user group, commercial availability, social software capabilities, sensors, interaction modalities, face, software extension capability and initial release year. This resulted in a rich dataset with detailed information about the social robots used in the HRI field. We also provide design guidelines for social robots to inform future research. Findings of this review may help both researchers & practitioners to select, and/or design, the best social robot for their particular experiment or application scenario.}
}
@article{ZHU2022104164,
title = {Compact lightweight magnetic gripper designed for biped climbing robots based on coaxial rotation of multiple magnets},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104164},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104164},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000938},
author = {Haifei Zhu and Zidong Lin and Jingyu Yan and Pengcheng Ye and Weixin Zhang and Shixin Mao and Yisheng Guan},
keywords = {Biped climbing robots, Switchable magnetic grippers, Simulation of adsorption characteristics, Steel structures},
abstract = {Biped climbing robots can move and work in three-dimensional steel structures, but are extremely sensitive to the weight, size, and adsorption performance of the devices attached at both their ends. Herein, we propose a novel gripper for biped climbing robots comprising two layers of multiple fan-shaped permanent magnets, wherein the upper layer can coaxially rotate with respect to the lower layer. The novel magnetic gripper can switch between the release and adsorption states by rotating the upper layer of magnets to a particular angle, and it can approximately linearly control the adsorption force by varying this rotation angle. The structural parameters and layout of the magnets were studied and optimized, and the adsorption characteristics of the gripper were analyzed via simulations and verified via experiments. Additionally, the proposed magnetic gripper was applied in a biped climbing robot for verifying the effectiveness of the design based on three climbing tests. The results revealed that the proposed magnetic gripper outperformed the existing models in terms of adsorption force to mass ratio. The proposed gripper design offers the advantages of compact structure, simple control, and natural self-locking of the release and adsorption states.}
}
@article{PEARSON2022104077,
title = {Improving obstacle boundary representations in predictive occupancy mapping},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104077},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104077},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000380},
author = {Erik Pearson and Kevin Doherty and Brendan Englot},
keywords = {Mapping, Range sensing, Mobile robotics},
abstract = {Predictive, inference-based occupancy mapping has been used successfully in many instances to create accurate and descriptive maps from sparse data, defining occupied space in a manner suitable to support autonomous navigation. However, one key drawback of inferring occupancy based largely on the proximity of range sensor observations is inaccuracy at the boundary between occupied and free space, where sparse coverage by the sensor data can be misinterpreted. To obtain a more accurate representation of the boundary between free and occupied space, we propose several modifications to a recently published occupancy mapping algorithm that uses Bayesian generalized kernel inference. In particular, our proposed algorithm distinguishes between unknown map cells with insufficient observations, and those which are uncertain due to disagreement among numerous observations, in a predictive, inference-based occupancy map. This distinction is key to our improved ability to capture ambiguities arising at the boundary between free and occupied space. We validate our approach using synthetic range data from a simulated environment and demonstrate real-time mapping performance using range data acquired by a ground robot operating in an underground mine.}
}
@article{WANG2022104185,
title = {Strategies for large scale elastic and semantic LiDAR reconstruction},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104185},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104185},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001075},
author = {Yiduo Wang and Milad Ramezani and Matias Mattamala and Sundara Tejaswi Digumarti and Maurice Fallon},
keywords = {LiDAR reconstruction, Pose-graph SLAM, Submaps, Semantic segmentation},
abstract = {This paper presents novel strategies for spawning and fusing submaps within an elastic dense 3D reconstruction system. The proposed system uses spatial understanding of the scanned environment to control memory usage growth by fusing overlapping submaps in different ways. This allows the number of submaps and memory consumption to scale with the size of the environment rather than the duration of exploration. By analysing spatial overlap and semantic information, our system segments distinct spaces on-the-fly during exploration, such as rooms, stairwells, and indoor–outdoor transitions. The proposed system associates semantically labelled submaps with poses of SLAM pose graph to enable global elasticity. A probabilistic model to merge the voxel labels of the different submaps is incorporated to ensure correct semantic submap fusion when SLAM loop closures occur. Additionally, we present a new mathematical formulation of relative uncertainty between poses to improve the global consistency of the reconstruction. Performance is demonstrated using experiments exploring multi-floor multi-room indoor environments, indoor–outdoor transitions and large-scale outdoor experiments. Relative to our baseline, the presented approach demonstrates improved scalability and accuracy.}
}
@article{TRAN2022104209,
title = {A computational design of robotic grasper by intelligence-based topology optimization for microassembly and micromanipulation},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104209},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104209},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001191},
author = {Ngoc Thoai Tran and Minh Phung Dang and Alokesh Pramanik and Animesh Basak and S. Shankar and Dharam Buddhi and Thanh-Phong Dao},
keywords = {Robotic grasper, Intelligent-based topology, Microassembly and micromanipulation, Bonobo optimizer, 3D printing},
abstract = {In robotic microassembly and micromanipulation, robotic grasper plays a vital role in picking up and releasing the product. However, the design synthesis method for creating a new robotic grasper has not deeply considered yet. Therefore, this article presents an effective computation method for designing a new robotic grasper that can be used for microassembly and micromanipulation. Firstly, a new structural scheme of robotic grasper is made by using the topology procedure. The compliance is the objective with the stress constraint during the topology. Then, a new variant of the grasper is refined where compliant joints are needed to reach the better compliance and the elastic motions of grasping hands. In the second phase, the modeling establishment for predicting the behaviors of the grasper are built via using the intelligent computation, namely GENFIS#1-neuro-fuzzy inference system (ANFIS), GENFIS#2-ANFIS, and GENFIS#3-ANFIS. The numerical data of the grasper are collected via the design of experiment-based finite element method. The results indicated that the GENFIS#3-ANFIS type is the best solver for modeling the hand’s stroke, the resonant frequency, and the strain energy. Meanwhile, the GENFIS#2-ANFIS type was the best procedure for modeling the stress. Subsequently, the optimum geometrical dimensions of the grasper are searched by using the Bonobo optimizer to improve the four mentioned performances of the grasper. In the circumstance #1, the results found that the hand’s displacement is about 0.0922 mm, the resonant frequency is 67.6247 Hz, the elastic energy is 1.4550 mJ, and the stress is 6.7249 MPa. The circumstance #2 determined the resonant frequency of 67.6247 Hz, the hand’s displacement of 0.0883 mm, the elastic energy of 1.9914 mJ, and the stress of 6.7086 MPa. Finally, the circumstance #3 found the elastic energy of 2.0501 mJ, the hand’s displacement of 0.0884 mm, the resonant frequency of 80.0012 Hz, and the stress of 6.7046 MPa. Statistically compared with the other methods, the presented method is the simple and effective procedure for designing 3D printed robotic grasper.}
}
@article{HAYAKAWA2022104152,
title = {Autonomous distributed system for single-legged modular robots to traverse environments by adaptive reconfiguration},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104152},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104152},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000872},
author = {Tomohiro Hayakawa and Fumitoshi Matsuno},
keywords = {Swarm robotics, Legged robot, Modular robot, Slope and gap traversal, Self-organization},
abstract = {Reconfigurable modular robots have the potential to achieve a range of tasks by changing their physical configuration. To identify a suitable configuration, the use of libraries has been suggested. However, such libraries usually assume centralized control, and developing a hardware-dependent library for all assumed tasks may be impractical. In this article, we focus on slope and gap traversal tasks for single-legged reconfigurable modular robots. We propose an autonomous distributed system to traverse the environments without determining the desired configuration a priori. Each module locally monitors the failure risk of the environment traversal for the entire robot. When it detects the high failure risk, the entire robot changes its morphology by adding an additional module to the component of the robot at a connecting place determined by the failure experience. By repeating the procedure, the entire robot gradually adapts the morphology to the environment and finally traverses the environment. Through dynamic simulations and robot experiments, we validated that entire robots with several initial configurations succeeded in changing their morphologies and traversing several slope and gap environments.}
}
@article{BAILONRUIZ2022104071,
title = {Real-time wildfire monitoring with a fleet of UAVs},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104071},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104071},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000355},
author = {Rafael Bailon-Ruiz and Arthur Bit-Monnot and Simon Lacroix},
keywords = {UAV, Remote sensing, Wildfire monitoring, Multi-robot planning},
abstract = {This paper introduces a wildfire monitoring system based on a fleet of Unmanned Aerial Vehicles (UAVs) to provide firefighters with precise and up-to-date information about a propagating wildfire, so that they can devise efficient suppression actions. We present an approach to plan trajectories for a fleet of fixed-wing UAVs to observe a wildfire evolving over time by tailoring the Variable Neighborhood Search metaheuristic to the problem characteristics. Realistic models of the terrain, of the fire propagation process, and of the UAVs are exploited, together with a model of the wind, to predict wildfire spread and plan accordingly the UAVs motions. Algorithms and models are integrated within a software architecture allowing tests with real and simulated UAVs flying over synthetic wildfires. Results of a mixed-reality test campaign show the ability of the proposed system to effectively map wildfire propagation.}
}
@article{ISHIHARA2022104018,
title = {Empirical study of future image prediction for image-based mobile robot navigation},
journal = {Robotics and Autonomous Systems},
volume = {150},
pages = {104018},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.104018},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002682},
author = {Yu Ishihara and Masaki Takahashi},
keywords = {Omni-directional camera, Action-conditioned image prediction, Mobile robot},
abstract = {Recent image-based robotic systems use predicted future state images to control robots. Therefore, the prediction accuracy of the future state image affects the performance of the robot. To predict images, most previous studies assume that the camera captures the entire scene and that the environment is static. However, in real robot applications, these assumptions do not always hold. For example, if a camera is attached to a mobile robot, its view changes from time to time. In this study, we analyzed the relationship between the performance of the image prediction model and the robot’s behavior, controlled by an image-based navigation algorithm. Through mobile robot navigation experiments using front-faced and omni-directional cameras, we discussed the capabilities of the image prediction models and demonstrated their performance when applied to the image-based navigation algorithm. Moreover, to adapt to the dynamic changes in the environment, we studied the effectiveness of directing the camera to the ceiling. We showed that robust navigation can be achieved without using images from cameras directed toward the front or the floor, because these views can be disturbed by moving objects in a dynamic environment.}
}
@article{SAARI2022104033,
title = {Exploring factors influencing the acceptance of social robots among early adopters and mass market representatives},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104033},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104033},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000112},
author = {Ulla A. Saari and Antero Tossavainen and Kirsikka Kaipainen and Saku J. Mäkinen},
keywords = {Robots, Technology acceptance model, Early adopter, Mass market representative, Diffusion of innovations, Workplace},
abstract = {When designing social robots, it is crucial to understand the diverse expectations of different kinds of innovation adopters. Different factors influence early adopters of innovations and mass market representatives’ perceptions of the usefulness of social robots. The first aim of the study was to test how applicable the technology acceptance model 3 (TAM3) is in the context of social robots. Participants’ acceptance of social robotics in a workplace environment in the fuzzy front-end (FFE) innovation phase of a robot development project was examined. Based on the findings for the model, we developed a reduced version of the TAM3 that is more applicable for social robots. The second objective was to analyze how early adopters’ and mass market representatives’ acceptance of social robots differs. Quantitative research methods were used. For early adopters, result demonstrability has a significant influence on perceived usefulness of social robots, while for mass market representatives, perceived enjoyment has a more significant influence on perceived usefulness. The findings indicate that users’ innovation adoption style influences the factors that users consider important in the usefulness of social robots. Robot developers should take these into account during the FFE innovation phase.}
}
@article{GARCIAFIDALGO2022104226,
title = {LiODOM: Adaptive local mapping for robust LiDAR-only odometry},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104226},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104226},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001324},
author = {Emilio Garcia-Fidalgo and Joan P. Company-Corcoles and Francisco Bonnin-Pascual and Alberto Ortiz},
keywords = {LiDAR odometry, Mapping, Localization},
abstract = {In the last decades, Light Detection And Ranging (LiDAR) technology has been extensively explored as a robust alternative for self-localization and mapping. These approaches typically state ego-motion estimation as a non-linear optimization problem dependent on the correspondences established between the current point cloud and a map, whatever its scope, local or global. This paper proposes LiODOM, a novel LiDAR-only ODOmetry and Mapping approach for pose estimation and map-building, based on minimizing a loss function derived from a set of weighted point-to-line correspondences with a local map abstracted from the set of available point clouds. Furthermore, this work places a particular emphasis on map representation given its relevance for quick data association. To efficiently represent the environment, we propose a data structure that combined with a hashing scheme allows for fast access to any section of the map. LiODOM is validated by means of a set of experiments on public datasets, for which it compares favourably against other solutions. Its performance on-board an aerial platform is also reported.}
}
@article{LIU2022104049,
title = {Quasi-critical collision-avoidance strategy for autonomous vehicles in complex traffic scenarios based on exclusive area of relative velocity vector algorithm},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104049},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104049},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000197},
author = {Zhaolin Liu and Jiqing Chen and Hongyang Xia and Fengchong Lan},
keywords = {Autonomous vehicle, Collision-avoidance strategy, Relative velocity vector, Escaping equations},
abstract = {Collision avoidance is one of the most important requirements for autonomous vehicles, particularly in complex and congested traffic scenarios where trajectories have little safety redundancy. However, simultaneously reaching the required accuracy and universal feasibility for different collision-avoidance behaviours is difficult due to the multi-state coupled motion of vehicles. To achieve the maximum traversability and ensure the safety of autonomous vehicles in any complex scenarios, we propose a quasi-critical collision-avoidance strategy based on a newly developed algorithm: the exclusive area-of-relative-velocity vector. This strategy first involves the construction of an exclusive area-of-velocity vector for each object vehicle to extract its position relative to the subject vehicle. In this procedure, to establish a subject-motion-decoupled scenario, projective transformation is applied to regularise the moving elliptical contour of the subject vehicle as a settled circle while retaining all positional relationships between the subject and object vehicles using the invariants. Subsequently, a group of escaping conditions for this exclusive area are established to express this quasi-critical collision-avoidance strategy explicitly and mathematically. The ultimate ability to escape from such an area is determined through theoretical derivations and experiments according to vehicle dynamics. In terms of real scenario data, a set of escaping equations is established to calculate the escaping conditions subject to the current state and the ultimate motion ability. Via scenario verifications, this strategy is shown to represent the safety boundary accurately and ensure quasi-critical collision-avoidance conditions under complex scenarios.}
}
@article{THOMAS2022104203,
title = {Safe motion planning with environment uncertainty},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104203},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104203},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001166},
author = {Antony Thomas and Fulvio Mastrogiovanni and Marco Baglietto},
keywords = {Localization, Collision probability, Obstacle avoidance},
abstract = {We present an approach for safe motion planning under robot state and environment (obstacle and landmark location) uncertainties. To this end, we first develop an approach that accounts for the landmark uncertainties during robot localization. Existing planning approaches assume that the landmark locations are well known or are known with little uncertainty. However, this might not be true in practice. Noisy sensors and imperfect motions compound to the errors originating from the estimate of environment features. Moreover, possible occlusions and dynamic objects in the environment render imperfect landmark estimation. Consequently, not considering this uncertainty can wrongly localize the robot, leading to inefficient plans. Our approach thus incorporates the landmark uncertainty within the Bayes filter estimation framework. We also analyze the effect of considering this uncertainty and delineate the conditions under which it can be ignored. Second, we extend the state-of-the-art by computing an exact expression for the collision probability under Gaussian distributed robot motion, perception and obstacle location uncertainties. We formulate the collision probability process as a quadratic form in random variables. Under Gaussian distribution assumptions, an exact expression for collision probability is thus obtained which is computable in real-time. In contrast, existing approaches approximate the collision probability using upper-bounds that can lead to overly conservative estimate and thereby suboptimal plans. We demonstrate and evaluate our approach using a theoretical example and simulations. We also present a comparison of our approach to different state-of-the-art methods.}
}
@article{PENG2022104160,
title = {Automatic aesthetics assessment of robotic dance motions},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104160},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104160},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000914},
author = {Hua Peng and Jing Li and Huosheng Hu and Keli Hu and Liping Zhao and Chao Tang},
keywords = {Machine aesthetics, Ensemble learning, Kinematic perception},
abstract = {Human dancers can understand and judge the aesthetics of their own dance motions from their movement perception. Inspired by this, we propose a novel mechanism of automatic aesthetics assessment of robotic dance motions, which is based on ensemble learning aimed at developing the autonomous judgment ability of robots. In the proposed mechanism, key pose descriptors based higher-order clustering features are designed to characterize robotic dance motion. Then, an ensemble classifier is built to train a machine aesthetics model for the automatic aesthetics assessment on robotic dance motions. The proposed mechanism has been implemented on a simulated robot environment, and experimental results show its feasibility and good performance.}
}
@article{IOVINO2022104096,
title = {A survey of Behavior Trees in robotics and AI},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104096},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104096},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000513},
author = {Matteo Iovino and Edvards Scukins and Jonathan Styrud and Petter Ögren and Christian Smith},
keywords = {Behavior Trees, Robotics, Artificial Intelligence, Learning Behavior Trees},
abstract = {Behavior Trees (BTs) were invented as a tool to enable modular AI in computer games, but have received an increasing amount of attention in the robotics community in the last decade. With rising demands on agent AI complexity, game programmers found that the Finite State Machines (FSM) that they used scaled poorly and were difficult to extend, adapt and reuse. In BTs, the state transition logic is not dispersed across the individual states, but organized in a hierarchical tree structure, with the states as leaves. This has a significant effect on modularity, which in turn simplifies both synthesis and analysis by humans and algorithms alike. These advantages are needed not only in game AI design, but also in robotics, as is evident from the research being done. In this paper we present a comprehensive survey of the topic of BTs in Artificial Intelligence and Robotic applications. The existing literature is described and categorized based on methods, application areas and contributions, and the paper is concluded with a list of open research challenges.}
}
@article{LINDQVIST2022104134,
title = {Multimodality robotic systems: Integrated combined legged-aerial mobility for subterranean search-and-rescue},
journal = {Robotics and Autonomous Systems},
volume = {154},
pages = {104134},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104134},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000756},
author = {Björn Lindqvist and Samuel Karlsson and Anton Koval and Ilias Tevetzidis and Jakub Haluška and Christoforos Kanellakis and Ali-akbar Agha-mohammadi and George Nikolakopoulos},
keywords = {Field robotics, Search-and-rescue robotics, Unmanned aerial vehicles, Quadruped robots, Multimodality robots, Subterranean exploration},
abstract = {This work presents a field-hardened autonomous multimodal legged-aerial robotic system for subterranean exploration, extending a legged robot to be the carrier of an aerial platform capable of a rapid deployment in search-and-rescue scenarios. The driving force for developing such robotic configurations are the requirements for large-scale and long-term missions, where the payload capacity and long battery life of the legged robot is combined and integrated with the agile motion of the aerial agent. The multimodal robot is structured around the quadruped Boston Dynamics Spot, enhanced with a custom configured autonomy sensor payload as well as a UAV carrier platform, while the aerial agent is a custom built quadcopter. This work presents the novel design and hardware implementation as well as the onboard sensor suites. Moreover it establishes the overall autonomy architecture in a unified supervision approach while respecting each locomotion modality, including guidance, navigation, perception, state estimation, and control capabilities with a focus on rapid deployment and efficient exploration. The robotic system complete architecture is evaluated in real subterranean tunnel areas, in multiple fully autonomous search-and-rescue missions with the goal of identifying and locating objects of interest within the subterranean environment.}
}
@article{PITTOL2022104179,
title = {Loop-Aware Exploration Graph: A concise representation of environments for exploration and active loop-closure},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104179},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104179},
url = {https://www.sciencedirect.com/science/article/pii/S092188902200104X},
author = {Diego Pittol and Mathias Mantelli and Renan Maffei and Mariana Kolberg and Edson Prestes},
keywords = {Mobile robotics, Autonomous robots, Exploration strategy, Map abstraction},
abstract = {Autonomous robots must have the ability to build an accurate map of an unknown environment by fully covering it in an exploration task. Several exploration approaches combine a Simultaneous Localization and Mapping (SLAM) technique with a strategy to move the robot through the environment actively looking for loops to be closed. When closing a loop, the robot revisits a previously mapped area, which allows it to reduce the uncertainty about its pose. In this paper, we present a concise environment representation named Loop-Aware Exploration Graph (LAEG). The LAEG’s nodes represent the essential information to the exploration process, such as the robot’s position and the frontiers of two different kinds, while the LAEG’s edges are the connections between these elements. Furthermore, the LAEG uses a specific type of edge to explicitly represent the predicted loops, facilitating the incorporation of this information into the exploration decision process. We also present an exploration approach that relies on the LAEG to make the decisions. Consequently, our approach maximizes the chances of closing a loop when choosing the next region to be explored, which is eased by the LAEG that represents the predicted loops as edges. The effectiveness of the proposed exploration approach was evaluated through experiments in five environments, comparing it with a greedy approach that only chases the most attractive unknown region and another one that makes the robot actively look for loop-closures.}
}
@article{LAZREG2022104114,
title = {Hybrid system for optimizing the robot mobile navigation using ANFIS and PSO},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104114},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104114},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000641},
author = {Malika Lazreg and Nacéra Benamrane},
keywords = {ANFIS, PSO, ROBOT, IA, Fuzzy logic},
abstract = {The important thing about mobile robotics is that its use satisfies rapid movement without collisions. Several methods have been designed for this purpose, but not all of them give the results expected by the user. Our contribution in this article is to allow the mobile robot to take advantage of two methods by the hybridization effect. These methods, implemented are ANFIS “Adaptive Neuro-Flou Inference System” and the PSO “Particle Swarm Optimization”. Learning by the connectionist approach of the ANFIS controller is sufficient to allow the robot to reach its target but remains unsatisfactory. The contribution of the PSO algorithm allows the hybrid controller to optimize, the speed and therefore the positions of robot. The controller thus constituted gives better simulation results of the distances measured in pixels traveled by the hybrid method.}
}
@article{XIE2022104035,
title = {Hierarchical forest based fast online loop closure for low-latency consistent visual-inertial SLAM},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104035},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104035},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000124},
author = {Hongle Xie and Weidong Chen and Jingchuan Wang},
keywords = {Visual-inertial SLAM, Global consistent localization, Binary descriptor search, Loop closure detection},
abstract = {Visual-inertial odometry (VIO) shows high localization accuracy in many environments. However, the inevitable estimation drift is constantly accumulating, which even leads to failures. Hence, an efficient loop closing (LC) is necessary for correcting drift. Unlike most existing methods rely on pre-trained model, we propose an incremental hierarchical forest (HF) based LC method (HF-LC), which online encodes frames for loop closing without any prior information, and it is suitable for arbitrary images. We thoroughly exploit the duality of binary descriptors, and propose a hierarchical forest based descriptor search method for loop frame retrieval, which is extremely fast with efficient descriptor clustering, binary search, and grid based loop closure selection modules. Moreover, we integrate HF-LC into a state-of-the-art keyframe based VIO, and develop a comprehensive hierarchical forest based visual-inertial SLAM (HFVIS) system. Furthermore, a lightweight geometric verification is designed for correctness checking and pose computing of loop keyframes. Finally, all keyframe poses are further optimized in global pose-graph optimization, which achieves better consistency. The efficacy of our method is validated on ground robot and aerial vehicle datasets. Extensive results confirm that the proposed HF-LC achieves better precision–recall performance, and our HFVIS system has higher localization accuracy and superior real-time performance.}
}
@article{KOBAYASHI2022104019,
title = {Adaptive and multiple time-scale eligibility traces for online deep reinforcement learning},
journal = {Robotics and Autonomous Systems},
volume = {151},
pages = {104019},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.104019},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002670},
author = {Taisuke Kobayashi},
keywords = {Deep reinforcement learning, Online learning, Eligibility traces},
abstract = {Deep reinforcement learning (DRL) is one promising approach to teaching robots to perform complex tasks. Because methods that directly reuse the stored experience data cannot follow the change of the environment in robotic problems with a time-varying environment, online DRL is required. The eligibility traces method is well known as an online learning technique for improving sample efficiency in traditional reinforcement learning with linear regressors rather than DRL. The dependency between parameters of deep neural networks would destroy the eligibility traces, which is why they are not integrated with DRL. Although replacing the gradient with the most influential one rather than accumulating the gradients as the eligibility traces can alleviate this problem, the replacing operation reduces the number of reuses of previous experiences. To address these issues, this study proposes a new eligibility traces method that can be used even in DRL while maintaining high sample efficiency. When the accumulated gradients differ from those computed using the latest parameters, the proposed method takes into account the divergence between the past and latest parameters to adaptively decay the eligibility traces. Bregman divergences between outputs computed by the past and latest parameters are exploited due to the infeasible computational cost of the divergence between the past and latest parameters. In addition, a generalized method with multiple time-scale traces is designed for the first time. This design allows for the replacement of the most influential adaptively accumulated (decayed) eligibility traces. The proposed method outperformed conventional methods in terms of learning speed and task quality by the learned policy on benchmark tasks on a dynamic robotic simulator. A real-robot demonstration confirmed the significance of online DRL as well as the adaptability of the proposed method to a changing environment.}
}
@article{KALIA2022104228,
title = {Improving MapReduce heterogeneous performance using KNN fair share scheduling},
journal = {Robotics and Autonomous Systems},
volume = {157},
pages = {104228},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104228},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001336},
author = {Khushboo Kalia and Saurav Dixit and Kaushal Kumar and Rajat Gera and Kirill Epifantsev and Vinod John and Natalia Taskaeva},
keywords = {Hadoop, MapReduce, Scheduling, Speculative prefetching, And clustering},
abstract = {MapReduce is one of the essential programming models for parallel processing and distributed storage of enormous data sets. The default Hadoop implementation assumes that the executing nodes are homogeneous. Data Locality is an important feature that Hadoop introduced to improve the performance of the traditional MapReduce model. The key idea is to move the map task closer to the node where the actual data resides rather than transferring the vast data set near the computation. Data Locality helps in lowering the network congestion and improving performance. However, this practice fails when processing the data in a heterogeneous Hadoop cluster. In a heterogeneous setup, nodes with different computational capabilities pose a crucial challenge. Nodes with a faster processing capacity finish the job compared to the nodes with slower processing ability. This paper proposes a KNN based scheduler that focuses on speculative prefetching and clustering of the data. The process starts with speculative prefetching and then performing the KNN clustering on the intermediate map output before directing it to the reducer for final processing. The performance evaluation of scheduler performance is analysed by executing different workloads like WordCount, RandomText, RandomNum, and Sort. The results show that the proposed idea improves the performance of job execution}
}
@article{CHAE2022104154,
title = {Generation of co-speech gestures of robot based on morphemic analysis},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104154},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104154},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000884},
author = {Yu-Jung Chae and Changjoo Nam and Daseul Yang and HunSeob Sin and ChangHwan Kim and Sung-Kee Park},
keywords = {Human–robot interaction, Co-speech gesture generation, Machine learning, Morphemic analysis, Word embedding},
abstract = {We propose a methodology for a robot to automatically generate felicitous co-speech gestures corresponding to robot utterances. First, the proposed method determines the part of a given robot utterance, where the robot makes a gesture by doing a morphemic analysis on the sentence of utterance. The part is herein called an expression unit. The method then predicts a gesture type to characterize the expression unit in the sense of conveying thoughts and feelings. The gesture type is selected from the four types of iconic, metaphoric, beat, and deictic categorized by McNeill by performing morphemic analysis on the sentence. A gesture proper to the gesture type is retrieved from a database of motion primitives that are built with predefined a limited number of words. For retrieving, Word2Vec is applied to estimate word similarity between the predefined words in the database and words in the expression unit such that the method can deal with an arbitrary sentence and generate an appropriate gesture for similar words in meaning. The proposed method showed 83% accuracy in determining expression units and gesture types for a set of sentences in Korean. Furthermore, a user study on feasibility has been performed with a humanoid, NAO, and received positive evaluations in terms of anthropomorphism for the robot.}
}
@article{KASTRITSI2022104073,
title = {A passive admittance controller to enforce Remote Center of Motion and Tool Spatial constraints with application in hands-on surgical procedures},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104073},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104073},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000367},
author = {Theodora Kastritsi and Zoe Doulgeri},
keywords = {Physical Human–Robot Interaction, RCM manipulation, Active constraints, Surgical robots, Variable damping},
abstract = {The restriction of feasible motions of a manipulator link constrained to move through an entry port is a common problem in minimally invasive surgery procedures. Additional spatial restrictions are required to ensure the safety of sensitive regions from unintentional damage. In this work, we design a target admittance model that is proved to enforce robot tool manipulation by a human through a remote center of motion and to guarantee that the tool will never enter or touch forbidden regions. The control scheme is proved passive under the exertion of a human force ensuring manipulation stability, and smooth natural motion in hands-on surgical procedures enhancing the user’s feeling of control over the task. Its performance is demonstrated by experiments with a setup mimicking a hands-on surgical procedure comprising a KUKA LWR4+ and a virtual intraoperative environment.}
}
@article{EISOLDT2022104205,
title = {A fully integrated system for hardware-accelerated TSDF SLAM with LiDAR sensors (HATSDF SLAM)},
journal = {Robotics and Autonomous Systems},
volume = {156},
pages = {104205},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104205},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001178},
author = {Marc Eisoldt and Julian Gaal and Thomas Wiemann and Marcel Flottmann and Marc Rothmann and Marco Tassemeier and Mario Porrmann},
keywords = {SLAM, Hardware acceleration, FPGA programming, 3D mapping},
abstract = {Simultaneous Localization and Mapping (SLAM) is one of the fundamental problems in autonomous robotics. Over the years, many approaches to solve this problem for 6D poses and 3D maps based on LiDAR sensors or depth cameras have been proposed. One of the main drawbacks of the solutions found in the literature is the required computational power and corresponding energy consumption. In this paper, we present an approach for LiDAR-based SLAM that maintains a global truncated signed distance function (TSDF) to represent the map. It is implemented on a System-On-Chip (SoC) with an integrated FPGA accelerator. The proposed system is able to track the position of state-of-the-art LiDARs in real time, while maintaining a global TSDF map that can be used to create a polygonal map of the environment. We show that our implementation delivers competitive results compared to state-of-the-art algorithms while drastically reducing the power consumption compared to classical CPU or GPU-based methods.}
}
@article{HAN2022104163,
title = {Slope walking of humanoid robot without IMU sensor on an unknown slope},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104163},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104163},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000926},
author = {Yun-Ho Han and Baek-Kyu Cho},
keywords = {Humanoid robots, Slope observer, Balance control, Slope walking, RoK-3},
abstract = {It is significantly challenging to develop biped robots, such as a humanoid robot, that can walk stably in complex environments, such as a rough terrain or slope. Additionally, various kinds of sensors are required. Force and torque (FT) and inertial measurement unit (IMU) sensors are necessary for a humanoid robot to achieve stable biped walking, and it is especially difficult to realize such locomotion without an IMU sensor in complex environments, such as a slope. Therefore, a new walking algorithm is needed so that a humanoid robot is able to walk well on a slope, even if the IMU sensor is damaged. This paper proposes a slope observer that can estimate the angle of the robot, angular velocity, and slope angle without an IMU sensor, as well as a controller for posture control and stabilization on a slope. The slope observer was developed based on a disturbance observer that can estimate the angle of the robot, angular velocity, and disturbance applied to the robot using only an FT sensor. The controller was designed as state feedback control based on the slope observer. Furthermore, the posture control was designed considering the slope angle such that the robot can always stand upright on the slope. The proposed slope observer and controller were verified with certain experiments performed in the lab, and the walking experiment of a real humanoid robot RoK-3 performed on the unknown slope. [https://youtu.be/x1PlzktlOpM]}
}
@article{CHEN2022104081,
title = {What should be the input: Investigating the environment representations in sim-to-real transfer for navigation tasks},
journal = {Robotics and Autonomous Systems},
volume = {153},
pages = {104081},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104081},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000409},
author = {Gang Chen and Hongzhe Yu and Wei Dong and Xinjun Sheng and Xiangyang Zhu and Han Ding},
keywords = {Transfer learning, Visual navigation, Environment representation},
abstract = {While training an end-to-end navigation network in the real world is usually costly, simulation serves as a safe and low-cost tool in this training process. However, training neural network models in simulation brings up the problem of effectively transferring the model from simulation to the real world (sim-to-real). In this work, we regard the environment representation as a crucial element in this transfer process, and we propose a visual information pyramid (VIP) model to investigate a practical environment representation systematically. A novel representation composed of spatial and semantic information synthesis is established accordingly, where noise model embedding is particularly considered. To explore the effectiveness of the proposed representation, we compared its performance with other popularly used representations in the literature, such as RGB image, depth image, and semantic segmentation image, in both simulated and real-world scenarios. Results suggest that our environment representation stands out. Furthermore, an analysis on the feature map is implemented to investigate the effectiveness through hidden layer reaction, which could be irradiative for future researches on sim-to-real learning-based navigation.}
}
@article{ADOLFSSON2022104136,
title = {CorAl: Introspection for robust radar and lidar perception in diverse environments using differential entropy},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104136},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104136},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000768},
author = {Daniel Adolfsson and Manuel Castellano-Quero and Martin Magnusson and Achim J. Lilienthal and Henrik Andreasson},
keywords = {Radar, Introspection, Localization},
abstract = {Robust perception is an essential component to enable long-term operation of mobile robots. It depends on failure resilience through reliable sensor data and pre-processing, as well as failure awareness through introspection, for example the ability to self-assess localization performance. This paper presents CorAl: a principled, intuitive, and generalizable method to measure the quality of alignment between pairs of point clouds, which learns to detect alignment errors in a self-supervised manner. CorAl compares the differential entropy in the point clouds separately with the entropy in their union to account for entropy inherent to the scene. By making use of dual entropy measurements, we obtain a quality metric that is highly sensitive to small alignment errors and still generalizes well to unseen environments. In this work, we extend our previous work on lidar-only CorAl to radar data by proposing a two-step filtering technique that produces high-quality point clouds from noisy radar scans. Thus, we target robust perception in two ways: by introducing a method that introspectively assesses alignment quality, and by applying it to an inherently robust sensor modality. We show that our filtering technique combined with CorAl can be applied to the problem of alignment classification, and that it detects small alignment errors in urban settings with up to 98% accuracy, and with up to 96% if trained only in a different environment. Our lidar and radar experiments demonstrate that CorAl outperforms previous methods both on the ETH lidar benchmark, which includes several indoor and outdoor environments, and the large-scale Oxford and MulRan radar data sets for urban traffic scenarios. The results also demonstrate that CorAl generalizes very well across substantially different environments without the need of retraining.}
}
@article{ZHONG2022104181,
title = {An incremental cross-modal transfer learning method for gesture interaction},
journal = {Robotics and Autonomous Systems},
volume = {155},
pages = {104181},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104181},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001051},
author = {Junpei Zhong and Jie Li and Ahmad Lotfi and Peidong Liang and Chenguang Yang},
keywords = {Transfer learning, Gesture recognition, Multi-modal, EMG, Depth camera, Leap Motion},
abstract = {Gesture can be used as an important way for human–robot interaction, since it is able to give accurate and intuitive instructions to the robots. Various sensors can be used to capture gestures. We apply three different sensors that can provide different modalities in recognizing human gestures. Such data also owns its own statistical properties for the purpose of transfer learning: they own the same labeled data, but both the source and the validation data-sets have their own statistical distributions. To tackle the transfer learning problem across different sensors with such kind of data-sets, we propose a weighting method to adjust the probability distributions of the data, which results in a more faster convergence result. We further apply this method in a broad learning system, which has proven to be efficient to learn with the incremental learning capability. The results show that although these three sensors measure different parts of the body using different technologies, transfer learning is able to find out the weighting correlation among the data-sets. It also suggests that using the proposed transfer learning is able to adjust the data which has different distributions which may be similar to the physical correlation between different parts of the body in the context of giving gestures.}
}