@article{WANG2020103336,
title = {A synthetic dataset for Visual SLAM evaluation},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103336},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103336},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301009},
author = {Senbo Wang and Jiguang Yue and Yanchao Dong and Shibo He and Haotian Wang and Shaochun Ning},
keywords = {Synthetic dataset, Computer graphic, Visual SLAM, Algorithm validation, Evaluation criteria},
abstract = {Vision-based self-localization methods are key functionalities for various research topics. Recent research results on related fields have catalyzed several accurate, versatile and reliable real-time Visual SLAM systems suitable for self-localization under a wide variety of environmental preconditions. These methods extend their functionalities from being only a good camera tracker to being able to recursively build up camera’s surroundings. The fast development of Visual SLAM research has proposed demands on innovating evaluation methods for Visual SLAM systems. However, retrieving images and ground truth from various kinds of environments, estimating calibration parameters between several sensors and annotating useful labels all require cumbersome human labor and will introduce inevitable errors. In this paper, we propose a method that uses virtually established models to automatically generate photorealistic images with accurate ground truth and several kinds of pixel-level annotations useful for Visual SLAM development and evaluation. We build and render a challenging dataset in low-texture environments with large scale camera movement, multiple moving objects and varying luminance status. We also propose several new evaluation criteria that can fully take advantage of ground truth and annotations from synthetic datasets. Experiments are conducted using the proposed datasets and criteria with several state-of-the-art Visual SLAM methods to demonstrate the functionality of our datasets.}
}
@article{CHANG2020103406,
title = {Shape-centric modeling for control of traveling wave rectilinear locomotion on snake-like robots},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103406},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103406},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019300831},
author = {Alexander H. Chang and Patricio A. Vela},
keywords = {Snake-like robot, Rectilinear, Dynamics, Trajectory planning, Control},
abstract = {A traveling wave rectilinear gait for elongated, continuous bodies is modeled as a cyclically-varying backbone curve. The gait shapes are represented as planar deviations relative to an average body curve and an associated, rigidly-attached body frame. Body-ground contact patterns and other geometric properties integral to computation of external forcing are conveniently defined with respect to this average body curve. Introducing a body-ground rolling friction model permits the controlled equations of motion to be derived in closed form. Incorporating a constant curvature into the average body realizes turning movements, and hence turning control. Repeated numerical integration of the system dynamics facilitates construction of a control-to-action mapping, characterizing steady system behavior with respect to the gait’s parameter space. The control-to-action map reduces this complex dynamical system to a kinematic unicycle model for which feedback tracking strategies are well understood. To illustrate its utility, it is applied in a trajectory planning and tracking framework for locomotion around obstacles. Using the framework, a robotic snake exercising the traveling wave rectilinear gait successfully plans feasible trajectories and traverses non-trivial obstacle arrangements to reach specified goal positions.}
}
@article{ALCALA2020103392,
title = {LPV-MP planning for autonomous racing vehicles considering obstacles},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103392},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103392},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304877},
author = {Eugenio Alcalá and Vicenç Puig and Joseba Quevedo},
keywords = {Autonomous driving, Racing planning, MPC, LPV, Obstacle avoidance},
abstract = {In this paper, we present an effective online planning solution for autonomous vehicles that aims at improving the computational load while preserving high levels of performance in racing scenarios. The method follows the structure of the model predictive (MP) optimal strategy where the main objective is to maximize the velocity while smoothing the dynamic behavior and fulfilling varying constraints. We focus on reformulating the non-linear original problem into a pseudo-linear problem by convexifying the objective function and reformulating the non-linear vehicle equations to be expressed in a Linear Parameter Varying (LPV) form. In addition, the ability of avoiding obstacles is introduced in a simple way and with reduced computational cost. We test and compare the performance of the proposed strategy against its non-linear approach through simulations. We focus on testing the performance of the trajectory planning approach in a racing scenario. First, the case of free obstacles track and afterwards a scenario including static obstacles. Simulation results show the effectiveness of the proposed strategy by reducing the algorithm elapsed time while finding appropriate trajectories under several input/state constraints.}
}
@article{KAMEDULA2020103482,
title = {Wheeled motion kinematics and control of a hybrid mobility CENTAURO robot},
journal = {Robotics and Autonomous Systems},
volume = {128},
pages = {103482},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103482},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304634},
author = {Małgorzata Kameduła and Navvab Kashiri and Nikos G. Tsagarakis},
keywords = {Hybrid locomotion, Wheeled-legged robots, Wheeled robots, Legged robots, Kinematic modelling, Motion control},
abstract = {Legged-wheeled robots combine the advantages of efficient wheeled mobility with the capability of adapting to real-world terrains through the legged locomotion. Thanks to their hybrid mobility skill, they can excel in many application scenarios where other mobile platforms are not suitable for. However, the improved versatility of their mobility increases the number of constraints in their motion control, where both the properties of legged and wheeled functionalities need to be considered. Relevant schemes for legged-wheeled motion control so far have attempted to address the problem by exploiting separate motion control of the wheeled and legged functionalities. The contribution of this paper is the introduction of derivation of the legged-wheeled motion kinematics without constraining the camber angles of the wheels. To this end, the wheel geometry is approximated by torus that more precisely represents a real wheel geometry than a standard sphere/cylinder. On the basis of the derived legged-wheeled motion kinematics, a first-order inverse kinematics (IK) scheme that resolves the legged-wheeled robot whole-body motion respecting the wheel rolling constraint is described. Furthermore, a higher-level method to resolve wheel steering to comply with a non-holonomic constraint is designed. A damping scheme is proposed to handle a structural singularity when a system non-holonomy deteriorates. Finally, the work adopts a floating base model that allows to easily incorporate the legged motion into the proposed scheme. The developed control scheme is tested in experiments on a legged-wheeled centaur-like robot — CENTAURO.}
}
@article{LU2020103486,
title = {Development of 3UPU-I parallel sensor with six division-force limbs for measuring robotic wrist load},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103486},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103486},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019309133},
author = {Yi Lu and Yongli Wang and Yang Lu},
keywords = {Parallel structure sensor, Division-force limb, Six-component force/torque, Performance evaluation},
abstract = {A 3UPU-I parallel sensor with six division-force limbs and six standard force sensors is developed for measuring robotic wrist load. Its measuring approach and performances are studied and evaluated. A prototype of the developed parallel sensor is built up and its merits are analyzed. A statics equation among the forces of the six standard force sensors and the wrist load is established, and a mapped matrix from the workload to the forces of the six standard force sensors is derived based on a 3UPU-I parallel mechanism of the developed parallel sensor. The performances of the developed parallel sensor are analyzed and evaluated by respectively varying key parameters for constructing the developed parallel sensor, and the reasonable values of the key parameters are determined. The forces of the six standard force sensors are measured by adding different workload components onto the loaded platform of the prototype. Finally, some theoretical solutions of the developed parallel sensor are solved and verified by the FE simulation solutions of the developed parallel sensor. The experimental calibration solutions of the prototype are coincident with the theoretical solutions.}
}
@article{LIU2019103268,
title = {Teleoperation for space manipulator based on complex virtual fixtures},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103268},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103268},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018307930},
author = {Zhengxiong Liu and Zhenyu Lu and Yang Yang and Panfeng Huang},
keywords = {Space teleoperation, Virtual tube, Velocity-based VF, Compound VFs, Haptic feedback},
abstract = {This paper presents a kind of complex virtual fixture (VF) to help space robots perform on-orbit operations in complex environments while ensuring operations safety. The main purpose of the VF is to provide virtual force feedback to adjust the manners of the operator throughout the remote operation process. The complex VF is comprised of a tube-type VF and a velocity-based VF. The tube-type VF ensures that the end effector approaches the target safely and at high speeds over long distances, and the velocity-based VF enables the end of the robot to observe the target within a safe and short distance near the target. Combined with dynamic prediction and path planning, the complex VF can improve the flexibility and efficiency of the operation, and avoid collisions in dynamic environments. The proposed methods are verified by several typical space manipulation tasks, the virtual experiment environment of which is built in CHAI3D. The comparative results indicate that the complex VF can reduce operation time and improve efficiency and accuracy.}
}
@article{MCGUIRE2019103261,
title = {A comparative study of bug algorithms for robot navigation},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103261},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103261},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018306687},
author = {K.N. McGuire and G.C.H.E. {de Croon} and K. Tuyls},
keywords = {Bug algorithms, Robotic navigation, Comparative study, Limited sensing, Indoor navigation},
abstract = {This paper presents a literature survey and a comparative study of Bug Algorithms, with the goal of investigating their potential for robotic navigation. At first sight, these methods seem to provide an efficient navigation paradigm, ideal for implementations on tiny robots with limited resources. Closer inspection, however, shows that many of these Bug Algorithms assume perfect global position estimate of the robot which in GPS-denied environments implies considerable expenses of computation and memory — relying on accurate Simultaneous Localization And Mapping (SLAM) or Visual Odometry (VO) methods. We compare a selection of Bug Algorithms in a simulated robot and environment where they endure different types noise and failure-cases of their on-board sensors. From the simulation results, we conclude that the implemented Bug Algorithms’ performances are sensitive to many types of sensor-noise, which was most noticeable for odometry-drift. This raises the question if Bug Algorithms are suitable for real-world, on-board, robotic navigation as is. Variations that use multiple sensors to keep track of their progress towards the goal, were more adept in completing their task in the presence of sensor-failures. This shows that Bug Algorithms must spread their risk, by relying on the readings of multiple sensors, to be suitable for real-world deployment.}
}
@article{SANJUAN2020103445,
title = {Cable driven exoskeleton for upper-limb rehabilitation: A design review},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103445},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103445},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303380},
author = {J.D. Sanjuan and A.D. Castillo and M.A. Padilla and M.C. Quintero and E.E. Gutierrez and I.P. Sampayo and J.R. Hernandez and M.H. Rahman},
keywords = {Cable-driven exoskeletons, Transmission systems, Stroke rehabilitation},
abstract = {One of the primary reasons for long-term disabilities in the world is strokes. The causes of these cerebrovascular diseases are various, i.e., high blood pressure, heart disease, etc. For those who survive strokes, this affectation causes loss in the mobility of extremities, requiring the intervention of long sessions with a therapeutic professional to recover the movement of the impair limb. Hence, the investment to threaten this condition is usually high, motivating researchers to implements exoskeletons in the rehabilitation process. Those devices permit the user means to conduct the therapies without the constant supervision of a professional. Furthermore, exoskeletons are capable of maintaining a detailed recording of the forces and movements developed for the patients throughout the session. However, the construction of an exoskeleton is not cheap principally for the actuation systems, especially if the exoskeleton requires the actuator to be placed at the joints of the user; in which, the actuator at a joint would have to withstand the load of the actuator of the following joint and so on. Researchers have addressed this drawback by applying cable transmission systems that allow the exoskeleton to place their actuator at a fixed base, reducing the weight of their design, and decreasing their cost. Thus, this paper reviews the principal models of cable-driven exoskeleton for stroke rehabilitation focusing on the upper-limb. The analysis departs from the study of the anatomy of the arm, including the shoulder, elbow, wrist, fingers, and thumb. Besides, it also includes the mechanical consideration to design a proper exoskeleton. Then, the article presents a compendium of the different transmission systems found in the literature, addressing their advantages, disadvantages and their requirements for the design. Lastly, the paper reviews the cable-driven exoskeleton for stroke rehabilitation of the upper limb. Again, for this analysis, it is included the design consideration of each prototype, focusing on their advantages in terms of anatomical mechanics.}
}
@article{MA2020103477,
title = {DeepGoal: Learning to drive with driving intention from human control demonstration},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103477},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103477},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019308048},
author = {Huifang Ma and Yue Wang and Rong Xiong and Sarath Kodagoda and Li Tang},
abstract = {Recent research on automotive driving has developed an efficient end-to-end learning mode that directly maps visual input to control commands. However, it models distinct driving variations in a single network, which increases learning complexity and is less adaptive for modular integration. In this paper, we re-investigate human’s driving style and propose to learn an intermediate driving intention region to relax the difficulties in end-to-end approach. The intention region follows both road structure in image and direction towards goal in public route planner, which addresses visual variations only and figures out where to go without conventional precise localization. Then the learned visual intention is projected on vehicle local coordinate and fused with reliable obstacle perception to render a navigation score map that is widely used for motion planning. The core of the proposed system is a weakly-supervised cGAN-LSTM model trained to learn driving intention from human demonstration. The adversarial loss learns from limited demonstration data with one local planned route and enables reasoning of multi-modal behaviors with diverse routes while testing. Comprehensive experiments are conducted with real-world datasets. Results indicate the proposed paradigm can produce more consistent motion commands with human demonstration and shows better reliability and robustness to environment change. Our code is available at https://github.com/HuifangZJU/visual-navigation.}
}
@article{FERRAGUTI2020103388,
title = {Safety barrier functions and multi-camera tracking for human–robot shared environment},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103388},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103388},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019306426},
author = {Federica Ferraguti and Chiara {Talignani Landi} and Silvia Costi and Marcello Bonfè and Saverio Farsoni and Cristian Secchi and Cesare Fantuzzi},
keywords = {Human–robot interaction, Collision avoidance, Control barrier function},
abstract = {A new vision in human–robot collaboration has allowed to place robots nearby human operators, working close to each other in industrial environments. As a consequence, human safety has become a dominant issue, together with production efficiency. In this paper we propose an optimization-based control algorithm that allows robots to avoid obstacles (like human operators) while minimizing the difference between the nominal acceleration input and the commanded one. Control Barrier Functions are exploited to build safety barriers around each robot link, to guarantee collision-free trajectories along the whole robot body. Human accelerations and velocities are computed by means of a bank of Kalman filters. To solve obstruction problems, two RGB-D cameras are used and the measured skeleton data are processed and merged using the mentioned bank of Kalman filters. The algorithm is implemented on an Universal Robots UR5 in order to validate the proposed approach.}
}
@article{IGNOROSARIO2019103263,
title = {Interactive system for painting artworks by regions using a robot},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103263},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103263},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304907},
author = {Otoniel Igno-Rosario and Claudia Hernandez-Aguilar and Alfredo Cruz-Orea and Arturo Dominguez-Pacheco},
keywords = {Bézier curve, Robotic artwork, Scattered interpolation, Interactive painting},
abstract = {In this work we present an interactive system capable of producing realistic artworks with acrylic paint based on a cartesian robot. This system focuses on painting artworks by regions, and can be applied for example in the painting of objects such as fruits, flowers, leaves and other individual objects. We have divided the development of the proposed system in three interactive stages: (1) interactive segmentation of work regions, (2) interactive designing of the field for orienting the brush strokes by tracing curves manually in each region and interpolating the curves to generate the vector field, and (3) painting by regions with the field. With our system it is possible to reproduce interactively an image producing pleasant results. The experimental results are presented by painting an apple with three main regions, for this we have utilized a realistic pictorial style and a monochromatic palette of 5 colors.}
}
@article{2022104027,
title = {Editorial Board},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {104027},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/S0921-8890(22)00006-9},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000069}
}
@article{ZHANG2020103390,
title = {Design and performance analysis of a parallel wrist rehabilitation robot (PWRR)},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103390},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103390},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019300843},
author = {Leiyu Zhang and Jianfeng Li and Ying Cui and Mingjie Dong and Bin Fang and Pengfei Zhang},
keywords = {Wrist rehabilitation, Parallel mechanism, Velocity Jacobian matrices, Workspace analysis, Wearable convenience},
abstract = {Wrist rehabilitation robots are essential for assisting patients with stoke or wrist injuries. Such devices compensate for deficiencies in manual rehabilitation training, and reduce the workload of rehabilitation physicians. A parallel wrist rehabilitation robot (PWRR) driven by two pneumatic actuators is developed in this paper, consisting of two rotational degrees of freedom for the movements of flexion/extension (F/E) and radial/ulnar deviation (R/U). All components connected to the forearm or the wrist adopt an open structure to improve the wearable convenience, and the PWRR is suitable for most patients, especially those with hypertonia. To determine the PWRR range of motion, the physiological motion space (PMS) of the wrist joint in autonomous and boundary elliptical movements is measured with the help of a VICON motion capture system. The PMS in boundary motions processes an elliptical shape, and the ulnar deviations occupy the most range of motion. The theoretical workspace (TWS) of PWRR is then calculated and designed based on the kinematic model and the distribution characteristics of PMS. In addition, two indices are introduced to evaluate the kinematic performance of PWRR. A PWRR prototype is developed based on the optimal geometrical parameters and detailed structures. Its effective workspace (EWS), which has more clinical significance, is acquired by measuring the F/E and R/U movements during autonomic movements. The EWS, is smaller than TWS due to the physical structure, volume, and interference of mechanical elements. Besides, EWS can nearly encircle PMS, and satisfies all single-axis rehabilitations and compound motions of the wrist complex. The two indices, motion isotropy da and condition number κ, within TWS change smoothly with no mutation, suggesting that PWRR is sufficiently kinematically isotropic, and has no singularity configuration. The analysis shows that the developed PWRR can be applied widely in the wrist rehabilitation.}
}
@article{YILMAZ2019103285,
title = {Self-adaptive Monte Carlo method for indoor localization of smart AGVs using LIDAR data},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103285},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103285},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302106},
author = {Abdurrahman Yilmaz and Hakan Temeltas},
keywords = {AGV, SA-MCL, 2D and 3D LIDARs, Localization},
abstract = {The vehicles used for transportation and logistics in the factories usually perceive their surroundings with range sensors. Today, 2D LIDARs are used as range sensors, and 3D LIDARs are becoming widespread with the developments of autonomous vehicle technology. Therefore, Self Adaptive Monte Carlo Localization, abbreviated as SA-MCL, is improved in this study to make the algorithm suitable for autonomous guided vehicles (AGVs) equipped with 2D or 3D LIDARs. Moreover, the traditional SA-MCL algorithm has a constraint that the range sensors on the robot are uniformly placed, and ellipse based energy model is proposed in this study to remove the constraint. This model can compute the energy value regardless of the robot orientation since it considers offsets due to the asymmetric placement of range sensors on the robot. The importance of localization increases since it is aimed that AGVs to be used in smart factories are able to use entire free space on the map in order to provide energy efficiency and time saving, and perform tasks that can vary at anytime instead of routine. SA-MCL algorithm is preferred in this study since traditional SA-MCL can overcome global localization, position tracking and kidnapping sub-problems of localization. The algorithm proposed in this study is verified to demonstrate its performance and effectiveness both in simulation and experimental studies using MATLAB and robot operating system (ROS).}
}
@article{SABOIA2019103239,
title = {Autonomous multi-material construction with a heterogeneous robot team},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103239},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302064},
author = {Maira Saboia and Vivek Thangavelu and Nils Napp},
keywords = {Autonomous construction, Collective robotic construction, Multi-material, Partial functions, Local sensing},
abstract = {We present a construction model that allows robots with different construction capabilities, using materials of different physical properties and sizes, to modify unstructured environments in a distributed system. Building steps are computed reactively so that they can respond to changes in the environment and imperfect assembly. The reactive approach allows robots to coordinate and add material to the same structure. Each robotic agent uses an abstract model of the environment to compute a set of legal construction steps based on its current knowledge of the world, and we show that in this setting more knowledge results in more legal moves. We exploit this capability by letting the system use a variety of materials and choose the most appropriate material given its current knowledge of the state of the structure. We demonstrate the approach by running the system on a variety of terrains and with mixed materials, including both deformable and rigid components.}
}
@article{AMIRI2020103425,
title = {Genetically optimized parameter estimation of mathematical model for multi-joints hip–knee exoskeleton},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103425},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103425},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019307584},
author = {Mohammad Soleimani Amiri and Rizauddin Ramli and Mohd Faisal Ibrahim},
keywords = {Parameter estimation, Lower Limb Exoskeleton, Optimization, Genetic algorithm},
abstract = {Achieving precise parameters of multi-joints actuators for Hip–Knee Exoskeleton (HKE) is a crucial process due to its non-linear characteristics. In this paper, a Genetic Algorithm (GA) based optimization is used for parameter estimation of the mathematical model for a four-Degree of Freedom (DoF) multi-joint HKE, which is a type of Lower Limb Exoskeleton (LLE). Mathematical model for electro-mechanical, mechanical, and electrical components of the HKE has been formulated, and its parameters are estimated using GA and experimental method. An objective function is determined based on the difference between the simulated and actual angular trajectory for each joint. The performance of the mathematical model is examined with different voltages under the range of 4 V to 8 V for hip and knee, respectively. Furthermore, the performance of the estimated model is compared with Particle Swarm Optimization (PSO). The results and numerical analysis demonstrated that the estimated model by GA and PSO with varying voltages predicted the actual angular trajectory with acceptable error, while GA provides the more accurate model. It can be ascertained that the proposed method of estimation for mathematical model of the HKE is applicable to identify its parameters, and useful for designing a control system.}
}
@article{FERREIRAFILHO2019103295,
title = {Abstraction based approach for segregation in heterogeneous robotic swarms},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103295},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103295},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018310042},
author = {Edson B. Ferreira-Filho and Luciano C.A. Pimenta},
keywords = {Robot swarms, Heterogeneous swarms, Segregation behavior, Abstractions},
abstract = {The focus of this study is to design individual control laws that segregate multiple groups of mobile heterogeneous robots. Our approach is based on the use of abstractions to represent each group of robots and an artificial potential function to segregate the groups. Different from other works in the literature, we prove that with our controller the system will always converge to a state where robots of the same group will be together while separated from robots of different groups. We also propose a collision avoidance scheme which does not interfere in the segregation controller. Furthermore, our controller has a local property, meaning that the controller might not require global information of the whole swarm to converge to the segregated state. The approach is validated with simulations varying the number of robots and groups and experiments with real robots.}
}
@article{FANG2020103495,
title = {Human-in-the-loop optimization of wearable robots to reduce the human metabolic energy cost in physical movements},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103495},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103495},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019308036},
author = {Jing Fang and Yuan Yuan},
keywords = {Wearable robotics, Human–robot interaction, Human-in-the-loop design},
abstract = {Most designs of wearable robots are based on human biomechanical statistics, engineering experience or individual experiments. Despite great successes, few of them consider the human–robot integration and individual differences between users. Additionally, the design periods, cost and safety also need to be further improved. Learning from the natural driving mechanism of human body, we propose a general human-in-the-loop (HIL) optimization designing approach for this kind of wearable robots. Firstly, the human–robot coupling model of the personalized wearable robot and the human musculoskeletal model are established. Then, the Computed Muscle Control (CMC) tool embedded in software OpenSim and the Bayesian optimization used in machine learning are combined to find the optimal design scheme for the personalized wearable robots to reduce the human metabolic energy cost in specific physical movement. The HIL approach could not only optimize the control parameters of wearable robots, but also optimize their geometry, material and any other design parameters flexibly and effectively. An application example for the HIL approach is also provided to help designers better understand and use the HIL method proposed in this paper.}
}
@article{MANSOURI2020103472,
title = {Deploying MAVs for autonomous navigation in dark underground mine environments},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103472},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103472},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019306256},
author = {Sina Sharif Mansouri and Christoforos Kanellakis and Dariusz Kominiak and George Nikolakopoulos},
keywords = {MAVs navigation, Autonomous tunnel inspection, Mining aerial robotics},
abstract = {Operating Micro Aerial Vehicles (MAVs) in subterranean environments is becoming more and more relevant in the field of aerial robotics. Despite the large spectrum of technological advances in the field, flying in such challenging environments is still an ongoing quest that requires the combination of multiple sensor modalities like visual/thermal cameras as well as 3D and 2D lidars. Nevertheless, there exist cases in subterranean environments where the aim is to deploy fast and lightweight aerial robots for area reckoning purposes after an event (e.g. blasting in production areas). This work proposes a novel baseline approach for the navigation of resource constrained robots, introducing the aerial underground scout, with the main goal to rapidly explore unknown areas and provide a feedback to the operator. The main proposed framework focuses on the navigation, control and vision capabilities of the aerial platforms with low-cost sensor suites, contributing significantly towards real-life applications. The merit of the proposed control architecture is that it considers the flying platform as a floating object, composing a velocity controller on the x, y axes and altitude control to navigate along the tunnel. Two novel approaches make up the cornerstone of the proposed contributions for the task of navigation: (1) a vector geometry method based on 2D lidar, and (2) a Deep Learning (DL) method through a classification process based on an on-board image stream, where both methods correct the heading towards the center of the mine tunnel. Finally, the framework has been evaluated in multiple field trials in an underground mine in Sweden.}
}
@article{NEJKOVIC2020103438,
title = {Semantic approach to RIoT autonomous robots mission coordination},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103438},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103438},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019306414},
author = {Valentina Nejkovic and Nenad Petrovic and Milorad Tosic and Nenad Milosevic},
keywords = {Coordination, Autonomous robots, Internet of Things, Ontology, Robot sensing systems, Semantic technology, Testbeds},
abstract = {Internet of Things (IoT) has recently become the key for innovation and progress in many industrial sectors and scientific areas. However, it brings many challenges and issues, such as growing number of connected devices, heterogeneity, amount of generated data, security and privacy issues, interoperability and many others. Since devices not only collect data, but also take actions that affect the environment, device coordination in the context of IoT systems is becoming more and more important, especially if the IoT convergence with robotics, known as “Internet of Robotic Things” (RIoT), is taken into consideration. In novel cyber–physical systems coordination is very important for situations when many devices working parallel have higher potential to achieve the given task more effectively, than a single device operating independently. RIoT experimentation testbeds facilitate development of such cyber–physical systems where devices need to be aware of the environment while interacting with other devices in order to achieve a common goal. In this paper, we propose a semantic-driven framework for automated autonomous robots coordination in the context of RIoT-based experimentation testbeds. Framework for automatic coordinated mission generation within the robotics experimentation platform testbed is evaluated. Results of evaluation are presented and discussed.}
}
@article{SHAH2019103246,
title = {GRAPE: Geometric Risk-Aware Pursuit-Evasion},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103246},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301927},
author = {Kunal Shah and Mac Schwager},
keywords = {Multi-agent pursuit-evasion, Reachability methods, Game theoretic control},
abstract = {We present a method for a collaborative team of pursuing robots to contain and capture a single evading robot. We address the practical case in which the pursuers do not know the exact location of the evader but rather must localize the evader with noisy on-board sensors. Under our policy, the pursuers move to maximally reduce the area of space reachable by the evader despite the uncertainty in the evader’s position estimate. Our pursuit policy is distributed in the sense that each pursuer only needs to broadcast its position and estimate to its closest neighbors. The policy guarantees that the evader’s reachable area is non-increasing between measurement updates regardless of the evader’s policy. Furthermore, we show in simulations and hardware that the pursuers capture the evader in spite of the position uncertainty provided that the pursuer’s measurement noise decreases with the distance to the evader.}
}
@article{CHEN2020103412,
title = {Virtual-joint based motion similarity criteria for human–robot kinematics mapping},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103412},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103412},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019305329},
author = {Zhang Chen and Ziwei Wang and Rongjian Liang and Bin Liang and Tao Zhang},
keywords = {Robotic imitation, Kinematics mapping, Motion similarity, Dissimilar embodiments, Human–robot cooperation},
abstract = {Motion mapping is an important part in human–robot cooperation. In this paper, a novel concept of virtual-joint based similarity criteria is proposed for flexible and efficient kinematics mapping between dissimilar embodiments, including different degrees of freedom (DOFs), different body morphology, and so on. Virtual joints are defined respectively in both the demonstrator and the imitator, with the same number. In virtual joints, the neglecting, re-ordering and repetitive usage of DOFs could be realized through the virtual decomposing matrices. Each virtual joint of the demonstrator and the corresponding one of the imitator formed a virtual joint pair. The Total Metric of Motion Similarity is the weighted sum of the metrics defined for each virtual joint pairs. Unlike traditional joint-space or Cartesian-space based metrics describing motion similarity solely at the DOF kinematic mode level, virtual-joint-based metrics can be adopted to describe different aspects of motion similarity between dissimilar agents, both in joint space and in Cartesian space. Two experiments are conducted to illustrate the effectiveness of the proposed approach.}
}
@article{MAVRAKIS2020103374,
title = {Estimation and exploitation of objects ’ inertial parameters in robotic grasping and manipulation: A survey},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103374},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103374},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302313},
author = {Nikos Mavrakis and Rustam Stolkin},
keywords = {Robot identification, Inertial parameters, Object dynamics, Robot grasping and manipulation},
abstract = {Inertial parameters characterise an object’s motion under applied forces, and can provide strong priors for planning and control of robotic actions to manipulate the object. However, these parameters are not available a-priori in situations where a robot encounters new objects. In this paper, we describe and categorise the ways that a robot can identify an object’s inertial parameters. We also discuss grasping and manipulation methods in which knowledge of inertial parameters is exploited in various ways. We begin with a discussion of literature which investigates how humans estimate the inertial parameters of objects, to provide background and motivation for this area of robotics research. We frame our discussion of the robotics literature in terms of three categories of estimation methods, according to the amount of interaction with the object: purely visual, exploratory, and fixed-object. Each category is analysed and discussed. To demonstrate the usefulness of inertial estimation research, we describe a number of grasping and manipulation applications that make use of the inertial parameters of objects. The aim of the paper is to thoroughly review and categorise existing work in an important, but under-explored, area of robotics research, present its background and applications, and suggest future directions. Note that this paper does not examine methods of identification of the robot’s inertial parameters, but rather the identification of inertial parameters of other objects which the robot is tasked with manipulating.}
}
@article{MCKINNON2020103314,
title = {Estimating and reacting to forces and torques resulting from common aerodynamic disturbances acting on quadrotors},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103314},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103314},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018307917},
author = {Christopher D. McKinnon and Angela P. Schoellig},
keywords = {Force estimation, Machine learning, Quadrotors},
abstract = {Quadrotors are increasingly expected to perform a wide variety of tasks that put them in close proximity to other objects and surfaces in the environment (including other quadrotors), where they are often subject to significant external forces and torques resulting from aerodynamic effects. We present an algorithm – based on an Unscented Kalman Filter – that estimates such forces and torques without making assumptions about their source, allowing us to bypass much of the complexity involved in modeling how wind currents interact with quadrotor dynamics. Furthermore, our algorithm does not rely on special sensors, making it suitable for commercial systems where payload and add-on capabilities are limited. Via experiment we show that the estimation algorithm can be used in conjunction with controls and machine learning for detecting and avoiding downwash and walls, and for tracking wind from a fan. We also show that the algorithm is sensitive enough to measure even small changes in force and torque.}
}
@article{ZHANG2020103362,
title = {Biologically inspired jumping robots: A comprehensive review},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103362},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103362},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301861},
author = {Chi Zhang and Wei Zou and Liping Ma and Zhiqing Wang},
keywords = {Jumping robots, Bionics, Autonomous robots, Mechanical structure, Actuator and energy storage, Material, Control and stability},
abstract = {Applying concepts and methods of bionics to endow autonomous robots with elegant and agile mobility just like natural living beings is gradually becoming a hot research topic in intelligent robot field. Compared with walking, crawling, rolling and other motion modes, jumping performs considerable advantages that can leap across obstacles and move to different heights in agility and flexibility. In this paper, we specifically review the developments of biologically inspired jumping robots in the past decades, and give comprehensive analysis on some key technologies for implementing a practical jumping robot effectively. First, the jumping mechanism of frog (amphibian, quadruped), locust (arthropod, hexapod), kangaroo (mammality, bipedalism) as examples of typical animals good at jumping is introduced and analyzed, from which it is concluded that power sources, limbs coordination and control are key elements for excellent jumping performances, which should be synthetically improved by combination with structure design and model establishment. Then, spring loaded inverted pendulum (SLIP), bio-inspired open-chain and closed-chain multi-linkage as representative jumping mechanical structures, their characteristics are explored accompanied with dynamic analysis. After a detailed analysis to actuators and energy storage devices and a comprehensive summarization to functional and soft materials commonly applied in jumping robots, different control methods and strategies adopted to achieve better jumping performance are reviewed and analyzed, from self-righting, driving control to path planning. Especially, how to analyze the stability of a jumping control system and how to stabilize it are explained theoretically by taking a vertical monopedal jumping robot as an example and via limit cycle analysis. Finally, some feasible and potential future developments in bio-inspired jumping robots are also presented after detailed discussions on current status and existing deficiencies.}
}
@article{FU2019103304,
title = {Industrial robot selection using stochastic multicriteria acceptability analysis for group decision making},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103304},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103304},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018309898},
author = {Yelin Fu and Ming Li and Hao Luo and George Q. Huang},
keywords = {Robot selection, Multiple criteria decision making, Stochastic multicriteria acceptability analysis, Group consensus},
abstract = {Most of the existing studies investigate the robot selection problem (RSP) in a multiple criteria decision making (MCDM) manner, from the viewpoint of a single person. This contradicts the reality that the robot selection decision is usually made by a committee or a group of experts with different expertise and concerns. For this reason, this paper proposes a group decision making (GDM) methodology for handling multiple criteria robot selection problem (MCRSP), the working process of which is (i) identifying experts, (ii) implementing the standard MCDM process and (iii) achieving a group consensus. Four objective weight determination methods, namely, Shannon entropy, CRITIC, ideal point and distance-based, are proposed to represent four experts. Experts play the role of think tank in supporting the decision maker who is responsible for MCRSP. In light of that the preference among different experts is uncertain, stochastic multicriteria acceptability analysis is then applied to achieve a holistic evaluation results for identifying good compromise choices. Two illustrative examples are presented to demonstrate the effectiveness and validity of our methodology, and compare the results with those obtained through VIKOR and ELECTRE II.}
}
@article{RAMIREZDUQUE2020103484,
title = {Robot-Assisted Intervention for children with special needs: A comparative assessment for autism screening},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103484},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103484},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304452},
author = {Andrés A. Ramírez-Duque and Teodiano Bastos and Marcela Munera and Carlos A. Cifuentes and Anselmo Frizera-Neto},
keywords = {Autism Spectrum Disorder, Autism screening, Social Assistive Robotics, Child–Robot Interaction},
abstract = {Despite the increment of researches related to Social Assistive Robotics (SAR), achieving a plausible Robot-Assisted Diagnosis (RAD) for Children with Autism Spectrum Disorders (CwASD) remains a considerable challenge to the clinical and robotics community. The work of specialists regarding ASD diagnosis is hard and labor-intensive due to the condition’s manifestations are inherently heterogeneous and makes the process more difficult. Besides, the aforementioned complexity may be the main reason for the slow progress in the development of SAR with diagnostic purposes. Thus, this work provides a comprehensive Robot-Assisted Intervention for CwASD showing the conditions in which a Robot-based approach can be useful to assess autism risk factors for an autism diagnosis purpose. The intervention scheme consists of an improved version of a multimodal environment for Robot-based intervention proposed in our previous work. More specifically, we compared the behavior of CwASD with that of children in a control group during a human/robot-mediated intervention while Joint Attention (JA) behaviors are elicited and analyzed. Through statistical data analysis, it was possible to identify that 17 out of 23 children of the CwASD group showed a different behavior pattern related to three characteristics of autism, which suggests that this pattern can be used to identify autism risk factors through Robot-based interventions.}
}
@article{VATANKHAH2019103255,
title = {Intermittent control model for ascending stair biped robot using a stable limit cycle model},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103255},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103255},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018308601},
author = {Maryam Vatankhah and Hamid R. Kobravi and Arthur Ritter},
keywords = {Stair ascent, Intermittent control system, Motion stability, Poincare theory},
abstract = {Among the different functional movements can be carried out by humanoid biped robots, stair climbing is considered an important functional activity. Although many papers have been published on the planning and executing walking gaits for humanoid robots, most of them were concerned with walking on level ground. This is because the fundamental mechanisms that are needed to fulfill these requirements are still scarcely understood. Thus, in this research, we focused on another perspective of this problem and are inspired by the human control system. The proposed hypotheses were to develop an innovative bio-inspired model based on human dynamic during stair ascent. The model has been established as a reference trajectory model representing the desired coordination pattern between the ankle, knee and hip joints during human stair ascending. An intermittent controller devised such that it keeps the system’s dynamic in a close neighborhood of the desired dynamic and become on/off based on the distance between the model output and the reference trajectory of each joint. The evaluation was carried out through some computer simulation studies on a five-link biped robot. Results show that the reference model follows the desired synergy pattern of lower extremities joints and coordinates joints such that the postural stability is achieved. It has been also proved that the proposed intermittent controller successfully maintains the balance of the robot during movement and can simulate the human ascending stair behavior steadily. It also supports the biped in DSP, SSP and impact phases very well.}
}
@article{ITO2019103310,
title = {An autonomous mobile robot with passive wheels propelled by a single motor},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103310},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103310},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019300090},
author = {Satoshi Ito and Kosuke Niwa and Shoya Sugiura and Ryosuke Morita},
keywords = {Wheeled mobile robot, Mechanism design, Single motor actuation, Autonomous propulsion, Motion control},
abstract = {This paper proposes a new propulsion mechanism for a passive-wheeled robot. By applying the propulsion principle of a two-wheeled skateboard, or “snakeboard,” a mobile robot with a rotor is constructed. Although the robot moves based on the counter force of the rotor rotation, the timely alternation of the orientations of the front and rear wheels is required. The mechanism proposed herein drives the rotor and the wheel orientations simultaneously using a single motor. Simulation analyses based on a dynamical model confirmed the desired temporal relation in motion between the rotor and wheel orientation, and evaluated the effect of some mechanical parameters to the traveling distance of the robot. Some experiments conducted using the robot demonstrated not only straight-line propulsion, as expected, but also controlled curved motion. Finally, by providing feedback of the positional information, the robot was able to autonomously arrive at a goal position by driving itself with its single motor.}
}
@article{MEMON2020103470,
title = {Loop closure detection using supervised and unsupervised deep neural networks for monocular SLAM systems},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103470},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103470},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019308425},
author = {Azam Rafique Memon and Hesheng Wang and Abid Hussain},
keywords = {Visual SLAM, Loop closure detection, Bag of words, Super dictionary},
abstract = {The detection of true loop closure in Visual Simultaneous Localization And Mapping (vSLAM) can help in many ways, it helps in re-localization, improves the accuracy of the map, and helps in registration algorithms to obtain more accurate and consistent results. The loop closure detection is affected by many parameters, including illumination conditions, seasons, different viewpoints and mobile objects. This paper proposes a novel approach based on super dictionary different from traditional BoW dictionary that uses more advanced and more abstract features of deep learning. The proposed approach does not need to generate vocabulary, which makes it memory efficient and instead it stores exact features, which are small in number and hold very less amount of memory as compared to traditional BoW approach in which each frame holds the same amount of memory as the number of words in the vocabulary. Two deep neural networks are used together to speed up the loop closure detection and to ignore the effect of mobile objects on loop closure detection. We have compared the results with most popular Bag of Words methods DBoW2 and DBoW3, and state-of-the-art iBoW-LCD using five publicly available datasets, and the results show that the proposed method robustly performs loop closure detection and is eight times faster than the state-of-the-art approaches of a similar kind.}
}
@article{BEHJAT2019103270,
title = {Learning reciprocal actions for cooperative collision avoidance in quadrotor unmanned aerial vehicles},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103270},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103270},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301617},
author = {Amir Behjat and Steve Paul and Souma Chowdhury},
keywords = {Bio-inspired, Collision avoidance, Learning, Optimization, Unmanned Aerial Vehicle (UAV)},
abstract = {The ability to avoid collisions with each other is one of the fundamental requirements for autonomous unmanned aerial vehicles (UAVs) to be safely integrated into the civilian airspace, and for the viability of multi-UAV operations. This paper introduces a new approach for online cooperative collision avoidance between quadcopters, involving reciprocal maneuvers, i.e., coherent maneuvers without requiring any real-time consensus. Two maneuver strategies are presented, where UAVs respectively change their speed or heading to avoid a collision. A learning-based framework that trains these reciprocal actions for collision evasion (called TRACE) is developed. The primary elements of this framework include: 1) designing simulated experiments that cover a variety of UAV–UAV approach scenarios; 2) performing optimization to identify speed/heading change actions that satisfy safety constraints while minimizing the energy cost of the maneuver; and 3) using the offline optimization outcomes to train classifier (via ensemble bagged tree) and function approximation (via neural networks and Kriging) models for respectively selecting and encoding the avoidance actions. Trajectory generation and dynamics/controls are incorporated in the simulation environment used for training and testing. Over 90% accuracy in action prediction and over 95% success in avoiding collisions is observed when the trained models are applied to simulated unseen test scenarios.}
}
@article{LI2020103365,
title = {A dual-stage parking system for differential-drive robots},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103365},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103365},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304749},
author = {Zhengguo Li and Wenchao Gao and Jiawei Ong},
keywords = {Asymptotic parking, Nonholonomic systems, Singularity line, Parking controller, Tracking controller},
abstract = {Due to the nonholonomic constraints, it is challenging to asymptotically stabilize a differential-drive robot at an arbitrary pose with desirable transient response. In this paper, an advanced parking system is introduced to tackle the problem of nonholonomic stabilization from an arbitrary starting position. The overall parking process is composed of two stages: a reference tracking stage and an asymptotically stabilization one. In the tracking stage, a reference trajectory is carefully generated by taking the robot kinematic constraints into consideration. An existing reference tracking controller is adopted to drive the robot to follow the prescribed route. In the second stage, a parking controller is switched on and is able to asymptotically stabilize the robot by taking advantage of straight and smooth motions in a “singularity line”. The overall performance of the parking system has been validated through simulation and real experiments.}
}
@article{ESTEVEZ2020103330,
title = {Enabling garment-agnostic laundry tasks for a Robot Household Companion},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103330},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103330},
url = {https://www.sciencedirect.com/science/article/pii/S0921889017307479},
author = {David Estevez and Juan G. Victores and Raul Fernandez-Fernandez and Carlos Balaguer},
keywords = {Robotics, Computer vision, Ironing, Garments, Deformable objects, Force/torque control},
abstract = {Domestic chores, such as laundry tasks, are dull and repetitive. These tasks consume a significant amount of daily time, and are however unavoidable. Additionally, a great portion of elder and disabled people require help to perform them due to lack of mobility. In this work we present advances towards a Robot Household Companion (RHC), focusing on the performance of two particular laundry tasks: unfolding and ironing garments. Unfolding is required to recognize the garment prior to any later folding operation. For unfolding, we apply an interactive algorithm based on the analysis of a colored 3D reconstruction of the garment. Regions are clustered based on height, and a bumpiness value is computed to determine the most suitable pick and place points to unfold the overlapping region. For ironing, a custom Wrinkleness Local Descriptor (WiLD) descriptor is applied to a 3D reconstruction to find the most significant wrinkles in the garment. These wrinkles are then ironed using an iterative path-following control algorithm that regulates the amount of pressure exerted on the garment. Both algorithms focus on the feasibility of a physical implementation in real unmodified environments. A set of experiments to validate the algorithms have been performed using a full-sized humanoid robot.}
}
@article{KLINGNER2019103306,
title = {Fault-tolerant Covariance Intersection for localizing robot swarms},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103306},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103306},
url = {https://www.sciencedirect.com/science/article/pii/S092188901930243X},
author = {John Klingner and Nisar Ahmed and Nikolaus Correll},
keywords = {Swarm robots, Cooperative localization, State estimation, Sensor fusion},
abstract = {This paper examines the important problem of cooperative localization in robot swarms, in the presence of unmodeled errors experienced by real sensors in hardware platforms. Many existing methods for cooperative swarm localization rely on approximate distance metric heuristics based on properties of the communication graph. We present a new cooperative localization method that is based on a rigorous and scalable treatment of estimation errors generated by peer-to-peer sharing of relative robot pose information. Our approach blends Covariance Intersection and Covariance Union techniques from distributed sensor fusion theory in a novel way, in order to maintain statistical estimation consistency for cooperative localization errors. Experimental validation results show that this approach provides both reliable and accurate state estimation results for Droplet swarms in scenarios where other existing swarm localization methods cannot.}
}
@article{YU2020103328,
title = {Flocking and topology manipulation based on space partitioning},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103328},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103328},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301873},
author = {Hongjun Yu and Cheng-Chew Lim and Robert Hunjet and Peng Shi},
keywords = {Network topology, Space partitioning, Decision-making, Limited ranges},
abstract = {Network topology plays a critical role in enabling a multi-agent system to adapt to environment changes and achieve desired objectives. This paper presents distributed topology manipulation schemes for a group of mobile agents. The agents have limited heterogeneous communication ranges, and connections among them are directional. The topology is established from the overlapping communication ranges. The admissible space is partitioned into enclosed areas by connectivity among the agents based on their communication ranges. Each agent occupies an enclosed area, and its decision-making manipulates the topology by guiding itself to an adjacent enclosed area. Both independent and coordinated decision-making approaches are provided. A guidance algorithm is designed to drive the vehicles to a flexible formation, in which the robustness of the network topology is enhanced.}
}
@article{SUN2019103272,
title = {Proxy based position control for flexible joint robot with link side energy feedback},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103272},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103272},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301356},
author = {Lei Sun and Wen Zhao and Wei Yin and Ning Sun and Jingtai Liu},
keywords = {Flexible joint robot, Position control, Energy feedback, Proxy-based sliding mode control},
abstract = {In this paper, a set-point regulation scheme for flexible joint robot (FJR) with link side energy (LSE) feedback is introduced. The drawbacks of traditional PD-type control laws are analyzed first. On this basis, a nonlinear regulator is designed by combining proxy based sliding mode control with LSE feedback, which is targeted at enhancement of vibration suppression. Asymptotic stability of the closed-loop system as well as boundedness of each signal are guaranteed with Lyapunov analysis. Furthermore, vibration suppression ability and robustness against external disturbances of the proposed method is validated on a self-built FJR platform.}
}
@article{HAUSER2020103467,
title = {Roombots extended: Challenges in the next generation of self-reconfigurable modular robots and their application in adaptive and assistive furniture},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103467},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103467},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303379},
author = {S. Hauser and M. Mutlu and P.-A. Léziart and H. Khodr and A. Bernardino and A.J. Ijspeert},
keywords = {Self-reconfiguring, Modular robots, Universal Gripper, Assistive furniture, Adaptive furniture},
abstract = {This work presents a series of demonstrations of our self-reconfigurable modular robots (SRMR) “Roombots” in the context of adaptive and assistive furniture. In literature, simulations are often ahead of what currently can be demonstrated in hardware with such systems due to significant challenges in transferring them to the real world. Here, we describe how Roombots tackled these difficulties in real hardware and focus qualitatively on selected hardware experiments rather than on quantitative measurements (in hardware and simulation) to showcase the many possibilities of an SRMR. We envision Roombots to be used in our living space and define five key tasks that such a system must possess. Consequently, we demonstrate these tasks, including self-reconfiguration with 12 modules (36 Degrees of Freedom), autonomously moving furniture, object manipulation and gripping capabilities, human-module-interaction and the development of an easy-to-use user interface. We conclude with the remaining challenges and point out possible directions of research for the future of adaptive and assistive furniture with Roombots.}
}
@article{KNEIP2020103323,
title = {Crop edge detection based on stereo vision},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103323},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103323},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303410},
author = {Johannes Kneip and Patrick Fleischmann and Karsten Berns},
keywords = {Agricultural automation, Computer vision for automation, Visual-based navigation, Advanced driver-assistance systems (ADAS)},
abstract = {This paper focuses on the development of a crop edge detection algorithm based on the point cloud produced by a stereo camera system using the GPU for fast matching of the camera images. The approach utilizes the 3D characteristics of the transition between the crop and the stubbles or the ground. Therefore, the point cloud is sorted into a grid of cells to create an elevation map. A segmentation in crop and ground is obtained using the Expectation–Maximization algorithm with a Gaussian Mixture Model to represent the distribution of the cell’s heights. This segmentation is Bayesian filtered over a short time frame to create a more robust segmentation result. Afterward, the resulting potential crop edge locations are processed using robust linear regression to come up with an overall linear crop edge model. The implemented system has been tested in a series of experiments with detailed results stated at the end of this work.}
}
@article{LACERDA2019103289,
title = {Petri net based multi-robot task coordination from temporal logic specifications},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103289},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103289},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302441},
author = {Bruno Lacerda and Pedro U. Lima},
keywords = {Multi-robot coordination, Linear temporal logic, Supervisory control, Petri nets},
abstract = {We propose a methodology for enforcing a set of coordination rules onto a multi-robot system, based on the use of Petri nets to model the team of robots, safe linear temporal logic to specify a set of coordination rules to be enforced, and supervisory control theory to synthesise a supervisor that enforces the coordination rules. We introduce a composition algorithm that allows us to build a Petri net that represents the largest restriction of the team behaviour that still satisfies the specification. Such a Petri net can be interpreted as a candidate for a supervisor, for which one needs to verify admissibility. We present a general verification procedure for this problem. We also present a syntactic restriction to safe linear temporal logic that guarantees admissibility of the composition a priori. We finish by providing an illustrative example, where we show how the use of temporal logic allows the designer to write the specifications intuitively, and the use of Petri nets allows us to tackle the large state spaces and high concurrency associated with multi-robot systems.}
}
@article{HYUN2019103309,
title = {A light-weight passive upper arm assistive exoskeleton based on multi-linkage spring-energy dissipation mechanism for overhead tasks},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103309},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103309},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304464},
author = {Dong Jin Hyun and KiHyeon Bae and KyuJung Kim and Seungkyu Nam and Dong-hyun Lee},
keywords = {H-VEX, Upper-limb assistive exoskeleton, Multi-linkage spring-energy storage mechanism, Poly-centric exoskeletal joint},
abstract = {This paper introduces a novel passive type upper arm exoskeletal vest for assisting overhead jobs in industrial environment such as automotive manufacturing centers. The developed upper arm exoskeleton named as Hyundai Vest Exoskeleton (H-VEX) proposes two key mechanical structural elements: (1) an energy-storage multi-linkage mechanism dissipating spring-loaded energy according to angle-increment of a wearer’s upper arm, and (2) a poly-centric shoulder joint mechanism on the transverse plane for its proper alignment with a wearer’s shoulder joint movement. Based on the proposed mechanical structures, H-VEX has effective ergonomic properties which enable it to provide a smooth-increasing upper arm assistive torque according to increment in a wearer’s arm angle up to its target angle without impeding movements in large ranges of motion (RoM). Especially, the critical design parameters of the energy-storage multi-linkage are able to be adjusted to generate customized assistive torque responses, and additionally, this mechanism can be covered in a thin cover frame for beneficial ergonomic & cosmetic reasons. Furthermore, industrial-purposed requirements such as mechanical endurance and cost-effectiveness can be achieved taking advantages of key structures. To verify the effectiveness of H-VEX on overhead works, activation signals of electromyography (EMG) on main corresponding muscles of ten subjects carrying out overhead manipulation tasks were measured and compared with cases without wearing the exoskeletal vest. The statistical analysis on acquired EMG signal indicates that assistive torque provided by H-VEX was shown to significantly decrease activation of the shoulder-related muscles during target tasks.}
}
@article{GANDLER2020103433,
title = {Object shape estimation and modeling, based on sparse Gaussian process implicit surfaces, combining visual data and tactile exploration},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103433},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103433},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303495},
author = {Gabriela Zarzar Gandler and Carl Henrik Ek and Mårten Björkman and Rustam Stolkin and Yasemin Bekiroglu},
keywords = {Tactile sensing, Shape modeling, Implicit surface, 3D reconstruction, Gaussian process, Regression},
abstract = {Inferring and representing three-dimensional shapes is an important part of robotic perception. However, it is challenging to build accurate models of novel objects based on real sensory data, because observed data is typically incomplete and noisy. Furthermore, imperfect sensory data suggests that uncertainty about shapes should be explicitly modeled during shape estimation. Such uncertainty models can usefully enable exploratory action planning for maximum information gain and efficient use of data. This paper presents a probabilistic approach for acquiring object models, based on visual and tactile data. We study Gaussian Process Implicit Surface (GPIS) representation. GPIS enables a non-parametric probabilistic reconstruction of object surfaces from 3D data points, while also providing a principled approach to encode the uncertainty associated with each region of the reconstruction. We investigate different configurations for GPIS, and interpret an object surface as the level-set of an underlying sparse GP. Experiments are performed on both synthetic data, and also real data sets obtained from two different robots physically interacting with objects. We evaluate performance by assessing how close the reconstructed surfaces are to ground-truth object models. We also evaluate how well objects from different categories are clustered, based on the reconstructed surface shapes. Results show that sparse GPs enable a reliable approximation to the full GP solution, and the proposed method yields adequate surface representations to distinguish objects. Additionally the presented approach is shown to provide computational efficiency, and also efficient use of the robot’s exploratory actions.}
}
@article{PARK2020103344,
title = {Active robot-assisted feeding with a general-purpose mobile manipulator: Design, evaluation, and lessons learned},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103344},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103344},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018307061},
author = {Daehyung Park and Yuuna Hoshi and Harshal P. Mahajan and Ho Keun Kim and Zackory Erickson and Wendy A. Rogers and Charles C. Kemp},
keywords = {Assistive robots, Manipulation, Assistive feeding, Meal assistance},
abstract = {Eating is an essential activity of daily living (ADL) for staying healthy and living at home independently. Although numerous assistive devices have been introduced, many people with disabilities are still restricted from independent eating due to the devices’ physical or perceptual limitations. In this work, we present a new meal-assistance system and evaluations of this system with people with motor impairments. We also discuss learned lessons and design insights based on the evaluations. The meal-assistance system uses a general-purpose mobile manipulator, a Willow Garage PR2, which has the potential to serve as a versatile form of assistive technology. Our active feeding framework enables the robot to autonomously deliver food to the user’s mouth, reducing the need for head movement by the user. The user interface, visually-guided behaviors, and safety tools allow people with severe motor impairments to successfully use the system. We evaluated our system with a total of 10 able-bodied participants and 9 participants with motor impairments. Both groups of participants successfully ate various foods using the system and reported high rates of success for the system’s autonomous behaviors. In general, participants who operated the system reported that it was comfortable, safe, and easy-to-use.}
}
@article{MEHREZ2020103468,
title = {Model Predictive Control without terminal constraints or costs for holonomic mobile robots},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103468},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103468},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019306232},
author = {Mohamed W. Mehrez and Karl Worthmann and Joseph P.V. Cenerini and Mostafa Osman and William W. Melek and Soo Jeon},
keywords = {Motion control, Holonomic mobile robots, Model Predictive Control, Stability analysis},
abstract = {We investigate Model Predictive Control (MPC) schemes without stabilizing constraints or costs for the set-point stabilization of holonomic mobile robots. Herein, we ensure closed-loop asymptotic stability using the concept of cost controllability. To this end, we derive a growth bound on the finite-horizon value function in terms of the running costs evaluated at the current state, which is then used to determine a stabilizing prediction horizon. In the discrete-time setting, we additionally show that asymptotic stability holds for the shortest possible prediction horizon. Moreover, we deduce a lower bound on the MPC performance on the infinite horizon. Theoretical results are verified by numerical simulations as well as laboratory experiments of stabilizing a holonomic mobile robot to a reference set point.}
}
@article{SEMIZ2020103435,
title = {Solving the area coverage problem with UAVs: A vehicle routing with time windows variation},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103435},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103435},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019306475},
author = {Fatih Semiz and Faruk Polat},
keywords = {Vehicle routing problem, Unmanned aerial vehicle, VRPTW, Transportation problem, Simplex algorithm},
abstract = {In real life, providing security for a set of large areas by covering the areas with Unmanned Aerial Vehicles (UAVs) is a difficult problem that consists of multiple objectives. These difficulties are even greater if the area coverage has to be sustained through a specific time window. We address this by considering a Vehicle Routing Problem with a Time Windows (VRPTW) variation in which the capacity of agents is counted as one and each customer (target area) is to be supplied with more than one vehicle simultaneously and without violating time windows. In this problem, our aim is to find a way to cover all areas with the necessary number of UAVs during the time windows, while minimizing the total distance traveled, and providing a fast solution by satisfying the additional constraint that each agent has limited fuel. We present a novel algorithm that relies on clustering the target areas according to their time windows, and then incrementally generating transportation problems with each cluster and the ready UAVs. We then solve the transportation problems with a simplex algorithm. The performance of the proposed algorithm and other algorithms implemented in order to compare the solution quality is evaluated through example scenarios with practical problem sizes.}
}
@article{LIU2020103350,
title = {Human-robot cooperative control based on sEMG for the upper limb exoskeleton robot},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103350},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103350},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018307462},
author = {Hao Liu and Jun Tao and Pan Lyu and Fang Tian},
keywords = {Human–robot cooperative control, Exoskeleton robot, Wearable robot, Surface electromyography(sEMG), Joint torque estimation, Joint state detector},
abstract = {An exoskeleton robot is a mechanical structure that integrates with the exterior of the human body to improve the wearer’s muscular power. The key to ensure performances and comfort of the system is human–robot cooperation. This paper proposes a human–robot cooperative control method based on sEMG (surface Electromyography) signals to drive a pneumatic upper limb exoskeleton to act in accordance with the wearer’s motion intentions. The intended movement information of the human is estimated by combining the regression method with the classification method. Based on the joint torque estimation model which is originated from the Hill-type musculoskeletal model, the regression method is used to estimate the joint’s desired torque by merging the sEMG signal with the joint angle. To avoid shaking and keep the robot’s limbs in the static condition, a classification method with the support vector machine is developed to find out the joint state that the human intends to keep. It was then applied to the exoskeleton’s elbow joint flexion and extension movement experiments to verify the controller’s effectiveness. The experimental results demonstrate that the controller can estimate human’s motion intention accurately and is appropriate for the human–robot collaboration.}
}
@article{RODRIGUEZ2020103408,
title = {Lagrange modeling and navigation based on quaternion for controlling a micro AUV under perturbations},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103408},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103408},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019307444},
author = {Jonathan Rodriguez and Herman Castañeda and J.L. Gordillo},
keywords = {Underwater vehicle, Dynamic model, Lagrange, Quaternions, Adaptive sliding mode control},
abstract = {This paper addresses the modeling of an autonomous underwater vehicle using quaternion formulation for angular position description and Lagrange method to compute the equations of motion. As the four parameters are dependent and generate a constraint, Lagrange multipliers are used with Baumgarte method to solve and stabilize the system. The dynamic model includes underwater effects like added mass and inertia, hydrodynamic damping, buoyancy and propeller forces. Moreover, a quaternion-based line of sight guidance algorithm is derived to avoid any use of trigonometric function and compute directly the orientation error of the underwater vehicle and the desired attitude in terms of quaternions. Motion control is achieved with a quaternion-based adaptive sliding mode controller rejecting model uncertainties and water current. The simulation results, where the vehicle follows a sequence of way-points including vertical diving motion demonstrate that the proposed guidance algorithm and motion control are deeply relevant both in terms of effectiveness and robustness for this particular type of vehicle and orientation formulation.}
}
@article{GAO2020103439,
title = {Magnetic crawler climbing detection robot basing on metal magnetic memory testing technology},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103439},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103439},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019305664},
author = {Fumin Gao and JianChun Fan and Laibin Zhang and Jiankang Jiang and Shoujie He},
keywords = {Climbing robot, Overcoming obstacles, Nondestructive testing, High payload},
abstract = {Failure detection of high facilities always presents a tremendous challenge. Climbing-wall robot with detection capacity has become a main approach. But owing to their limitations in overcoming obstacles and complicated wall situation, reliable wall-climbing property and precise detection abilities are the most basic demand for achieving this function. Hence, further research is required to enhance robot capabilities in overcoming obstacles and accurate detection signal. The paper presents a new climbing-wall detection robot mechanism. The wall-climbing robot consists of two climbing modules. The two climbing modules are connected by anti-overturning mechanism to provide a capacity of anti-overturning during overcoming obstacle. The detection mechanism is installed at the bottom of the robot. Detailed design issues are presented with analyses of the design parameters. Transition displacement of anti-overturning mechanism and force transfer equation are derived, and stable operating conditions are verified. The abilities of flat surface locomotion, anti-overturning, preload and detection capacity are validated by using experiments. Experiment results show that the prototype achieves 10kg payload capacity on vertical surfaces and can overcome 10mm obstacle. 1mm×1mm circular groove can be found.}
}
@article{2022104003,
title = {Editorial Board},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {104003},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/S0921-8890(21)00258-X},
url = {https://www.sciencedirect.com/science/article/pii/S092188902100258X}
}
@article{MINELLI2020103384,
title = {Self-optimization of resilient topologies for fallible multi-robots},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103384},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103384},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301903},
author = {Marco Minelli and Jacopo Panerati and Marcel Kaufmann and Cinara Ghedini and Giovanni Beltrame and Lorenzo Sabattini},
keywords = {Fault-tolerance, Resilience, Multi-robot systems, Connectivity, Graph theory, Control, Online optimization, Robotic hardware},
abstract = {Effective exchange of information in multi-robot systems is one of the grand challenges of today’s robotics. Here, we address the problem of simultaneously maximizing the (i) resilience to faults and (ii) area coverage of dynamic multi-robot topologies. We want to avoid the onset of single points of failure, i.e., situations in which the failure of a single robot causes the loss of connectivity in the overall network. Our methodology is based on (i) a three-fold control law and (ii) a distributed online optimization strategy that computes the optimal choice of control parameters for each robot. By doing so, connectivity is not only preserved, but also made resilient to failures as the network topology evolves. To assess the effectiveness of our approach, we ran experiments with a team of eight two-wheeled robots and we evaluated it against the injection of two separate classes of faults: communication and hardware failures. Results show that the proposed approach continues to perform as intended, even in the presence of these hazards.}
}
@article{KARUNARATHNE2020103443,
title = {Understanding a public environment via continuous robot observations},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103443},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103443},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019300934},
author = {Deneth Karunarathne and Yoichi Morales and Takayuki Kanda and Hiroshi Ishiguro},
keywords = {Human tracking, Point cloud data, Data analysis},
abstract = {This paper presents a study on a point cloud analysis captured by a robot navigating in a shopping mall environment. It investigates the type and how much information the robot could extract from the environment. For this purpose, information regarding environmental changes and the number of people in shops was extracted and analyzed. First, the robot was manually controlled to collect data in a typical shopping mall having different types of shops and a food court. As the robot navigated thoroughly around the environment, seven data recordings of data obtained from various onboard sensors were recorded during afternoon hours over three consecutive days. We built a composite map by overlaying 3D point clouds for each recording sharing the same coordinate frame, which reveals the changes in the environment’s static objects. The number of humans at each shop in each recording was computed using a human tracker. Then, we computed a fourteen-dimensional vector for each shop: seven dimensions for environmental changes and seven for human density. Experimental results show that the environmental changes and the human density at each shop are consistent with the visual changes that occurred in the shops and the number of people who visited the shops. Correlation analysis was done among shop changes, shop open space, and human density where results suggest that change in shop configurations are often done in smaller shops and shops with larger open space tend to attract larger number of customers. Finally, information extracted from shops was used to categorize the shops according to similarity.}
}
@article{DECONINCK2020103474,
title = {Learning robots to grasp by demonstration},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103474},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103474},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304956},
author = {Elias {De Coninck} and Tim Verbelen and Pieter {Van Molle} and Pieter Simoens and Bart Dhoedt},
keywords = {Artificial neural networks, Machine learning, Collaborative robotics, Industrial internet of things},
abstract = {In recent years, we have witnessed the proliferation of so-called collaborative robots or cobots, that are designed to work safely along with human operators. These cobots typically use the “program from demonstration” paradigm to record and replay trajectories, rather than the traditional source-code based programming approach. While this requires less knowledge from the operator, the basic functionality of a cobot is limited to simply replay the sequence of actions as they were recorded. In this paper, we present a system that mitigates this restriction and learns to grasp an arbitrary object from visual input using demonstrated examples. While other learning-based approaches for robotic grasping require collecting a large amount of examples, either manually or automatically harvested in a real or simulated world, our approach learns to grasp from a single demonstration with the ability to improve on accuracy using additional input samples. We demonstrate grasping of various objects with the Franka Panda collaborative robot. We show that the system is able to grasp various objects from demonstration, regardless their position and rotation in less than 5 min of training time on a NVIDIA Titan X GPU, achieving over 90% average success rate.}
}
@article{CUI2020103316,
title = {Trajectory planning of a spatial flexible manipulator for vibration suppression},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103316},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103316},
url = {https://www.sciencedirect.com/science/article/pii/S092188901930288X},
author = {Leilei Cui and Hesheng Wang and Weidong Chen},
keywords = {Flexible manipulator, Trajectory planning, Vibration suppression, Particle swam optimization},
abstract = {Vibration decreases operational accuracy and productivity of flexible manipulators, and trajectory planning is an effective way to suppress vibration. However, the existing trajectory planning methods can only suppress vibration of planar flexible manipulators. In this paper, a trajectory planning method is proposed to suppress vibration of spatial flexible manipulators. Firstly, the dynamic models of each link of the flexible manipulator are established separately. Then with the constraint equations, the dynamic model of the flexible manipulator is established as a Differential Algebraic Equation (DAE). Secondly, the trajectory functions are designed as quintic polynomials, and the conditions are deduced to satisfy acceleration limits of each joint. Finally, the trajectory planning problem is transferred to an optimal problem. Particle Swam Optimization (PSO) is adopted to solve the optimal problem. Numerical simulation is conducted to demonstrate the good performance of the proposed method.}
}
@article{KAWANO2020103369,
title = {Distributed tunneling reconfiguration of cubic modular robots without meta-module’s disassembling in severe space requirement},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103369},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103369},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301447},
author = {Hiroshi Kawano},
keywords = {Cubic modular robots, Reconfiguration algorithm, Distributed robots},
abstract = {This paper studies a tunneling-based reconfiguration algorithm for cubic modular robots. Tunneling-based reconfiguration is a promising approach for cubic modular robot reconfiguration in severe space requirements. This is because a tunneling modular robot only uses spaces occupied by the start and goal configurations. However, previously proposed methods have a limitation on the arrangement of the start and goal configurations, in which the overlapped part between them must be connected. We propose a tunneling reconfiguration algorithm that removes the limitation and is available for cases with multi-overlapped parts between the start and goal configurations. It is often the case that a tunneling-based reconfiguration assumes the use of a meta-module-based structure to maintain the connectivity and mobility of the robot structure. However, in previous methods, the meta-modules often come apart during the tunneling process, and each module belongs to a different meta-module before and after the reconfiguration. The proposed algorithm also solves this problem. We implement the algorithm in a distributed form and prove its completeness for assumed robot structures. We examine the proposed tunneling algorithm by simulation.}
}
@article{REN2020103386,
title = {Learning inverse kinematics and dynamics of a robotic manipulator using generative adversarial networks},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103386},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103386},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303501},
author = {Hailin Ren and Pinhas Ben-Tzvi},
keywords = {Inverse kinematics, Inverse dynamics, Generative adversarial networks},
abstract = {Obtaining inverse kinematics and dynamics of a robotic manipulator is often crucial for robot control. Analytical models are typically used to approximate real robot systems, and various controllers have been designed on top of the analytical model to compensate for the approximation error. Recently, machine learning techniques have been developed for error compensation, resulting in better performance. Unfortunately, combining a learned compensator with an analytical model makes the designed controller redundant and computationally expensive. Also, general machine learning techniques require a lot of data to perform the training process and approximation, especially in solving high dimensional problems. As a result, state-of-the-art machine learning applications are either expensive in terms of computation and data collection, or limited to a local approximation for a specific task or routine. In order to address the high dimensionality problem in learning inverse kinematics and dynamics, as well as to make the training process more data efficient, this paper presents a novel approach using a series of modified Generative Adversarial Networks (GANs). Namely, we use Conditional GANs (CGANs), Least Squares GANs (LSGANs), Bidirectional GANs (BiGANs) and Dual GANs(DualGANs). We trained and tested the proposed methods using real-world data collected from two types of robotic manipulators, a MICO robotic manipulator and a Fetch robotic manipulator. The data input to the GANs was obtained using a sampling method applied to the real data. The proposed approach enables approximating the real model using limited data without compromising the performance and accuracy. The proposed methods were tested in real-world experiments using unseen trajectories to validate the “learned” approximate inverse kinematics and inverse dynamics as well as to demonstrate the capability and effectiveness of the proposed algorithm over existing analytical models.}
}
@article{STECCANELLA2020103346,
title = {Waterline and obstacle detection in images from low-cost autonomous boats for environmental monitoring},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103346},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103346},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302775},
author = {L. Steccanella and D.D. Bloisi and A. Castellini and A. Farinelli},
keywords = {Water detection, Autonomous surface vessels, Robotic boats, Robot vision, Water quality monitoring},
abstract = {Waterline detection from images taken by cameras mounted on low-cost autonomous surface vehicles (ASVs) is a key process for obtaining a fast obstacle detection. Achieving an accurate waterline prediction is difficult due to the instability of the ASV on which the camera is mounted and the presence of reflections, illumination changes, and waves. In this work, we present a method for waterline and obstacle detection designed for low-cost ASVs employed in environmental monitoring. The proposed approach is made of two steps: (1) a pixel-wise segmentation of the current image is used to generate a binary mask separating water and non-water regions, (2) the mask is analyzed to infer the position of the waterline, which in turn is used for detecting obstacles. Experiments were carried out on two publicly available datasets containing floating obstacles such as buoys, sailing and motor boats, and swans moving near the ASV. Quantitative results show the effectiveness of the proposed approach with 98.8% pixel-wise segmentation accuracy running at 10 frames per second on an embedded GPU board.}
}
@article{KOIDE2020103348,
title = {Monocular person tracking and identification with on-line deep feature selection for person following robots},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103348},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103348},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302891},
author = {Kenji Koide and Jun Miura and Emanuele Menegatti},
keywords = {Person tracking, Person identification, Mobile robot},
abstract = {This paper presents a new person tracking and identification framework based on solely a monocular camera. In this framework, we first track persons in the robot coordinate space using Unscented Kalman filter with the ground plane information and human height estimation. Then, we identify the target person to be followed with the combination of Convolutional Channel Features (CCF) and online boosting. It allows us to take advantage of deep neural network-based feature representation while adapting the person classifier to a specific target person depending on the circumstances. The entire system can be run on a recent embedded computation board with a GPU (NVIDIA Jetson TX2), and it can easily be reproduced and reused on a new mobile robot platform. Through evaluations, we validated that the proposed method outperforms existing person identification methods for mobile robots. We applied the proposed method to a real person following robot, and it has been shown that CCF-based person identification realizes robust person following in both indoor and outdoor environments.}
}
@article{WANG2020103453,
title = {Research on optimized time-synchronous online trajectory generation method for a robot arm},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103453},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103453},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019305093},
author = {Mingli Wang and Juliang Xiao and Fan Zeng and Guodong Wang},
keywords = {Online trajectory generation, Jerk constraint, Time synchronization, Minimum peak of velocity, Minimum acceleration peak},
abstract = {Based on sensor input, a robot arm should dynamically adjust its trajectory while maintaining stability to react to a sudden change in the target point in an unknown environment. To solve this problem, in this study, a time-optimized online trajectory generation (OTG) method is proposed using an S-curve velocity profile, which can generate trajectories in response to external sensor signals. The generated trajectory has characteristics that can guarantee the synchronization of multijoints according to an arbitrary initial state and a desired target state under velocity, acceleration, and jerk constraints. For multijoints time synchronization, two different characteristics are considered according to different application scenarios: minimum velocity or peak acceleration, which correspond to two sub-methods. The first one can be used to calculate with a minimum velocity peak, which can quickly adjust the trajectory according to the signal feedback. The second can be used to calculate the minimization of the acceleration peak, which can reduce the vibration of the robot arm due to a change in the motion. Compared with other OTG methods, the second proposed sub-method can effectively reduce the acceleration peak of the planned motion with the same synchronization time and parameters. Additionally, both sub-methods have the advantage of a rapid calculation and can generate time synchronization motion trajectories for 6 axes in 0.21 ms on a personal computer, fully satisfying the requirements of online motion planning. Finally, the effectiveness of the algorithm is verified by simulations and experiments with a lab-developed robot arm.}
}
@article{DEMIRCAN2020103429,
title = {Operational space analysis of human muscular effort in robot assisted reaching tasks},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103429},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103429},
url = {https://www.sciencedirect.com/science/article/pii/S0921889017303846},
author = {Emel Demircan and Stephanie Yung and Mathew Choi and Jon Baschshi and Brian Nguyen and Javier Rodriguez},
keywords = {Human performance augmentation, Rehabilitation robotics, Dynamics},
abstract = {Human motor performance is a key area of investigation in both biomechanics and robotics. In robotics, understanding human muscular control is important to synthesize prosthetic motions and ensure safe human–robot interaction. Building controllable biomechanical models can help in quantifying the characteristics of a subject’s motion and in designing effective treatments, like motion training. This paper presents the task-based motion analysis of muscular effort using an upper-body musculoskeletal model, validated through motion capture experiments and dynamic simulations. To study the contribution of robotic assistance in improving human motor skills, the muscular effort of the task of reaching with and without robotic assistance was investigated for 10 subjects. Reduction of 21.4% in the arm muscular effort was observed for the tasks with robotic assistance.}
}
@article{CIESLAK2020103396,
title = {Practical formulation of obstacle avoidance in the Task-Priority framework for use in robotic inspection and intervention scenarios},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103396},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103396},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019306104},
author = {Patryk Cieślak and Roberto Simoni and Pere {Ridao Rodríguez} and Dina Youakim},
keywords = {I-AUV, Set-based Task-Priority, Obstacle avoidance, Robot control, Valve turning},
abstract = {This paper presents a new formulation of a reactive obstacle avoidance algorithm, in the Task-Priority framework, delivering a practical solution for obstacle avoidance between vehicle-manipulator systems and complex environments. The presented concepts were implemented on an intervention autonomous underwater vehicle (I-AUV) and tested in an underwater pipe structure inspection and valve turning scenario, in a test tank, using GIRONA500 with an ECA 5E Micro manipulator. The obstacle avoidance is treated as an inequality (set-based) task, which takes into account all obstacles that are interacting with the robot links. Both the robot and the obstacles are represented by spheres to allow for analytical formulation. However, the environment is wrapped with spheres based on its actual geometry stored as an Octomap, hence it can be represented at different resolutions. Depending on the type of the mission performed by the robot we defined two modes of operation: (1) Navigation and Inspection, and (2) Intervention. For each mode, the algorithm takes into account different number of key points at the I-AUV and a different resolution of the environment representation. Typically, for the Intervention mode the resolution is higher, to allow for more precise motion. We also present an escape point strategy in case of the robot getting stuck between obstacles.}
}
@article{ZLATINTSI2020103451,
title = {I-Support: A robotic platform of an assistive bathing robot for the elderly population},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103451},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103451},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304968},
author = {A. Zlatintsi and A.C. Dometios and N. Kardaris and I. Rodomagoulakis and P. Koutras and X. Papageorgiou and P. Maragos and C.S. Tzafestas and P. Vartholomeos and K. Hauer and C. Werner and R. Annicchiarico and M.G. Lombardi and F. Adriano and T. Asfour and A.M. Sabatini and C. Laschi and M. Cianchetti and A. Güler and I. Kokkinos and B. Klein and R. López},
keywords = {Human–robot communication, Assistive human–robot interaction (HRI), Bathing robot, Multimodal dataset, Audio–gestural command recognition, Online validation with elderly users},
abstract = {In this paper we present a prototype integrated robotic system, the I-Support bathing robot, that aims at supporting new aspects of assisted daily-living activities on a real-life scenario. The paper focuses on describing and evaluating key novel technological features of the system, with the emphasis on cognitive human–robot interaction modules and their evaluation through a series of clinical validation studies. The I-Support project on its whole has envisioned the development of an innovative, modular, ICT-supported service robotic system that assists frail seniors to safely and independently complete an entire sequence of physically and cognitively demanding bathing tasks, such as properly washing their back and their lower limbs. A variety of innovative technologies have been researched and a set of advanced modules of sensing, cognition, actuation and control have been developed and seamlessly integrated to enable the system to adapt to the target population abilities. These technologies include: human activity monitoring and recognition, adaptation of a motorized chair for safe transfer of the elderly in and out the bathing cabin, a context awareness system that provides full environmental awareness, as well as a prototype soft robotic arm and a set of user-adaptive robot motion planning and control algorithms. This paper focuses in particular on the multimodal action recognition system, developed to monitor, analyze and predict user actions with a high level of accuracy and detail in real-time, which are then interpreted as robotic tasks. In the same framework, the analysis of human actions that have become available through the project’s multimodal audio–gestural dataset, has led to the successful modeling of Human–Robot Communication, achieving an effective and natural interaction between users and the assistive robotic platform. In order to evaluate the I-Support system, two multinational validation studies were conducted under realistic operating conditions in two clinical pilot sites. Some of the findings of these studies are presented and analyzed in the paper, showing good results in terms of: (i) high acceptability regarding the system usability by this particularly challenging target group, the elderly end-users, and (ii) overall task effectiveness of the system in different operating modes.}
}
@article{RUBERT2019103274,
title = {Predicting grasp success in the real world - A study of quality metrics and human assessment},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103274},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103274},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019300247},
author = {Carlos Rubert and Daniel Kappler and Jeannette Bohg and Antonio Morales},
keywords = {Grasping, Grasp simulation, Machine learning, Prediction model, Real grasp execution},
abstract = {Grasp quality metrics aim at quantifying different aspects of a grasp configuration between a specific robot hand and object. They produce a numerical value that allows to rank grasp configurations and optimize based on them. Grasp quality metrics are a key part of most analytical grasp-planning approaches. Additionally, they are often used to generate ground-truth labels for synthetically generated grasp exemplars required for learning-based approaches. Recent studies have highlighted the limitations of grasp quality metrics when used to predict the outcome of a grasp execution on a real robot. In this paper, we systematically study how well seven commonly-used grasp quality metrics perform in the real world. To this end, we generated two datasets of grasp candidates in simulation, each one for a different robotic system. The quality of these synthetic grasp candidates is quantified by the aforementioned metrics. For validation, we developed an experimental procedure to accurately replicate grasp candidates on two real robotic systems and to evaluate the performance of each grasp. Given the resulting datasets, we trained different classifiers to predict grasp success using only grasp quality metrics as input. Our results show that combinations of quality metrics can achieve up to a 85% classification accuracy for real grasps.}
}
@article{2022103953,
title = {Editorial Board},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103953},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/S0921-8890(21)00229-3},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002293}
}
@article{TAKANO2020103378,
title = {Representation and classification of whole-body motion integrated with finger motion},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103378},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103378},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304841},
author = {Wataru Takano and Yusuke Murakami and Yoshihiko Nakamura},
keywords = {Motion primitive, Motion classification, Stochastic model},
abstract = {This paper presents a novel approach toward representing human whole-body motions with fingers and classification of human motions while performing tasks that require delicate finger movements, such as holding or grasping. Human whole-body motions are recorded using an optical motion capture system that measures positions of markers attached to a performer. Additionally, the performer wears data gloves with strain gauges fixed at the finger joints to measure flexions and extensions. Combining whole-body motion with finger motions forms a representation of integrated motion, which is subsequently encoded into a probabilistic model whose parameters are optimized such that the model most likely generates the training data for the integrated motion. Observations of integrated motion are classified into the relevant probabilistic model with the largest probability of generating the observation. Synchronous measurements of human whole-body and finger motions created a dataset of integrated human motions. We tested our proposed approach on this dataset, thereby demonstrating that representations of whole-body motion integrated with finger motions improved classification of human motions while manipulating objects.}
}
@article{ZAMBELLI2020103312,
title = {Multimodal representation models for prediction and control from partial information},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103312},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103312},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301575},
author = {Martina Zambelli and Antoine Cully and Yiannis Demiris},
keywords = {Multimodal learning, Autonomous learning, Variational autoencoder},
abstract = {Similar to humans, robots benefit from interacting with their environment through a number of different sensor modalities, such as vision, touch, sound. However, learning from different sensor modalities is difficult, because the learning model must be able to handle diverse types of signals, and learn a coherent representation even when parts of the sensor inputs are missing. In this paper, a multimodal variational autoencoder is proposed to enable an iCub humanoid robot to learn representations of its sensorimotor capabilities from different sensor modalities. The proposed model is able to (1) reconstruct missing sensory modalities, (2) predict the sensorimotor state of self and the visual trajectories of other agents actions, and (3) control the agent to imitate an observed visual trajectory. Also, the proposed multimodal variational autoencoder can capture the kinematic redundancy of the robot motion through the learned probability distribution. Training multimodal models is not trivial due to the combinatorial complexity given by the possibility of missing modalities. We propose a strategy to train multimodal models, which successfully achieves improved performance of different reconstruction models. Finally, extensive experiments have been carried out using an iCub humanoid robot, showing high performance in multiple reconstruction, prediction and imitation tasks.}
}
@article{THOMPSON2020103404,
title = {Robust mission planning for Autonomous Marine Vehicle fleets},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103404},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103404},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303355},
author = {Fletcher Thompson and Roberto Galeazzi},
keywords = {Planning AI, Multi-robot systems, Marine robotics},
abstract = {Mission planning for Autonomous Marine Vehicles (AMVs) is non-trivial because significant uncertainty is present when profiling the operating environment, especially for underwater missions. Mission complexity is compounded for each vehicle added to the mission. In practice, fleet operations are formulated as separate temporal problems by the operator and solved using a temporal planner. This paper proposes a planning method that uses energy as the base planning resource instead of time. Unlike temporal planners, energy planners account for physical loads endured by the vehicles. The extent of uncertainty in the vehicle loads is clarified by using the vehicle dynamics model and Monte Carlo simulation on the model parameters. The planning method is a multistage procedure to decompose operator specified task, obstacle, and vehicle data into an energy formulation of the Team Orienteering Problem (TOP) which is then solved using Discrete Strengthened PSO (DStPSO). The DStPSO algorithm has been modified to include a selective swarm size decay method that allows for larger initial swarm sizes to promote early exploration and preserves a percentage of the best performing particles on each iteration to save computational resources. The planner produces near-optimal routes containing feasible trajectories for individual vehicles that maximise tasks completed according to individual vehicle energy constraints. A case-study mission for long-term, large-scale, underwater inspection of a wind turbine array was converted into input data to evaluate the planner. Energy planning presents the opportunity for vehicles to actively monitor the feasibility of their individual plan against their current energy consumption, allowing for advanced reasoning and fault handling to occur in situ without operator assistance.}
}
@article{CHOI2020103372,
title = {Robust aerial scene-matching algorithm based on relative velocity model},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103372},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103372},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302660},
author = {Sung Hyuk Choi and Chan Gook Park},
keywords = {Scene matching, Feature points, Aerial image, Inertial navigation system, Horizontal pixel boundary},
abstract = {We present a robust scene-matching (SM) algorithm using time-invariant features that are propagated and bounded by a model propagator and pixel boundary. The SM based absolute navigation has the advantage that the position of the vehicle can be independently calculated without external information, making it possible to calculate a stable navigation solution without cumulative errors. However, SM-based absolute localization has a mismatching problem, this is due to the difference between the reference for the matching and the input image, and the more the change, the higher the probability of mismatching. In this paper we propose an algorithm that can mitigate the mismatching problem with a model-based propagator and time-invariant features. The propagator is based on a relative velocity of the inertial navigation system (INS) model, which is very accurate for a short time. Also the propagated feature points have pixel boundaries, which considers not only INS model uncertainty but also distortion of the aerial images caused by various terrain characteristics. The proposed algorithm is verified by simulation using real experimental data. Consequently we can found the proposed algorithm is very effective in mitigating the mismatching problem in urban areas.}
}
@article{WANG2020103402,
title = {Disturbance compensation based controller for an indoor blimp robot},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103402},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103402},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304683},
author = {Yue Wang and Gang Zheng and Denis Efimov and Wilfrid Perruquetti},
keywords = {Blimp robot, Navigation, Estimation, Uncertainty compensation, Robust control},
abstract = {This paper presents the robust controller design for an indoor blimp robot to achieve application such as the surveillance. The commonly used 6 degrees of freedom dynamic model is simplified under reasonable assumptions and decoupled into two independent parts. The blimp simplified horizontal plane movement model is complemented with disturbance terms to ensure the modeling accuracy, then it is transformed to a simpler form for the ease of controller design. Next, the disturbance terms are evaluated by the designed real-time estimator, and the perturbation estimates are compensated in the conceived motion controller for cancellation of the influence of disturbances. The performance and robustness of the disturbance compensation-based controller are verified by both simulations and experiments on the developed blimp robot. Finally, the results prove the feasibility of the blimp robot in indoor surveillance application by stabilizing itself at a fixed position or patrolling along a predefined path.}
}
@article{MIAO2020103334,
title = {A robot-assisted bilateral upper limb training strategy with subject-specific workspace: A pilot study},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103334},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103334},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018308777},
author = {Qing Miao and Mingming Zhang and Andrew McDaid and Yuxin Peng and Sheng Q. Xie},
keywords = {Robot-assisted, Bilateral, Upper limb, Training strategy, Subject-specific workspace},
abstract = {This paper proposes a new robot-assisted bilateral upper limb training strategy, focusing on the bilateral coordination of users’ upper limbs. The strategy is implemented and evaluated on a bilateral upper limb rehabilitation device (BULReD) that is an H-bot mechanism actuated by two Maxon DC motors. The control system consists of a position controller, an admittance controller and an adaptive algorithm, where the BULReD stiffness is modified session by session based on training performance. This strategy is also integrated with subject-specific workspace for enhanced training safety. Experiments were carried out with five subjects through active reaching tasks. Results indicate that the proposed training strategy requires significant coordination of bilateral upper limbs for task completion, and is able to tune control parameters to an appropriate difficulty level based on participants’ training performance. Future work will focus on its clinical evaluation on patients with upper limb disabilities.}
}
@article{LIN2020103480,
title = {Hybrid strategy based model parameter estimation of irregular-shaped underwater vehicles for predicting velocity},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103480},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103480},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019309285},
author = {Mingwei Lin and Canjun Yang and Dejun Li},
keywords = {Hydrodynamic model, Parameter estimation, Underwater vehicles, Model-based velocity prediction, Hybrid strategy},
abstract = {The hydrodynamic model can be used to predict velocity of underwater vehicles in still water. However, there are few economical and effective methods for estimating the hydrodynamic parameters of irregular-shaped underwater vehicles. Thus, this paper proposes a hybrid estimation strategy, which contains a rough estimation using a least squares (LS) based algorithm and a precise estimation using an improved particle swarm optimization (IPSO) algorithm. The numerical simulation and field data based tests suggest that the accuracy of the predicted velocity using the hydrodynamic parameters estimated by the IPSO-based hybrid strategy is better than two state-of-the-art algorithms. Finally, a pool experiment is conducted to verify the accuracy of the predicted horizontal velocity of the underwater vehicle.}
}
@article{SONG2020103414,
title = {Collaborative infotaxis: Searching for a signal-emitting source based on particle filter and Gaussian fitting},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103414},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103414},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019306451},
author = {Cheng Song and Yuyao He and Branko Ristic and Xiaokang Lei},
keywords = {Cognition difference, Bayesian estimation, Collaborative infotaxis, Particle filter, Gaussian fitting},
abstract = {To effectively leverage the spatio-temporal sensing capabilities of the team searching for a signal-emitting source, this paper presents a collaborative search method, in which each robot employs the weighted social Bayesian estimation and executes the distributed infotaxis search for the source. Cognition difference between robots, measuring the dissimilarity of probability maps, is specially introduced to obtain the heterogeneous weights of Bayesian estimation. However, the requirement of exchanging the whole probability map presents additional challenges in computation and communication for real-time applications. In this work, a solution for fast low-cost collaborative infotaxis method based on a combination of particle filter and Gaussian fitting is proposed. A particle filter is first employed for the representation of the source probability distribution, which makes the infotaxis strategy computationally tractable for large complex spaces using the limited and tractable amount of randomly drawn particles. By fitting a Gaussian density to the particles, each robot obtains the likelihood weight for social Bayesian estimation by only reporting the mean and the covariance matrix of Gaussian distribution rather than exchanging the whole probability maps. The simulation shows the proposed collaborative infotaxis can achieve an efficient search behavior in complex environments using a small number of particles and a lower communication bandwidth.}
}
@article{BA2019103265,
title = {Second order matrix sensitivity analysis of force-based impedance control for leg hydraulic drive system},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103265},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103265},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301290},
author = {Kaixian Ba and Bin Yu and Qixin Zhu and Zhengjie Gao and Guoliang Ma and Zhengguo Jin and Xiangdong Kong},
keywords = {Leg hydraulic drive system (LHDS), Hydraulic drive unit (HDU), Second order matrix sensitivity analysis (SOMSA), Force-based impedance control},
abstract = {In this paper, the mathematical expressions of a second-order matrix sensitivity analysis (SOMSA) is derived. This method has higher accuracy and requires less calculation works than previous analysis methods. Based on the SOMSA, when the traditional force-based impedance control is applied in leg hydraulic drive system (LHDS) of legged robots, the effects of parameter variations on control performance are studied by sensitivity dynamic analysis under nine working conditions. Then, combined with two measurable sensitivity indexes, the results of the sensitivity dynamic analysis are studied quantitatively. Finally, the above results are verified experimentally by using LHDS test platform. The conclusions contribute to the optimization of the LHDS structure and provide theoretical references for compensation control strategies of the traditional force-based impedance control.}
}
@article{ALDANAMURILLO2020103497,
title = {Coupling humanoid walking pattern generation and visual constraint feedback for pose-regulation and visual path-following},
journal = {Robotics and Autonomous Systems},
volume = {128},
pages = {103497},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103497},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019306694},
author = {Noé G. Aldana-Murillo and Luis Sandoval and Jean-Bernard Hayet and Claudia Esteves and Hector M. Becerra},
keywords = {Humanoid robots locomotion, Visual servoing, Visual path following, Visual geometric constraint},
abstract = {In this article, we show how visual constraints such as homographies and fundamental matrices can be integrated tightly into the locomotion controller of a humanoid robot to drive it from one configuration to another (pose-regulation), only by means of images. The visual errors generated by these constraints are stacked as terms of the objective function of a Quadratic Program so as to specify the final pose of the robot with a reference image. By using homographies or fundamental matrices instead of specific points, we avoid the features occlusion problem. This image-based strategy is also extended to solve the problem of following a visual path by a humanoid robot, which allows the robot to execute much longer paths and plans than when using just one reference image. The effectiveness of our approach is validated with a humanoid dynamic simulator.}
}
@article{SHERWANI2020103354,
title = {RISE-based adaptive control for EICoSI exoskeleton to assist knee joint mobility},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103354},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103354},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303070},
author = {Kashif I.K. Sherwani and Neelesh Kumar and Ahmed Chemori and Munna Khan and Samer Mohammed},
keywords = {Adaptive controller, Asymptotic stability, RISE feedback, Knee exoskeleton},
abstract = {Exoskeleton devices are used to assist joint motion of subjects suffering from mobility deficiencies. Controlling an exoskeleton subjects to high nonlinearities, which are mainly due to the mechanical coupling, external disturbances, parameter uncertainties, and modeling errors. Keeping in view the requirement of a relatively accurate movement tracking while reducing the disturbances effects, there is a need for a robust controller. In this paper, an adaptive RISE (Robust Integral of Sign Error) controller is developed and implemented on the EICoSI (Exoskeleton Intelligently Communicating and Sensitive to Intention) knee exoskeleton. RISE has an advantage over standard controllers that it achieves semi-global asymptotic tracking even in the presence of unstructured disturbances. But to achieve this tracking, high control gains are required. Thus, to limit such high gains, RISE control strategy is combined with an adaptive controller, which has the advantage of improving the tracking performance while reducing the eventual overshoots. The stability of the coupled human/ exoskeleton system is analyzed based on Lyapunov theory and the system has shown semi-global asymptotic stability. The adaptive RISE controller gives better SNR (signal to noise ratio) by 11% and 2% as compared with adaptive and RISE controller respectively. In terms of tracking error, the adaptive RISE controller shows 9% more RMSE than adaptive controller but 41% less when compared with RISE controller Three experimental scenarios are analyzed to validate the proposed controller, namely (i) external disturbances, that could come from the ground during walking; (ii) induced payload, that could come from the resistive/assistive torque from the muscles and (iii) payload with external disturbances. The system is found to be robust and efficient in tracking the reference trajectories while maintaining limited error and high signal to noise ratio.}
}
@article{MIAO2020103478,
title = {Subject-specific compliance control of an upper-limb bilateral robotic system},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103478},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103478},
url = {https://www.sciencedirect.com/science/article/pii/S092188901930898X},
author = {Qing Miao and Yuxin Peng and Li Liu and Andrew McDaid and Mingming Zhang},
keywords = {Compliance control, Subject-specific workspace, Upper-limb robotics, Bilateral},
abstract = {This paper proposes a new compliance control strategy on a robot-assisted bilateral upper limb rehabilitation system. The robotic compliance regulation was achieved by modifying predefined training trajectories in real time, based on measured human–robot interaction force and human users’ position within subject-specific workspace. Experimental data were collected from healthy subjects, and indicate that human users can follow predefined training trajectories well under real-time compliance variation, with the maximum normalized root mean square error (NRMSE) value no greater than 1.44%. Preliminary findings are encouraging, which demonstrates the availability of the proposed subject-specific compliance adaptation strategy, and the potential with enhanced training safety and efficacy. Future work will consider conducting a direct comparison between a bilateral upper limb rehabilitation device (BULReD)-assisted compliance training with or without subject-specific adaptation on a large sample of participants with upper limb disabilities.}
}
@article{WANG2020103427,
title = {A dual-mode soft gripper for food packaging},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103427},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103427},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019300879},
author = {Zhongkui Wang and Keung Or and Shinichi Hirai},
keywords = {Soft gripper, Grasping, Suction, Food packaging, Automation},
abstract = {Robotics and automation in the food industry is not as widely applied as in other industries, such as automotive and electrical industries, due to the large variations in the shape and properties of food materials and the frequent alterations of food products. Robotic end effectors that can adapt to these variations and handle multiple types of food materials are in high demand. Therefore, we propose a dual-mode soft gripper made of rubber material that can grasp and suck different types of objects. The gripper consists of four soft fingers, fabricated with rubber material using casting process, each of which is designed as a combination of a PenuNet bending actuator and a suction pad located at the fingertip. We introduce a new design for the air paths, which play an important role in the proper function of the soft finger. Finite element (FE) simulations were performed to confirm the finger design. Experimental tests were conducted to evaluate single finger bending, gripper lifting force, and grasping and sucking actions for various types of food materials. Results show that the soft gripper can lift a 273.97-g hot dog in the grasping mode, as well as a 512.62-g bagged Kernel corn and a 1072.65-g Macbook Air in the suction mode. It can adapt to approximately circular and square targets, such as a piece of fried chicken and an orange, when the soft fingers are in a perpendicular configuration. While in a parallel configuration, the gripper can successfully handle elongated targets, such as a hot dog. An experiment is also presented to demonstrate the automatic packaging of a Japanese boxed lunch, which requires both grasping and suction modes to be employed.}
}
@article{ZARROUK2020103366,
title = {Vision-based magnetic actuator positioning for wireless control of microrobots},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103366},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103366},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303604},
author = {Azaddien Zarrouk and Karim Belharet and Omar Tahri},
abstract = {This work is concerned with targeted drug delivery inside the human body using magnetic microrobots. It proposes a vision-based magnetic platform for guiding microrobots in both open-loop/closed-loop schemes. The open-loop scheme can be used for example in the case of the inner ear, where the microrobots cannot be localized in real time. On the other hand, for more accuracy, closed-loop scheme can be used for organs as the human eye since microrobots can be localized using a vision sensor. For both schemes, the platform is designed to compensate for human body movements. It is composed of a new magnetic actuator mounted on a robot end-effector and a hybrid vision system. The latter consists of a camera and two microscopes, while the newly proposed magnetic actuator is built using four permanent magnets. The proposed actuator has been designed to create a local maximum of the magnetic field magnitude in a planar workspace. This results in a convergence point for magnetic microrobots that are in its influence zone, making possible open-loop control with a satisfactory accuracy. The procedures for calibrating each component of the proposed platform are described and validated. Finally, several experiments have been carried out to validate the modeling part and to show the feasibility of the concept. The obtained experimental results show that using such platform, the microrobots guiding can be achieved in open-loop under reasonable perturbations and in closed-loop with an accuracy of 200 μm.}
}
@article{KAISER2019103293,
title = {Engineered self-organization for resilient robot self-assembly with minimal surprise},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103293},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103293},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019300855},
author = {Tanja Katharina Kaiser and Heiko Hamann},
keywords = {Self-assembly, Evolutionary swarm robotics, Pattern formation, Self-organization},
abstract = {In collective robotic systems, the automatic generation of controllers for complex tasks is still a challenging problem. Open-ended evolution of complex robot behaviors can be a possible solution whereby an intrinsic driver for pattern formation and self-organization may prove to be important. We implement such a driver in collective robot systems by evolving prediction networks as world models in pair with action–selection networks. Fitness is given for good predictions which causes a bias towards easily predictable environments and behaviors in the form of emergent patterns, that is, environments of minimal surprise. There is no task-dependent bias or any other explicit predetermination for the different qualities of the emerging patterns. A careful configuration of actions, sensor models, and the environment is required to stimulate the emergence of complex behaviors. We study self-assembly to increase the scenario’s complexity for our minimal surprise approach and, at the same time, limit the complexity of our simulations to a grid world to manage the feasibility of this approach. We investigate the impact of different swarm densities and the shape of the environment on the emergent patterns. Furthermore, we study how evolution can be biased towards the emergence of desired patterns. We analyze the resilience of the resulting self-assembly behaviors by causing damages to the assembled pattern and observe the self-organized reassembly of the structure. In summary, we evolved swarm behaviors for resilient self-assembly and successfully engineered self-organization in simulation. In future work, we plan to transfer our approach to a swarm of real robots.}
}
@article{SANCHEZBELENGUER2020103324,
title = {Global matching of point clouds for scan registration and loop detection},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103324},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103324},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302635},
author = {Carlos Sánchez-Belenguer and Simone Ceriani and Pierluigi Taddei and Erik Wolfart and Vítor Sequeira},
keywords = {Global registration, Loop detection, Place recognition, SLAM},
abstract = {We present a robust Global Matching technique focused on 3D mapping applications using laser range-finders. Our approach works under the assumption that places can be recognized by analyzing the projection of the observed points along the gravity direction. Relative poses between pairs of 3D point clouds are estimated by aligning their 2D projective representations and benefiting from the corresponding dimensional reduction. We present the complete processing pipeline for two different applications that use the global matcher as a core component: First, the global matcher is used for the registration of static scan sets where no a-priori information of the relative poses is available. It is combined with an effective procedure for validating the matches that exploits the implicit empty space information associated to single acquisitions. In the second use case, the global matcher is used for the loop detection required for 3D SLAM applications. We use an Extended Kalman Filter to obtain a belief of the map poses, which allows to validate matches and to execute hierarchical overlap tests, which reduce the number of potential matches to be evaluated. Additionally, the global matcher is combined with a fast local technique. In both use cases, the global reconstruction problem is modeled as a sparse graph, where scan poses (nodes) are connected through matches (edges). The graph structure allows formulating a sparse global optimization problem that optimizes scan poses, considering simultaneously all accepted matches. Our approach is being used in production systems and has been successfully evaluated on several real and publicly available datasets.}
}
@article{ITADERA2020103326,
title = {Admittance control based robotic clinical gait training with physiological cost evaluation},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103326},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103326},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018306900},
author = {Shunki Itadera and Jun Nakanishi and Yasuhisa Hasegawa and Toshio Fukuda and Masanori Tanimoto and Izumi Kondo},
keywords = {Rehabilitation robotics, Human–robot interaction, Assistive robots, Gait analysis},
abstract = {In this paper, we investigate an effective control strategy for a cane-type assistive mobile robot toward clinical gait training. Assistive robots are expected to provide aid in order to reduce the burden of caregivers and physical therapists, e.g., in gait rehabilitation of elderly people. Our group has been developing a series of cane-type walking assistive robots named Intelligent Cane as a mobile hand-holding device based on admittance control to provide safe and efficient gait training. This paper explores a systematic design methodology of the admittance control model in order to provide suitable walking load during gait training. We first conduct a pilot experiment to investigate the relationship between the physiological cost of user’s walking and the coefficients in the admittance control model of the cane robot. Then, we present a clinical gait training study conducted in a hospital to evaluate the feasibility in practical use of the proposed control strategy of our cane robot in gait rehabilitation. These experimental results suggest the effectiveness of the proposed gait rehabilitation strategy with our robot.}
}
@article{KAPPASSOV2020103332,
title = {Touch driven controller and tactile features for physical interactions},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103332},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103332},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019300697},
author = {Zhanat Kappassov and Juan-Antonio Corrales and Véronique Perdereau},
keywords = {Robot Arm control, Physical interaction, Tactile sensing arrays, Tactile servoing, Manipulation, Haptic exploration},
abstract = {We propose an approach that considers controlling contact between a robot and the environment during physical interactions. Current physical interaction control approaches are limited in terms of the range of tasks that can be performed. To allow robots to perform more tasks, we derive tactile features representing deformations of the mechanically compliant sensing surface of a tactile sensor and incorporate these features to a robot controller, akin to a visual servo, via touch- and task-dependent tactile feature mapping matrices. As a first contribution, we derive tactile features to localize a contact coordinate frame between an object and an array of pressure sensing elements, with a mechanically compliant surface, attached onto a robot arm end-effector interacting with the object. As a second contribution, we propose tactile projection matrices to design a tactile servoing controller that combines these tactile features with a Cartesian impedance controller of the robot arm. These matrices convert the proposed tactile features to balance not only normal forces but also torques about the sensor’s axes. It allows the end-effector to steer the contact frame in a desired manner by regulating errors in the tactile features to address several common issues in robotics: exploration and co-manipulation.}
}
@article{ZHANG2020103394,
title = {Assistive devices of human knee joint: A review},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103394},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103394},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303203},
author = {Li Zhang and Geng Liu and Bing Han and Zhe Wang and Han Li and Yan Jiao},
keywords = {Knee dysfunction, Knee assistive device, Wearable robot, Gait rehabilitation, Human–robot interaction},
abstract = {Knee dysfunction, such as knee osteoarthritis, meniscus injury, ligament injury, spinal cord injury and stroke, considerably impacts the normal living ability and mental health of these patients. Developing more effective knee assistive devices is in urgent need for effectively recovering their motion capabilities and improving their self-living activities. In this paper, we review and discuss the mechanical system design, sensing and control systems design, and performance evaluation of the main research advances in knee assistive devices. Firstly, in order to clearly illustrate and compare the mechanical system design, the mechanical system design is classified into four components to discuss: human attachment design, joint alignment design, actuation design and power transmission design. Then, the sensing and control systems design, which includes human biological signals based control systems, human–device interaction signals based control systems and device signals only based control systems, is compared and discussed. Furthermore, the performance evaluation methods and effectiveness of most of the knee assistive devices are reviewed. Finally, a discussion of the existing problems in the current studies and some recommendations for future research are presented.}
}
@article{VOCHTEN2019103291,
title = {Generalizing demonstrated motion trajectories using coordinate-free shape descriptors},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103291},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103291},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019303288},
author = {Maxim Vochten and Tinne {De Laet} and Joris {De Schutter}},
keywords = {Learning from demonstration, Trajectory generalization, Invariant shape descriptors, Constraint-based optimization},
abstract = {In learning by demonstration, the generalization of motion trajectories far away from the set of demonstrations is often limited by the dependency of the learned models on arbitrary coordinate references. Trajectory shape descriptors have the potential to remove these dependencies by representing demonstrated trajectories in a coordinate-free way. This paper proposes a constraint-based optimization framework to generalize demonstrated rigid-body motion trajectories to new situations starting from the shape descriptor of the demonstration. Experimental results indicate excellent generalization capabilities showing how, starting from only a single demonstration, new trajectories are easily generalized to novel situations anywhere in task space, such as new initial or target positions and orientations, while preserving similarity with the demonstration. The results encourage the use of trajectory shape descriptors in learning by demonstration to reduce the number of required demonstrations.}
}
@article{SAEED2020103320,
title = {A Boundary Node Method for path planning of mobile robots},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103320},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103320},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018307310},
author = {R.A. Saeed and Diego Reforgiato Recupero and Paolo Remagnino},
keywords = {Robot path planning, Path optimization, Simulation model, Autonomous mobile robot, Potential function, Boundary Node Method, Path Enhancement Method},
abstract = {In this paper we propose a new method for solving the path planning problem in a static environment to find an optimal collision-free path between starting and goal points. First, the grid model of the robot’s working environment is constructed, and then the potential value of the grid cells is calculated based on the new proposed potential function. This function is used to guide the robot to move toward the desired goal, it has the lowest value at the goal position and the value is increased as the robot moves further away. Second, we developed an efficient method, called the Boundary Node Method, to find the initial feasible path. In this method, the robot is simulated by a nine-node quadrilateral element, where the centroid node represents the robot’s position. The robot moves in the working environment toward the goal with eight-boundary nodes based on the potential value of the boundary nodes. The initial feasible path is generated from a sequence of waypoints that the robot has to traverse as it moves toward the goal point without colliding with any obstacles. However, the proposed method can generate the path safely and efficiently, but the path is not optimal in terms of the total path length. Therefore, in order to construct an optimal or near-optimal collision-free path, an additional method, called the Path Enhancement Method, is developed. Finally, the cubic spline interpolation is adopted to generate a continuous smooth path that connects the starting point to the goal point. The proposed method has been tested in several working environments with different degrees of complexities. The results demonstrated that the proposed method is able to generate near-optimal collision-free path efficiently. Moreover, we compared the performance of the proposed methods with the other path planning methods in terms of path length and computational time. The results revealed that the proposed method can solve the robot path planning problem more efficiently. Finally, in order to verify the performance of the developed method for generating a collision-free path, experimental studies were carried out on the real robot.}
}
@article{HAGHIGHAT2019103241,
title = {Lightweight physics-based models for the control of fluid-mediated self-assembly of robotic modules},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103241},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302350},
author = {Bahar Haghighat and Hala Khodr and Alcherio Martinoli},
keywords = {Programmable self-assembly, Model-based design, Physics-based models, Ruleset controllers, Distributed robotic systems},
abstract = {Self-assembling robotic systems form a subclass of distributed robotic systems that undertake the fundamental task of structure formation. These systems build desired target structures by putting their constituting robotic modules together in a distributed and stochastic fashion, i.e., through a self-assembly process. The use of self-assembly as the underpinning coordination mechanism provides powerful means for structure formation across a variety of length scales as well as media. In particular, fluidic media have been shown to be very efficient enablers for small-scale self-assembly. In this paper, we consider a distributed robotic system consisting of multiple miniature robotic modules performing self-assembly in 2D, at the water–air interface. The course of the assembly process in the system culminating in a predefined target structure is shaped by the ruleset controllers programmed on the individual robotic modules, allowing only certain formations and ruling out others throughout the process. Designing control strategies relies heavily on accurate models of the system dynamics. Faithfully modeling such systems and their inter-module interactions involves capturing the hydrodynamic forces acting on the modules using typically computationally expensive fluid dynamic modeling tools. Such computational cost restricts the usability of the resulting models, particularly for the purpose of designing optimized controllers. In this paper, we present a new modeling approach and proceed by employing the resulting model for optimizing ruleset controllers. First, we show how the hardware and firmware of the robotic platform can be faithfully modeled in a high-fidelity robotic simulator. Second, we develop a physics plugin to recreate the hydrodynamic forces acting on the modules and propose a trajectory-based method for calibrating the plugin model parameters. Finally, we employ the resulting model and obtain automatically optimized ruleset controllers for given target structures.}
}
@article{LEONARD2020103398,
title = {Bootstrapped Neuro-Simulation as a method of concurrent neuro-evolution and damage recovery},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103398},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103398},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018305256},
author = {Brydon A. Leonard and Mathys C. {du Plessis} and Grant W. Woodford},
keywords = {Evolutionary robotics, Evolutionary computation, Machine learning},
abstract = {Bootstrapped Neuro-Simulation (BNS) is a method of concurrent simulator and robot controller evolution. The algorithm requires little domain knowledge and no pre-investigation data gathering. Additionally, it bridges the reality gap effectively, rapidly evolves functional controllers, and recovers from damage automatically. In this paper, the first evidence of the ability of BNS to evolve closed-loop controllers is shown; in this case to solve a light-following problem. The algorithm is then evaluated for its damage recovery ability for these closed-loop controllers and shown to be very effective, with only minor adaptations.}
}
@article{LOMBARD2020103449,
title = {Stochastic triangular mesh mapping: A terrain mapping technique for autonomous mobile robots},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103449},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103449},
url = {https://www.sciencedirect.com/science/article/pii/S092188901930805X},
author = {Clint D. Lombard and Corné E. {van Daalen}},
keywords = {Dense mapping, Submapping, Perception, Triangular mesh, Probabilistic graphical model, Stereo cameras, LiDAR},
abstract = {For mobile robots to operate autonomously in general environments, perception is required in the form of a dense metric map. For this purpose, we present the stochastic triangular mesh (STM) mapping technique: a 2.5-D representation of the surface of the environment using a continuous mesh of triangular surface elements, where each surface element models the mean plane and roughness of the underlying surface. In contrast to existing mapping techniques, an STM map models the structure of the environment by ensuring a continuous model, while also being able to be incrementally updated with linear computational cost in the number of measurements. We reduce the effect of uncertainty in the robot pose (position and orientation) by using landmark-relative submaps. The uncertainty in the measurements and robot pose are accounted for by the use of Bayesian inference techniques during the map update. We demonstrate that an STM map can be used with sensors that generate point measurements, such as stochastic triangular mesh (LiDAR) sensors and stereo cameras. We show that an STM map is a more accurate model than the only comparable online surface mapping technique – a standard elevation map – and we also provide qualitative results on practical datasets.}
}
@article{URREA2020103447,
title = {Development of a virtual reality simulator for a strategy for coordinating cooperative manipulator robots using cloud computing},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103447},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103447},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019307651},
author = {Claudio Urrea and Rodrigo Matteoda},
keywords = {Cloud, Services, Collaborative, Cooperative, Coordination, Virtual reality},
abstract = {This article deals with the development of a simulator that recreates, in virtual reality, a team of Selectively Compliance Assembly Robot Arms (SCARA). This team works cooperatively to fulfill the task of stacking rectangular objects coordinated through a strategy that includes a cloud server responsible for communication between the robots. The execution of the task is based on a leader/follower configuration. In this configuration, the leader performs a computed trajectory constantly reporting its position to the remote server. The remote server, in turn, sends this information back to the follower so this can follow the leader. The application combines MatLab® and Java. The latter is specifically used for communication routines, since its versatility makes it easy to be incorporated into any type of machine. This paper seeks to demonstrate the advantages of incorporating cloud resources into a multi-robot system and how its performance can be tested by means of the application developed.}
}
@article{MOYSIS2020103377,
title = {A chaotic path planning generator based on logistic map and modulo tactics},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103377},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103377},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019305871},
author = {Lazaros Moysis and Eleftherios Petavratzis and Christos Volos and Hector Nistazakis and Ioannis Stouboulos},
keywords = {Autonomous mobile robot, Path planning, Terrain coverage, Chaos, Logistic map},
abstract = {A simple, short and efficient chaotic path planning algorithm is proposed for autonomous mobile robots, with the aim of covering a given terrain using chaotic, unpredictable motion. The proposed technique utilizes the logistic map with a chaotic tactic that utilizes a modulo function to produce a sequence of directions for a robot that can move in eight different directions on a grid. Extensive simulations are performed, and the results show a fast and efficient scanning of the given area. In addition, the proposed algorithm is further enhanced with a pheromone inspired memory technique, with good improvements in efficiency.}
}
@article{TAKANO2020103353,
title = {A data-driven approach to probabilistic impedance control for humanoid robots},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103353},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103353},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019305354},
author = {Wataru Takano and Hiroki Kanayama and Taro Takahashi and Tomohisa Moridaira and Yoshihiko Nakamura},
keywords = {Impedance control, Probabilistic model, Humanoid robot},
abstract = {This paper presents a novel approach toward synthesizing whole-body motions from visual perception and reaction force for a humanoid robot that maintains a suitable physical interaction with an environment. A behavior containing a whole-body motion, reaction force, and visual perception is encoded into a probabilistic model referred to as a “motion symbol”. The humanoid robot selects a motion symbol appropriate to the current situation and computes references for joint angles and reaction forces according to the selected symbol. The robot subsequently modifies these references to satisfy a desired impedance relating the robot whole-body positions and forces. This computation builds visual and physical feedback loops with knowledge about the behaviors, making it possible for a humanoid robot to not only perform human-like motion behaviors similar to training behaviors, but to also physically adapt to the immediate environment. We applies this proposed framework only to controlling the upper-body motion for a humanoid robot. Experiments demonstrate that the proposed method allows a humanoid robot to control its upper-body motion in response to visual perception and reaction forces acting on its hands to achieve five tasks while controlling its lower-body motion for its balance.}
}
@article{ZHU2020103318,
title = {Indoor place classification by building cardinal-direction prototyping blocks on point clouds},
journal = {Robotics and Autonomous Systems},
volume = {123},
pages = {103318},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103318},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018308121},
author = {Bo Zhu and Xiang Gao and Guozheng Xu and Yi Wang and Youqi Zheng},
keywords = {Indoor place classification, Scene geometry, Place perception, Place description, Semantic cognition},
abstract = {Making robots know people’s place concepts has attracted researchers for decades. People believe that this capability will firmly benefit not only robot–human interaction but also reasonable and social robot behaviors, or even traditional problems in robot research such as object detection. Focusing on place classification, this paper builds a kind of native pure 3D geometric description to capture place layouts based on common point clouds. This perspective enables our method to naturally accommodate various illuminations, including extremely bad lighting for which traditional image methods cannot work properly. The space of a place is first divided into 3D voxels. The cardinal orientations of this space are then extracted, and the geometric attributes of the voxels are subsequently represented based on the cardinal orientations. The voxels with geometric attributes are defined as the cardinal-direction prototyping blocks (CDPBs). Next, the CDPB distribution for a scene is calculated by qualitative spatial description technology, thereby obtaining the complete place description. Given the sparse description, the sparse random forest (SRF) is used for learning. The experiments indicate that the CDPB-based method outperforms the current 3D geometric method and its mixed method, and it has good time performance. The main advantages of our method are that it does not require any strict hypotheses on surfaces, such as planar surfaces, it requires smaller fusion windows to attain satisfactory classification rates, it can be used in extreme lighting environments, and its parameter selection is easy.}
}
@article{PASANDI2020103423,
title = {A programmable central pattern generator with bounded output},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103423},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103423},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019305998},
author = {Venus Pasandi and Aiko Dinale and Mehdi Keshmiri and Daniele Pucci},
keywords = {Online trajectory generation, Central pattern generator, Oscillator synchronization, Bounded output oscillator},
abstract = {Despite extensive studies on cyclic tasks in robotics, definitive solutions for the problem of trajectory generation for periodic motions have not been achieved so far. In this paper, we present an approach for online trajectory generation from a library of desired periodic trajectories. The proposed approach consists of a Central Pattern Generator (CPG) architecture ensuring entrainment of any periodic trajectory, smooth motion modulation and observing position and velocity limits of the robot. The proposed CPG is composed of a synchronized network of novel bounded output oscillatory systems. Every oscillatory system is a three-dimensional dynamical system encoding a one-dimensional periodic function as a stable limit cycle. We also use the state transformation method to bound the oscillator’s output and its first time derivative. Finally, we present a synchronization technique to construct a synchronized network of the proposed oscillators for generating multi dimensional periodic functions. Using Lyapunov based arguments, we prove that the proposed CPG ensures stability, convergence, and synchronization of the desired trajectory. The soundness of the proposed oscillator and the resulting CPG are validated both in simulations and experiments on the humanoid robot iCub.}
}
@article{WANG2020103410,
title = {Multi-agent sensitivity enhanced iterative best response: A real-time game theoretic planner for drone racing in 3D environments},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103410},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103410},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301939},
author = {Zijian Wang and Tim Taubner and Mac Schwager},
keywords = {Game theoretic motion planning, Nash equilibrium, Multi-robot systems},
abstract = {This paper presents a real-time game theoretic motion planning approach that enables an autonomous drone to race competitively against an arbitrary number of opponent drones along a 2D or 3D racecourse. Our method computes an approximate Nash equilibrium in the space of robot trajectories to maximally advance the ego robot while taking into account the opponents’ intentions and responses. The core of our solution is a “sensitivity enhanced” iterative best response algorithm that the ego robot uses to repeatedly plan its own trajectory and infer opponents’ trajectories, ultimately seeking a Nash equilibrium in the joint space of trajectories for all the drones. The algorithm includes a term that allows the ego vehicle to gain advantage by exploiting the influence of the ego drone’s trajectory on the adversaries’ objectives through the shared collision avoidance constraints among the vehicles. We also propose two methods for accelerating this computationally intensive iterative algorithm using (i) parallel computing with multiple CPU cores, and (ii) a neural network model that learns to predict trajectories close to the Nash equilibrium through offline training examples. Extensive simulation studies are conducted to benchmark the performance of our game theoretic planner and the statistical results show that our approach largely outperforms a baseline model predictive control algorithm that does not account for the opponents’ reactions. Hardware experiments with 4 quadrotor robots on a 3D racecourse are performed to show the applicability of our method in real-time robotic systems.}
}
@article{MUNISHKIN2020103370,
title = {Min–max time efficient inspection of ground vehicles by a UAV team},
journal = {Robotics and Autonomous Systems},
volume = {125},
pages = {103370},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103370},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301952},
author = {Alexey A. Munishkin and Dejan Milutinović and David W. Casbeer},
abstract = {We present a control design for N unmanned aerial vehicles (UAVs) tasked with an inspection of M ground moving vehicles. The location of each ground vehicle is known to each UAV, but the navigation and intent of each ground vehicle are unknown, therefore, this uncertainty has to be anticipated in each UAV’s navigation. We use the minimum time stochastic optimal control to navigate each UAV towards the inspection of each ground vehicle. Based on this control, we formulate assignments of ground vehicles to be inspected by UAVs as an optimization problem to inspect all ground vehicles in the minimum expected time. Accounting for ground vehicle uncertain trajectories, we update the optimal assignment by a Markov inequality rule. The rule prevents the possibility of indefinite updating of assignments without finishing the inspection of all vehicles. On the other hand, it updates an assignment if it leads to a statistically significant improvement of the inspection expected time. The presented approach is illustrated with numerical examples.}
}
@article{SCHEPER2020103380,
title = {Evolution of robust high speed optical-flow-based landing for autonomous MAVs},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103380},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103380},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302404},
author = {Kirk Y.W. Scheper and Guido C.H.E. {de Croon}},
keywords = {Evolutionary robotics, Bio-inspired landing, Reality gap, High speed flight},
abstract = {Automatic optimization of robotic behavior has been the long-standing goal of Evolutionary Robotics. Allowing the problem at hand to be solved by automation often leads to novel approaches and new insights. A common problem encountered with this approach is that when this optimization occurs in a simulated environment, the optimized policies are subject to the reality gap when implemented in the real world. This often results in sub-optimal behavior, if it works at all. This paper investigates the automatic optimization of neurocontrollers to perform quick but safe landing maneuvers for a quadrotor micro air vehicle using the divergence of the optical flow field of a downward looking camera. The optimized policies showed that a piece-wise linear control scheme is more effective than the simple linear scheme commonly used, something not yet considered by human designers. Additionally, we show the utility in using abstraction on the input and output of the controller as a tool to improve the robustness of the optimized policies to the reality gap by testing our policies optimized in simulation on real world vehicles. We tested the neurocontrollers using two different methods to generate and process the visual input, one using a conventional CMOS camera and one a dynamic vision sensor, both of which perform significantly differently than the simulated sensor. The use of the abstracted input resulted in near seamless transfer to the real world with the controllers showing high robustness to a clear reality gap.}
}
@article{SIMETTI2019103287,
title = {A task priority approach to cooperative mobile manipulation: Theory and experiments},
journal = {Robotics and Autonomous Systems},
volume = {122},
pages = {103287},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103287},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019302763},
author = {E. Simetti and G. Casalino and F. Wanderlingh and M. Aicardi},
keywords = {Cooperative mobile manipulation, Task priority framework, Mobile manipulators},
abstract = {Cooperative manipulation and transportation by means of multi-robot systems is a subject that has received an increased interest in the last few years. In this work, a task priority approach is first recalled from the authors previous works as framework for the control of a single mobile manipulator, to manage all its control objectives, including set membership ones and a proper coordination between the manipulator and its supporting vehicle. The approach is then extended, through a novel coordination policy, to execute a cooperative transportation of a common load by means of two (or more) mobile manipulators, via an explicit but limited information exchange, without modifying the individual controllers. Experimental results with two YouBot mobile manipulators are shown to demonstrate the effectiveness of the approach.}
}
@article{GONZALEZSIEIRA2020103455,
title = {Autonomous navigation for UAVs managing motion and sensing uncertainty},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103455},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103455},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019307080},
author = {Adrián González-Sieira and Daniel Cores and Manuel Mucientes and Alberto Bugarín},
keywords = {Autonomous navigation, Motion planning, Motion uncertainty, UAVs, Scene reconstruction},
abstract = {We present a motion planner for the autonomous navigation of UAVs that manages motion and sensing uncertainty at planning time. By doing so, optimal paths in terms of probability of collision, traversal time and uncertainty are obtained. Moreover, our approach takes into account the real dimensions of the UAV in order to reliably estimate the probability of collision from the predicted uncertainty. The motion planner relies on a graduated fidelity state lattice and a novel multi-resolution heuristic which adapt to the obstacles in the map. This allows managing the uncertainty at planning time and yet obtaining solutions fast enough to control the UAV in real time. Experimental results show the reliability and the efficiency of our approach in different real environments and with different motion models. Finally, we also report planning results for the reconstruction of 3D scenarios, showing that with our approach the UAV can obtain a precise 3D model autonomously.}
}
@article{YU2020103401,
title = {Enhancing adaptability with local reactive behaviors for hexapod walking robot via sensory feedback integrated central pattern generator},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103401},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103401},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019304142},
author = {Haitao Yu and Haibo Gao and Zongquan Deng},
keywords = {Hexapod walking robot, Legged locomotion, Local reactive behavior, Central pattern generator (CPG)},
abstract = {Local reactive behaviors endow animals the ability to exhibit agile and dexterous performance when traversing challenging terrains. This paper presents a novel locomotion control method based on the central pattern generator (CPG) concept for hexapod walking robot with local reactive behavior to cope with terrain irregularities. Firstly, a two-layered CPG-based single-leg controller is developed to generate the rhythmical movement for each leg executing tripod walking. The Van der Pol oscillator is employed on the high-layer to construct a coupled CPG network which serves as a phase regulator (PR) to produce rhythmic signals with prescribed phase relations amongst neurons. On the low-layer, an auxiliary linear converter (LC) transforms these signals into the desired joint trajectories. Subsequently, by embodying the proprioceptive sensing and external tactile information as the sensory feedback, two typical local reactive mechanisms including the elevator reflex and searching reflex are achieved by virtue of on-line adjusting the coupling scheme of the PR and the coefficients of the LC. A locomotion control framework for hexapod walking robot is further established by combining the single-leg controller with a finite state machine to allocate swing/stance commands for individual joints in dealing with terrain perturbations. The effectiveness of the proposed method has been verified through both virtual model simulation and experiments on a physical hexapod platform.}
}
@article{DANG2020103441,
title = {DWnet: Deep-wide network for 3D action recognition},
journal = {Robotics and Autonomous Systems},
volume = {126},
pages = {103441},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103441},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019308176},
author = {Yonghao Dang and Fuxing Yang and Jianqin Yin},
keywords = {Action recognition, Deep structure, 3D skeleton, Human–robot cooperation},
abstract = {Action recognition plays an important role in human–robot cooperation and interaction. By recognizing human actions, robots can imitate or reproduce human actions and obtain skills. Recently, convolutional neural networks (CNNs) have been widely used to recognize actions based on 3D skeleton. Good performance has been achieved due to the approximation capability gained from the depth of the model. Unfortunately, in the mainstream deep structures, dropout and fully connected layers are usually used to classify actions. That is to say, ensemble is used to guarantee the recognition performance, which decreases the computational efficiency. In order to improve the computational efficiency, we propose in this paper a deep-wide network (DWnet) to recognize human actions based on 3D skeleton. Specifically, we modify the decision-making mechanism of the deep CNN with a shallow structure, which improves the computational efficiency. The state-of-the-art deep CNN is used to extract spatial–temporal features from the skeletal sequence. Then features are transformed into a higher dimensional feature space to obtain global information and classified by the modified decision making mechanism. Experiments on two skeletal datasets demonstrate the advantage of the proposed model on testing efficiency and the effectiveness of the novel model to recognize the action. The code has been publicly available at https://github.com/YHDang/DWnet.}
}
@article{YAZDANI2020103382,
title = {A survey of underwater docking guidance systems},
journal = {Robotics and Autonomous Systems},
volume = {124},
pages = {103382},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103382},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019300181},
author = {A.M. Yazdani and K. Sammut and O. Yakimenko and A. Lammas},
keywords = {Autonomous underwater vehicles, Autonomous docking, Universal docking guidance framework},
abstract = {Autonomous underwater vehicles (AUVs) are increasingly being used for underwater survey and exploration missions. The expanding mission scope for AUVs highlights the need for a long-endurance operational capability, which mainly depends on propulsion system efficiency and battery capacity. The use of submerged docking stations permitting battery recharge and data download/upload offers a means of enabling persistence without compromising propulsion and payload power budgets, while also reducing associated deployment/recovery costs and risks. Autonomous docking with an underwater station is, however, complicated by the presence of currents and obstacles in the water, and by the relative dynamic differences in pose between the dock and the vehicle. A robust docking guidance system is identified as a core and crucial component for ensuring successful AUV docking. This paper presents a detailed literature review summarizing the current state-of-the-art in AUV docking guidance methodologies, identifying their relative merits and shortcomings, and revealing the docking guidance methodologies that seems to be the most prominent.}
}
@article{YAMAGUCHI2020103464,
title = {Selective grasp in occluded space by all-around proximity perceptible finger},
journal = {Robotics and Autonomous Systems},
volume = {127},
pages = {103464},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103464},
url = {https://www.sciencedirect.com/science/article/pii/S092188901930274X},
author = {Naoya Yamaguchi and Shun Hasegawa and Masaki Murooka and Kei Okada and Masayuki Inaba},
keywords = {Proximity sensor, Robot hand, Environment map, Grasp, Shape classification},
abstract = {The goal of this research is to develop a “Selective Grasp” system with which robots can grasp and identify the target object even in occluded environments. In pursuit of this goal, we first develop a robot hand on which proximity sensors are mounted all around. In addition to the development, we propose a sensor model of the robot hand. By using the sensor model, robots can estimate the distance to the object and calibrate the sensors. With our robot hand, robots can accurately recognize their surroundings without touch. Secondly, we propose an approach in which robots can memorize spatial information of surroundings by building an environment map. The building map motion is generated by a combination of manipulation primitives based on proximity sensors. Thirdly, we propose a grasp planning method and an object shape classification method based on the environment map. By these methods, robots can grasp objects and classify shapes of the objects in occluded spaces. Lastly, we conduct real robot experiments, through which we validate the effectiveness of our proposed Selective Grasp system.}
}