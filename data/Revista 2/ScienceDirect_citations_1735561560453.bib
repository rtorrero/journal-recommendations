@article{YIN2023171,
title = {Continual learning with attentive recurrent neural networks for temporal data classification},
journal = {Neural Networks},
volume = {158},
pages = {171-187},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004270},
author = {Shao-Yu Yin and Yu Huang and Tien-Yu Chang and Shih-Fang Chang and Vincent S. Tseng},
keywords = {Continual learning, Temporal data classification, Recurrent neural networks, Deep learning},
abstract = {Continual learning is an emerging research branch of deep learning, which aims to learn a model for a series of tasks continually without forgetting knowledge obtained from previous tasks. Despite receiving a lot of attention in the research community, temporal-based continual learning techniques are still underutilized. In this paper, we address the problem of temporal-based continual learning by allowing a model to continuously learn on temporal data. To solve the catastrophic forgetting problem of learning temporal data in task incremental scenarios, in this research, we propose a novel method based on attentive recurrent neural networks, called Temporal Teacher Distillation (TTD). TTD solves the catastrophic forgetting problem in an attentive recurrent neural network based on three hypotheses, namely Rotation Hypothesis, Redundant Hypothesis, and Recover Hypothesis. Rotation Hypothesis and Redundant hypotheses could cause the attention shift phenomenon, which degrades the model performance on the learned tasks. Moreover, not considering the Recover Hypothesis increases extra memory usage in continuously training different tasks. Therefore, the proposed TTD based on the above hypotheses complements the inadequacy of the existing methods for temporal-based continual learning. For evaluating the performance of our proposed method in task incremental setting, we use a public dataset, WIreless Sensor Data Mining (WISDM), and a synthetic dataset, Split-QuickDraw-100. According to experimental results, the proposed TTD significantly outperforms state-of-the-art methods by up to 14.6% and 45.1% in terms of accuracy and forgetting measures, respectively. To the best of our knowledge, this is the first work that studies continual learning in real-world incremental categories for temporal data classification with attentive recurrent neural networks and provides the proper application-oriented scenario.}
}
@article{ZHANG202390,
title = {Multi-Aspect enhanced Graph Neural Networks for recommendation},
journal = {Neural Networks},
volume = {157},
pages = {90-102},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003859},
author = {Chenyan Zhang and Shan Xue and Jing Li and Jia Wu and Bo Du and Donghua Liu and Jun Chang},
keywords = {Recommender systems, Graph neural networks, Aspect-based sentiment analysis, Capsule network},
abstract = {Graph neural networks (GNNs) have achieved remarkable performance in personalized recommendation, for their powerful data representation capabilities. However, these methods still face several challenging problems: (1) the majority of user–item interaction graphs only utilize the interaction information, which cannot reflect the users’ specific preferences for different aspects, making it difficult to capture user preferences in a fine-grained manner. (2) there is no effective way to integrate multi-aspect preferences into a unified model to capture the comprehensive user interests. To address these challenges, we propose a Multi-Aspect enhanced Graph Neural Networks (MA-GNNs) model for item recommendation. Specifically, we learn the aspect-based sentiments from reviews and use them to construct multiple aspect-aware user–item graphs, thus giving the edge practical meaning. And aspect semantic features are introduced into the information aggregation process to adjust users’ preferences for different items. Furthermore, we design a routing-based fusion mechanism, which adaptively allocates weights to different aspects to realize the dynamic fusion of aspect preferences. We conduct experiments on four publicly available datasets, and the experimental results show that the proposed MA-GNNs model outperforms state-of-the-art methods. Further analysis proves that fine-grained interest modeling can improve the interpretability of recommendations.}
}
@article{AKETI2022451,
title = {Low precision decentralized distributed training over IID and non-IID data},
journal = {Neural Networks},
volume = {155},
pages = {451-460},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.032},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200332X},
author = {Sai Aparna Aketi and Sangamesh Kodge and Kaushik Roy},
keywords = {Distributed training, Decentralized training, Low precision training, Communication efficiency, Non-IID data, Hardware efficiency},
abstract = {Decentralized distributed learning is the key to enabling large-scale machine learning (training) on the edge devices utilizing private user-generated local data, without relying on the cloud. However, practical realization of such on-device training is limited by the communication and compute bottleneck. In this paper, we propose and show the convergence of low precision decentralized training that aims to reduce the computational complexity and communication cost of decentralized training. Many feedback-based compression techniques have been proposed in the literature to reduce communication costs. To the best of our knowledge, there is no work that applies and shows compute efficient training techniques such as quantization, pruning etc., for peer-to-peer decentralized learning setups. Since real-world applications have a significant skew in the data distribution, we design ”Range-EvoNorm” as the normalization activation layer which is better suited for low precision training over non-IID data. Moreover, we show that the proposed low precision training can be used in synergy with other communication compression methods decreasing the communication cost further. Our experiments indicate that 8-bit decentralized training has minimal accuracy loss compared to its full precision counterpart even with non-IID data. However, when low precision training is accompanied by communication compression through sparsification we observe a 1−2% drop in accuracy. The proposed low precision decentralized training decreases computational complexity, memory usage, and communication cost by ∼4× and compute energy by a factor of ∼20×, while trading off less than a 1% accuracy for both IID and non-IID data. In particular, for higher skew values, we observe an increase in accuracy (by ∼0.5%) with low precision training, indicating the regularization effect of the quantization.}
}
@article{LI202229,
title = {Switching pinning control for memristive neural networks system with Markovian switching topologies},
journal = {Neural Networks},
volume = {156},
pages = {29-38},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003458},
author = {Ning Li and Wei Xing Zheng},
keywords = {Memristive neural networks, Bipartite synchronization, Switching topology, Signed graph, Pinning control},
abstract = {This work concentrates on the issue of leader-following bipartite synchronization of multiple memristive neural networks with Markovian jump topology. In contrast to conventional coupled neural network systems, the coupled neural network model under consideration possesses both cooperative and competitive connections among neuron nodes. Specifically, the interaction between neighbors’ nodes is described by a signed graph, in which a positive weight represents an alliance relationship between two neuron nodes while a negative weight represents an adversarial relationship between two neuron nodes. By designing a pinning discontinuous controller that makes full use of the mode information, some effective criteria that ensure the stability of bipartite synchronization error states are obtained. All network nodes can synchronize the target node state bipartitely. Finally, two simulation examples are provided to demonstrate the viability of the suggested bipartite synchronization control approach.}
}
@article{WEDLER2022123,
title = {Surface similarity parameter: A new machine learning loss metric for oscillatory spatio-temporal data},
journal = {Neural Networks},
volume = {156},
pages = {123-134},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003732},
author = {Mathies Wedler and Merten Stender and Marco Klein and Svenja Ehlers and Norbert Hoffmann},
keywords = {Deep learning, Loss function, Error metric, Similarity, Nonlinear dynamics, Spatio-temporal dynamics},
abstract = {Supervised machine learning approaches require the formulation of a loss functional to be minimized in the training phase. Sequential data are ubiquitous across many fields of research, and are often treated with Euclidean distance-based loss functions that were designed for tabular data. For smooth oscillatory data, those conventional approaches lack the ability to penalize amplitude, frequency and phase prediction errors at the same time, and tend to be biased towards amplitude errors. We introduce the surface similarity parameter (SSP) as a novel loss function that is especially useful for training machine learning models on smooth oscillatory sequences. Our extensive experiments on chaotic spatio-temporal dynamical systems indicate that the SSP is beneficial for shaping gradients, thereby accelerating the training process, reducing the final prediction error, increasing weight initialization robustness, and implementing a stronger regularization effect compared to using classical loss functions. The results indicate the potential of the novel loss metric particularly for highly complex and chaotic data, such as data stemming from the nonlinear two-dimensional Kuramoto–Sivashinsky equation and the linear propagation of dispersive surface gravity waves in fluids.}
}
@article{ZHAO2022340,
title = {Multi-granularity heterogeneous graph attention networks for extractive document summarization},
journal = {Neural Networks},
volume = {155},
pages = {340-347},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003215},
author = {Yu Zhao and Leilei Wang and Cui Wang and Huaming Du and Shaopeng Wei and Huali Feng and Zongjian Yu and Qing Li},
keywords = {Extractive document summarization, Multi-granularity heterogeneous graph attention networks, Graph Neural Networks},
abstract = {Extractive document summarization is a fundamental task in natural language processing (NLP). Recently, several Graph Neural Networks (GNNs) are proposed for this task. However, most existing GNN-based models can neither effectively encode semantic nodes of multiple granularity level apart from sentences nor substantially capture different cross-sentence meta-paths. To address these issues, we propose MHgatSum, a novel Multi-granularity Heterogeneous Graph ATtention networks for extractive document SUMmarization. Specifically, we first build a multi-granularity heterogeneous graph (HetG) for each document, which is better to represent the semantic meaning of the document. The HetG contains not only sentence nodes but also multiple other granularity effective semantic units with different semantic levels, including keyphrases and topics. These additional nodes act as the intermediary between sentences to build the meta-paths involved in sentence node (i.e., Sentence-Keyphrase-Sentence and Sentence-Topic-Sentence). Then, we propose a heterogeneous graph attention networks to embed the constructed HetG for extractive summarization, which enjoys multi-granularity semantic representations. The model is based on a hierarchical attention mechanism, including node-level and semantic-level attentions. The node-level attention can learn the importance between a node and its meta-path based neighbors, while the semantic-level attention is able to learn the importance of different meta-paths. Moreover, to better integrate sentence global knowledge, we further incorporate sentence node global importance in local node-level attention. We conduct empirical experiments on two benchmark datasets, which demonstrates the superiority of MHgatSum over previous SOTA models on the task of extractive summarization.}
}
@article{DU202397,
title = {Efficient Perturbation Inference and Expandable Network for continual learning},
journal = {Neural Networks},
volume = {159},
pages = {97-106},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004269},
author = {Fei Du and Yun Yang and Ziyuan Zhao and Zeng Zeng},
keywords = {Continual learning, Dynamic networks, Class incremental learning, Uncertainty inference},
abstract = {Although humans are capable of learning new tasks without forgetting previous ones, most neural networks fail to do so because learning new tasks could override the knowledge acquired from previous data. In this work, we alleviate this issue by proposing a novel Efficient Perturbation Inference and Expandable Network (EPIE-Net), which dynamically expands lightweight task-specific decoders for new classes and utilizes a mixed-label uncertainty strategy to improve the robustness. Moreover, we calculate the average probability of perturbed samples at inference, which can generally improve the performance of the model. Experimental results show that our method consistently outperforms other methods with fewer parameters in class incremental learning benchmarks. For example, on the CIFAR-100 10 steps setup, our method achieves an average accuracy of 76.33% and the last accuracy of 65.93% within only 3.46M average parameters.}
}
@article{LI202214,
title = {A privacy preservation framework for feedforward-designed convolutional neural networks},
journal = {Neural Networks},
volume = {155},
pages = {14-27},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003057},
author = {De Li and Jinyan Wang and Qiyu Li and Yuhang Hu and Xianxian Li},
keywords = {Differential privacy, Convolutional neural networks, Feedforward-designed, Feature selection, Over-fitting},
abstract = {A feedforward-designed convolutional neural network (FF-CNN) is an interpretable neural network with low training complexity. Unlike a neural network trained using backpropagation (BP) algorithms and optimizers (e.g., stochastic gradient descent (SGD) and Adam), a FF-CNN obtains the model parameters in one feed-forward calculation based on two methods of data statistics: subspace approximation with adjusted bias and least squares regression. Currently, models based on FF-CNN training methods have achieved outstanding performance in the fields of image classification and point cloud data processing. In this study, we analyze and verify that there is a risk of user privacy leakage during the training process of FF-CNN and existing privacy-preserving methods for model gradients or loss functions do not apply to FF-CNN models. Therefore, we propose a securely forward-designed convolutional neural network algorithm (SFF-CNN) to protect the privacy and security of data providers for the FF-CNN model. Firstly, we propose the DPSaab algorithm to add the corresponding noise to the one-stage Saab transform in the FF-CNN design for improved protection performance. Secondly, because noise addition brings the risk of model over-fitting and further increases the possibility of privacy leakage, we propose the SJS algorithm to filter the input features of the fully connected model layer. Finally, we theoretically prove that the proposed algorithm satisfies differential privacy and experimentally demonstrate that the proposed algorithm has strong privacy protection. The proposed algorithm outperforms the compared deep learning privacy-preserving algorithms in terms of utility and robustness.}
}
@article{MEI2022551,
title = {TaskDrop: A competitive baseline for continual learning of sentiment classification},
journal = {Neural Networks},
volume = {155},
pages = {551-560},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003331},
author = {Jian-Ping Mei and Yilun Zhen and Qianwei Zhou and Rui Yan},
keywords = {Continual learning, Sentiment classification, Catastrophic forgetting, Knowledge transfer, Random masking},
abstract = {In this paper, we study the multi-task sentiment classification problem in the continual learning setting, i.e., a model is sequentially trained to classify the sentiment of reviews of products in a particular category. The use of common sentiment words in reviews of different product categories leads to large cross-task similarity, which differentiates it from continual learning in other domains. This knowledge sharing nature renders forgetting reduction focused approaches less effective for the problem under consideration. Unlike existing approaches, where task-specific masks are learned with specifically presumed training objectives, we propose an approach called Task-aware Dropout (TaskDrop) to randomly sample a binary mask for each task. While the standard dropout generates and applies random masks for each training instance per epoch for regularization, random masks in TaskDrop are used for model capacity allocation and reuse to each coming task. We conducted experimental studies on Amazon review data and made comparison to various baselines and state-of-the-art approaches. Our empirical results show that regardless of simplicity, TaskDrop overall achieved competitive performance, especially after relatively long term learning. This demonstrates that the proposed random capacity allocation mechanism works well for continual sentiment classification.}
}
@article{WANG2023404,
title = {Neurodynamics-driven portfolio optimization with targeted performance criteria},
journal = {Neural Networks},
volume = {157},
pages = {404-421},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004142},
author = {Jun Wang and Xin Gan},
keywords = {Portfolio selection, Risk-adjusted performance criteria, Pseudoconvex optimization, Iteratively weighted optimization, Distributed optimization, Neurodynamic optimization},
abstract = {This paper addresses portfolio selection with targeted performance criteria via neurodynamic optimization. Five portfolio optimization problems are formulated with a variable weight to maximize five risk-adjusted performance criteria in Markowitz’s mean–variance framework and reformulated as iteratively weighted convex optimization problems to facilitate subsequent problem-solving solution procedures. In addition, distributed portfolio optimization problems with separable performance criteria are also formulated. Three neurodynamic approaches are developed based on two globally convergent recurrent neural networks to solve the formulated and reformulated problems. Extensive experimental results on 13 datasets of world stock markets are elaborated to demonstrate the superior performance of the neurodynamic approaches against the baselines in terms of five given evaluation criteria and two investment returns.}
}
@article{BASAK2022108,
title = {3D face-model reconstruction from a single image: A feature aggregation approach using hierarchical transformer with weak supervision},
journal = {Neural Networks},
volume = {156},
pages = {108-122},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003690},
author = {Shubhajit Basak and Peter Corcoran and Rachel McDonnell and Michael Schukat},
keywords = {Face reconstruction, Hierarchical transformer, Feature fusion, ViT, Swin Transformer},
abstract = {Convolutional Neural Networks (CNN) have gained popularity as the de-facto model for any computer vision task. However, CNN have drawbacks, i.e. they fail to extract long-range perceptions in images. Due to their ability to capture long-range dependencies, transformer networks are adopted in computer vision applications, where they show state-of-the-art (SOTA) results in popular tasks like image classification, instance segmentation, and object detection. Although they gained ample attention, transformers have not been applied to 3D face reconstruction tasks. In this work, we propose a novel hierarchical transformer model, added to a feature pyramid aggregation structure, to extract the 3D face parameters from a single 2D image. More specifically, we use pre-trained Swin Transformer backbone networks in a hierarchical manner and add the feature fusion module to aggregate the features in multiple stages. We use a semi-supervised training approach and train our model in a supervised way with the 3DMM parameters from a publicly available dataset and unsupervised training with a differential renderer on other parameters like facial keypoints and facial features. We also train our network on a hybrid unsupervised loss and compare the results with other SOTA approaches. When evaluated across two public datasets on face reconstruction and dense 3D face alignment tasks, our method can achieve comparable results to the current SOTA performance and in some instances do better than the SOTA methods. A detailed subjective evaluation also shows that our method performs better than the previous works in realism and occlusion resistance.}
}
@article{TERZIYAN2022177,
title = {Hyper-flexible Convolutional Neural Networks based on Generalized Lehmer and Power Means},
journal = {Neural Networks},
volume = {155},
pages = {177-203},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003173},
author = {Vagan Terziyan and Diana Malyk and Mariia Golovianko and Vladyslav Branytskyi},
keywords = {Convolutional Neural Network, Flexibility, Adversarial robustness, Pooling, Lehmer Mean, Power Mean},
abstract = {Convolutional Neural Network is one of the famous members of the deep learning family of neural network architectures, which is used for many purposes, including image classification. In spite of the wide adoption, such networks are known to be highly tuned to the training data (samples representing a particular problem), and they are poorly reusable to address new problems. One way to change this would be, in addition to trainable weights, to apply trainable parameters of the mathematical functions, which simulate various neural computations within such networks. In this way, we may distinguish between the narrowly focused task-specific parameters (weights) and more generic capability-specific parameters. In this paper, we suggest a couple of flexible mathematical functions (Generalized Lehmer Mean and Generalized Power Mean) with trainable parameters to replace some fixed operations (such as ordinary arithmetic mean or simple weighted aggregation), which are traditionally used within various components of a convolutional neural network architecture. We named the overall architecture with such an update as a hyper-flexible convolutional neural network. We provide mathematical justification of various components of such architecture and experimentally show that it performs better than the traditional one, including better robustness regarding the adversarial perturbations of testing data.}
}
@article{CI202311,
title = {Multiple asymptotical ω-periodicity of fractional-order delayed neural networks under state-dependent switching},
journal = {Neural Networks},
volume = {157},
pages = {11-25},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003847},
author = {Jingxuan Ci and Zhenyuan Guo and Han Long and Shiping Wen and Tingwen Huang},
keywords = {Fractional-order neural network, Multiple asymptotical ω-periodicity, Delay, State-dependent switching},
abstract = {This paper presents theoretical results on multiple asymptotical ω-periodicity of a state-dependent switching fractional-order neural network with time delays and sigmoidal activation functions. Firstly, by combining the geometrical properties of activation functions with the range of switching threshold, a partition of state space is given. Then, the conditions guaranteeing that the solutions can approach each other infinitely in each positive invariant set are derived. Furthermore, the S-asymptotical ω-periodicity and the convergence of solutions in positive invariant sets are discussed. It is worth noting that the number of attractors increases to 3n from 2n in a neural network without switching. Finally, three numerical examples are given to substantiate the theoretical results.}
}
@article{GAO202239,
title = {Label smoothing and task-adaptive loss function based on prototype network for few-shot learning},
journal = {Neural Networks},
volume = {156},
pages = {39-48},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003689},
author = {Farong Gao and Xingsheng Luo and Zhangyi Yang and Qizhong Zhang},
keywords = {Flexible hyperparameters, Improved loss function, Few-shot learning, Image classification, Deep learning},
abstract = {Aiming at solving the problems of prototype network that the label information is not reliable enough and that the hyperparameters of the loss function cannot follow the changes of image feature information, we propose a method that combines label smoothing and hyperparameters. First, the label information of an image is processed by label smoothing regularization. Then, according to different classification tasks, the distance matrix and logarithmic operation of the image feature are used to fuse the distance matrix of the image with the hyperparameters of the loss function. Finally, the hyperparameters are associated with the smoothed label and the distance matrix for predictive classification. The method is validated on the miniImageNet, FC100 and tieredImageNet datasets. The results show that, compared with the unsmoothed label and fixed hyperparameters methods, the classification accuracy of the flexible hyperparameters in the loss function under the condition of few-shot learning is improved by 2%–3%. The result shows that the proposed method can suppress the interference of false labels, and the flexibility of hyperparameters can improve classification accuracy.}
}
@article{DAHL202295,
title = {Time series (re)sampling using Generative Adversarial Networks},
journal = {Neural Networks},
volume = {156},
pages = {95-107},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003446},
author = {Christian M. Dahl and Emil N. Sørensen},
keywords = {Generative adversarial nets, Dependent processes, Bootstrapping},
abstract = {We propose a novel bootstrap procedure for time series data based on Generative Adversarial networks (GANs). We show that the dynamics of common stationary time series processes can be learned by GANs and demonstrate that GANs trained on a single sample path can be used to generate additional samples from the process. We find that temporal convolutional neural networks provide a suitable design for the generator and discriminator, and that convincing samples can be generated on the basis of a vector drawn from a normal distribution with zero mean and an identity variance–covariance matrix. We demonstrate the finite sample properties of GAN sampling and the suggested bootstrap using simulations where we compare the performance to circular block bootstrapping in the case of resampling an AR(1) time series processes. We find that resampling using the GAN can outperform circular block bootstrapping in terms of empirical coverage. Finally, we provide an empirical application to the Sharpe ratio.}
}
@article{LEI202267,
title = {BAT: Block and token self-attention for speech emotion recognition},
journal = {Neural Networks},
volume = {156},
pages = {67-80},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003720},
author = {Jianjun Lei and Xiangwei Zhu and Ying Wang},
keywords = {Speech emotion recognition, Transformer, Self-attention},
abstract = {Transformers have achieved great success in many artificial intelligence fields, such as computer vision (CV), audio processing and natural language processing (NLP). In speech emotion recognition (SER), transformer-based architectures usually compute attention in a token-by-token (frame-by-frame) manner, but this approach lacks adequate capacity to capture local emotion information and is easily affected by noise. This paper proposes a novel SER architecture, referred to as block and token self-attention (BAT), that splits a mixed spectrogram into blocks and computes self-attention by combining these blocks with tokens, which can alleviate the effect of local noise while capturing authentic sentiment expressions. Furthermore, we present a cross-block attention mechanism to facilitate information interaction among blocks while integrating a frequency compression and channel enhancement (FCCE) module to smooth the attention biases between blocks and tokens. BAT achieves 73.2% weighted accuracy (WA) and 75.2% unweighted accuracy (UA) on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset, surpassing the results of previously developed state-of-the-art approaches with the same dataset partitioning operation. Further experimental results reveal that our proposed method is also well suited for cross-database and cross-domain tasks, achieving 89% WA and 87.4% UA on Emo-DB and producing a top-1 recognition accuracy of 88.32% with only 15.01 Mb of parameters on the CIFAR-10 image dataset under a scenario with no data augmentation or pretraining.}
}
@article{LUQUE2022422,
title = {Electrical coupling regulated by GABAergic nucleo-olivary afferent fibres facilitates cerebellar sensory–motor adaptation},
journal = {Neural Networks},
volume = {155},
pages = {422-438},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003203},
author = {Niceto R. Luque and Francisco Naveros and Ignacio Abadía and Eduardo Ros and Angelo Arleo},
keywords = {Vestibulo-ocular reflex (VOR), Inferior olive (IO), Nucleo-olivary path, Cerebellar adaptation, Spiking neural networks, Electrical synapses},
abstract = {The inferior olivary (IO) nucleus makes up the signal gateway for several organs to the cerebellar cortex. Located within the sensory–motor-cerebellum pathway, the IO axons, i.e., climbing fibres (CFs), massively synapse onto the cerebellar Purkinje cells (PCs) regulating motor learning whilst the olivary nucleus receives negative feedback through the GABAergic nucleo-olivary​ (NO) pathway. The NO pathway regulates the electrical coupling (EC) amongst the olivary cells thus facilitating synchrony and timing. However, the involvement of this EC regulation on cerebellar adaptive behaviour is still under debate. In our study we have used a spiking cerebellar model to assess the role of the NO pathway in regulating vestibulo-ocular-reflex (VOR) adaptation. The model incorporates spike-based synaptic plasticity at multiple cerebellar sites and an electrically-coupled olivary system. The olivary system plays a central role in regulating the CF spike-firing patterns that drive the PCs, whose axons ultimately shape the cerebellar output. Our results suggest that a systematic GABAergic NO deactivation decreases the spatio-temporal complexity of the IO firing patterns thereby worsening the temporal resolution of the olivary system. Conversely, properly coded IO spatio-temporal firing patterns, thanks to NO modulation, finely shape the balance between long-term depression and potentiation, which optimises VOR adaptation. Significantly, the NO connectivity pattern constrained to the same micro-zone helps maintain the spatio-temporal complexity of the IO firing patterns through time. Moreover, the temporal alignment between the latencies found in the NO fibres and the sensory–motor pathway delay appears to be crucial for facilitating the VOR. When we consider all the above points we believe that these results predict that the NO pathway is instrumental in modulating the olivary coupling and relevant to VOR adaptation.}
}
@article{FUJIMOTO2022224,
title = {Deep learning-based image deconstruction method with maintained saliency},
journal = {Neural Networks},
volume = {155},
pages = {224-241},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200315X},
author = {Keisuke Fujimoto and Kojiro Hayashi and Risa Katayama and Sehyung Lee and Zhen Liang and Wako Yoshida and Shin Ishii},
keywords = {Attention, Image transformation, Saliency map, Deep learning, Variational autoencoder, Functional magnetic resonance imaging},
abstract = {Visual properties that primarily attract bottom-up attention are collectively referred to as saliency. In this study, to understand the neural activity involved in top-down and bottom-up visual attention, we aim to prepare pairs of natural and unnatural images with common saliency. For this purpose, we propose an image transformation method based on deep neural networks that can generate new images while maintaining the consistent feature map, in particular the saliency map. This is an ill-posed problem because the transformation from an image to its corresponding feature map could be many-to-one, and in our particular case, the various images would share the same saliency map. Although stochastic image generation has the potential to solve such ill-posed problems, the most existing methods focus on adding diversity of the overall style/touch information while maintaining the naturalness of the generated images. To this end, we developed a new image transformation method that incorporates higher-dimensional latent variables so that the generated images appear unnatural with less context information but retain a high diversity of local image structures. Although such high-dimensional latent spaces are prone to collapse, we proposed a new regularization based on Kullback–Leibler divergence to avoid collapsing the latent distribution. We also conducted human experiments using our newly prepared natural and corresponding unnatural images to measure overt eye movements and functional magnetic resonance imaging, and found that those images induced distinctive neural activities related to top-down and bottom-up attentional processing.}
}
@article{WANG2023377,
title = {Neurodynamics-driven holistic approaches to semi-supervised feature selection},
journal = {Neural Networks},
volume = {157},
pages = {377-386},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004257},
author = {Yadi Wang and Jun Wang},
keywords = {Semi-supervised feature selection, Information-theoretic measures, Neurodynamic optimization, Fractional programming},
abstract = {Feature selection is a crucial part of machine learning and pattern recognition, which aims at selecting a subset of informative features from the original dataset. Because of label information, supervised feature selection performs better than unsupervised feature selection without label information. However, in the presence of a small number of labeled data and a large number of unlabeled data, it is challenging for supervised feature selection methods to select relevant features. In this paper, we propose three neurodynamics-driven holistic approaches to semi-supervised feature selection via semi-supervised feature redundancy minimization and semi-supervised feature relevancy maximization. We first define information-theoretic semi-supervised similarity coefficient matrix and semi-supervised feature relevancy vector based on multi-information, unsupervised symmetric uncertainty, and entropy to measure feature redundancy and relevancy. We then formulate a fractional programming problem and an iteratively weighted quadratic programming problem based on the semi-supervised similarity coefficient matrix and semi-supervised feature relevancy vector for semi-supervised feature selection. To solve the formulated problems, we delineate three neurodynamic optimization approaches based on two projection neural networks. We elaborate on the experimental results on six benchmark datasets to demonstrate the superior classification performance of the proposed neurodynamic approaches against six existing supervised and semi-supervised feature selection methods.}
}
@article{LIU202365,
title = {Meta-HGT: Metapath-aware HyperGraph Transformer for heterogeneous information network embedding},
journal = {Neural Networks},
volume = {157},
pages = {65-76},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003288},
author = {Jie Liu and Lingyun Song and Guangtao Wang and Xuequn Shang},
keywords = {Heterogeneous information network, Hypergraph neural networks, Metapath, Node classification, Mutual attention},
abstract = {Heterogeneous information network embedding aims to learn low-dimensional node vectors in heterogeneous information networks (HINs), concerning not only structural information but also heterogeneity of diverse node and relation types. Most existing HIN embedding models mainly rely on metapath to define composite relations between node pairs and thus extract substructures from the original HIN. However, due to the pairwise structure of metapath, these models fail to capture the high-order relations (such as “Multiple authors co-authoring a paper”) implicitly contained in HINs. To tackle the limitation, this paper proposes a Metapath-aware HyperGraph Transformer (Meta-HGT) for node embedding in HINs. Meta-HGT first extends metapath to guide the high-order relation extraction from original HIN and constructs multiple metapath based hypergraphs with diverse composite semantics. Then, Meta-HGT learns the latent node and hyperedge embeddings in each metapath based hypergraph through Meta-HGT layers. Each layer consists of two types of components, i.e., intra-hyperedge aggregation and inter-hyperedge aggregation, in which a novel type-dependent attention mechanism is proposed for node and hyperedge feature aggregation. Finally, it fuses multiple node embeddings learned from different metapath based hypergraphs via a semantic attention layer and generates the final node embeddings. Extensive experiments have been conducted on three HIN benchmarks for node classification. The results demonstrate that Meta-HGT achieves state-of-the-art performance on all three datasets.}
}
@article{TAO20221,
title = {Brain-inspired chaotic backpropagation for MLP},
journal = {Neural Networks},
volume = {155},
pages = {1-13},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003045},
author = {Peng Tao and Jie Cheng and Luonan Chen},
keywords = {Error backpropagation, Chaotic neural network, Multilayer perception, Global optimization},
abstract = {Backpropagation (BP) algorithm is one of the most basic learning algorithms in deep learning. Although BP has been widely used, it still suffers from the problem of easily falling into the local minima due to its gradient dynamics. Inspired by the fact that the learning of real brains may exploit chaotic dynamics, we propose the chaotic backpropagation (CBP) algorithm by integrating the intrinsic chaos of real neurons into BP. By validating on multiple datasets (e.g. cifar10), we show that, for multilayer perception (MLP), CBP has significantly better abilities than those of BP and its variants in terms of optimization and generalization from both computational and theoretical viewpoints. Actually, CBP can be regarded as a general form of BP with global searching ability inspired by the chaotic learning process in the brain. Therefore, CBP not only has the potential of complementing or replacing BP in deep learning practice, but also provides a new way for understanding the learning process of the real brain.}
}
@article{LUO2023216,
title = {Adversarial style discrepancy minimization for unsupervised domain adaptation},
journal = {Neural Networks},
volume = {157},
pages = {216-225},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004099},
author = {Xin Luo and Wei Chen and Zhengfa Liang and Chen Li and Yusong Tan},
keywords = {Domain adaptation, Transfer learning},
abstract = {Mainstream unsupervised domain adaptation (UDA) methods align feature distributions across different domains via adversarial learning. However, most of them focus on global distribution alignment, ignoring the fine-grained domain discrepancy. Besides, they generally require auxiliary models, bringing extra computation costs. To tackle these issues, this study proposes an UDA method that differentiates individual samples without the help of extra models. To this end, we introduce a novel discrepancy metric, termed style discrepancy, to distinguish different target samples. We also propose a paradigm for adversarial style discrepancy minimization (ASDM). Specifically, we fix the parameters of the feature extractor and maximize style discrepancy to update the classifier, which helps detect more hard samples. Adversely, we fix the parameters of the classifier and minimize the style discrepancy to update the feature extractor, pushing those hard samples near the support of the source distribution. Such adversary helps to progressively detect and adapt more hard samples, leading to fine-grained domain adaptation. Experiments on different UDA tasks validate the effectiveness of ASDM. Overall, without any extra models, ASDM reaches a 46.9% mIoU in the GTA5 to Cityscapes benchmark and an 84.7% accuracy in the VisDA-2017 benchmark, outperforming many existing adversarial-learning-based methods.}
}
@article{ZHANG2023147,
title = {Maximum Decentral Projection Margin Classifier for High Dimension and Low Sample Size problems},
journal = {Neural Networks},
volume = {157},
pages = {147-159},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004130},
author = {Zhiwang Zhang and Jing He and Jie Cao and Shuqing Li},
keywords = {High dimension, Low sample size, Support vector classifier, Classification},
abstract = {Compared with relatively easy feature creation or generation in data analysis, manual data labeling needs a lot of time and effort in most cases. Even if automated data labeling​ seems to make it better in some cases, the labeling results still need to be checked and verified by manual. The High Dimension and Low Sample Size (HDLSS) data are therefore very common in data mining and machine learning. For classification problems with the HDLSS data, due to data piling and approximate equidistance between any two input points in high-dimension space, some traditional classifiers often give poor predictive performance. In this paper, we propose a Maximum Decentral Projection Margin Classifier (MDPMC) in the framework of a Support Vector Classifier (SVC). In the MDPMC model, the constraints of maximizing the projection distance between decentralized input points and their supporting hyperplane are integrated into the SVC model in addition to maximizing the margin of two supporting hyperplanes. On ten real HDLSS datasets, the experiment results show that the proposed MDPMC approach can deal well with data piling and approximate equidistance problems. Compared with SVC with Linear Kernel (SVC-LK) and Radial Basis Function Kernel (SVC-RBFK), Distance Weighted Discrimination (DWD), weighted DWD (wDWD), Distance-Weighted Support Vector Machine (DWSVM), Population-Guided Large Margin Classifier (PGLMC), and Data Maximum Dispersion Classifier (DMDC), MDPMC obtains better predictive accuracy and lower classification errors than the other seven classifiers on the HDLSS data.}
}
@article{LUO2022155,
title = {DualG-GAN, a Dual-channel Generator based Generative Adversarial Network for text-to-face synthesis},
journal = {Neural Networks},
volume = {155},
pages = {155-167},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003161},
author = {Xiaodong Luo and Xiaohai He and Xiang Chen and Linbo Qing and Jin Zhang},
keywords = {Conditional GAN, Face synthesis, Text-to-face synthesis, Text-to-image synthesis, DualG-GAN},
abstract = {Text-to-image synthesis is a fundamental and challenging task in computer vision, which aims to synthesize realistic images from given descriptions. Recently, text-to-image synthesis methods have achieved great improvements in the quality of synthesized images. However, very few works have explored its application in the scenario of face synthesis, which is of great potentials in face-related applications and the public safety domain. On the other side, the faces generated by existing methods are generally of poor quality and have low consistency to the given text. To tackle this issue, in this paper, we build a novel end-to-end dual-channel generator based generative adversarial network, named DualG-GAN, to improve the quality of the generated images and the consistency to the text description. In DualG-GAN, to improve the consistency between the synthesized image and the input description, a dual-channel generator block is introduced, and a novel loss is designed to improve the similarity between the generated image and the ground-truth in three different semantic levels. Extensive experiments demonstrate that DualG-GAN achieves state-of-the-art results on SCU-Text2face dataset. To further verify the performance of DualG-GAN, we compare it with the current optimal methods on text-to-image synthesis tasks, where quantitative and qualitative results show that the proposed DualG-GAN achieves optimal performance in both Fréchet inception distance (FID) and R-precision metrics. As only a few works are focusing on text-to-face synthesis, this work can be seen as a baseline for future research.}
}
@article{POYATOS202359,
title = {EvoPruneDeepTL: An evolutionary pruning model for transfer learning based deep neural networks},
journal = {Neural Networks},
volume = {158},
pages = {59-82},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004051},
author = {Javier Poyatos and Daniel Molina and Aritz D. Martinez and Javier {Del Ser} and Francisco Herrera},
keywords = {Deep learning, Evolutionary algorithms, Pruning, Feature selection, Transfer learning},
abstract = {In recent years, Deep Learning models have shown a great performance in complex optimization problems. They generally require large training datasets, which is a limitation in most practical cases. Transfer learning allows importing the first layers of a pre-trained architecture and connecting them to fully-connected layers to adapt them to a new problem. Consequently, the configuration of the these layers becomes crucial for the performance of the model. Unfortunately, the optimization of these models is usually a computationally demanding task. One strategy to optimize Deep Learning models is the pruning scheme. Pruning methods are focused on reducing the complexity of the network, assuming an expected performance penalty of the model once pruned. However, the pruning could potentially be used to improve the performance, using an optimization algorithm to identify and eventually remove unnecessary connections among neurons. This work proposes EvoPruneDeepTL, an evolutionary pruning model for Transfer Learning based Deep Neural Networks which replaces the last fully-connected layers with sparse layers optimized by a genetic algorithm. Depending on its solution encoding strategy, our proposed model can either perform optimized pruning or feature selection over the densely connected part of the neural network. We carry out different experiments with several datasets to assess the benefits of our proposal. Results show the contribution of EvoPruneDeepTL and feature selection to the overall computational efficiency of the network as a result of the optimization process. In particular, the accuracy is improved, reducing at the same time the number of active neurons in the final layers.}
}
@article{ALKHOURI2022168,
title = {A differentiable approach to the maximum independent set problem using dataless neural networks},
journal = {Neural Networks},
volume = {155},
pages = {168-176},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003082},
author = {Ismail R. Alkhouri and George K. Atia and Alvaro Velasquez},
keywords = {Combinatorial optimization, Maximum independent set problem, Maximum Clique problem, Dataless Neural Networks, Community detection},
abstract = {The success of machine learning solutions for reasoning about discrete structures has brought attention to its adoption within combinatorial optimization algorithms. Such approaches generally rely on supervised learning by leveraging datasets of the combinatorial structures of interest drawn from some distribution of problem instances. Reinforcement learning has also been employed to find such structures. In this paper, we propose a different approach in that no data is required for training the neural networks that produce the solution. In this sense, what we present is not a machine learning solution, but rather one that is dependent on neural networks and where backpropagation is applied to a loss function defined by the structure of the neural network architecture as opposed to a training dataset. In particular, we reduce the popular combinatorial optimization problem of finding a maximum independent set to a neural network and employ a dataless training scheme to refine the parameters of the network such that those parameters yield the structure of interest. Additionally, we propose a universal graph reduction procedure to handle large-scale graphs. The reduction exploits community detection for graph partitioning and is applicable to any graph type and/or density. Experimental results on both real and synthetic graphs demonstrate that our proposed method performs on par or outperforms state-of-the-art learning-based methods in terms of the size of the found set without requiring any training data.}
}
@article{WANG2023176,
title = {Pairwise learning problems with regularization networks and Nyström subsampling approach},
journal = {Neural Networks},
volume = {157},
pages = {176-192},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003914},
author = {Cheng Wang and Ting Hu and Siyang Jiang},
keywords = {Pairwise learning, Nyström sampling approach, Coefficient-based regularization, Kernel network, Convergence rate},
abstract = {Pairwise learning usually refers to the learning problem that works with pairs of training samples, such as ranking, similarity and metric learning, and AUC maximization. To overcome the challenge of pairwise learning in the large scale computation, this paper introduces Nyström sampling approach to the coefficient-based regularized pairwise algorithm in the context of kernel networks. Our theorems establish that the obtained Nyström estimator achieves the minimax error over all estimators using the whole data provided that the subsampling level is not too small. We derive the function relation between the subsampling level and regularization parameter that guarantees computation cost reduction and asymptotic behaviors’ optimality simultaneously. The Nyström coefficient-based pairwise learning method does not require the kernel to be symmetric or positive semi-definite, which provides more flexibility and adaptivity in the learning process. We apply the method to the bipartite ranking problem, which improves the state-of-the-art theoretical results in previous works. By developing probability inequalities for U-statistics on Hilbert–Schmidt operators, we provide new mathematical tools for handling pairs of examples involved in pairwise learning.}
}
@article{GOU2023364,
title = {Discriminative and Geometry-Preserving Adaptive Graph Embedding for dimensionality reduction},
journal = {Neural Networks},
volume = {157},
pages = {364-376},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004208},
author = {Jianping Gou and Xia Yuan and Ya Xue and Lan Du and Jiali Yu and Shuyin Xia and Yi Zhang},
keywords = {Dimensionality reduction, Graph embedding, Graph construction, Image classification},
abstract = {Learning graph embeddings for high-dimensional data is an important technology for dimensionality reduction. The learning process is expected to preserve the discriminative and geometric information of high-dimensional data in a new low-dimensional subspace via either manual or automatic graph construction. Although both manual and automatic graph constructions can capture the geometry and discrimination of data to a certain degree, they working alone cannot fully explore the underlying data structure. To learn and preserve more discriminative and geometric information of the high-dimensional data in the low-dimensional subspace as much as possible, we develop a novel Discriminative and Geometry-Preserving Adaptive Graph Embedding (DGPAGE). It systematically integrates manual and adaptive graph constructions in one unified graph embedding framework, which is able to effectively inject the essential information of data involved in predefined graphs into the learning of an adaptive graph, in order to achieve both adaptability and specificity of data. Learning the adaptive graph jointly with the optimized projections, DGPAGE can generate an embedded subspace that has better pattern discrimination for image classification. Results derived from extensive experiments on image data sets have shown that DGPAGE outperforms the state-of-the-art graph-based dimensionality reduction methods. The ablation studies show that it is beneficial to have an integrated framework, like DGPAGE, that brings together the advantages of manual/adaptive graph construction.}
}
@article{DONG202354,
title = {Practical synchronization of neural networks with delayed impulses and external disturbance via hybrid control},
journal = {Neural Networks},
volume = {157},
pages = {54-64},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003756},
author = {Shiyu Dong and Xinzhi Liu and Shouming Zhong and Kaibo Shi and Hong Zhu},
keywords = {Neural networks, Practical synchronization, Hybrid-driven impulsive control, Delayed impulses, External disturbance},
abstract = {This paper studies the problem of practical synchronization for delayed neural networks via hybrid-driven impulsive control in which delayed impulses and external disturbance are taken into account. Firstly, a switching method which establishes the relationship between error signals and a threshold function is introduced, which determines whether time-driven control or event-driven control is activated. Secondly, the effects of delayed impulses and external disturbance on impulsive systems are considered, and the corresponding comparison lemma is proposed. Thirdly, whenever the norm of the initial value of the error system state is less than or greater than the initial value of the threshold function, under the proposed hybrid-driven impulsive control scheme, the practical synchronization of the delayed neural networks with delayed impulses and external disturbance can be achieved by synchronizing impulses. Moreover, the Zeno behavior can be excluded under the proposed hybrid-driven impulsive control. Finally, two numerical examples are presented to verify the effectiveness of the theoretical results.}
}
@article{QIU2022369,
title = {Imbalanced low-rank tensor completion via latent matrix factorization},
journal = {Neural Networks},
volume = {155},
pages = {369-382},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003239},
author = {Yuning Qiu and Guoxu Zhou and Junhua Zeng and Qibin Zhao and Shengli Xie},
keywords = {Tensor analysis, Tensor completion, Tensor ring decomposition, Low-rank tensor recovery, Image/video inpainting},
abstract = {Tensor completion has been widely used in computer vision and machine learning. Most existing tensor completion methods empirically assume the intrinsic tensor is simultaneous low-rank in all over modes. However, tensor data recorded from real-world applications may conflict with these assumptions, e.g., face images taken from different subjects often lie in a union of low-rank subspaces, which may result in a quite high rank or even full rank structure in its sample mode. To this aim, in this paper, we propose an imbalanced low-rank tensor completion method, which can flexibly estimate the low-rank incomplete tensor via decomposing it into a mixture of multiple latent tensor ring (TR) rank components. Specifically, each latent component is approximated using low-rank matrix factorization based on TR unfolding matrix. In addition, an effective proximal alternating minimization algorithm is developed and theoretically proved to maintain the global convergence property, that is, the whole sequence of iterates is convergent and converges to a critical point. Extensive experiments on both synthetic and real-world tensor data demonstrate that the proposed method achieves more favorable completion results with less computational cost when compared to the state-of-the-art tensor completion methods.}
}
@article{ZHANG20221,
title = {A leader-following paradigm based deep reinforcement learning method for multi-agent cooperation games},
journal = {Neural Networks},
volume = {156},
pages = {1-12},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200346X},
author = {Feiye Zhang and Qingyu Yang and Dou An},
keywords = {Multi-agent systems, Deep reinforcement learning, Centralized training with decentralized execution, Cooperative games},
abstract = {Multi-agent deep reinforcement learning algorithms with centralized training with decentralized execution (CTDE) paradigm has attracted growing attention in both industry and research community. However, the existing CTDE methods follow the action selection paradigm that all agents choose actions at the same time, which ignores the heterogeneous roles of different agents. Motivated by the human wisdom in cooperative behaviors, we present a novel leader-following paradigm based deep multi-agent cooperation method (LFMCO) for multi-agent cooperative games. Specifically, we define a leader as someone who broadcasts a message representing the selected action to all subordinates. After that, the followers choose their individual action based on the received message from the leader. To measure the influence of leader’s action on followers, we introduced a concept of information gain, i.e., the change of followers’ value function entropy, which is positively correlated with the influence of leader’s action. We evaluate the LFMCO on several cooperation scenarios of StarCraft2. Simulation results confirm the significant performance improvements of LFMCO compared with four state-of-the-art benchmarks on the challenging cooperative environment.}
}
@article{KIRTAS2022561,
title = {Quantization-aware training for low precision photonic neural networks},
journal = {Neural Networks},
volume = {155},
pages = {561-573},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003598},
author = {M. Kirtas and A. Oikonomou and N. Passalis and G. Mourgias-Alexandris and M. Moralis-Pegios and N. Pleros and A. Tefas},
keywords = {Photonic deep learning, Neural network quantization, Constrained-aware training},
abstract = {Recent advances in Deep Learning (DL) fueled the interest in developing neuromorphic hardware accelerators that can improve the computational speed and energy efficiency of existing accelerators. Among the most promising research directions towards this is photonic neuromorphic architectures, which can achieve femtojoule per MAC efficiencies. Despite the benefits that arise from the use of neuromorphic architectures, a significant bottleneck is the use of expensive high-speed and precision analog-to-digital (ADCs) and digital-to-analog conversion modules (DACs) required to transfer the electrical signals, originating from the various Artificial Neural Networks (ANNs) operations (inputs, weights, etc.) in the photonic optical engines. The main contribution of this paper is to study quantization phenomena in photonic models, induced by DACs/ADCs, as an additional noise/uncertainty source and to provide a photonics-compliant framework for training photonic DL models with limited precision, allowing for reducing the need for expensive high precision DACs/ADCs. The effectiveness of the proposed method is demonstrated using different architectures, ranging from fully connected and convolutional networks to recurrent architectures, following recent advances in photonic DL.}
}
@article{MOOSAEI2023125,
title = {Inverse free reduced universum twin support vector machine for imbalanced data classification},
journal = {Neural Networks},
volume = {157},
pages = {125-135},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003872},
author = {Hossein Moosaei and M.A. Ganaie and Milan Hladík and M. Tanveer},
keywords = {Universum, Class-imbalanced, Twin support vector machine, Universum twin support vector machine, Rectangular kernel, Reduced universum twin support vector machine},
abstract = {Imbalanced datasets are prominent in real-world problems. In such problems, the data samples in one class are significantly higher than in the other classes, even though the other classes might be more important. The standard classification algorithms may classify all the data into the majority class, and this is a significant drawback of most standard learning algorithms, so imbalanced datasets need to be handled carefully. One of the traditional algorithms, twin support vector machines (TSVM), performed well on balanced data classification but poorly on imbalanced datasets classification. In order to improve the TSVM algorithm’s classification ability for imbalanced datasets, recently, driven by the universum twin support vector machine (UTSVM), a reduced universum twin support vector machine for class imbalance learning (RUTSVM) was proposed. The dual problem and finding classifiers involve matrix inverse computation, which is one of RUTSVM’s key drawbacks. In this paper, we improve the RUTSVM and propose an improved reduced universum twin support vector machine for class imbalance learning (IRUTSVM). We offer alternative Lagrangian functions to tackle the primal problems of RUTSVM in the suggested IRUTSVM approach by inserting one of the terms in the objective function into the constraints. As a result, we obtain new dual formulation for each optimization problem so that we need not compute inverse matrices neither in the training process nor in finding the classifiers. Moreover, the smaller size of the rectangular kernel matrices is used to reduce the computational time. Extensive testing is carried out on a variety of synthetic and real-world imbalanced datasets, and the findings show that the IRUTSVM algorithm outperforms the TSVM, UTSVM, and RUTSVM algorithms in terms of generalization performance.}
}
@article{ASLAN2022461,
title = {HVIOnet: A deep learning based hybrid visual–inertial odometry approach for unmanned aerial system position estimation},
journal = {Neural Networks},
volume = {155},
pages = {461-474},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003355},
author = {Muhammet Fatih Aslan and Akif Durdu and Abdullah Yusefi and Alper Yilmaz},
keywords = {BiLSTM, IMU, RNN, ROS, UAS, VIO},
abstract = {Sensor fusion is used to solve the localization problem in autonomous mobile robotics applications by integrating complementary data acquired from various sensors. In this study, we adopt Visual–Inertial Odometry (VIO), a low-cost sensor fusion method that integrates inertial data with images using a Deep Learning (DL) framework to predict the position of an Unmanned Aerial System (UAS). The developed system has three steps. The first step extracts features from images acquired from a platform camera and uses a Convolutional Neural Network (CNN) to project them to a visual feature manifold. Next, temporal features are extracted from the Inertial Measurement Unit (IMU) data on the platform using a Bidirectional Long Short Term Memory (BiLSTM) network and are projected to an inertial feature manifold. The final step estimates the UAS position by fusing the visual and inertial feature manifolds via a BiLSTM-based architecture. The proposed approach is tested with the public EuRoC (European Robotics Challenge) dataset and simulation environment data generated within the Robot Operating System (ROS). The result of the EuRoC dataset shows that the proposed approach achieves successful position estimations comparable to previous popular VIO methods. In addition, as a result of the experiment with the simulation dataset, the UAS position is successfully estimated with 0.167 Mean Square Error (RMSE). The obtained results prove that the proposed deep architecture is useful for UAS position estimation.}
}
@article{ZHAO202284,
title = {Joint clothes image detection and search via anchor free framework},
journal = {Neural Networks},
volume = {155},
pages = {84-94},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003112},
author = {Mingbo Zhao and Shanchuan Gao and Jianghong Ma and Zhao Zhang},
keywords = {Fashion analysis, End-to-end learning, Clothes image search, Anchor-based and anchor-free detectors},
abstract = {Clothes image search is an important learning task in fashion analysis to find the most relevant clothes in a database given a user-provided query. To address this problem, most existing methods employ a two-step approach, i.e., first detect the target clothes, and then crop it to feed the model for similarity learning. But the two-step approach is time-consuming and resource-intensive. On the other hand, one-step methods provide efficient solutions to integrate clothes detection and search in a unified framework. However, since one-step methods usually explore anchor-based detectors, they inevitably inherit limitations, such as high computational complexity caused by dense anchors, and high sensitivity to hyperparameters. To address the aforementioned issues, we propose an anchor-free framework for joint clothes detection and search. Specifically, we first choose an anchor-free detector as backbone. We then add a mask prediction branch and a Re-ID embedding branch to the framework. The mask prediction branch aims to predict the masks of clothes, while Re-ID embedding branch aims to extract the rich embedding features of clothes, in which we aggregate the feature of clothes via a mask pooling module by referencing the estimated target clothes masks. In this way, the extracted target clothes features can grasp more information in the area of the clothes mask; finally, we further introduce a match loss to fine-tune the embedding feature in Re-ID branch for improving the retrieval performance. Simulation results based on real datasets demonstrate the effectiveness of the proposed work.}
}
@article{ALAMIA2023280,
title = {On the role of feedback in image recognition under noise and adversarial attacks: A predictive coding perspective},
journal = {Neural Networks},
volume = {157},
pages = {280-287},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004166},
author = {Andrea Alamia and Milad Mozafari and Bhavin Choksi and Rufin VanRullen},
keywords = {Predictive coding, Deep learning, Feedback, Corruption robustness},
abstract = {Brain-inspired machine learning is gaining increasing consideration, particularly in computer vision. Several studies investigated the inclusion of top-down feedback connections in convolutional networks; however, it remains unclear how and when these connections are functionally helpful. Here we address this question in the context of object recognition under noisy conditions. We consider deep convolutional networks (CNNs) as models of feed-forward visual processing and implement Predictive Coding (PC) dynamics through feedback connections (predictive feedback) trained for reconstruction or classification of clean images. First, we show that the accuracy of the network implementing PC dynamics is significantly larger compared to its equivalent forward network. Importantly, to directly assess the computational role of predictive feedback in various experimental situations, we optimize and interpret the hyper-parameters controlling the network’s recurrent dynamics. That is, we let the optimization process determine whether top-down connections and predictive coding dynamics are functionally beneficial. Across different model depths and architectures (3-layer CNN, ResNet18, and EfficientNetB0) and against various types of noise (CIFAR100-C), we find that the network increasingly relies on top-down predictions as the noise level increases; in deeper networks, this effect is most prominent at lower layers. All in all, our results provide novel insights relevant to Neuroscience by confirming the computational role of feedback connections in sensory systems, and to Machine Learning by revealing how these can improve the robustness of current vision models.}
}
@article{JIANG202399,
title = {Characterizing functional brain networks via Spatio-Temporal Attention 4D Convolutional Neural Networks (STA-4DCNNs)},
journal = {Neural Networks},
volume = {158},
pages = {99-110},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004440},
author = {Xi Jiang and Jiadong Yan and Yu Zhao and Mingxin Jiang and Yuzhong Chen and Jingchao Zhou and Zhenxiang Xiao and Zifan Wang and Rong Zhang and Benjamin Becker and Dajiang Zhu and Keith M. Kendrick and Tianming Liu},
keywords = {Four-Dimensional Convolutional Neural Network, Functional brain network, Functional MRI, Individualized, Spatio-temporal pattern},
abstract = {Characterizing individualized spatio-temporal patterns of functional brain networks (FBNs) via functional magnetic resonance imaging (fMRI) provides a foundation for understanding complex brain function. Although previous studies have achieved promising performances based on either shallow or deep learning models, there is still much space to improve the accuracy of spatio-temporal pattern characterization of FBNs by optimally integrating the four-dimensional (4D) features of fMRI. In this study, we introduce a novel Spatio-Temporal Attention 4D Convolutional Neural Network (STA-4DCNN) model to characterize individualized spatio-temporal patterns of FBNs. Particularly, STA-4DCNN is composed of two subnetworks, in which the first Spatial Attention 4D CNN (SA-4DCNN) models the spatio-temporal features of 4D fMRI data and then characterizes the spatial pattern of FBNs, and the second Temporal Guided Attention Network (T-GANet) further characterizes the temporal pattern of FBNs under the guidance of the spatial pattern together with 4D fMRI data. We evaluate the proposed STA-4DCNN on seven different task fMRI and one resting state fMRI datasets from the publicly released Human Connectome Project. The experimental results demonstrate that STA-4DCNN has superior ability and generalizability in characterizing individualized spatio-temporal patterns of FBNs when compared to other state-of-the-art models. We further apply STA-4DCNN on another independent ABIDE I resting state fMRI dataset including both autism spectrum disorder (ASD) and typical developing (TD) subjects, and successfully identify abnormal spatio-temporal patterns of FBNs in ASD compared to TD. In general, STA-4DCNN provides a powerful tool for FBN characterization and for clinical applications on brain disease characterization at the individual level.}
}
@article{NAGAR2022398,
title = {A novel data-driven visualization of n-dimensional feasible region using interpretable self-organizing maps (iSOM)},
journal = {Neural Networks},
volume = {155},
pages = {398-412},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003197},
author = {Deepak Nagar and Kiran Pannerselvam and Palaniappan Ramu},
keywords = {Self-organizing maps, Graphical optimization, Decision processes, Machine learning, Unsupervised learning},
abstract = {Graphical optimization allows solving one or two dimensional optimization problems visually by merely plotting the objective function and constraint function contours. In addition to the discovery of optima, such a visualization-based approach enables understanding and interpretation of design variable and objective behavior with respect to feasibility and optimality, permitting intuitive decision making for designers. However, visualization of optimization problems in higher dimensions is challenging, though it is desirable. Interpretable self-organizing map (iSOM) is an artificial neural network that enables visualization of many dimensions via two-dimensional representations. We introduce iSOM to solve multidimensional optimization problems graphically. In the current work, a novel graphical representation of the n-dimensional feasible region, called B-matrix is constructed using iSOM. B-matrix is used to represent feasible range of design variables and objective function on separate plots. Consequently, dimension-wise shrinkage in the search space is also obtained. The proposed approach is demonstrated on various benchmark analytical examples and engineering examples with dimensions ranging from 2 to 30.}
}
@article{YANG2022592,
title = {Neurodynamic approaches for sparse recovery problem with linear inequality constraints},
journal = {Neural Networks},
volume = {155},
pages = {592-601},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003471},
author = {Jiao Yang and Xing He and Tingwen Huang},
keywords = {-minimization problem, Neurodynamic approaches, Global convergence, Sparse signal recovery},
abstract = {This paper develops two neurodynamic approaches for solving the L1-minimization problem with the linear inequality constraints. First, a centralized neurodynamic approach is proposed based on projection operator and nonnegative quadrant. The stability and global convergence of the centralized neurodynamic approach are analyzed by the Lyapunov method in detail. Considering that the distributed optimization problem has the advantages of information protection and scalability, the L1-minimization problem with linear inequality constraints is transformed into a distributed sparse optimization problem under mild conditions. Then, using the centralized neurodynamic approach and multi-agent consensus theory, a distributed neurodynamic approach is proposed for the distributed optimization problem. Furthermore, relevant theories show that each agent globally converges to an optimal solution of the distributed optimization problem. Finally, the presented centralized neurodynamic approach is applied to sparse recovery problem with L∞-norm noise constraints and the effectiveness of distributed approach is shown by several experiments on sparse signal recovery.}
}
@article{YU202228,
title = {Fast 2-step regularization on style optimization for real face morphing},
journal = {Neural Networks},
volume = {155},
pages = {28-38},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003070},
author = {Cheng Yu and Wenmin Wang and Honglei Li and Roberto Bugiolacchi},
keywords = {Real face morphing (RFM), StyleGAN, GAN inversion, Interpretable direction},
abstract = {StyleGAN is now capable of achieving excellent results, especially high-quality face synthesis. Recently, some studies have tried to invert real face images into style latent space via StyleGAN. However, morphing real faces via latent representation is still in its infancy. Training costs are high and/or require huge samples with labels. By adding regularization to style optimization, we propose a novel method to morph real faces based on StyleGAN. To do the supervised task, we label latent vectors via synthesized faces and release the label set; then we utilize logistic regression to fast discover interpretable directions in latent space. Appropriate regularization helps us to optimize both latent vectors (faces and directions). Moreover, we use learned directions under different layer representations to handle real face morphing. Compared to the existing methods, our method faster yields a larger diverse and realistic output. Code and cases are available at https://github.com/disanda/RFM.}
}
@article{SEMENOGLOU202339,
title = {Image-based time series forecasting: A deep convolutional neural network approach},
journal = {Neural Networks},
volume = {157},
pages = {39-53},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003902},
author = {Artemios-Anargyros Semenoglou and Evangelos Spiliotis and Vassilios Assimakopoulos},
keywords = {Time series, Forecasting, Images, Deep Learning, Convolutional Neural Networks, M competitions},
abstract = {Inspired by the successful use of deep learning in computer vision, in this paper we introduce ForCNN, a novel deep learning method for univariate time series forecasting that mixes convolutional and dense layers in a single neural network. Instead of using conventional, numeric representations of time series data as input to the network, the proposed method considers visual representations of it in the form of images to directly produce point forecasts. Three variants of deep convolutional neural networks are examined to process the images, the first based on VGG-19, the second on ResNet-50, while the third on a self-designed architecture. The performance of the proposed approach is evaluated using time series of the M3 and M4 forecasting competitions. Our results suggest that image-based time series forecasting methods can outperform both standard and state-of-the-art forecasting models.}
}
@article{CHEN2022258,
title = {Event-triggered H∞ consensus for uncertain nonlinear systems using integral sliding mode based adaptive dynamic programming},
journal = {Neural Networks},
volume = {156},
pages = {258-270},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003744},
author = {Zitao Chen and Kairui Chen and Si-Zhe Chen and Yun Zhang},
keywords = {Multi-agent systems, Adaptive dynamic programming, Event-triggered control,  control, Concurrent learning},
abstract = {This paper studies a robust optimal consensus problem for uncertain nonlinear multi-agent systems, where the uncertainties include both input and external disturbances. Adaptive distributed observer, integral sliding mode control and H∞ adaptive dynamic programming are integrated to obtain a sub-optimal control protocol for each follower. Firstly, an adaptive distributed observer is designed for state estimation of the leader, which serves as the reference of the ADP algorithm. Then, an H∞ ADP algorithm is presented to make each follower track the reference in real-time. An integral sliding manifold-based discontinuous control is designed to eliminate the matched uncertainty, and continuous control is obtained by solving the Hamilton–Jacobi–Isaac equation under the H∞ tracking framework. Two event-triggered rules are developed to relieve the communication pressure. For simplicity, a critic-only structure is used to numerically implement the proposed algorithm, and a concurrent learning technique is employed to update weights of neural networks. All signals in the closed-loop system are proven to be uniformly ultimately bounded. Finally, a simulation is conducted to demonstrate demonstrates the effectiveness of the method.}
}
@article{FAYDASICOK2022330,
title = {A novel Lyapunov stability analysis of neutral-type Cohen–Grossberg neural networks with multiple delays},
journal = {Neural Networks},
volume = {155},
pages = {330-339},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003227},
author = {Ozlem Faydasicok and Sabri Arik},
keywords = {Lyapunov stability theory, Cohen–Grossberg neural systems, Matrix theory, Neutral systems},
abstract = {The major target of this research article is to conduct a new Lyapunov stability analysis of a special model of Cohen–Grossberg neural networks that include multiple delay terms in state variables of systems neurons and multiple delay terms in time derivatives of state variables of systems neurons in the network structure. Employing some proper linear combinations of three different positive definite and positive semi-definite Lyapunov functionals, we obtain some novel sufficient criteria that guarantee global asymptotic stability of this type of multiple delayed Cohen–Grossberg type neural systems. These newly derived stability results are determined to be completely independent of the involved time delay terms and neutral delay terms, and they are totally characterized by the values of the interconnection parameters of Cohen–Grossberg neural system. Besides, the validation of the obtained stability criteria can be justified by applying some simple appropriate algebraic equations that form some particular relations among the constant system elements of the considered neutral neural systems. A useful and instructive numerical example is analysed to exhibit some major advantages and novelties of these newly proposed global stability results in this paper over some previously reported corresponding asymptotic stability conditions.}
}
@article{WU202249,
title = {MG-CNN: A deep CNN to predict saddle points of matrix games},
journal = {Neural Networks},
volume = {156},
pages = {49-57},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003586},
author = {Dawen Wu and Abdel Lisser},
keywords = {convolutional neural network, Saddle point, Matrix game},
abstract = {Finding the saddle point of a matrix game is a classical problem that arises in various fields, e.g., economics, computer science, and engineering. The standard problem-solving methods consist of formulating the problem as a linear program (LP). However, this approach seems less efficient when many instances need to be solved. In this paper, we propose a Convolutional Neural Network based approach, which is able to predict both the strategy profile (x,y) and the optimal value v of the game. We call this approach Matrix Game-Conventional Neural Network or MG-CNN for short. Thanks to a global pooling technique, MG-CNN can solve matrix games with different shapes. We propose a specialized algorithm to train MG-CNN, which includes both data generation and model training. Our numerical experiments show that MG-CNN outperforms standard LP solvers in terms of computational CPU time and provides a high-quality prediction.}
}
@article{BAI2022144,
title = {Structure enhanced deep clustering network via a weighted neighbourhood auto-encoder},
journal = {Neural Networks},
volume = {155},
pages = {144-154},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003069},
author = {Ruina Bai and Ruizhang Huang and Luyi Zheng and Yanping Chen and Yongbin Qin},
keywords = {Structural deep clustering, Graph convolution network, Structure enhanced semantics, Joint supervision},
abstract = {Structural deep clustering involves the use of neural networks for fusing semantic and structural representations for clustering tasks, and it has been receiving increasing attention. In some pioneering works, auto-encoder (AE)-specific representations were integrated with a graph convolutional network (GCN)-specific representation by delivering semantic information to the GCN module layer-by-layer. Although promising performance has been achieved in various applications, we observed that a vital aspect was overlooked in these works: the structural information may vanish in the learning process because of the over-smoothing problem of the GCN module, leading to non-representative features and, thus, deteriorating clustering performance. In this study, we address this issue by proposing a structure enhanced deep clustering network. The GCN-specific structural data representation is enhanced and supervised by its structural information. Specifically, the GCN-specific structural data representation is strengthened during the learning process by combining it with a structure enhanced semantic (SES) representation. A novel structure enhanced AE, named the weighted neighbourhood AE (wNAE), is employed to learn the SES representation for each data sample. Finally, we design a joint supervision strategy to uniformly guide the simultaneous learning of the wNAE and GCN modules and the clustering assignment. Experimental results for different datasets empirically validate the importance of semantic and neighbour-wise structure learning.}
}
@article{YOSHIDA202377,
title = {Tropical support vector machines: Evaluations and extension to function spaces},
journal = {Neural Networks},
volume = {157},
pages = {77-89},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003860},
author = {Ruriko Yoshida and Misaki Takamori and Hideyuki Matsumoto and Keiji Miura},
keywords = {Extreme value statistics, Function spaces, Max-plus algebra, Supervised learning, Tropical geometry},
abstract = {Support Vector Machines (SVMs) are one of the most popular supervised learning models to classify using a hyperplane in an Euclidean space. Similar to SVMs, tropical SVMs classify data points using a tropical hyperplane under the tropical metric with the max-plus algebra. In this paper, first we show generalization error bounds of tropical SVMs over the tropical projective torus. While the generalization error bounds attained via Vapnik–Chervonenkis (VC) dimensions in a distribution-free manner still depend on the dimension, we also show numerically and theoretically by extreme value statistics that the tropical SVMs for classifying data points from two Gaussian distributions as well as empirical data sets of different neuron types are fairly robust against the curse of dimensionality. Extreme value statistics also underlie the anomalous scaling behaviors of the tropical distance between random vectors with additional noise dimensions. Finally, we define tropical SVMs over a function space with the tropical metric.}
}
@article{GAUTAM2022487,
title = {Tf-GCZSL: Task-free generalized continual zero-shot learning},
journal = {Neural Networks},
volume = {155},
pages = {487-497},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003343},
author = {Chandan Gautam and Sethupathy Parameswaran and Ashish Mishra and Suresh Sundaram},
keywords = {Zero-shot learning, Continual learning, Experience replay, Continual zero-shot learning, VAE},
abstract = {Learning continually from a stream of training data or tasks with an ability to learn the unseen classes using a zero-shot learning framework is gaining attention in the literature. It is referred to as continual zero-shot learning (CZSL). Existing CZSL requires clear task-boundary information during training which is not practically feasible. This paper proposes a task-free generalized CZSL (Tf-GCZSL) method with short-term/long-term memory to overcome the requirement of task-boundary in training. A variational autoencoder (VAE) handles the fundamental ZSL tasks. The short-term and long-term memory help to overcome the condition of the task boundary in the CZSL framework. Further, the proposed Tf-GCZSL method combines the concept of experience replay with dark knowledge distillation and regularization to overcome the catastrophic forgetting issues in a continual learning framework. Finally, the Tf-GCZSL uses a fully connected classifier developed using the synthetic features generated at the latent space of the VAE. The performance of the proposed Tf-GCZSL is evaluated in the existing task-agnostic prediction setting and the proposed task-free setting for the generalized CZSL over the five ZSL benchmark datasets. The results clearly indicate that the proposed Tf-GCZSL improves the prediction at least by 12%, 1%, 3%, 4%, and 3% over existing state-of-the-art and baseline methods for CUB, aPY, AWA1, AWA2, and SUN datasets, respectively in both settings (task-agnostic prediction and task-free learning). The source code is available at https://github.com/Chandan-IITI/Tf-GCZSL.}
}
@article{MIN2022439,
title = {Attentional feature pyramid network for small object detection},
journal = {Neural Networks},
volume = {155},
pages = {439-450},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200329X},
author = {Kyungseo Min and Gun-Hee Lee and Seong-Whan Lee},
keywords = {Object detection, Small object detection, Feature pyramid network, Attention mechanism},
abstract = {Recent state-of-the-art detectors generally exploit the Feature Pyramid Networks (FPN) due to its advantage of detecting objects at different scales. Despite significant advances in object detection owing to the design of feature pyramids, it is still challenging to detect small objects with low resolution and dense distribution in complex scenes. To address these problems, we propose Attentional Feature Pyramid Network, a new feature pyramid architecture named AFPN which consists of three components to enhance the small object detection ability, specifically: Dynamic Texture Attention, Foreground-Aware Co-Attention, and Detail Context Attention. First, Dynamic Texture Attention augments the texture features dynamically by filtering out redundant semantics to highlight small objects in lower layers and amplifying credible details to emphasize large objects in higher layers. Then, Foreground-Aware Co-Attention is explored to detect densely arranged small objects by enhancing the objects feature via foreground-correlated contexts and suppressing the background noise. Finally, to better capture the features of small objects, Detail Context Attention adaptively aggregates detail cues of RoI features with different scales for a more accurate feature representation. By substituting FPN with AFPN in Faster R-CNN, our method performs on par with the state-of-the-art performance on Tsinghua-Tencent 100K. Furthermore, we achieve highly competitive results on small category of both PASCAL VOC and MS COCO.}
}
@article{XIA2022204,
title = {Synergetic learning structure-based neuro-optimal fault tolerant control for unknown nonlinear systems},
journal = {Neural Networks},
volume = {155},
pages = {204-214},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003100},
author = {Hongbing Xia and Bo Zhao and Ping Guo},
keywords = {Synergetic learning, Adaptive dynamic programming, Fault tolerant control, Neural networks, Zero-sum games},
abstract = {In this paper, a synergetic learning structure-based neuro-optimal fault tolerant control (SLSNOFTC) method is proposed for unknown nonlinear continuous-time systems with actuator failures. Under the framework of the synergetic learning structure (SLS), the optimal control input and the actuator failure are viewed as two subsystems. Then, the fault tolerant control (FTC) problem can be regarded as a two-player zero-sum differential game according to the game theory. A radial basis function neural network-based identifier, which uses the measured input/output data, is constructed to identify the completely unknown system dynamics. To develop the SLSNOFTC method, the Hamilton–Jacobi–Isaacs equation is solved by an asymptotically stable critic neural network (ASCNN) which is composed of cooperative adaptive tuning laws. Besides, with the help of the Lyapunov stability analysis, the identification error, the weight error of ASCNN, and all signals of closed-loop system are guaranteed to be converged to zero asymptotically, rather than uniformly ultimately bounded. Numerical simulation examples further verify the effectiveness and reliability of the proposed method.}
}
@article{BAUMANN2023226,
title = {Gateway identity and spatial remapping in a combined grid and place cell attractor},
journal = {Neural Networks},
volume = {157},
pages = {226-239},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004154},
author = {Tristan Baumann and Hanspeter A. Mallot},
keywords = {Attractors, Remapping, Place cells, Grid cells, Path integration},
abstract = {The spatial specificities of hippocampal place cells, i.e., their firing fields, are subject to change if the rat enters a new compartment in the experimental maze. This effect is known as remapping. It cannot be explained from path integration (grid cell activity) and local sensory cues alone but requires additional knowledge of the different compartments in the form of context recognition at the gateways between them. Here we present a model for the hippocampal–entorhinal interplay in which the activity of place and grid cells follows a joint attractor dynamic. Place cells depend on the current grid cell activity but can also reset the grid cell activity in the remapping process. Remapping is triggered by the passage through a gateway. When this happens, a previously stored pattern of place cell activity associated with the gateway is reactivated from a “gateway database”. The joint attractor will then reinstate the grid cell pattern that was active when the gateway had first been learned and path integration can proceed from there. The model is tested with various mazes used in the experimental literature and reproduces the published results, and we make predictions for remapping in a new maze type. We propose the involvement of memory in the form of “gate cells” that drive the place cells and with them the joint hippocampal–entorhinal loop into the corresponding attractor whenever a compartment is entered.}
}
@article{YU202258,
title = {Not all edges are peers: Accurate structure-aware graph pooling networks},
journal = {Neural Networks},
volume = {156},
pages = {58-66},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003380},
author = {Hualei Yu and Jinliang Yuan and Yirong Yao and Chongjun Wang},
keywords = {Graph neural networks, Graph classification, Pooling operator},
abstract = {Graph Neural Networks (GNNs) have achieved state-of-the-art performance in graph-related tasks. For graph classification task, an elaborated pooling operator is vital for learning graph-level representations. Most pooling operators derived from existing GNNs generate a coarsen graph through ordering the nodes and selecting some top-ranked ones. However, these methods fail to explore the fundamental elements other than nodes in graphs, which may not efficiently utilize the structure information. Besides, all edges attached to the low-ranked nodes are discarded, which destroys graphs’ connectivity and loses information. Moreover, the selected nodes tend to concentrate on some substructures while overlooking information in others. To address these challenges, we propose a novel pooling operator called Accurate Structure-Aware Graph Pooling (ASPool), which can be integrated into various GNNs to learn graph-level representation. Specifically, ASPool adaptively retains a subset of edges to calibrate the graph structure and learns the abstracted representations, wherein all the edges are viewed as non-peers instead of simply connecting nodes. To preserve the graph’s connectivity, we further introduce the selection strategy considering both top-ranked nodes and dropped edges. Additionally, ASPool performs a two-stage calculation process to promise that the sampled nodes are distributed throughout the graph. Experiment results on 9 widely used benchmarks show that ASPool achieves superior performance over the state-of-the-art graph representation learning methods.}
}
@article{MAHAUR2023305,
title = {Improved Residual Network based on norm-preservation for visual recognition},
journal = {Neural Networks},
volume = {157},
pages = {305-322},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004191},
author = {Bharat Mahaur and K.K. Mishra and Navjot Singh},
keywords = {Deep learning, Convolutional neural networks, Residual Networks, Gradient flow, Norm preservation, Optimization stability},
abstract = {Residual Network (ResNet) achieves deeper and wider networks with high-performance gains, representing a powerful convolutional neural network architecture. In this paper, we propose architectural refinements to ResNet that address the information flow through several layers of the network, including the input stem, downsampling block, projection shortcut, and identity blocks. We will show that our collective refinements facilitate stable backpropagation by preserving the norm of the error gradient within the residual blocks, which can reduce the optimization difficulties of training very deep networks. Our proposed modifications enhance the learning dynamics, resulting in high accuracy and inference performance by enforcing norm-preservation throughout the network training. The effectiveness of our method is verified by extensive experimental results on five computer vision tasks, including image classification (ImageNet and CIFAR-100), video classification (Kinetics-400), multi-label image recognition (MS-COCO), object detection and semantic segmentation (PASCAL VOC). We also empirically show consistent improvements in generalization performance when applying our modifications over different networks to provide new insights and inspire new architectures. The source code is publicly available at: https://github.com/bharatmahaur/LeNo.}
}
@article{WANG2022179,
title = {Lag H∞ synchronization in coupled reaction–diffusion neural networks with multiple state or derivative couplings},
journal = {Neural Networks},
volume = {156},
pages = {179-192},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.030},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200380X},
author = {Lu Wang and Yougang Bian and Zhenyuan Guo and Manjiang Hu},
keywords = {Coupled reaction–diffusion neural networks, Lag  synchronization, Multiple derivative couplings, Multiple state couplings},
abstract = {This paper mainly attempts to discuss lag H∞ synchronization in multiple state or derivative coupled reaction–diffusion neural networks without and with parameter uncertainties. Firstly, we respectively propose two types of reaction–diffusion neural networks with multiple state and derivative couplings subject to parameter uncertainties. Secondly, by exploiting designed state feedback controllers, several criteria of the lag H∞ synchronization for these two networks are developed based on Lyapunov functional and inequality techniques. Thirdly, lag H∞ synchronization issues of these two networks are also coped with by virtue of devised adaptive control strategies. Finally, we provide two numerical examples to verify the obtained lag H∞ synchronization criteria.}
}
@article{WANG2023240,
title = {DAFA-BiLSTM: Deep Autoregression Feature Augmented Bidirectional LSTM network for time series prediction},
journal = {Neural Networks},
volume = {157},
pages = {240-256},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003938},
author = {Heshan Wang and Yiping Zhang and Jing Liang and Lili Liu},
keywords = {Time series prediction, Long short-term memory, Deep recurrent neural network, Feature augmented, Vector autoregression transformation},
abstract = {Time series forecasting models that use the past information of exogenous or endogenous sequences to forecast future series play an important role in the real world because most real-world time series datasets are rich in time-dependent information. Most conventional prediction models for time series datasets are time-consuming and fraught with complex limitations because they usually fail to adequately exploit the latent spatial dependence between pairs of variables. As a successful variant of recurrent neural networks, the long short-term memory network (LSTM) has been demonstrated to have stronger nonlinear dynamics to store sequential data than traditional machine learning models. Nevertheless, the common shallow LSTM architecture has limited capacity to fully extract the transient characteristics of long interval sequential datasets. In this study, a novel deep autoregression feature augmented bidirectional LSTM network (DAFA-BiLSTM) is proposed as a new deep BiLSTM architecture for time series prediction. Initially, the input vectors are fed into a vector autoregression (VA) transformation module to represent the time-delayed linear and nonlinear properties of the input signals in an unsupervised way. Then, the learned nonlinear combination vectors of VA are progressively fed into different layers of BiLSTM and the output of the previous BiLSTM module is also concatenated with the time-delayed linear vectors of the VA as an augmented feature to form new additional input signals for the next adjacent BiLSTM layer. Extensive real-world time series applications are addressed to demonstrate the superiority and robustness of the proposed DAFA-BiLSTM. Comparative experimental results and statistical analysis show that the proposed DAFA-BiLSTM has good adaptive performance as well as robustness even in noisy environment.}
}
@article{WU2023336,
title = {Event-triggered adaptive dynamic programming for decentralized tracking control of input constrained unknown nonlinear interconnected systems},
journal = {Neural Networks},
volume = {157},
pages = {336-349},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.025},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200421X},
author = {Qiuye Wu and Bo Zhao and Derong Liu and Marios M. Polycarpou},
keywords = {Adaptive dynamic programming, Event-triggered control, Decentralized tracking control, Input constraints, Experience replay, Neural networks},
abstract = {This paper addresses decentralized tracking control (DTC) problems for input constrained unknown nonlinear interconnected systems via event-triggered adaptive dynamic programming. To reconstruct the system dynamics, a neural-network-based local observer is established by using local input–output data and the desired trajectories of all other subsystems. By employing a nonquadratic value function, the DTC problem of the input constrained nonlinear interconnected system is transformed into an optimal control problem. By using the observer-critic architecture, the DTC policy is obtained by solving the local Hamilton–Jacobi–Bellman equation through the local critic neural network, whose weights are tuned by the experience replay technique to relax the persistence of excitation condition. Under the event-triggering mechanism, the DTC policy is updated at the event-triggering instants only. Then, the computational resource and the communication bandwidth are saved. The stability of the closed-loop system is guaranteed by implementing event-triggered DTC policy via Lyapunov’s direct method. Finally, simulation examples are provided to demonstrate the effectiveness of the proposed scheme.}
}
@article{SAEED2022193,
title = {One-shot many-to-many facial reenactment using Bi-Layer Graph Convolutional Networks},
journal = {Neural Networks},
volume = {156},
pages = {193-204},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003811},
author = {Uzair Saeed and Ammar Armghan and Wang Quanyu and Fayadh Alenezi and Sun Yue and Prayag Tiwari},
keywords = {Facial reenactment, CNN, BGCLN},
abstract = {Facial reenactment is aimed at animating a source face image into a new place using a driving facial picture. In a few shot scenarios, the present strategies are designed with one or more identities or identity-sustained suffering protection challenges. These current solutions are either developed with one or more identities in mind, or face identity protection issues in one or more shot situations. Multiple pictures from the same entity have been used in previous research to model facial reenactment. In contrast, this paper presents a novel model of one-shot many-to-many facial reenactments that uses only one facial image of a face. The proposed model produces a face that represents the objective representation of the same source identity. The proposed technique can simulate motion from a single image by decomposing an object into two layers. Using bi-layer with Convolutional Neural Network (CNN), we named our model Bi-Layer Graph Convolutional Layers (BGCLN) which utilized to create the latent vector’s optical flow representation. This yields the precise structure and shape of the optical stream. Comprehensive studies suggest that our technique can produce high-quality results and outperform most recent techniques in both qualitative and quantitative data comparisons. Our proposed system can perform facial reenactment at 15 fps, which is approximately real time. Our code is publicly available at https://github.com/usaeed786/BGCLN.}
}
@article{TIMILSINA2022205,
title = {Boundary heat diffusion classifier for a semi-supervised learning in a multilayer network embedding},
journal = {Neural Networks},
volume = {156},
pages = {205-217},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003896},
author = {Mohan Timilsina and Vít Nováček and Mathieu d’Aquin and Haixuan Yang},
keywords = {Multiplex network, Diffusion, Heat, Prediction, Label},
abstract = {The scarcity of high-quality annotations in many application scenarios has recently led to an increasing interest in devising learning techniques that combine unlabeled data with labeled data in a network. In this work, we focus on the label propagation problem in multilayer networks. Our approach is inspired by the heat diffusion model, which shows usefulness in machine learning problems such as classification and dimensionality reduction. We propose a novel boundary-based heat diffusion algorithm that guarantees a closed-form solution with an efficient implementation. We experimentally validated our method on synthetic networks and five real-world multilayer network datasets representing scientific coauthorship, spreading drug adoption among physicians, two bibliographic networks, and a movie network. The results demonstrate the benefits of the proposed algorithm, where our boundary-based heat diffusion dominates the performance of the state-of-the-art methods.}
}
@article{ANTONOV2022512,
title = {Continuous learning of spiking networks trained with local rules},
journal = {Neural Networks},
volume = {155},
pages = {512-522},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003379},
author = {D.I. Antonov and K.V. Sviatov and S. Sukhov},
keywords = {Continual learning, Catastrophic forgetting, Spiking neural network, Spike-timing-dependent plasticity, Langevin dynamics},
abstract = {Artificial neural networks (ANNs) experience catastrophic forgetting (CF) during sequential learning. In contrast, the brain can learn continuously without any signs of catastrophic forgetting. Spiking neural networks (SNNs) are the next generation of ANNs with many features borrowed from biological neural networks. Thus, SNNs potentially promise better resilience to CF. In this paper, we study the susceptibility of SNNs to CF and test several biologically inspired methods for mitigating catastrophic forgetting. SNNs are trained with biologically plausible local training rules based on spike-timing-dependent plasticity (STDP). Local training prohibits the direct use of CF prevention methods based on gradients of a global loss function. We developed and tested the method to determine the importance of synapses (weights) based on stochastic Langevin dynamics without the need for the gradients. Several other methods of catastrophic forgetting prevention adapted from analog neural networks were tested as well. The experiments were performed on freely available datasets in the SpykeTorch environment.}
}
@article{ZHAO2022271,
title = {Adaptive graph convolutional clustering network with optimal probabilistic graph},
journal = {Neural Networks},
volume = {156},
pages = {271-284},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003653},
author = {Jiayi Zhao and Jipeng Guo and Yanfeng Sun and Junbin Gao and Shaofan Wang and Baocai Yin},
keywords = {Deep clustering, Graph convolutional network, Adaptive graph structure learning, Self-supervised learning},
abstract = {The graph convolutional network (GCN)-based clustering approaches have achieved the impressive performance due to strong ability of exploiting the topological structure. The adjacency graph seriously affects the clustering performance, especially for non-graph data. Existing approaches usually conduct two independent steps, i.e., constructing a fixed graph structure and then graph embedding representation learning by GCN. However, the constructed graph structure may be unreliable one due to noisy data, resulting in sub-optimal graph embedding representation. In this paper, we propose an adaptive graph convolutional clustering network (AGCCN) to alternatively learn the similarity graph structure and node embedding representation in a unified framework. Our AGCCN learns the weighted adjacency graph adaptively from the node representations by solving the optimization problem of graph learning, in which adaptive and optimal neighbors for each sample are assigned with probabilistic way according to local connectivity. Then, the attribute feature extracted by parallel Auto-Encoder (AE) module is fused into the input of adaptive graph convolution module layer-by-layer to learn the comprehensive node embedding representation and strengthen its representation ability. This also skillfully alleviates the over-smoothing problem of GCN. To further improve the discriminant ability of node representation, a dual self-supervised clustering mechanism is designed to guide model optimization with pseudo-labels information. Extensive experimental results on various real-world datasets consistently show the superiority and effectiveness of the proposed deep graph clustering method.}
}
@article{LIU2022308,
title = {Multi-agent based optimal equilibrium selection with resilience constraints for traffic flow},
journal = {Neural Networks},
volume = {155},
pages = {308-317},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003136},
author = {Ping Liu and Iakov Korovin and Sergey Gorbachev and Nadezhda Gorbacheva and Jinde Cao},
keywords = {Flow network, Strong resilience, Distributed algorithm, Equilibrium selection, Multi-agent system},
abstract = {Traffic guidance and traffic control are effective means to alleviate traffic problems. Formulating effective traffic guidance measures can improve the utilization rate of road resources and optimize the performance of the entire traffic network. Assuming that the traffic coordinator can capture traffic flow information in real-time utilizing sensors installed on each road, we consider the strong resilience constraints to construct an optimal selection problem of balanced flow in the traffic network. Based on multi-agent modeling, each agent has access to the corresponding traffic information of each link. We design a distributed optimization algorithm to tackle this optimization problem. In addition to the inherent advantages of distributed multi-agent algorithms, the communication topology among the sensors is allowed to be time-varying, which is more consistent with reality. To prove the effectiveness of the proposed algorithm, we also give a numerical simulation in the multi-agent environment. It should be reiterated that the optimization problem studied in this paper mainly focuses on traffic managers’ perspectives. The goal of the studied optimization problem is to minimize the overall cost of the traffic network by adjusting the optimal equilibrium traffic flow. This study provides a reference for solving congestion optimization in today’s cities.}
}
@article{LEI2022475,
title = {Sequential multi-view subspace clustering},
journal = {Neural Networks},
volume = {155},
pages = {475-486},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003410},
author = {Fangyuan Lei and Qin Li},
keywords = {Multi-view subspace clustering, Matrix factorization, Weighted tensor schatten -norm, Adaptive loss},
abstract = {Self-representation based subspace learning has shown its effectiveness in many applications, but most existing methods do not consider the difference between different views. As a result, the learned self-representation matrix cannot well characterize the clustering structure. Moreover, some methods involve an undesired weighted vector of the tensor nuclear norm, which reduces the flexibility of the algorithm in practical applications. To handle these problems, we present a tensorized multi-view subspace clustering. Specifically, our method employs matrix factorization and decomposes the self-representation matrix to orthogonal projection matrix and affinity matrix. We also add ℓ1,2-norm regularization on affinity representation to characterize the cluster structure. Moreover, the proposed method uses weighted tensor Schatten p-norm to explore higher-order structure and complementary information embedded in multi-view data, which can allocate the ideal weight for each view automatically without additional weight and penalty parameters. We apply the adaptive loss function to the model to maintain the robustness to outliers and efficiently learn the data distribution. Extensive experimental results on different datasets reveal that our method is superior to other state-of-the-art multi-view subspace clustering methods.}
}
@article{HUANG2023437,
title = {Attention-enabled gated spiking neural P model for aspect-level sentiment classification},
journal = {Neural Networks},
volume = {157},
pages = {437-443},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004464},
author = {Yanping Huang and Hong Peng and Qian Liu and Qian Yang and Jun Wang and David Orellana-Martín and Mario J. Pérez-Jiménez},
keywords = {Sentiment classification, Nonlinear spiking neural P systems, Gated spiking neural P systems, Attention-enabled GSNP model, Attention mechanism},
abstract = {Gated spiking neural P (GSNP) model is a recently developed recurrent-like network, which is abstracted by nonlinear spiking mechanism of nonlinear spiking neural P systems. In this study, a modification of GSNP is combined with attention mechanism to develop a novel model for sentiment classification, called attention-enabled GSNP model or termed as AGSNP model. The AGSNP model has two channels that process content words and aspect item respectively, where two modified GSNPs are used to obtain dependencies between content words and between aspect words. Moreover, two attention components are used to establish semantic correlation between content words and aspect item. Comparative experiments on three real data sets and several baseline models are conducted to verify the effectiveness of the AGSNP model. The comparison results demonstrate that the AGSNP model is competent for aspect-level sentiment classification tasks.}
}
@article{LI2023387,
title = {Temperature guided network for 3D joint segmentation of the pancreas and tumors},
journal = {Neural Networks},
volume = {157},
pages = {387-403},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004221},
author = {Qi Li and Xiyu Liu and Yiming He and Dengwang Li and Jie Xue},
keywords = {Pancreatic tumor segmentation, Temperature guided, 3D joint segmentation},
abstract = {Accurate and automatic segmentation of pancreatic tumors and organs from medical images is important for clinical diagnoses and making treatment plans for patients with pancreatic cancer. Although deep learning methods have been widely adopted for this task, the segmentation accuracy, especially for pancreatic tumors, still needs to be further improved because (1) phenotypic differences, such as volumes, tend to make the models focus on pancreatic learning, resulting in insufficient tumor feature selection; (2) deep learning models may fall into local optima, leading to unsatisfactory segmentation results for tumors and pancreas. To alleviate the above issues, in this paper, we propose a 3D fully convolutional neural network with three temperature guided modules, namely, balance temperature loss, rigid temperature optimizer and soft temperature indictor, to realize joint segmentation of the pancreas and tumors. Specifically, balance temperature loss is designed to dynamically adjust the learning points between tumors and the pancreas to balance the selected features, and it is aimed at improving the accuracy of tumor segmentation without losing pancreas information. Rigid temperature optimizer is proposed to accept nonimproving moves probabilistically to adaptively avoid local optima. To further refine the segmentation results, we propose the soft temperature indictor to guide the network into a fine-tuning state automatically when the model tends to stability. Our experimental results are more accurate than the fourteen top-ranking methods in pancreas and tumors segmentation on the MSD pancreas dataset and six top-ranking methods in brain tumors segmentation. Ablation studies verify the effectiveness of the three temperature guided modules.}
}
@article{ZHANG2022383,
title = {Latent adversarial regularized autoencoder for high-dimensional probabilistic time series prediction},
journal = {Neural Networks},
volume = {155},
pages = {383-397},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003252},
author = {Jing Zhang and Qun Dai},
keywords = {Probabilistic prediction, High-dimensional time series, Generative adversarial network, Autoencoder},
abstract = {Many practical applications require probabilistic prediction of time series to model the distribution on future horizons. With ever-increasing dimensions, much effort has been invested into developing methods that often make an assumption about the independence between time series. Consequently, the probabilistic prediction in high-dimensional environments has become an essential topic with significant challenges. In this paper, we propose a novel probabilistic model called latent adversarial regularized autoencoder, abbreviated as TimeLAR, specifically for high-dimensional multivariate Time Series Prediction (TSP). It integrates the flexibility of Generative Adversarial Networks (GANs) and the capability of autoencoders in extracting higher-level non-linear features. Through flexible autoencoder mapping, TimeLAR learns cross-series relationships and encodes this global information into several latent variables. We design a modified Transformer for these latent variables to capture global temporal patterns and infer latent space prediction distributions, where only one step is required to output multi-step predictions. Furthermore, we employ the GAN to further refine the performance of latent space predictions, by using a discriminator to guide the training of the autoencoder and the Transformer in an adversarial process. Finally, complex distributions of multivariate time series data can be modeled by the non-linear decoder of the autoencoder. The effectiveness of TimeLAR is empirically underpinned by extensive experiments conducted on five real-world high-dimensional time series datasets in the fields of transportation, electricity, and web page views.}
}
@article{DYER2023160,
title = {Inferring the location of neurons within an artificial network from their activity},
journal = {Neural Networks},
volume = {157},
pages = {160-175},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004063},
author = {Alexander J. Dyer and Lewis D. Griffin},
keywords = {Artificial neural networks, Network inference, Supervised learning, Correlation},
abstract = {Inferring the connectivity of biological neural networks from neural activation data is an open problem. We propose that the analogous problem in artificial neural networks is more amenable to study and may illuminate the biological case. Here, we study the specific problem of assigning artificial neurons to locations in a network of known architecture, specifically the LeNet image classifier. We evaluate a supervised learning approach based on features derived from the eigenvectors of the activation correlation matrix. Experiments highlighted that for an image dataset to be effective for accurate localisation, it should fully activate the network and contain minimal confounding correlations. No single image dataset was found that resulted in perfect assignment, however perfect assignment was achieved using a concatenation of features from multiple image datasets.}
}
@article{TAN202258,
title = {Interpretable Artificial Intelligence through Locality Guided Neural Networks},
journal = {Neural Networks},
volume = {155},
pages = {58-73},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003094},
author = {Randy Tan and Lei Gao and Naimul Khan and Ling Guan},
keywords = {Convolutional Neural Network (CNN), Self-Organizing Map (SOM), Explainable Artificial Intelligence (XAI)},
abstract = {In current deep learning architectures, each of the deeper layers in networks tends to contain hundreds of unorganized neurons which makes it hard for humans to understand how they interact with each other. By organizing the neurons using correlation as the criteria, humans can observe how clusters of neighbouring neurons interact with each other. Research in Explainable Artificial Intelligence (XAI) aims to all alleviate the black-box nature of current AI methods and make them understandable by humans. In this paper, we extend our previous algorithm for XAI in deep learning, called Locality Guided Neural Network (LGNN). LGNN preserves locality between neighbouring neurons within each layer of a deep network during training. Motivated by Self-Organizing Maps (SOMs), the goal is to enforce a local topology on each layer of a deep network such that neighbouring neurons are highly correlated with each other. Our algorithm can be easily plugged into current state of the art Convolutional Neural Network (CNN) models to make the neighbouring neurons more correlated. A cluster of neighbouring neurons activating for a class makes the network both quantitatively and qualitatively more interpretable when visualized, as we show through our experiments. This paper focuses on image processing with CNNs, but can theoretically be applied to any type of deep learning architecture. In our experiments, we train VGG and WRN networks for image classification on CIFAR100 and Imagenette. Our experiments analyse different perceptible clusters of activations in response to different input classes.}
}
@article{YANG2023193,
title = {More refined superbag: Distantly supervised relation extraction with deep clustering},
journal = {Neural Networks},
volume = {157},
pages = {193-201},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003926},
author = {Suizhu Yang and Yanxia Liu and Yuantong Jiang and Zhiqiang Liu},
keywords = {Distant supervision, Superbag, Deep clustering},
abstract = {Distant supervision (DS) can automatically generate annotated data for relation extraction (RE) with knowledge bases and corpora. The existing DS methods that train on bags selected by attention mechanism are susceptible to noisy bags and neglect useful information in noisy bags. In this paper, we propose DCSR, a novel DS method which utilizes deep clustering to obtain refined superbag representations for solving the wrong labeling problem. we substitute deep clustering for selective attention to construct superbags, capturing helpful information between spatially-close bags, including noisy bags. Moreover, we implement data augmentation on the input sentences to handle the long-tail problem. Experiments on the NYT2010 and NYT-H datasets show that our method can effectively improve RE and significantly outperforms state-of-the-art methods.}
}
@article{VARADY2022574,
title = {Natural Reweighted Wake–Sleep},
journal = {Neural Networks},
volume = {155},
pages = {574-591},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003409},
author = {Csongor Várady and Riccardo Volpi and Luigi Malagò and Nihat Ay},
keywords = {Natural gradient, Helmholtz machine, Wake–Sleep, Information geometry},
abstract = {Helmholtz Machines (HMs) are a class of generative models composed of two Sigmoid Belief Networks (SBNs), acting respectively as an encoder and a decoder. These models are commonly trained using a two-step optimization algorithm called Wake–Sleep (WS) and more recently by improved versions, such as Reweighted Wake–Sleep (RWS) and Bidirectional Helmholtz Machines (BiHM). The locality of the connections in an SBN induces sparsity in the Fisher Information Matrices associated to the probabilistic models, in the form of a finely-grained block-diagonal structure. In this paper we exploit this property to efficiently train SBNs and HMs using the natural gradient. We present a novel algorithm, called Natural Reweighted Wake–Sleep (NRWS), that corresponds to the geometric adaptation of its standard version. In a similar manner, we also introduce Natural Bidirectional Helmholtz Machine (NBiHM). Differently from previous work, we will show how for HMs the natural gradient can be efficiently computed without the need of introducing any approximation in the structure of the Fisher information matrix. The experiments performed on standard datasets from the literature show a consistent improvement of NRWS and NBiHM not only with respect to their non-geometric baselines but also with respect to state-of-the-art training algorithms for HMs. The improvement is quantified both in terms of speed of convergence as well as value of the log-likelihood reached after training.}
}
@article{DING2022170,
title = {Shared subspace-based radial basis function neural network for identifying ncRNAs subcellular localization},
journal = {Neural Networks},
volume = {156},
pages = {170-178},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003768},
author = {Yijie Ding and Prayag Tiwari and Fei Guo and Quan Zou},
keywords = {Biological sequence classification, Shared subspace learning, Radial basis function neural networks, Multi-label classification},
abstract = {Non-coding RNAs (ncRNAs) play an important role in revealing the mechanism of human disease for anti-tumor and anti-virus substances. Detecting subcellular locations of ncRNAs is a necessary way to study ncRNA. Traditional biochemical methods are time-consuming and labor-intensive, and computational-based methods can help detect the location of ncRNAs on a large scale. However, many models did not consider the correlation information among multiple subcellular localizations of ncRNAs. This study proposes a radial basis function neural network based on shared subspace learning (RBFNN-SSL), which extract shared structures in multi-labels. To evaluate performance, our classifier is tested on three ncRNA datasets. Our model achieves better performance in experimental results.}
}
@article{WANG202274,
title = {Location-aware convolutional neural networks for graph classification},
journal = {Neural Networks},
volume = {155},
pages = {74-83},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003008},
author = {Zhaohui Wang and Qi Cao and Huawei Shen and Bingbing Xu and Keting Cen and Xueqi Cheng},
keywords = {Graph classification, Convolutional neural networks, Location-aware},
abstract = {Graph patterns play a critical role in various graph classification tasks, e.g., chemical patterns often determine the properties of molecular graphs. Researchers devote themselves to adapting Convolutional Neural Networks (CNNs) to graph classification due to their powerful capability in pattern learning. The varying numbers of neighbor nodes and the lack of canonical order of nodes on graphs pose challenges in constructing receptive fields for CNNs. Existing methods generally follow a heuristic ranking-based framework, which constructs receptive fields by selecting a fixed number of nodes and dropping the others according to predetermined rules. However, such methods may lose important structure information through dropping nodes, and they also cannot learn task-oriented graph patterns. In this paper, we propose a Location learning-based Convolutional Neural Networks (LCNN) for graph classification. LCNN constructs receptive fields by learning the location of each node according to its embedding that contains structures and features information, then standard CNNs are applied to capture graph patterns. Such a location learning mechanism not only retains the information of all nodes, but also provides the ability for task-oriented pattern learning. Experimental results show the effectiveness of the proposed LCNN, and visualization results further illustrate the valid pattern learning ability of our method for graph classification.}
}
@article{SILVETTI2023103,
title = {A Reinforcement Meta-Learning framework of executive function and information demand},
journal = {Neural Networks},
volume = {157},
pages = {103-113},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003884},
author = {Massimo Silvetti and Stefano Lasaponara and Nabil Daddaoua and Mattias Horan and Jacqueline Gottlieb},
keywords = {Information seeking, Effort, Meta Reinforcement Learning, Visual attention, MPFC, Free energy},
abstract = {Gathering information is crucial for maximizing fitness, but requires diverting resources from searching directly for primary rewards to actively exploring the environment. Optimal decision-making thus maximizes information while reducing effort costs, but little is known about the neuro-computational implementation of this tradeoff. We present a Reinforcement Meta-Learning (RML) computational model that solves the trade-off between the value and costs of gathering information. We implement the RML in a biologically plausible architecture that links catecholaminergic neuromodulators, the medial prefrontal cortex and topographically organized visual maps and show that it accounts for neural and behavioral findings on information demand motivated by instrumental incentives and intrinsic utility. Moreover, the utility function used by the RML, encoded by dopamine, is an approximation of variational free energy. Thus, the RML presents a biologically plausible mechanism for coordinating motivational, executive and sensory systems generate visual information gathering policies that minimize free energy.}
}
@article{MURALIDHARAN2023257,
title = {Improving malicious email detection through novel designated deep-learning architectures utilizing entire email},
journal = {Neural Networks},
volume = {157},
pages = {257-279},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003367},
author = {Trivikram Muralidharan and Nir Nissim},
keywords = {Malware, Phishing, Email, Detection, Deep learning, Analysis},
abstract = {In today’s email dependent world, cyber criminals often target organizations using a variety of social engineering techniques and specially crafted malicious emails. When successful, such attacks can result in significant harm to physical and digital systems and assets, the leakage of sensitive information, reputation damage, and financial loss. Despite the plethora of studies on the detection of phishing attacks and malicious links in emails, there are no solutions capable of effectively, quickly, and accurately coping with more complex email-based attacks, such as malicious email attachments. This paper presents the first fully automated malicious email detection framework using deep ensemble learning to analyze all email segments (body, header, and attachments); this eliminates the need for human expert intervention for feature engineering. In this paper, we also demonstrate how an ensemble framework of deep learning classifiers each of which are trained on specific portions of an email (thereby independently utilizing the entire email) can generalize better than popular email analysis methods that analyze just a specific portion of the email for analysis. The proposed framework is evaluated comprehensively and with an AUC of 0.993, the proposed framework’s results surpass state-of-the-art malicious email detection methods, including human expert feature-based machine learning models by a TPR of 5%.}
}
@article{ZHOU2023114,
title = {Robustness meets accuracy in adversarial training for graph autoencoder},
journal = {Neural Networks},
volume = {157},
pages = {114-124},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200404X},
author = {Xianchen Zhou and Kun Hu and Hongxia Wang},
keywords = {Graph embedding, Adversarial training, Graph autoencoder, Robustness},
abstract = {Graph autoencoder (GAE) is an effective deep method for graph embedding, while it is vulnerable to the graph adversarial attacks. Adversarial training, which generates adversarial examples in the adversarial scope(neighborhood of natural examples), is effective to improve the robustness of GAE. However, it may lead to degradation of natural accuracy (accuracy on natural examples) due to the extra training examples generated in the adversarial scope (the reasonable scope of adversarial examples). Therefore, considering robustness and natural accuracy is crucial to GAE. In this paper, an improved GAE model is formulated by combining the Structure and Feature encoders, and a novel Adversarial Training strategy (GAE-SFAT) is proposed based on improved GAE. GAE-SFAT has a smaller but more reasonable adversarial scope for adversarial training, which keeps the robustness and reduces the degradation of natural accuracy compared with ordinary adversarial training. In addition, a novel algorithm considering the robustness and accuracy is designed to optimize the GAE-SFAT. We conduct experiments both on the natural graphs as well as perturbed graphs for three datasets. The results show that GAE-SFAT can perform better than state of arts adversarial training model under different kinds of perturbations.}
}
@article{XU2022135,
title = {EEG decoding method based on multi-feature information fusion for spinal cord injury},
journal = {Neural Networks},
volume = {156},
pages = {135-151},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003641},
author = {Fangzhou Xu and Jincheng Li and Gege Dong and Jianfei Li and Xinyi Chen and Jianqun Zhu and Jinglu Hu and Yang Zhang and Shouwei Yue and Dong Wen and Jiancai Leng},
keywords = {Brain–computer interface, Electroencephalography, Motor imagery, Modified graph convolution neural network, Spinal cord injury},
abstract = {To develop an efficient brain–computer interface (BCI) system, electroencephalography (EEG) measures neuronal activities in different brain regions through electrodes. Many EEG-based motor imagery (MI) studies do not make full use of brain network topology. In this paper, a deep learning framework based on a modified graph convolution neural network (M-GCN) is proposed, in which temporal-frequency processing is performed on the data through modified S-transform (MST) to improve the decoding performance of original EEG signals in different types of MI recognition. MST can be matched with the spatial position relationship of the electrodes. This method fusions multiple features in the temporal-frequency-spatial domain to further improve the recognition performance. By detecting the brain function characteristics of each specific rhythm, EEG generated by imaginary movement can be effectively analyzed to obtain the subjects’ intention. Finally, the EEG signals of patients with spinal cord injury (SCI) are used to establish a correlation matrix containing EEG channel information, the M-GCN is employed to decode relation features. The proposed M-GCN framework has better performance than other existing methods. The accuracy of classifying and identifying MI tasks through the M-GCN method can reach 87.456%. After 10-fold cross-validation, the average accuracy rate is 87.442%, which verifies the reliability and stability of the proposed algorithm. Furthermore, the method provides effective rehabilitation training for patients with SCI to partially restore motor function.}
}
@article{XU2022215,
title = {An inertial neural network approach for loco-manipulation trajectory tracking of mobile robot with redundant manipulator},
journal = {Neural Networks},
volume = {155},
pages = {215-223},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003124},
author = {Chentao Xu and Miao Wang and Guoyi Chi and Qingshan Liu},
keywords = {Redundant manipulator, Trajectory tracking, Inertial neural network, Augmented Lagrange multiplier method, Constrained optimization},
abstract = {This paper proposes a novel constrained optimization model to address the loco-manipulation problem of mobile robot with redundant manipulator for trajectory tracking. To alleviate the accumulative error of the end-effector’s position, a new control law is designed to eliminate the negative effect from the deviation of the initial position, leading to better performance than existing ones. To deal with the locomotion constraints in the loco-manipulation problem, the optimization model is converted to an augmented Lagrangian primal–dual problem. Furthermore, an inertial neural network approach is used to solve the problem and the corresponding Lyapunov proof guarantees the convergence of variables. The numerical simulations show that the proposed approach is more suitable for application since the model is more effective and the algorithm has better convergence rate.}
}
@article{HUANG2023323,
title = {Stacked attention hourglass network based robust facial landmark detection},
journal = {Neural Networks},
volume = {157},
pages = {323-335},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004178},
author = {Ying Huang and He Huang},
keywords = {Facial landmark detection, Stacked hourglass network, Spatial attention residual, Channel attention branch, Robust loss function},
abstract = {Deep learning based facial landmark detection (FLD) has made rapid progress. However, the accuracy and robustness of FLD algorithms are degraded heavily when the face is subject to diverse expressions, posture deflection, partial occlusion and other uncertain circumstances. To learn more discriminative representations and reduce the negative effect caused by outliers, a stacked attention hourglass network (SAHN) is proposed for FLD, where new attention mechanism is introduced. Basically, in the design of SAHN, a spatial attention residual (SAR) unit is constructed such that relevant areas of facial landmarks are specially emphasized and essential features of different scales can be well extracted, and a channel attention branch (CAB) is introduced to better guide the next-level hourglass network for feature extraction. Due to the introduction of SAR and CAB, only two hourglass networks are stacked as the proposed SAHN with fewer parameters, which is different from traditional SHNs stacked by four hourglass networks. Furthermore, a variable robustness (VR) loss function is introduced for the training of SAHN. The robustness of the proposed model for FLD is guaranteed with the help of the VR loss by adaptively adjusting a continuous parameter. Extensive experimental results on three public datasets including 300W, WFLW and COFW confirm that our method is superior to some previous ones.}
}
@article{LEI202389,
title = {LAC-GAN: Lesion attention conditional GAN for Ultra-widefield image synthesis},
journal = {Neural Networks},
volume = {158},
pages = {89-98},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004452},
author = {Haijun Lei and Zhihui Tian and Hai Xie and Benjian Zhao and Xianlu Zeng and Jiuwen Cao and Weixin Liu and Jiantao Wang and Guoming Zhang and Shuqiang Wang and Baiying Lei},
keywords = {Ultra-widefield image, Disease detection, Conditional GAN, Lesion attention},
abstract = {Automatic detection of retinal diseases based on deep learning technology and Ultra-widefield (UWF) images plays an important role in clinical practices in recent years. However, due to small lesions and limited data samples, it is not easy to train a detection-accurate model with strong generalization ability. In this paper, we propose a lesion attention conditional generative adversarial network (LAC-GAN) to synthesize retinal images with realistic lesion details to improve the training of the disease detection model. Specifically, the generator takes the vessel mask and class label as the conditional inputs, and processes the random Gaussian noise by a series of residual block to generate the synthetic images. To focus on pathological information, we propose a lesion feature attention mechanism based on random forest (RF) method, which constructs its reverse activation network to activate the lesion features. For discriminator, a weight-sharing multi-discriminator is designed to improve the performance of model by affine transformations. Experimental results on multi-center UWF image datasets demonstrate that the proposed method can generate retinal images with reasonable details, which helps to enhance the performance of the disease detection model.}
}
@article{WANG2022413,
title = {Comprehensive analysis of fixed-time stability and energy cost for delay neural networks},
journal = {Neural Networks},
volume = {155},
pages = {413-421},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003240},
author = {Yuchun Wang and Song Zhu and Hu Shao and Yu Feng and Li Wang and Shiping Wen},
keywords = {Delay neural networks, Comprehensive analysis, Fixed-time stability, Energy cost},
abstract = {This paper focuses on comprehensive analysis of fixed-time stability and energy consumed by controller in nonlinear neural networks with time-varying delays. A sufficient condition is provided to assure fixed-time stability by developing a global composite switched controller and employing inequality techniques. Then the specific expression of the upper of energy required for achieving control is deduced. Moreover, the comprehensive analysis of the energy cost and fixed-time stability is investigated utilizing a dual-objective optimization function. It illustrates that adjusting the control parameters can make the system converge to the equilibrium point under better control state. Finally, one numerical example is presented to verify the effectiveness of the provided control scheme.}
}
@article{XIAO2023460,
title = {BASeg: Boundary aware semantic segmentation for autonomous driving},
journal = {Neural Networks},
volume = {157},
pages = {460-470},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004294},
author = {Xiaoyang Xiao and Yuqian Zhao and Fan Zhang and Biao Luo and Lingli Yu and Baifan Chen and Chunhua Yang},
keywords = {Semantic segmentation, Autonomous driving, Boundary information, Long-range context aggregation},
abstract = {Semantic segmentation is a critical component for street understanding task in autonomous driving field. Existing various methods either focus on constructing the object’s inner consistency by aggregating global or multi-scale context information, or simply combine semantic features with boundary features to refine object details. Despite impressive, most of them neglect the long-range dependences between the inner objects and boundaries. To this end, we present a Boundary Aware Network (BASeg) for semantic segmentation by exploiting boundary information as a significant cue to guide context aggregation. Specifically, a Boundary Refined Module (BRM) is proposed in the BASeg to refine coarse low-level boundary features from a Canny detector by high-level multi-scale semantic features from the backbone, and based on which, the Context Aggregation Module (CAM) is further proposed to capture long-range dependences between the boundary regions and the object inner pixels, achieving mutual gains and enhancing the intra-class consistency. Moreover, our method can be plugged into other CNN backbones for higher performance with a minor computation budget, and obtains 45.72%, 81.2%, and 77.3% of mIoU on the datasets ADE20K, Cityscapes, and CamVid, respectively. Compared with some state-of-the-art ResNet101-based segmentation methods, extensive experiments demonstrate the effectiveness of our method. Our code is available at https://github.com/Lature-Yang/BASeg.}
}
@article{WANG2022152,
title = {Neural network-based event-triggered data-driven control of disturbed nonlinear systems with quantized input},
journal = {Neural Networks},
volume = {156},
pages = {152-159},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003719},
author = {Xianming Wang and Hamid Reza Karimi and Mouquan Shen and Dan Liu and Li-Wei Li and Jiantao Shi},
keywords = {Event-triggered control, Neural network, Model-free adaptive control},
abstract = {This paper is devoted to design an event-triggered data-driven control for a class of disturbed nonlinear systems with quantized input. A uniform quantizer reconstructed with decreasing quantization intervals is employed to reduce the quantization error. A neural network-based estimation strategy is proposed to estimate both the pseudo partial derivative and disturbances. Consequently, an input triggering rule for single-input single-output systems is provided by incorporating the estimated disturbances, the quantization error bound and tracking errors. Resorting to the Lyapunov method, sufficient conditions for synthesized error systems to be uniformly ultimately bounded are presented. The validity of the proposed scheme is demonstrated via a simulation example.}
}
@article{FUKUMASU2022218,
title = {Extraction of bouton-like structures from neuropil calcium imaging data},
journal = {Neural Networks},
volume = {156},
pages = {218-238},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003835},
author = {Kazushi Fukumasu and Akinao Nose and Hiroshi Kohsaka},
keywords = {Neuropil, Calcium imaging, Patch-wise modularity, Pixel clustering, Simulated annealing, Scale-free networks},
abstract = {The neuropil, the plexus of axons and dendrites, plays a critical role in operating the circuit processing of the nervous system. Revealing the spatiotemporal activity pattern within the neuropil would clarify how the information flows throughout the nervous system. However, calcium imaging to examine the circuit dynamics has mainly focused on the soma population due to their discrete distribution. The development of a methodology to analyze the calcium imaging data of a densely packed neuropil would provide us with new insights into the circuit dynamics. Here, we propose a new method to decompose calcium imaging data of the neuropil into populations of bouton-like synaptic structures with a standard desktop computer. To extract bouton-like structures from calcium imaging data, we introduced a new type of modularity, a widely used quality measure in graph theory, and optimized the clustering configuration by a simulated annealing algorithm, which is established in statistical physics. To assess this method’s performance, we conducted calcium imaging of the neuropil of Drosophila larvae. Based on the obtained data, we established artificial neuropil imaging datasets. We applied the decomposition procedure to the artificial and experimental calcium imaging data and extracted individual bouton-like structures successfully. Based on the extracted spatiotemporal data, we analyzed the network structure of the central nervous system of fly larvae and found it was scale-free. These results demonstrate that neuropil calcium imaging and its decomposition could provide new insight into our understanding of neural processing.}
}
@article{DONG2022498,
title = {Support vector machine embedding discriminative dictionary pair learning for pattern classification},
journal = {Neural Networks},
volume = {155},
pages = {498-511},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003318},
author = {Jing Dong and Liu Yang and Chang Liu and Wei Cheng and Wenwu Wang},
keywords = {Discriminative dictionary learning, Pattern classification, Support vector machine, Sparse representation},
abstract = {Discriminative dictionary learning (DDL) aims to address pattern classification problems via learning dictionaries from training samples. Dictionary pair learning (DPL) based DDL has shown superiority as compared with most existing algorithms which only learn synthesis dictionaries or analysis dictionaries. However, in the original DPL algorithm, the discrimination capability is only promoted via the reconstruction error and the structures of the learned dictionaries, while the discrimination of coding coefficients is not considered in the process of dictionary learning. To address this issue, we propose a new DDL algorithm by introducing an additional discriminative term associated with coding coefficients. Specifically, a support vector machine (SVM) based term is employed to enhance the discrimination of coding coefficients. In this model, a structured dictionary pair and SVM classifiers are jointly learned, and an optimization method is developed to address the formulated optimization problem. A classification scheme based on both the reconstruction error and SVMs is also proposed. Simulation results on several widely used databases demonstrate that the proposed method can achieve competitive performance as compared with some state-of-the-art DDL algorithms.}
}
@article{LIN2023197,
title = {Accelerating reinforcement learning with case-based model-assisted experience augmentation for process control},
journal = {Neural Networks},
volume = {158},
pages = {197-215},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004129},
author = {Runze Lin and Junghui Chen and Lei Xie and Hongye Su},
keywords = {Reinforcement learning, Process control, Experience augmentation, Local dynamic model, Case-based reasoning},
abstract = {In the context of intelligent manufacturing in the process industry, traditional model-based optimization control methods cannot adapt to the situation of drastic changes in working conditions or operating modes. Reinforcement learning (RL) directly achieves the control objective by interacting with the environment, and has significant advantages in the presence of uncertainty since it does not require an explicit model of the operating plant. However, most RL algorithms fail to retain transfer learning capabilities in the presence of mode variation, which becomes a practical obstacle to industrial process control applications. To address these issues, we design a framework that uses local data augmentation to improve the training efficiency and transfer learning (adaptability) performance. Therefore, this paper proposes a novel RL control algorithm, CBR-MA-DDPG, organically integrating case-based reasoning (CBR), model-assisted (MA) experience augmentation, and deep deterministic policy gradient (DDPG). When the operating mode changes, CBR-MA-DDPG can quickly adapt to the varying environment and achieve the desired control performance within several training episodes. Experimental analyses on a continuous stirred tank reactor (CSTR) and an organic Rankine cycle (ORC) demonstrate the superiority of the proposed method in terms of both adaptability and control performance/robustness. The results show that the control performance of the CBR-MA-DDPG agent outperforms the conventional PI and MPC control schemes, and that it has higher training efficiency than the state-of-the-art DDPG, TD3, and PPO algorithms in transfer learning scenarios with mode shift situations.}
}
@article{HUANG202213,
title = {DEFEAT: Decoupled feature attack across deep neural networks},
journal = {Neural Networks},
volume = {156},
pages = {13-28},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003434},
author = {Lifeng Huang and Chengying Gao and Ning Liu},
keywords = {Adversarial example, Transferability, Black-box, Feature-level attack, Defenses},
abstract = {Adversarial attacks pose a security challenge for deep neural networks, motivating researchers to build various defense methods. Consequently, the performance of black-box attacks turns down under defense scenarios. A significant observation is that some feature-level attacks achieve an excellent success rate to fool undefended models, while their transferability is severely degraded when encountering defenses, which give a false sense of security. In this paper, we explain one possible reason caused this phenomenon is the domain-overfitting effect, which degrades the capabilities of feature perturbed images and makes them hardly fool adversarially trained defenses. To this end, we study a novel feature-level method, referred to as Decoupled Feature Attack (DEFEAT). Unlike the current attacks that use a round-robin procedure to estimate gradient estimation and update perturbation, DEFEAT decouples adversarial example generation from the optimization process. In the first stage, DEFEAT learns an distribution full of perturbations with high adversarial effects. And it then iteratively samples the noises from learned distribution to assemble adversarial examples. On top of that, we can apply transformations of existing methods into the DEFEAT framework to produce more robust perturbations. We also provide insights into the relationship between transferability and latent features that helps the community to understand the intrinsic mechanism of adversarial attacks. Extensive experiments evaluated on a variety of black-box models suggest the superiority of DEFEAT, i.e., our method fools defenses at an average success rate of 88.4%, remarkably outperforming state-of-the-art transferable attacks by a large margin of 11.5%. The code is publicly available at https://github.com/mesunhlf/DEFEAT.}
}
@article{WANG2023350,
title = {Finite-time consensus control for multi-agent systems with full-state constraints and actuator failures},
journal = {Neural Networks},
volume = {157},
pages = {350-363},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004245},
author = {Jianhui Wang and Yancheng Yan and Zhi Liu and C.L. Philip Chen and Chunliang Zhang and Kairui Chen},
keywords = {Multi-agent systems (MASs), Consensus control, Full-state constraints, Actuator failures, Neural network, Finite-time convergence},
abstract = {Aiming at a class of uncertain nonlinear multi-agent systems (MASs) with full-state constraints and actuator failures, a finite-time consensus control method is developed. Full-state constraints and actuator failures are ubiquitous in practical engineering applications. Violation of constraints would drastically affect the performance of MASs, even arise security problems. It is challenging to guarantee the performance of the MASs when undergoing actuator failures. To tackle these problems, an adaptive consensus control method is established by applying the Backstepping technique and Barrier Lyapunov functions (BLFs) to ensure the performance of the MASs with full-state constraints no matter actuator failures occur. Simultaneously, for the uncertain nonlinear MASs, a finite-time neural network (NN) consensus control scheme is established to ensure system’s signals are synchronized in finite time. Moreover, an event-triggered control strategy is constructed to relieve the communication pressure of each agent. Finally, numerical and practical examples are employed to verify the effectiveness of the proposed control strategy.}
}
@article{ZHANG2022244,
title = {Feature extraction framework based on contrastive learning with adaptive positive and negative samples},
journal = {Neural Networks},
volume = {156},
pages = {244-257},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003793},
author = {Hongjie Zhang and Siyu Zhao and Wenwen Qiang and Yingyi Chen and Ling Jing},
keywords = {Feature extraction, Dimension reduction, Contrastive learning, Mutual information},
abstract = {Feature extraction is an efficient approach for alleviating the issue of dimensionality in high-dimensional data. As a popular self-supervised learning method, contrastive learning has recently garnered considerable attention. In this study, we propose a unified feature extraction framework based on contrastive learning with adaptive positive and negative samples (CL-FEFA) that is suitable for unsupervised, supervised, and semi-supervised feature extraction. CL-FEFA constructs adaptively positive and negative samples from the result of feature extraction, which makes them more appropriate and accurate. Meanwhile, the discriminative features are extracted based on adaptive positive and negative samples, which will make the intra-class embedded samples more compact and the inter-class embedded samples more dispersed. In the process, using the potential structure information of subspace samples to dynamically construct positive and negative samples can make our framework more robust to noisy data. Furthermore, it is proven that CL-FEFA actually maximizes the mutual information of positive samples, which captures non-linear statistical dependencies between similar samples in potential structure space and thus can act as a measure of true dependence. This also provides theoretical support for its advantages in feature extraction. The final numerical experiments prove that the proposed framework has a strong advantage over traditional feature extraction methods and contrastive learning methods.}
}
@article{JIANG2022348,
title = {Fast multiple graphs learning for multi-view clustering},
journal = {Neural Networks},
volume = {155},
pages = {348-359},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003276},
author = {Tianyu Jiang and Quanxue Gao},
keywords = {Multi-view learning, Clustering, Graph learning},
abstract = {Graph-based multi-view clustering has become an active topic due to the efficiency in characterizing both the complex structure and relationship between multimedia data. However, existing methods have the following shortcomings: (1) They are inefficient or even fail for graph learning in large scale due to the graph construction and eigen-decomposition. (2) They cannot well exploit both the complementary information and spatial structure embedded in graphs of different views. To well exploit complementary information and tackle the scalability issue plaguing graph-based multi-view clustering, we propose an efficient multiple graph learning model via a small number of anchor points and tensor Schatten p-norm minimization. Specifically, we construct a hidden and tractable large graph by anchor graph for each view and well exploit complementary information embedded in anchor graphs of different views by tensor Schatten p-norm regularizer. Finally, we develop an efficient algorithm, which scales linearly with the data size, to solve our proposed model. Extensive experimental results on several datasets indicate that our proposed method outperforms some state-of-the-art multi-view clustering algorithms.}
}
@article{WEI2023202,
title = {ExpGCN: Review-aware Graph Convolution Network for explainable recommendation},
journal = {Neural Networks},
volume = {157},
pages = {202-215},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004087},
author = {Tianjun Wei and Tommy W.S. Chow and Jianghong Ma and Mingbo Zhao},
keywords = {Explainable recommendation, Recommender system, Graph Neural Network, Multi-task learning, Collaborative filtering},
abstract = {Existing works in recommender system have widely explored extracting reviews as explanations beyond user–item interactions, and formulated the explanation generation as a ranking task to enhance item recommendation performance. To associate explanations with users and items, graph neural networks (GNN) are usually employed to learn node representations on the heterogeneous user–item–explanation interaction graph. However, modeling heterogeneous graph convolution poses limitations in both message passing styles and computational efficiency, resulting in sub-optimal recommendation performance. To address the limitations, we propose an Explanation-aware Graph Convolution Network (ExpGCN). In particular, the heterogeneous interaction graph is divided to subgraphs regard to the edge types in ExpGCN. By aggregating information from distinct subgraphs, ExpGCN is capable of generating node representations for explanation ranking task and item recommendation task respectively. Task-oriented graph convolution can not only reduce the complexity of heterogeneous node aggregation, but also alleviate the performance degeneration caused by the conflicts between task learning objectives, which has been neglected in current studies. Extensive experiments on four public datasets show that ExpGCN significantly outperforms state-of-the-art baselines with high efficiency, demonstrating the effectiveness of ExpGCN in explainable recommendations.}
}
@article{ABDELJAWAD2022536,
title = {Integral representations of shallow neural network with rectified power unit activation function},
journal = {Neural Networks},
volume = {155},
pages = {536-550},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003392},
author = {Ahmed Abdeljawad and Philipp Grohs},
keywords = {Shallow neural network, Integral representation, Rectified power unit, Radon transform},
abstract = {In this paper we characterize the set of functions that can be represented by infinite width neural networks with RePU activation function max(0,x)p, when the network coefficients are regularized by an ℓ2/p (quasi)norm. Compared to the more well-known ReLU activation function (which corresponds to p=1), the RePU activation functions exhibit a greater degree of smoothness which makes them preferable in several applications. Our main result shows that such representations are possible for a given function if and only if the function is κ-order Lipschitz and its R-norm is finite. This extends earlier work on this topic that has been restricted to the case of the ReLU activation function and coefficient bounds with respect to the ℓ2 norm. Since for q<2, ℓq regularizations are known to promote sparsity, our results also shed light on the ability to obtain sparse neural network representations.}
}
@article{ABRAR2022160,
title = {Perturbation of deep autoencoder weights for model compression and classification of tabular data},
journal = {Neural Networks},
volume = {156},
pages = {160-169},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003707},
author = {Sakib Abrar and Manar D. Samad},
keywords = {Weight pruning, Autoencoder, Tabular data, Model compression, Sparse learning, Deep neural network},
abstract = {Fully connected deep neural networks (DNN) often include redundant weights leading to overfitting and high memory requirements. Additionally, in tabular data classification, DNNs are challenged by the often superior performance of traditional machine learning models. This paper proposes periodic perturbations (prune and regrow) of DNN weights, especially at the self-supervised pre-training stage of deep autoencoders. The proposed weight perturbation strategy outperforms dropout learning or weight regularization (L1 or L2) for four out of six tabular data sets in downstream classification tasks. Unlike dropout learning, the proposed weight perturbation routine additionally achieves 15% to 40% sparsity across six tabular data sets, resulting in compressed pretrained models. The proposed pretrained model compression improves the accuracy of downstream classification, unlike traditional weight pruning methods that trade off performance for model compression. Our experiments reveal that a pretrained deep autoencoder with weight perturbation can outperform traditional machine learning in tabular data classification, whereas baseline fully-connected DNNs yield the worst classification accuracy. However, traditional machine learning models are superior to any deep model when a tabular data set contains uncorrelated variables. Therefore, the performance of deep models with tabular data is contingent on the types and statistics of constituent variables.}
}
@article{WU20231,
title = {Pinning synchronization of stochastic neutral memristive neural networks with reaction–diffusion terms},
journal = {Neural Networks},
volume = {157},
pages = {1-10},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003823},
author = {Xiang Wu and Shutang Liu and Huiyu Wang},
keywords = {Pinning synchronization, Stochastic, Memristive, Neutral, Reaction–diffusion},
abstract = {This paper investigates the pinning synchronization of stochastic neutral memristive neural networks with reaction–diffusion terms. Firstly, two novel pinning controllers, which contain both current state and past state, are designed. Subsequently, in terms of Green’s theorem, inequality technology, stochastic analysis theory and pinning control technology, two easy-to-test sufficient conditions based on algebraic inequalities are obtained to ensure the mean-square asymptotic synchronization of stochastic memristive neural networks with neutral delays and reaction–diffusion terms by providing a new Lyapunov–Krasovskii functional. In addition, some existing results can be regarded as special cases of our work. Finally, illustrative examples further verify the correctness and validity of the derived results.}
}
@article{ZHANG202326,
title = {Rutting prediction and analysis of influence factors based on multivariate transfer entropy and graph neural networks},
journal = {Neural Networks},
volume = {157},
pages = {26-38},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003306},
author = {Jinren Zhang and Jinde Cao and Wei Huang and Xinli Shi and Xingye Zhou},
keywords = {Rutting prediction, Analysis of influence factor, Multivariate transfer entropy, GRU-attention, Directed graph convolution networks, RIOHTrack},
abstract = {The Rutting prediction model is an essential element of efficient pavement management systems. Accuracy of commonly used predictive model necessitates knowledge of the input parameters that was incorporated and local calibration of the model coefficients. In this paper, a novel rutting prediction model based on multivariate transfer entropy and graph neural networks is proposed for incorporating a limited number of observable inputs, which can accommodate with sufficient prediction performance and generalization to a variety of complex pavement design structure data. The multivariate transfer entropy based graph representation is able to find the significant causality between variables and rutting. The influence factor analysis results confirm the high influence of temperature and vehicle axle load. Several experiments are set up on the Research Institute of Highway Ministry of Transport track (RIOHTrack) dataset for the comparison between the proposed model and the state-of-art prediction models. The result demonstrates that the proposed model is more accurate and robust compared to existing methods on the rutting prediction task.}
}
@article{CHEN2022239,
title = {Synchronization of multi-cluster complex networks},
journal = {Neural Networks},
volume = {156},
pages = {239-243},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200377X},
author = {Tianping Chen},
keywords = {Multi-cluster complex network, Intra-synchronization, Inter-synchronization, Complete synchronization},
abstract = {In this paper, a class of multi-cluster complex networks is discussed. Complete synchronization of such networks is analysed in detail. It is explored how the synchronization depends on the intra coupling matrices, the inter coupling matrices and the corresponding coupling strengths. The approach proposed also applies to more general networks composed of multi-cluster networks, too.}
}
@article{LIU2022318,
title = {Self-supervised knowledge distillation for complementary label learning},
journal = {Neural Networks},
volume = {155},
pages = {318-327},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003148},
author = {Jiabin Liu and Biao Li and Minglong Lei and Yong Shi},
keywords = {Complementary labels learning, Self-supervision learning, Knowledge distillation},
abstract = {In this paper, we tackle a new learning paradigm called learning from complementary labels, where the training data specifies classes that instances do not belong to, instead of the accuracy labels. In general, it is more efficient to collect the complementary labels compared with collecting the supervised ones, with no need for selecting the correct one from a number of candidates. While current state-of-the-art methods design various loss functions to train competitive models by the limited supervised information, they overlook learning from the data and model themselves, which always contain fruitful information that can improve the performance of complementary label learning. In this paper, we propose a novel learning framework, which seamlessly integrates self-supervised and self-distillation to complementary learning. Based on the general complementary learning framework, we employ an entropy regularization term to guarantee the network outputs exhibit a sharper state. Then, to intensively learn information from the data, we leverage the self-supervised learning based on rotation and transformation operations as a plug-in auxiliary task to learn better transferable representations. Finally, knowledge distillation is introduced to further extract the “dark knowledge” from a network to guide the training of a student network. In the extensive experiments, our method surprisingly demonstrates compelling performance in accuracy over several state-of-the-art approaches.}
}
@article{WANG2022523,
title = {Sequential safe feature elimination rule for L1-regularized regression with Kullback–Leibler divergence},
journal = {Neural Networks},
volume = {155},
pages = {523-535},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003422},
author = {Hongmei Wang and Kun Jiang and Yitian Xu},
keywords = {-regularized regression, Kullback–Leibler divergence, Safe elimination, Sparse learning},
abstract = {The L1-regularized regression with Kullback–Leibler divergence (KL-L1R) is a popular regression technique. Although many efforts have been devoted to its efficient implementation, it remains challenging when the number of features is extremely large. In this paper, to accelerate KL-L1R, we introduce a novel and fast sequential safe feature elimination rule (FER) based on its sparsity, local regularity properties, and duality theory. It takes negligible time to select and delete most redundant features before and during the training process. Only one reduced model needs to be solved, which makes the computational time shortened. To further speed up the reduced model, the Newton coordinate descent method (Newton-CDM) is chosen as a solver. The superiority of FER is safety, i.e., its solution is exactly the same as the original KL-L1R. Numerical experiments on three artificial datasets, five real-world datasets, and one handwritten digit dataset demonstrate the feasibility and validity of our FER.}
}
@article{YANAGISAWA2023422,
title = {Free energy model of emotional valence in dual-process perceptions},
journal = {Neural Networks},
volume = {157},
pages = {422-436},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004233},
author = {Hideyoshi Yanagisawa and Xiaoxiang Wu and Kazutaka Ueda and Takeo Kato},
keywords = {Emotional valence, Dual process, Free energy, Bayesian model},
abstract = {An appropriate level of arousal induces positive emotions, and a high arousal potential may provoke negative emotions. To explain the effect of arousal on emotional valence, we propose a novel mathematical framework of arousal potential variations in the dual process of human cognition: automatic and controlled. A suitable mathematical formulation to explain the emotions in the dual process is still absent. Our model associates free energy with arousal potential and its variations to explain emotional valence. Decreasing and increasing free energy consequently induce positive and negative emotions, respectively. We formalize a transition from the automatic to the controlled process in the dual process as a change of Bayesian prior. Further, we model emotional valence using free energy increase (FI) when one tries changing one’s Bayesian prior and its reduction (FR) when one succeeds in recognizing the same stimuli with a changed prior and define three emotions: “interest,” “confusion,” and “boredom” using the variations. The results of our mathematical analysis comparing various Gaussian model parameters reveals the following: (1) prediction error (PR) increases FR (representing “interest”) when the first prior variance is greater than the second prior variance, (2) PR decreases FR when the first prior variance is less than the second prior variance, and (3) the distance between priors’ means always increases FR. We also discuss the association of the outcomes with emotions in the controlled process. The proposed mathematical model provides a general framework for predicting and controlling emotional valence in the dual process that varies with viewpoint and stimuli, as well as for understanding the contradictions in the effects of arousal on the valence.}
}
@article{PAN2023288,
title = {Reinforcement learning for automatic quadrilateral mesh generation: A soft actor–critic approach},
journal = {Neural Networks},
volume = {157},
pages = {288-304},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.022},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200418X},
author = {Jie Pan and Jingwei Huang and Gengdong Cheng and Yong Zeng},
keywords = {Reinforcement learning, Mesh generation, Soft actor–critic, Neural networks, Computational geometry, Quadrilateral mesh},
abstract = {This paper proposes, implements, and evaluates a reinforcement learning (RL)-based computational framework for automatic mesh generation. Mesh generation plays a fundamental role in numerical simulations in the area of computer aided design and engineering (CAD/E). It is identified as one of the critical issues in the NASA CFD Vision 2030 Study. Existing mesh generation methods suffer from high computational complexity, low mesh quality in complex geometries, and speed limitations. These methods and tools, including commercial software packages, are typically semiautomatic and they need inputs or help from human experts. By formulating the mesh generation as a Markov decision process (MDP) problem, we are able to use a state-of-the-art reinforcement learning (RL) algorithm called “soft actor-critic” to automatically learn from trials the policy of actions for mesh generation. The implementation of this RL algorithm for mesh generation allows us to build a fully automatic mesh generation system without human intervention and any extra clean-up operations, which fills the gap in the existing mesh generation tools. In the experiments to compare with two representative commercial software packages, our system demonstrates promising performance with respect to scalability, generalizability, and effectiveness.}
}
@article{FONSECABUSTOS202281,
title = {Robust image hashing for content identification through contrastive self-supervised learning},
journal = {Neural Networks},
volume = {156},
pages = {81-94},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.09.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003781},
author = {Jesús Fonseca-Bustos and Kelsey Alejandra Ramírez-Gutiérrez and Claudia Feregrino-Uribe},
keywords = {Content identification, Robust image hashing, Self-supervised learning, Image processing},
abstract = {Content identification systems are an essential technology for many applications. These systems identify query multimedia items using a database of known identities. A hash-based system uses a perceptual hashing function that generates a hash value invariant against a set of expected manipulations in an image, later compared to perform identification. Usually, this set of manipulations is well-known, and the researcher creates the perceptual hashing function that best adapts to the set. However, a new manipulation may break the hashing function, requiring to create a new one, which may be costly and time-consuming. Therefore, we propose to let the hashing function learn an invariant feature space automatically. For this, we exploit the recent advances in self-supervised learning, where a model uses unlabeled data to generate a feature representation by solving a metric learning-based pretext task that enforces the robust image hashing properties for content identification systems. To achieve model transferability on unseen data, our pretext task enforces the feature vector invariance against the manipulation set, and through random sampling on the unlabeled training set, we present the model a wide variety of perceptual information to work on. As exhaustive experimentation shows, this method achieves excellent robustness against a comprehensive set of manipulations, even difficult ones such as horizontal flip and rotation, with excellent identification performance. Also, the trained model is highly discriminative against the presence of near-duplicate images. Furthermore, this method does not need re-training or fine-tuning on a new dataset to achieve the observed performance, indicating an excellent generalization capacity.}
}
@article{PAN2022360,
title = {AFINet: Attentive Feature Integration Networks for image classification},
journal = {Neural Networks},
volume = {155},
pages = {360-368},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003264},
author = {Xinglin Pan and Jing Xu and Yu Pan and Liangjian Wen and Wenxiang Lin and Kun Bai and Hongguang Fu and Zenglin Xu},
keywords = {CNN, Attention, Image classification, Feature integration},
abstract = {Convolutional Neural Networks (CNNs) have achieved tremendous success in a number of learning tasks including image classification. Residual-like networks, such as ResNets, mainly focus on the skip connection to avoid gradient vanishing. However, the skip connection mechanism limits the utilization of intermediate features due to simple iterative updates. To mitigate the redundancy of residual-like networks, we design Attentive Feature Integration (AFI) modules, which are widely applicable to most residual-like network architectures, leading to new architectures named AFI-Nets. AFI-Nets explicitly model the correlations among different levels of features and selectively transfer features with a little overhead. AFI-ResNet-152 obtains a 1.24% relative improvement on the ImageNet dataset while decreases the FLOPs by about 10% and the number of parameters by about 9.2% compared to ResNet-152.}
}
@article{LOU2023136,
title = {Classification-based prediction of network connectivity robustness},
journal = {Neural Networks},
volume = {157},
pages = {136-146},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004075},
author = {Yang Lou and Ruizi Wu and Junli Li and Lin Wang and Chang-Bing Tang and Guanrong Chen},
keywords = {Complex network, Connectivity, Robustness, Convolutional neural network, Prediction},
abstract = {Today, there is an increasing concern about malicious attacks on various networks in society and industry, against which the network robustness is critical. Network connectivity robustness, in particular, is of fundamental importance, which is generally measured by a sequence of calculated values that indicate the connectedness of the remaining network after a sequence of attacks by means of node- or edge-removal. It is computationally time-consuming, however, to measure and evaluate the network connectivity robustness using the conventional attack simulations, especially for large-scale networked systems. In the present paper, an efficient robustness predictor based on multiple convolutional neural networks (mCNN-RP) is proposed for predicting the network connectivity robustness, which is an natural extension of the single CNN-based predictor. In mCNN-RP, one CNN works as the classifier, while each of the rest CNNs works as an estimator for predicting the connectivity robustness of every classified network category. The network categories are classified according to the available prior knowledge. A data-based filter is installed for predictive data refinement. Extensive experimental studies on both synthetic and real-world networks, including directed and undirected as well as weighted and unweighted topologies, verify the effectiveness of mCNN-RP. The results demonstrate that the average prediction error is lower than the standard deviation of the tested data, which outperforms the single CNN-based framework. The runtime in assessing network connectivity robustness is significantly reduced by using the CNN-based technique. The proposed mCNN-RP not only can accurately predict the connectivity robustness of various complex networks, but also provides an excellent indicator for the connectivity robustness, better than other existing prediction measures.}
}