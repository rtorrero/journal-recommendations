@article{YANG2023692,
title = {A scalable second order optimizer with an adaptive trust region for neural networks},
journal = {Neural Networks},
volume = {167},
pages = {692-705},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300504X},
author = {Donghee Yang and Junhyun Cho and Sungchul Lee},
keywords = {Second order optimizer, Fisher information matrix, Trust region, Neural network, Gradient descent},
abstract = {We introduce Tadam (Trust region ADAptive Moment estimation), a new optimizer based on the trust region of the second-order approximation of the loss using the Fisher information matrix. Despite the enhanced gradient estimations offered by second-order approximations, their practical implementation requires sizable batch sizes to estimate the second-order approximation matrices and perform matrix inversions. Consequently, integrating second-order approximations entails additional memory consumption and imposes substantial computational demands due to the inversion of large matrices. In light of these challenges, we have devised a second-order approximation algorithm that mitigates these issues by judiciously approximating the pertinent large matrix, requiring only a marginal increase in memory usage while minimizing the computational burden. Tadam approximates the loss up to the second order using the Fisher information matrix. Since estimating the Fisher information matrix is expensive in both memory and time, Tadam approximates the Fisher information matrix and reduces the computational burdens to the O(N) level. Furthermore, Tadam employs an adaptive trust region scheme to reduce approximate errors and guarantee stability. Tadam evaluates how well it minimizes the loss function and uses this information to adjust the trust region dynamically. In addition, Tadam adjusts the learning rate internally, even if we provide the learning rate as a fixed constant. We run several experiments to measure Tadam’s performance against Adam, AMSGrad, Radam, and Nadam, which have the same space and time complexity as Tadam. The test results show that Tadam outperforms the benchmarks and finds reasonable solutions fast and stably.}
}
@article{LUO2023588,
title = {Adaptive optimal control of affine nonlinear systems via identifier–critic neural network approximation with relaxed PE conditions},
journal = {Neural Networks},
volume = {167},
pages = {588-600},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.044},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004641},
author = {Rui Luo and Zhinan Peng and Jiangping Hu and Bijoy Kumar Ghosh},
keywords = {Adaptive optimal control, Affine nonlinear system, Identifier–critic neural network, Dynamic regressor extension and mixing, Relaxed persistence of excitation conditions},
abstract = {This paper considers an optimal control of an affine nonlinear system with unknown system dynamics. A new identifier–critic framework is proposed to solve the optimal control problem. Firstly, a neural network identifier is built to estimate the unknown system dynamics, and a critic NN is constructed to solve the Hamiltonian–Jacobi–Bellman equation associated with the optimal control problem. A dynamic regressor extension and mixing technique is applied to design the weight update laws with relaxed persistence of excitation conditions for the two classes of neural networks. The parameter estimation of the update laws and the stability of the closed-loop system under the adaptive optimal control are analyzed using a Lyapunov function method. Numerical simulation results are presented to demonstrate the effectiveness of the proposed IC learning based optimal control algorithm for the affine nonlinear system.}
}
@article{DAI2023256,
title = {UNIMEMnet: Learning long-term motion and appearance dynamics for video prediction with a unified memory network},
journal = {Neural Networks},
volume = {168},
pages = {256-271},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005178},
author = {Kuai Dai and Xutao Li and Chuyao Luo and Wuqiao Chen and Yunming Ye and Shanshan Feng},
keywords = {Video prediction, Memory network, Long-term motion-appearance dynamics, Short-term motion-appearance dynamics},
abstract = {As a pixel-wise dense forecast task, video prediction is challenging due to its high computation complexity, dramatic future uncertainty, and extremely complicated spatial–temporal patterns. Many deep learning methods are proposed for the task, which bring up significant improvements. However, they focus on modeling short-term spatial–temporal dynamics and fail to sufficiently exploit long-term ones. As a result, the methods tend to deliver unsatisfactory performance for a long-term forecast requirement. In this article, we propose a novel unified memory network (UNIMEMnet) for long-term video prediction, which can effectively exploit long-term motion-appearance dynamics and unify the short-term spatial–temporal dynamics and long-term ones in an architecture. In the UNIMEMnet, a dual branch multi-scale memory module is carefully designed to extract and preserve long-term spatial–temporal patterns. In addition, a short-term spatial–temporal dynamics module and an alignment and fusion module are devised to capture and coordinate short-term motion-appearance dynamics with long-term ones from our designed memory module. Extensive experiments on five video prediction datasets from both synthetic and real-world scenarios are conducted, which validate the effectiveness and superiority of our proposed method UNIMEMnet over state-of-the-art methods.}
}
@article{GOMEZFLORES2023665,
title = {Learning smooth dendrite morphological neurons by stochastic gradient descent for pattern classification},
journal = {Neural Networks},
volume = {168},
pages = {665-676},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005294},
author = {Wilfrido Gómez-Flores and Humberto Sossa},
keywords = {Dendrite morphological neurons, Spherical dendrites, Stochastic gradient descent, Smooth activation functions, Learnable softmax layer},
abstract = {This article presents a learning algorithm for dendrite morphological neurons (DMN) based on stochastic gradient descent (SGD). In particular, we focus on a DMN topology that comprises spherical dendrites, smooth maximum activation function nodes, and a softmax output layer, whose original learning algorithm is performed in two independent stages: (1) dendrites’ centroids are learned by k-means, and (2) softmax layer weights are adjusted by gradient descent. A drawback of this learning method is that both stages are unplugged; once dendrites’ centroids are defined, they keep static during weights learning, so no feedback is performed to correct the dendrites’ positions to improve classification performance. To overcome this issue, we derive the delta rules for adjusting the dendrites’ centroids and the output layer weights by minimizing the cross-entropy loss function under an SGD scheme. This gradient descent-based learning is feasible because the smooth maximum activation function that interfaces the dendrite units with the output layer is differentiable. The proposed DMN is compared against eight morphological neuron models with distinct topologies and learning methods and four well-established classifiers: support vector machine (SVM), multilayer perceptron (MLP), and random forest (RF), and k-nearest neighbors (k-NN). Besides, the classification performance is evaluated on 81 datasets. The experimental results show that the proposed method tends to outperform the DMN methods and is competitive or even better than SVM, MLP, RF, and k-NN. Thus, it is an alternative approach that can effectively be used for pattern classification. Moreover, SGD for DMN learning standardizes this neural model, like current artificial neural networks.}
}
@article{ZHOU2023380,
title = {Multiple-instance ensemble for construction of deep heterogeneous committees for high-dimensional low-sample-size data},
journal = {Neural Networks},
volume = {167},
pages = {380-399},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004483},
author = {Qinghua Zhou and Shuihua Wang and Hengde Zhu and Xin Zhang and Yudong Zhang},
keywords = {Committee learning, Deep learning, HDLS, Attention},
abstract = {Deep ensemble learning, where we combine knowledge learned from multiple individual neural networks, has been widely adopted to improve the performance of neural networks in deep learning. This field can be encompassed by committee learning, which includes the construction of neural network cascades. This study focuses on the high-dimensional low-sample-size (HDLS) domain and introduces multiple instance ensemble (MIE) as a novel stacking method for ensembles and cascades. In this study, our proposed approach reformulates the ensemble learning process as a multiple-instance learning problem. We utilise the multiple-instance learning solution of pooling operations to associate feature representations of base neural networks into joint representations as a method of stacking. This study explores various attention mechanisms and proposes two novel committee learning strategies with MIE. In addition, we utilise the capability of MIE to generate pseudo-base neural networks to provide a proof-of-concept for a “growing” neural network cascade that is unbounded by the number of base neural networks. We have shown that our approach provides (1) a class of alternative ensemble methods that performs comparably with various stacking ensemble methods and (2) a novel method for the generation of high-performing “growing” cascades. The approach has also been verified across multiple HDLS datasets, achieving high performance for binary classification tasks in the low-sample size regime.}
}
@article{YE2023533,
title = {PEPNet: A barotropic primitive equations-based network for wind speed prediction},
journal = {Neural Networks},
volume = {167},
pages = {533-550},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.042},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300463X},
author = {Rui Ye and Baoquan Zhang and Xutao Li and Yunming Ye},
keywords = {Neural networks, Wind speed prediction, The barotropic primitive equation mode},
abstract = {In wind speed prediction technologies, deep learning-based methods have achieved promising advantages. However, most existing methods focus on learning implicit knowledge in a data-driven manner but neglect some explicit knowledge from the physical theory of meteorological dynamics, failing to make stable and long-term predictions. In this paper, we explore introducing explicit physical knowledge into neural networks and propose Physical Equations Predictive Network (PEPNet) for multi-step wind speed predictions. In PEPNet, a new neural block called the Augmented Neural Barotropic Equations (ANBE) block is designed as its key component, which aims to capture the wind dynamics by combining barotropic primitive equations and deep neural networks. Specifically, the ANBE block adopts a two-branch structure to model wind dynamics, where one branch is physic-based and the other is data-driven-based. The physic-based branch constructs temporal partial derivatives of meteorological elements (including u-component wind, v-component wind, and geopotential height) in a new Neural Barotropic Equations Unit (NBEU). The NBEU is developed based on the barotropic primitive equations mode in numerical weather prediction (NWP). Besides, considering that the barotropic primitive mode is a crude assumption of atmospheric motion, another data-driven-based branch is developed in the ANBE block, which aims at capturing meteorological dynamics beyond barotropic primitive equations. Finally, the PEPNet follows a time-variant structure to enhance the model’s capability to capture wind dynamics over time. To evaluate the predictive performance of PEPNet, we have conducted several experiments on two real-world datasets. Experimental results show that the proposed method outperforms the state-of-the-art techniques and achieve optimal performance.}
}
@article{ASIF2023342,
title = {Metaheuristics optimization-based ensemble of deep neural networks for Mpox disease detection},
journal = {Neural Networks},
volume = {167},
pages = {342-359},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004525},
author = {Sohaib Asif and Ming Zhao and Fengxiao Tang and Yusen Zhu and Baokang Zhao},
keywords = {Ensemble learning, Metaheuristic optimization, Mpox disease, Deep learning, Disease diagnosis},
abstract = {The rising number of cases of human Mpox has emerged as a major global concern due to the daily increase of cases in several countries. The disease presents various skin symptoms in infected individuals, making it crucial to promptly identify and isolate them to prevent widespread community transmission. Rapid determination and isolation of infected individuals are therefore essential to curb the spread of the disease. Most research in the detection of Mpox disease has utilized convolutional neural network (CNN) models and ensemble methods. However, to the best of our knowledge, none have utilized a meta-heuristic-based ensemble approach. To address this gap, we propose a novel metaheuristics optimization-based weighted average ensemble model (MO-WAE) for detecting Mpox disease. We first train three transfer learning (TL)-based CNNs (DenseNet201, MobileNet, and DenseNet169) by adding additional layers to improve their classification strength. Next, we use a weighted average ensemble technique to fuse the predictions from each individual model, and the particle swarm optimization (PSO) algorithm is utilized to assign optimized weights to each model during the ensembling process. By using this approach, we obtain more accurate predictions than individual models. To gain a better understanding of the regions indicating the onset of Mpox, we performed a Gradient Class Activation Mapping (Grad-CAM) analysis to explain our model’s predictions. Our proposed MO-WAE ensemble model was evaluated on a publicly available Mpox dataset and achieved an impressive accuracy of 97.78%. This outperforms state-of-the-art (SOTA) methods on the same dataset, thereby providing further evidence of the efficacy of our proposed model.}
}
@article{LU2023283,
title = {Bidirectionally self-normalizing neural networks},
journal = {Neural Networks},
volume = {167},
pages = {283-291},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004367},
author = {Yao Lu and Stephen Gould and Thalaiyasingam Ajanthan},
keywords = {Neural networks, Vanishing/exploding gradient problem, Training, Optimization},
abstract = {The problem of vanishing and exploding gradients has been a long-standing obstacle that hinders the effective training of neural networks. Despite various tricks and techniques that have been employed to alleviate the problem in practice, there still lacks satisfactory theories or provable solutions. In this paper, we address the problem from the perspective of high-dimensional probability theory. We provide a rigorous result that shows, under mild conditions, how the vanishing/exploding gradients problem disappears with high probability if the neural networks have sufficient width. Our main idea is to constrain both forward and backward signal propagation in a nonlinear neural network through a new class of activation functions, namely Gaussian–Poincaré normalized functions, and orthogonal weight matrices. Experiments on both synthetic and real-world data validate our theory and confirm its effectiveness on very deep neural networks when applied in practice.}
}
@article{SHI2023105,
title = {CEGAT: A CNN and enhanced-GAT based on key sample selection strategy for hyperspectral image classification},
journal = {Neural Networks},
volume = {168},
pages = {105-122},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.059},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004884},
author = {Cuiping Shi and Haiyang Wu and Liguo Wang},
keywords = {Deep learning, Convolution neural network, Graph convolution network, Hyperspectral image classification},
abstract = {In recent years, the application of convolutional neural networks (CNNs) and graph convolutional networks (GCNs) in hyperspectral image classification (HSIC) has achieved remarkable results. However, the limited label samples are still a major challenge when using CNN and GCN to classify hyperspectral images. In order to alleviate this problem, a double branch fusion network of CNN and enhanced graph attention network (CEGAT) based on key sample selection strategy is proposed. First, a linear discrimination of spectral inter-class slices (LD_SICS) module is designed to eliminate spectral redundancy of HSIs. Then, a spatial spectral correlation attention (SSCA) module is proposed, which can extract and assign attention weight to the spatial and spectral correlation features. On the graph attention (GAT) branch, the HSI is segmented into some super pixels as input to reduce the amount of network parameters. In addition, an enhanced graph attention (EGAT) module is constructed to enhance the relationship between nodes. Finally, a key sample selection (KSS) strategy is proposed to enable the network to achieve better classification performance with few labeled samples. Compared with other state-of-the-art methods, CEGAT has better classification performance under limited label samples.}
}
@article{YU2023326,
title = {How to backdoor split learning},
journal = {Neural Networks},
volume = {168},
pages = {326-336},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005336},
author = {Fangchao Yu and Lina Wang and Bo Zeng and Kai Zhao and Zhi Pang and Tian Wu},
keywords = {Split learning, Backdoor attack, Shadow model, Auxiliary model},
abstract = {Split learning, a distributed learning framework, has garnered significant attention from academic and industrial communities. In contrast to federated learning, split learning offers a more flexible architecture for participants with limited computing resources. However, the security of split learning has been questioned due to the separation of data and model control rights from usage rights. Currently, most research work focuses on inference attacks in split learning. In this paper, we first reveal the vulnerability of split learning to backdoor attacks and present two backdoor attack frameworks from both the server and client perspectives. Regarding the client-side attacker, we insert backdoor samples into the training data by utilizing the client’s direct control over local data, and propose two methods for labeling backdoor samples that can be adapted to various application scenarios. Due to the server’s lack of control over the client in split learning, it is infeasible for server-side attackers to inject backdoor samples into training data. Our strategy involves leveraging the server’s control over the training process to shape the optimization direction of the client model, thereby enabling it to encode backdoor samples. Moreover, we introduce an auxiliary model into the attack framework to enhance the effectiveness of the backdoor attack. The auxiliary model can increase the distinction between backdoor samples and clean samples in the feature space to improve the sensitivity of the client model to backdoor samples. Extensive evaluations demonstrate the high attack accuracy of both proposed attack frameworks without causing any compromise to the performance of the main task. Our research uncovers the potential security risks and rings the alarm for the application of split learning.}
}
@article{ZHANG2023129,
title = {Graph embedding based multi-label Zero-shot Learning},
journal = {Neural Networks},
volume = {167},
pages = {129-140},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004409},
author = {Haigang Zhang and Xianglong Meng and Weipeng Cao and Ye Liu and Zhong Ming and Jinfeng Yang},
keywords = {Zero-shot Learning, Knowledge graph, Multi-label classification, Feature embedding},
abstract = {Multi-label Zero-shot Learning (ZSL) is more reasonable and realistic than standard single-label ZSL because several objects can co-exist in a natural image in real scenarios. Intra-class feature entanglement is a significant factor influencing the alignment of visual and semantic features, resulting in the model’s inability to recognize unseen samples comprehensively and completely. We observe that existing multi-label ZSL methods place a greater emphasis on attention-based refinement and decoupling of visual features, while ignoring the relationship between label semantics. Relying on label correlations to solve multi-label ZSL tasks has not been deeply studied. In this paper, we make full use of the co-occurrence relationship between category labels and build a directed weighted semantic graph based on statistics and prior knowledge, in which node features represent category semantics and weighted edges represent conditional probabilities of label co-occurrence. To guide the targeted extraction of visual features, node features and edge set weights are simultaneously updated and refined, and embedded into the visual feature extraction network from a global and local perspective. The proposed method’s effectiveness was demonstrated by simulation results on two challenging multi-label ZSL benchmarks: NUS-WIDE and Open Images. In comparison to state-of-the-art models, our model achieves an absolute gain of 2.4% mAP on NUS-WIDE and 2.1% mAP on Open Images respectively.}
}
@article{ZHU2023656,
title = {Improving Differentiable Architecture Search via self-distillation},
journal = {Neural Networks},
volume = {167},
pages = {656-667},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.062},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004926},
author = {Xunyu Zhu and Jian Li and Yong Liu and Weiping Wang},
keywords = {Neural architecture search, Neural networks, Flatness, Knowledge distillation, Sharpness-aware minimization},
abstract = {Differentiable Architecture Search (DARTS) is a simple yet efficient Neural Architecture Search (NAS) method. During the search stage, DARTS trains a supernet by jointly optimizing architecture parameters and network parameters. During the evaluation stage, DARTS discretizes the supernet to derive the optimal architecture based on architecture parameters. However, recent research has shown that during the training process, the supernet tends to converge towards sharp minima rather than flat minima. This is evidenced by the higher sharpness of the loss landscape of the supernet, which ultimately leads to a performance gap between the supernet and the optimal architecture. In this paper, we propose Self-Distillation Differentiable Neural Architecture Search (SD-DARTS) to alleviate the discretization gap. We utilize self-distillation to distill knowledge from previous steps of the supernet to guide its training in the current step, effectively reducing the sharpness of the supernet’s loss and bridging the performance gap between the supernet and the optimal architecture. Furthermore, we introduce the concept of voting teachers, where multiple previous supernets are selected as teachers, and their output probabilities are aggregated through voting to obtain the final teacher prediction. Experimental results on real datasets demonstrate the advantages of our novel self-distillation-based NAS method compared to state-of-the-art alternatives.}
}
@article{WANG2023272,
title = {A multi-scale self-supervised hypergraph contrastive learning framework for video question answering},
journal = {Neural Networks},
volume = {168},
pages = {272-286},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.057},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004872},
author = {Zheng Wang and Bin Wu and Kaoru Ota and Mianxiong Dong and He Li},
keywords = {Video question answering, Hypergraph contrastive learning, Data augmentation, High-order relations, Multi-scale},
abstract = {Video question answering (VideoQA) is a challenging video understanding task that requires a comprehensive understanding of multimodal information and accurate answers to related questions. Most existing VideoQA models use Graph Neural Networks (GNN) to capture temporal–spatial interactions between objects. Despite achieving certain success, we argue that current schemes have two limitations: (i) existing graph-based methods require stacking multi-layers of GNN to capture high-order relations between objects, which inevitably introduces irrelevant noise; (ii) neglecting the unique self-supervised signals in the high-order relational structures among multiple objects that can facilitate more accurate QA. To this end, we propose a novel Multi-scale Self-supervised Hypergraph Contrastive Learning (MSHCL) framework for VideoQA. Specifically, we first segment the video from multiple temporal dimensions to obtain multiple frame groups. For different frame groups, we design appearance and motion hyperedges based on node semantics to connect object nodes. In this way, we construct a multi-scale temporal–spatial hypergraph to directly capture high-order relations among multiple objects. Furthermore, the node features after hypergraph convolution are injected into a Transformer to capture the global information of the input sequence. Second, we design a self-supervised hypergraph contrastive learning task based on the node- and hyperedge-dropping data augmentation and an improved question-guided multimodal interaction module to enhance the accuracy and robustness of the VideoQA model. Finally, extensive experiments on three benchmark datasets demonstrate the superiority of our proposed MSHCL compared with stat-of-the-art methods.}
}
@article{QIAO2023223,
title = {Self-supervised depth super-resolution with contrastive multiview pre-training},
journal = {Neural Networks},
volume = {168},
pages = {223-236},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005166},
author = {Xin Qiao and Chenyang Ge and Chaoqiang Zhao and Fabio Tosi and Matteo Poggi and Stefano Mattoccia},
keywords = {Depth super-resolution, Self-supervised learning, Contrastive pre-training, Mutual-modulation, Cross-modal},
abstract = {Many low-level vision tasks, including guided depth super-resolution (GDSR), struggle with the issue of insufficient paired training data. Self-supervised learning is a promising solution, but it remains challenging to upsample depth maps without the explicit supervision of high-resolution target images. To alleviate this problem, we propose a self-supervised depth super-resolution method with contrastive multiview pre-training. Unlike existing contrastive learning methods for classification or segmentation tasks, our strategy can be applied to regression tasks even when trained on a small-scale dataset and can reduce information redundancy by extracting unique features from the guide. Furthermore, we propose a novel mutual modulation scheme that can effectively compute the local spatial correlation between cross-modal features. Exhaustive experiments demonstrate that our method attains superior performance with respect to state-of-the-art GDSR methods and exhibits good generalization to other modalities.}
}
@article{CHEN2023450,
title = {LJIR: Learning Joint-Action Intrinsic Reward in cooperative multi-agent reinforcement learning},
journal = {Neural Networks},
volume = {167},
pages = {450-459},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004355},
author = {Zihan Chen and Biao Luo and Tianmeng Hu and Xiaodong Xu},
keywords = {Reinforcement learning, Multi-agent system, Intrinsic reward, Curiosity-driven exploration, Transformer},
abstract = {Effective exploration is the key to achieving high returns for reinforcement learning. Agents must explore jointly in multi-agent systems to find the optimal joint policy. Due to the exploration problem and the shared reward, the policy-based multi-agent reinforcement learning algorithms face policy overfitting, which may lead to the joint policy falling into a local optimum. This paper introduces a novel general framework called Learning Joint-Action Intrinsic Reward (LJIR) for improving multi-agent reinforcement learners’ joint exploration ability and performance. LJIR observes agents’ state and joint actions to learn to construct an intrinsic reward online that can guide effective joint exploration. With the novel combination of Transformer and random network distillation, LJIR selects the novel states to give more intrinsic rewards, which help agents find the best joint actions. LJIR can dynamically adjust the weight of exploration and exploitation during training and keep the policy invariance finally. To ensure LJIR seamlessly adopts existing MARL algorithms, we also provide a flexible combination method for intrinsic and external rewards. Empirical results on the SMAC benchmark show that the proposed method achieves state-of-the-art performance in challenging tasks.}
}
@article{HE2023459,
title = {Exploring the role of edge distribution in graph convolutional networks},
journal = {Neural Networks},
volume = {168},
pages = {459-470},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.048},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005440},
author = {Liancheng He and Liang Bai and Xian Yang and Zhuomin Liang and Jiye Liang},
keywords = {Graph Neural Networks, Heterophilous graphs, Node representation learning, Edge distribution, Neighbor selection},
abstract = {Graph Convolutional Networks (GCNs) have shown remarkable performance in processing graph-structured data by leveraging neighborhood information for node representation learning. While most GCN models assume strong homophily within the networks they handle, some models can also handle heterophilous graphs. However, the selection of neighbors participating in the node representation learning process can significantly impact these models’ performance. To address this, we investigate the influence of neighbor selection on GCN performance, focusing on the analysis of edge distribution through theoretical and empirical approaches. Based on our findings, we propose a novel GCN model called Graph Convolution Network with Improved Edge Distribution (GCN-IED). GCN-IED incorporates both direct edges, which rely on local neighborhood similarity, and hidden edges, obtained by aggregating information from multi-hop neighbors. We extensively evaluate GCN-IED on diverse graph benchmark datasets and observe its superior performance compared to other state-of-the-art GCN methods on heterophilous datasets. Our GCN-IED model, which considers the role of neighbors and optimizes edge distribution, provides valuable insights for enhancing graph representation learning and achieving superior performance on heterophilous graphs.}
}
@article{LI2023415,
title = {Information theory-guided heuristic progressive multi-view coding},
journal = {Neural Networks},
volume = {167},
pages = {415-432},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004471},
author = {Jiangmeng Li and Hang Gao and Wenwen Qiang and Changwen Zheng},
keywords = {Self-supervised learning, Representation learning, Multi-view, Wasserstein distance, Information theory},
abstract = {Multi-view representation learning aims to capture comprehensive information from multiple views of a shared context. Recent works intuitively apply contrastive learning to different views in a pairwise manner, which is still scalable: view-specific noise is not filtered in learning view-shared representations; the fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; evenly measuring the similarities between terms might interfere with optimization. Importantly, few works study the theoretical framework of generalized self-supervised multi-view learning, especially for more than two views. To this end, we rethink the existing multi-view learning paradigm from the perspective of information theory and then propose a novel information theoretical framework for generalized multi-view learning. Guided by it, we build a multi-view coding method with a three-tier progressive architecture, namely Information theory-guided heuristic Progressive Multi-view Coding (IPMC). In the distribution-tier, IPMC aligns the distribution between views to reduce view-specific noise. In the set-tier, IPMC constructs self-adjusted contrasting pools, which are adaptively modified by a view filter. Lastly, in the instance-tier, we adopt a designed unified loss to learn representations and reduce the gradient interference. Theoretically and empirically, we demonstrate the superiority of IPMC over state-of-the-art methods.}
}
@article{SI2023143,
title = {Symmetric LINEX loss twin support vector machine for robust classification and its fast iterative algorithm},
journal = {Neural Networks},
volume = {168},
pages = {143-160},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.055},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004756},
author = {Qi Si and Zhixia Yang and Junyou Ye},
keywords = {Robust classification, Symmetric LINEX loss function, Twin support vector machine, Iterative algorithm},
abstract = {Twin support vector machine (TSVM) is a practical machine learning algorithm, whereas traditional TSVM can be limited for data with outliers or noises. To address this problem, we propose a novel TSVM with the symmetric LINEX loss function (SLTSVM) for robust classification. There are several advantages of our method: (1) The performance of the proposed SLTSVM for data with outliers or noise can be improved by using the symmetric LINEX loss function. (2) The introduction of regularization term can effectively improve the generalization ability of our model. (3) An efficient iterative algorithm is developed to solve the optimization problems of our SLTSVM. (4) The convergence and time complexity of the iterative algorithm are analyzed in detail. Furthermore, our model does not involve loss function parameter, which makes our method more competitive. Experimental results on synthetic, benchmark and image datasets with label noises and feature noises demonstrate that our proposed method slightly outperforms other state-of-the-art methods on most datasets.}
}
@article{LEI2023194,
title = {Reliable prediction intervals with directly optimized inductive conformal regression for deep learning},
journal = {Neural Networks},
volume = {168},
pages = {194-205},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004999},
author = {Haocheng Lei and Anthony Bellotti},
keywords = {Conformal prediction, Deep learning, Prediction intervals, Neural networks, Uncertainty estimation},
abstract = {By generating prediction intervals (PIs) to quantify the uncertainty of each prediction in deep learning regression, the risk of wrong predictions can be effectively controlled. High-quality PIs need to be as narrow as possible, whilst covering a preset proportion of real labels. At present, many approaches to improve the quality of PIs can effectively reduce the width of PIs, but they do not ensure that enough real labels are captured. Inductive Conformal Predictor (ICP) is an algorithm that can generate effective PIs which is theoretically guaranteed to cover a preset proportion of data. However, typically ICP is not directly optimized to yield minimal PI width. In this study, we propose Directly Optimized Inductive Conformal Regression (DOICR) for neural networks that takes only the average width of PIs as the loss function and increases the quality of PIs through an optimized scheme, under the validity condition that sufficient real labels are captured in the PIs. Benchmark experiments show that DOICR outperforms current state-of-the-art algorithms for regression problems using underlying Deep Neural Network structures for both tabular and image data.}
}
@article{MA2023350,
title = {Multidomain active defense: Detecting multidomain backdoor poisoned samples via ALL-to-ALL decoupling training without clean datasets},
journal = {Neural Networks},
volume = {168},
pages = {350-362},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005324},
author = {Binhao Ma and Jiahui Wang and Dejun Wang and Bo Meng},
keywords = {Backdoor defense, Multidomain defense, Decoupling neural networks, Active defense, Mutual information},
abstract = {Deep learning is vulnerable to backdoor poisoning attacks in which an attacker can easily embed a hidden backdoor into a trained model by injecting poisoned samples into the training set. Many prior state-of-the-art techniques for detecting backdoor poisoning attacks are based on a potential separability assumption. However, current adaptive poisoning strategies can significantly reduce ’distinguishable behavior’, making most prior state-of-the-art techniques less effective. In addition, we note that existing detection methods are not practical for multidomain datasets and may leak user privacy because they require and collect clean samples. To address the above issues, we propose a multidomain active defense approach that does not use clean datasets. The proposed approach can generate diverse clean samples from different domains and decouple neural networks round by round using clean samples to disassociate features and labels, making backdoor poisoned samples easier to detect without fitting clean samples. We demonstrate the advantage of our approach through an extensive evaluation of CIFAR10, CelebA, MNIST & MNIST-M, MNIST & USPS & MNIST-M, MNIST & USPS & SVHN and CIFAR10 & Tiny-ImageNet.}
}
@article{FARAJI2023502,
title = {CollectiveNet-AltSpec: A collective concurrent CNN architecture of alternate specifications for EEG media perception and emotion tracing aided by multi-domain feature-augmentation},
journal = {Neural Networks},
volume = {167},
pages = {502-516},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004513},
author = {Parham Faraji and Mohammad Bagher Khodabakhshi},
keywords = {Audio–visual cerebral activity, Affective emotion analysis, Deep convolutional neural networks, Collective pattern analysis, Neurocognitive neuroinformatic electroencephalography, Spatiotemporal feature constructs},
abstract = {Enhancing computability of cerebral recordings and connections made with human/non-human brain have been on track and are expected to propel in our current era. An effective contribution towards said ends is improving accuracy of attempts at discerning intricate phenomena taking place within human brain. Here and in two different capacities of experiments, we attempt to distinguish cerebral perceptions shaped and affective states surfaced during observation of samples of media incorporating distinct audio–visual and emotional contents, through employing electroencephalograph/EEG recorded sessions of two reputable datasets of DEAP and SEED. Here we introduce AltSpec(E3) the inceptive form of CollectiveNet intelligent computational architectures employing collective and concurrent multi-spec analysis to exploit complex patterns in complex data-structures. This processing technique uses a full array of diversification protocols with multifarious parts enabling surgical levels of optimization while integrating a holistic analysis of patterns. Data-structures designed here contain multi-electrode neuroinformatic and neurocognitive features studying emotion reactions and attentive patterns. These spatially and temporally featured 2D/3D constructs of domain-augmented data are eventually AI-processed and outputs are defragmented forming one definitive judgement. The media-perception tracing is arguably first of its kind, at least when implemented on mentioned datasets. Backed by this multi-directional approach and in subject-independent configurations for perception-tracing on 5-media-class basis, mean accuracies of 81.00% and 68.93% were obtained on DEAP and SEED, respectively. We also managed to classify emotions with accuracies of 61.59% and 66.21% in cross-dataset validation followed by 81.47% and 88.12% in cross-subject validation settings trained on DEAP and SEED, consecutively.}
}
@article{DUAN2023223,
title = {Self-supervised contrastive graph representation with node and graph augmentation},
journal = {Neural Networks},
volume = {167},
pages = {223-232},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.039},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004598},
author = {Haoran Duan and Cheng Xie and Bin Li and Peng Tang},
keywords = {Self-supervised learning, Graph representation learning, Graph neural network},
abstract = {Graph representation is a critical technology in the field of knowledge engineering and knowledge-based applications since most knowledge bases are represented in the graph structure. Nowadays, contrastive learning has become a prominent way for graph representation by contrasting positive–positive and positive–negative node pairs between two augmentation graphs. It has achieved new state-of-the-art in the field of self-supervised graph representation. However, existing contrastive graph representation methods mainly focus on modifying (normally removing some edges/nodes) the original graph structure to generate the augmentation graph for the contrastive. It inevitably changes the original graph structures, meaning the generated augmentation graph is no longer equivalent to the original graph. This harms the performance of the representation in many structure-sensitive graphs such as protein graphs, chemical graphs, molecular graphs, etc. Moreover, there is only one positive–positive node pair but relatively massive positive–negative node pairs in the self-supervised graph contrastive learning. This can lead to the same class, or very similar samples are considered negative samples. To this end, in this work, we propose a Virtual Masking Augmentation (VMA) to generate an augmentation graph without changing any structures from the original graph. Meanwhile, a node augmentation method is proposed to augment the positive node pairs by discovering the most similar nodes in the same graph. Then, two different augmentation graphs are generated and put into a contrastive learning model to learn the graph representation. Extensive experiments on massive datasets demonstrate that our method achieves new state-of-the-art results on self-supervised graph representation. The source code of the proposed method is available at https://github.com/DuanhaoranCC/CGRA.}
}
@article{PAPP2023517,
title = {DEBI-NN: Distance-encoding biomorphic-informational neural networks for minimizing the number of trainable parameters},
journal = {Neural Networks},
volume = {167},
pages = {517-532},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300446X},
author = {Laszlo Papp and David Haberl and Boglarka Ecsedi and Clemens P. Spielvogel and Denis Krajnc and Marko Grahovac and Sasan Moradi and Wolfgang Drexler},
keywords = {Biomorphic computing, Informational neural network, Distance encoding, Machine learning, Artificial intelligence, Medical AI},
abstract = {Modern artificial intelligence (AI) approaches mainly rely on neural network (NN) or deep NN methodologies. However, these approaches require large amounts of data to train, given, that the number of their trainable parameters has a polynomial relationship to their neuron counts. This property renders deep NNs challenging to apply in fields operating with small, albeit representative datasets such as healthcare. In this paper, we propose a novel neural network architecture which trains spatial positions of neural soma and axon pairs, where weights are calculated by axon-soma distances of connected neurons. We refer to this method as distance-encoding biomorphic-informational (DEBI) neural network. This concept significantly minimizes the number of trainable parameters compared to conventional neural networks. We demonstrate that DEBI models can yield comparable predictive performance in tabular and imaging datasets, where they require a fraction of trainable parameters compared to conventional NNs, resulting in a highly scalable solution.}
}
@article{VENKATESHA2023569,
title = {Divide-and-conquer the NAS puzzle in resource-constrained federated learning systems},
journal = {Neural Networks},
volume = {168},
pages = {569-579},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005609},
author = {Yeshwanth Venkatesha and Youngeun Kim and Hyoungseob Park and Priyadarshini Panda},
keywords = {Neural architecture search, Federated learning},
abstract = {Federated Learning (FL) is a privacy-preserving distributed machine learning approach geared towards applications in edge devices. However, the problem of designing custom neural architectures in federated environments is not tackled from the perspective of overall system efficiency. In this paper, we propose DC-NAS—a divide-and-conquer approach that performs supernet-based Neural Architecture Search (NAS) in a federated system by systematically sampling the search space. We propose a novel diversified sampling strategy that balances exploration and exploitation of the search space by initially maximizing the distance between the samples and progressively shrinking this distance as the training progresses. We then perform channel pruning to reduce the training complexity at the devices further. We show that our approach outperforms several sampling strategies including Hadamard sampling, where the samples are maximally separated. We evaluate our method on the CIFAR10, CIFAR100, EMNIST, and TinyImagenet benchmarks and show a comprehensive analysis of different aspects of federated learning such as scalability, and non-IID data. DC-NAS achieves near iso-accuracy as compared to full-scale federated NAS with 50% fewer resources.}
}
@article{ZHOU2023775,
title = {Sparse discriminant PCA based on contrastive learning and class-specificity distribution},
journal = {Neural Networks},
volume = {167},
pages = {775-786},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.061},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004914},
author = {Qian Zhou and Quanxue Gao and Qianqian Wang and Ming Yang and Xinbo Gao},
keywords = {Principal components analysis, Contrastive learning, Sparse learning, Classification, Class-specificity distribution},
abstract = {Much mathematical effort has been devoted to developing Principal Component Analysis (PCA), which is the most popular feature extraction method. To suppress the negative effect of noise on PCA performance, there have been extensive studies and applications of a large number of robust PCAs achieving outstanding results. However, existing methods suffer from at least two shortcomings: (1) They expressed PCA as a reconstruction model measured by Euclidean distance, which only considers the relationship between the data and its reconstruction and ignores the differences between different data points; (2) They did not consider the class-specificity distribution information contained in the data itself, thus lacking discriminative properties. To overcome the above problems, we propose a Sparse Discriminant Principal Components Analysis (SDPCA) model based on contrastive learning and class-specificity distribution. Specifically, we use contrastive learning to measure the relationship between samples and their reconstructions, which fully takes the discriminative information between data into account in PCA. In order to make the extracted low-dimensional features profoundly reflect the class-specificity distribution of the data, we minimize the squared ℓ1,2-norm of the low-dimensional embedding. In addition, to reduce the effects of redundant features and noise and to improve the interpretability of PCA at the same time, we impose sparsity constraints on the projection matrix using the squared ℓ1,2-norm. Our experimental results on different types of benchmark databases demonstrate that our model has state-of-the-art performance.}
}
@article{STANOJEVIC202374,
title = {An exact mapping from ReLU networks to spiking neural networks},
journal = {Neural Networks},
volume = {168},
pages = {74-88},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005051},
author = {Ana Stanojevic and Stanisław Woźniak and Guillaume Bellec and Giovanni Cherubini and Angeliki Pantazi and Wulfram Gerstner},
keywords = {Spiking neural network, ReLU network, Temporal coding, Single-spike network, Deep network conversion},
abstract = {Deep spiking neural networks (SNNs) offer the promise of low-power artificial intelligence. However, training deep SNNs from scratch or converting deep artificial neural networks to SNNs without loss of performance has been a challenge. Here we propose an exact mapping from a network with Rectified Linear Units (ReLUs) to an SNN that fires exactly one spike per neuron. For our constructive proof, we assume that an arbitrary multi-layer ReLU network with or without convolutional layers, batch normalization and max pooling layers was trained to high performance on some training set. Furthermore, we assume that we have access to a representative example of input data used during training and to the exact parameters (weights and biases) of the trained ReLU network. The mapping from deep ReLU networks to SNNs causes zero percent drop in accuracy on CIFAR10, CIFAR100 and the ImageNet-like data sets Places365 and PASS. More generally our work shows that an arbitrary deep ReLU network can be replaced by an energy-efficient single-spike neural network without any loss of performance.}
}
@article{XIE2023638,
title = {Visual question generation for explicit questioning purposes based on target objects},
journal = {Neural Networks},
volume = {167},
pages = {638-647},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004264},
author = {Jiayuan Xie and Jiali Chen and Wenhao Fang and Yi Cai and Qing Li},
keywords = {Visual question generation, Questioning purposes, Target object},
abstract = {Visual question generation aims to focus on some target objects in an image to generate questions with certain questioning purposes. Existing studies mainly utilize an answer to extract the target object corresponding to the questioning purpose for questioning. However, answers fail to accurately and completely map to every target object, such as the objects corresponding to the answer are ambiguous or the answers are the relationship between multiple objects. To address this problem, we propose a content-controlled question generation model, which generates questions based on a given target object set specified from an image. Considering that the target objects have different contributions during the generation process, we design a recurrent generative architecture to explicitly control attention to different objects and their corresponding image information at each generative stage. Extensive experiments on the VQA v2.0 dataset and the Visual7w dataset show that the proposed model outperforms the state-of-the-art models and can controllably generate questions with specified content.}
}
@article{WU2023206,
title = {Adaptive neural network control for Markov jumping systems against deception attacks},
journal = {Neural Networks},
volume = {168},
pages = {206-213},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300518X},
author = {Junhui Wu and Gang Qin and Jun Cheng and Jinde Cao and Huaicheng Yan and Iyad Katib},
keywords = {Deception attacks, Security control, Neural network, Markov chain},
abstract = {This paper proposes an innovative approach for mitigating the effects of deception attacks in Markov jumping systems by developing an adaptive neural network control strategy. To address the challenge of dual-mode monitoring mechanisms, two independent Markov chains are used to describe the state changes of the system and the intermittent actuator. By employing a mapping technique, these individual chains are amalgamated into a unified joint Markov chain. Additionally, to effectively approximate the unbounded false signals injected by deception attacks, an adaptive neural network technique is skillfully built. A mode monitoring scheme is implemented to design an asynchronous control law that links the mode information between the joint Markov chain and controller with fewer modes. The paper derives sufficient criteria for the mean-square bounded stability of the resulting system based on Lyapunov theories. Finally, a numerical experiment is conducted to demonstrate the effectiveness of the proposed method.}
}
@article{LIN2023331,
title = {Adaptive dynamic programming-based hierarchical decision-making of non-affine systems},
journal = {Neural Networks},
volume = {167},
pages = {331-341},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.044},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004021},
author = {Danyu Lin and Shan Xue and Derong Liu and Mingming Liang and Yonghua Wang},
keywords = {Adaptive dynamic programming, Multiplayer Stackelberg game, Non-affine systems, Neural networks},
abstract = {In this paper, the problem of multiplayer hierarchical decision-making problem for non-affine systems is solved by adaptive dynamic programming. Firstly, the control dynamics are obtained according to the theory of dynamic feedback and combined with the original system dynamics to construct the affine augmented system. Thus, the non-affine multiplayer system is transformed into a general affine form. Then, the hierarchical decision problem is modeled as a Stackelberg game. In the Stackelberg game, the leader makes a decision based on the information of all followers, whereas the followers do not know each other’s information and only obtain their optimal control strategy based on the leader’s decision. Then, the augmented system is reconstructed by a neural network (NN) using input–output data. Moreover, a single critic NN is used to approximate the value function to obtain the optimal control strategy for each player. An extra term added to the weight update law makes the initial admissible control law no longer needed. According to the Lyapunov theory, the state of the system and the error of the weights of the NN are both uniformly ultimately bounded. Finally, the feasibility and validity of the algorithm are confirmed by simulation.}
}
@article{CHENG2023460,
title = {Communication-efficient federated learning with stagewise training strategy},
journal = {Neural Networks},
volume = {167},
pages = {460-472},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004549},
author = {Yifei Cheng and Shuheng Shen and Xianfeng Liang and Jingchang Liu and Joya Chen and Tie Zhang and Enhong Chen},
keywords = {Federated learning, Optimization algorithm, Communication complexity, Convergence rate},
abstract = {The efficiency of communication across workers is a significant factor that affects the performance of federated learning. Though periodic communication strategy is applied to reduce communication rounds in training, the communication cost is still high when the training data distributions are not independently and identically distributed (non-IID) which is common in federated learning. Recently, some works introduce variance reduction to eliminate the effect caused by non-IID data among workers. Nevertheless the provable optimal communication complexity O(log(ST)) and convergence rate O(1/(ST)) cannot be achieved simultaneously, where S denotes the number of sampled workers in each round and T is the number of iterations. To deal with this dilemma, we propose an optimization algorithm SQUARFA that adopts stagewise training framework coupling with variance reduction and uses a quick-start phase in each loop. Theoretical results show that SQUARFA achieves both optimal convergence rate and communication complexity for both strongly convex objectives and non-convex objectives under PL condition, thus fills the gap mentioned above. Then, a variant of SQUARFA yields the optimal theoretical results for general non-convex objectives. We further extend the technique in SQUARFA to the large batch setting and achieve optimal communication complexity. Experimental results demonstrate the superiority of the proposed algorithms.}
}
@article{FAN202344,
title = {An Adversarial Time–Frequency Reconstruction Network for Unsupervised Anomaly Detection},
journal = {Neural Networks},
volume = {168},
pages = {44-56},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005117},
author = {Jin Fan and Zehao Wang and Huifeng Wu and Danfeng Sun and Jia Wu and Xin Lu},
keywords = {Anomaly detection, Unsupervised anomaly detection, Neural networks},
abstract = {Detecting anomalies in massive volumes of multivariate time series data, particularly in the IoT domain, is critical for maintaining stable systems. Existing anomaly detection models based on reconstruction techniques face challenges in distinguishing normal and abnormal samples from unlabeled data, leading to performance degradation. Moreover, accurately reconstructing abnormal values and pinpointing anomalies remains a limitation. To address these issues, we introduce the Adversarial Time–Frequency Reconstruction Network for Unsupervised Anomaly Detection (ATF-UAD). ATF-UAD consists of a time reconstructor, a frequency reconstructor and a dual-view adversarial learning mechanism. The time reconstructor utilizes a parity sampling mechanism to weaken the dependency between neighboring points. Then attention mechanisms and graph convolutional networks (GCNs) are used to update the feature information for each point, which combines points with close feature relationships and dilutes the influence of abnormal points on normal points. The frequency reconstructor transforms the input sequence into the frequency domain using a Fourier transform and extracts the relationship between frequencies to reconstruct anomalous frequency bands. The dual-view adversarial learning mechanism aims to maximize the normal values in the reconstructed sequences and highlight anomalies and aid in their localization within the data. Through dual-view adversarial learning, ATF-UAD minimizes reconstructed value errors and maximizes the identification of residual outliers. We conducted extensive experiments on nine datasets from different domains, and ATF-UAD showed an average improvement of 6.94% in terms of F1 score compared to the state-of-the-art method.}
}
@article{UKITA2023875,
title = {Adversarial attacks and defenses using feature-space stochasticity},
journal = {Neural Networks},
volume = {167},
pages = {875-889},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004422},
author = {Jumpei Ukita and Kenichi Ohki},
keywords = {Adversarial attack, Adversarial defense, Feature smoothing},
abstract = {Recent studies in deep neural networks have shown that injecting random noise in the input layer of the networks contributes towards ℓp-norm-bounded adversarial perturbations. However, to defend against unrestricted adversarial examples, most of which are not ℓp-norm-bounded in the input layer, such input-layer random noise may not be sufficient. In the first part of this study, we generated a novel class of unrestricted adversarial examples termed feature-space adversarial examples. These examples are far from the original data in the input space but adjacent to the original data in a hidden-layer feature space and far again in the output layer. In the second part of this study, we empirically showed that while injecting random noise in the input layer was unable to defend these feature-space adversarial examples, they were defended by injecting random noise in the hidden layer. These results highlight the novel benefit of stochasticity in higher layers, in that it is useful for defending against these feature-space adversarial examples, a class of unrestricted adversarial examples.}
}
@article{LIU2023559,
title = {On exploring node-feature and graph-structure diversities for node drop graph pooling},
journal = {Neural Networks},
volume = {167},
pages = {559-571},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.046},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004665},
author = {Chuang Liu and Yibing Zhan and Baosheng Yu and Liu Liu and Bo Du and Wenbin Hu and Tongliang Liu},
keywords = {Graph neural networks, Graph pooling, Graph classification},
abstract = {Graph Neural Networks (GNNs) have been successfully applied to graph-level tasks in various fields such as biology, social networks, computer vision, and natural language processing. For the graph-level representations learning of GNNs, graph pooling plays an essential role. Among many pooling techniques, node drop pooling has garnered significant attention and is considered as a leading approach. However, existing node drop pooling methods, which typically retain the top-k nodes based on their significance scores, often overlook the diversity inherent in node features and graph structures. This limitation leads to suboptimal graph-level representations. To overcome this, we introduce a groundbreaking plug-and-play score scheme, termed MID. MID comprises a Multidimensional score space and two key operations: flIpscore and Dropscore. The multidimensional score space depicts the significance of nodes by multiple criteria; the flipscore process promotes the preservation of distinct node features; the dropscore compels the model to take into account a range of graph structures rather than focusing on local structures. To evaluate the effectiveness of our proposed MID, we have conducted extensive experiments by integrating it with a broad range of recent node drop pooling methods, such as TopKPool, SAGPool, GSAPool, and ASAP. In particular, MID has proven to bring a significant average improvement of approximately 2.8% over the four aforementioned methods when tested on 17 real-world graph classification datasets. Code is available at https://github.com/whuchuang/mid.}
}
@article{ZHAO2023648,
title = {Contrastive self-representation learning for data clustering},
journal = {Neural Networks},
volume = {167},
pages = {648-655},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.050},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004707},
author = {Wenhui Zhao and Quanxue Gao and Shikun Mei and Ming Yang},
keywords = {Self-representation, Contrastive learning, Subspace clustering},
abstract = {This paper is concerned with self-representation subspace learning. It is one of the most representative subspace techniques, which has attracted considerable attention for clustering due to its good performance. Among these methods, low-rank representation (LRR) has achieved impressive results for subspace clustering. However, it only considers the similarity between the data itself, while neglecting the differences with other samples. Besides, it cannot well deal with noise and portray cluster-to-cluster relationships well. To solve these problems, we propose a Contrastive Self-representation model for Clustering (CSC). CSC simultaneously takes into account the similarity/dissimilarity between positive/negative pairs when learning the self-representation coefficient matrix of data while the form of the loss function can reduce the effect of noise on the results. Moreover, We use the ℓ1,2-norm regularizer on the coefficient matrix to achieve its sparsity to better characterize the cluster structure. Thus, the learned self-representation coefficient matrix well encodes both the discriminative information and cluster structure. Extensive experiments on seven benchmark databases indicate the superiority of our proposed method.}
}
@article{JANTRE2023309,
title = {Layer adaptive node selection in Bayesian neural networks: Statistical guarantees and implementation details},
journal = {Neural Networks},
volume = {167},
pages = {309-330},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004495},
author = {Sanket Jantre and Shrijita Bhattacharya and Tapabrata Maiti},
keywords = {Node selection, Dynamic pruning, Model compression, Spike-and-slab priors, Variational inference, Contraction rates},
abstract = {Sparse deep neural networks have proven to be efficient for predictive model building in large-scale studies. Although several works have studied theoretical and numerical properties of sparse neural architectures, they have primarily focused on the edge selection. Sparsity through edge selection might be intuitively appealing; however, it does not necessarily reduce the structural complexity of a network. Instead pruning excessive nodes leads to a structurally sparse network with significant computational speedup during inference. To this end, we propose a Bayesian sparse solution using spike-and-slab Gaussian priors to allow for automatic node selection during training. The use of spike-and-slab prior alleviates the need of an ad-hoc thresholding rule for pruning. In addition, we adopt a variational Bayes approach to circumvent the computational challenges of traditional Markov Chain Monte Carlo (MCMC) implementation. In the context of node selection, we establish the fundamental result of variational posterior consistency together with the characterization of prior parameters. In contrast to the previous works, our theoretical development relaxes the assumptions of the equal number of nodes and uniform bounds on all network weights, thereby accommodating sparse networks with layer-dependent node structures or coefficient bounds. With a layer-wise characterization of prior inclusion probabilities, we discuss the optimal contraction rates of the variational posterior. We empirically demonstrate that our proposed approach outperforms the edge selection method in computational complexity with similar or better predictive performance. Our experimental evidence further substantiates that our theoretical work facilitates layer-wise optimal node recovery.}
}
@article{FARAHAT2023400,
title = {A novel feature-scrambling approach reveals the capacity of convolutional neural networks to learn spatial relations},
journal = {Neural Networks},
volume = {167},
pages = {400-414},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004410},
author = {Amr Farahat and Felix Effenberger and Martin Vinck},
keywords = {Computer vision, Object recognition, Visual cortex, CNNs, Shape representations, Texture bias},
abstract = {Convolutional neural networks (CNNs) are one of the most successful computer vision systems to solve object recognition. Furthermore, CNNs have major applications in understanding the nature of visual representations in the human brain. Yet it remains poorly understood how CNNs actually make their decisions, what the nature of their internal representations is, and how their recognition strategies differ from humans. Specifically, there is a major debate about the question of whether CNNs primarily rely on surface regularities of objects, or whether they are capable of exploiting the spatial arrangement of features, similar to humans. Here, we develop a novel feature-scrambling approach to explicitly test whether CNNs use the spatial arrangement of features (i.e. object parts) to classify objects. We combine this approach with a systematic manipulation of effective receptive field sizes of CNNs as well as minimal recognizable configurations (MIRCs) analysis. In contrast to much previous literature, we provide evidence that CNNs are in fact capable of using relatively long-range spatial relationships for object classification. Moreover, the extent to which CNNs use spatial relationships depends heavily on the dataset, e.g. texture vs. sketch. In fact, CNNs even use different strategies for different classes within heterogeneous datasets (ImageNet), suggesting CNNs have a continuous spectrum of classification strategies. Finally, we show that CNNs learn the spatial arrangement of features only up to an intermediate level of granularity, which suggests that intermediate rather than global shape features provide the optimal trade-off between sensitivity and specificity in object classification. These results provide novel insights into the nature of CNN representations and the extent to which they rely on the spatial arrangement of features for object classification.}
}
@article{ZHAO2023180,
title = {Dynamic sparse coding-based value estimation network for deep reinforcement learning},
journal = {Neural Networks},
volume = {168},
pages = {180-193},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005063},
author = {Haoli Zhao and Zhenni Li and Wensheng Su and Shengli Xie},
keywords = {Deep reinforcement learning, Value estimation network, Dynamic sparse coding},
abstract = {Deep Reinforcement Learning (DRL) is one powerful tool for varied control automation problems. Performances of DRL highly depend on the accuracy of value estimation for states from environments. However, the Value Estimation Network (VEN) in DRL can be easily influenced by the phenomenon of catastrophic interference from environments and training. In this paper, we propose a Dynamic Sparse Coding-based (DSC) VEN model to obtain precise sparse representations for accurate value prediction and sparse parameters for efficient training, which is not only applicable in Q-learning structured discrete-action DRL but also in actor–critic structured continuous-action DRL. In detail, to alleviate interference in VEN, we propose to employ DSC to learn sparse representations for accurate value estimation with dynamic gradients beyond the conventional ℓ1 norm that provides same-value gradients. To avoid influences from redundant parameters, we employ DSC to prune weights with dynamic thresholds more efficiently than static thresholds like ℓ1 norm. Experiments demonstrate that the proposed algorithms with dynamic sparse coding can obtain higher control performances than existing benchmark DRL algorithms in both discrete-action and continuous-action environments, e.g., over 25% increase in Puddle World and about 10% increase in Hopper. Moreover, the proposed algorithm can reach convergence efficiently with fewer episodes in different environments.}
}
@article{PEREG2023445,
title = {Information theoretic perspective on sample complexity},
journal = {Neural Networks},
volume = {167},
pages = {445-449},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004537},
author = {Deborah Pereg},
keywords = {Information theory, Supervised learning, Sample complexity, Generalization},
abstract = {The statistical supervised learning framework assumes an input–output set with a joint probability distribution that is reliably represented by the training dataset. The learning system is then required to output a prediction rule learned from the training dataset’s input–output pairs. In this work, we investigate the relationship between the sample complexity, the empirical risk and the generalization error based on the asymptotic equipartition property (AEP) (Shannon, 1948). We provide theoretical guarantees for reliable learning under the information-theoretic AEP, with respect to the generalization error and the sample size in different settings.}
}
@article{LI2023471,
title = {EQNAS: Evolutionary Quantum Neural Architecture Search for Image Classification},
journal = {Neural Networks},
volume = {168},
pages = {471-483},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.040},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005348},
author = {Yangyang Li and Ruijiao Liu and Xiaobin Hao and Ronghua Shang and Peixiang Zhao and Licheng Jiao},
keywords = {Quantum neural networks (QNN), Neural architecture search (NAS), Quantum evolutionary algorithm (QEA), Quantum circuits},
abstract = {Quantum neural network (QNN) is a neural network model based on the principles of quantum mechanics. The advantages of faster computing speed, higher memory capacity, smaller network size and elimination of catastrophic amnesia make it a new idea to solve the problem of training massive data that is difficult for classical neural networks. However, the quantum circuit of QNN are artificially designed with high circuit complexity and low precision in classification tasks. In this paper, a neural architecture search method EQNAS is proposed to improve QNN. First, initializing the quantum population after image quantum encoding. The next step is observing the quantum population and evaluating the fitness. The last is updating the quantum population. Quantum rotation gate update, quantum circuit construction and entirety interference crossover are specific operations. The last two steps need to be carried out iteratively until a satisfactory fitness is achieved. After a lot of experiments on the searched quantum neural networks, the feasibility and effectiveness of the algorithm proposed in this paper are proved, and the searched QNN is obviously better than the original algorithm. The classification accuracy on the mnist dataset and the warship dataset not only increased by 5.31% and 4.52%, respectively, but also reduced the parameters by 21.88% and 31.25% respectively. Code will be available at https://gitee.com/Pcyslist/models/tree/master/research/cv/EQNAS, and https://github.com/Pcyslist/EQNAS.}
}
@article{CHEN2023118,
title = {Structure-aware deep clustering network based on contrastive learning},
journal = {Neural Networks},
volume = {167},
pages = {118-128},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004379},
author = {Bowei Chen and Sen Xu and Heyang Xu and Xuesheng Bian and Naixuan Guo and Xiufang Xu and Xiaopeng Hua},
keywords = {Deep clustering, Contrastive learning, Auto-encoder, Graph auto-encoder},
abstract = {Recently, deep clustering has been extensively employed for various data mining tasks, and it can be divided into auto-encoder (AE)-based and graph neural networks (GNN)-based methods. However, existing AE-based methods fall short in effectively extracting structural information, while GNN suffer from smoothing and heterophily. Although methods that combine AE and GNN achieve impressive performance, there remains an inadequate balance between preserving the raw structure and exploring the underlying structure. Accordingly, we propose a novel network named Structure-Aware Deep Clustering network (SADC). Firstly, we compute the cumulative influence of non-adjacent nodes at multiple depths and, thus, enhance the adjacency matrix. Secondly, an enhanced graph auto-encoder is designed. Thirdly, the latent space of AE is endowed with the ability to perceive the raw structure during the learning process. Besides, we design self-supervised mechanisms to achieve co-optimization of node representation learning and topology learning. A new loss function is designed to preserve the inherent structure while also allowing for exploration of latent data structure. Extensive experiments on six benchmark datasets validate that our method outperforms state-of-the-art methods.}
}
@article{MIRKAZEMY2023865,
title = {Mathematical expression recognition using a new deep neural model},
journal = {Neural Networks},
volume = {167},
pages = {865-874},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.045},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004653},
author = {Abolfazl Mirkazemy and Peyman Adibi and Seyed Mohhamad Saied Ehsani and Alireza Darvishy and Hans-Peter Hutter},
keywords = {Mathematical expression recognition, Deep learning, Encoder–decoder​ architecture, Attention, Scientific documents accessibility},
abstract = {In this paper, we propose a novel deep neural model for Mathematical Expression Recognition (MER). The proposed model uses encoder–decoder transformer architecture that is supported by additional pre/post-processing modules, to recognize the image of mathematical formula and convert it to a well-formed language. A novel pre-processing module based on domain prior knowledge is proposed to generate random pads around the formula’s image to create more efficient feature maps and keeps all the encoder neurons active during the training process. Also, a new post-processing module is developed which uses a sliding window to extract additional position-based information from the feature map, that is proved to be useful in the recognition process. The recurrent decoder module uses the combination of feature maps and the additional position-based information, which takes advantage of a soft attention mechanism, to extract the formula context into the LaTeX well-formed language. Finally, a novel Reinforcement Learning (RL) module processes the decoder output and tunes its results by sending proper feedbacks to the previous steps. The experimental results on im2latex-100k benchmark dataset indicate that each devised pre/post-processing as well as the RL refinement module has a positive effect on the performance of the proposed model. The results also demonstrate the higher accuracy of the proposed model compared to the state-of-the-art methods.}
}
@article{HUANG2023123,
title = {Bifurcations of a delayed fractional-order BAM neural network via new parameter perturbations},
journal = {Neural Networks},
volume = {168},
pages = {123-142},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.060},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004896},
author = {Chengdai Huang and Huanan Wang and Heng Liu and Jinde Cao},
keywords = {Self-regulating parameter, Implicit array, Hopf bifurcation, Fractional-order, Bidirectional associative memory neural network},
abstract = {This paper makes a new breakthrough in deliberating the bifurcations of fractional-order bidirectional associative memory neural network (FOBAMNN). In the beginning, the corresponding bifurcation results are established according to self-regulating parameter, which is different from bifurcation outcomes available by using time delay as the bifurcation parameter, and greatly enriches the bifurcation results of continuous neural networks(NNs). The deived results manifest that a larger self-regulating parameter is more conducive to the stability of the system, which is consistent with the actual meaning of the self-regulating parameter representing the decay rate of activity. In addition to the innovation in the research object, this paper also has innovation in the procedure of calculating the bifurcation critical point. In the face of the quartic equation about the bifurcation parameters, this paper utilizes the methodology of implicit array to calculate the bifurcation critical point succinctly and effectively, which eschews the disadvantages of the conventional Ferrari approach, such as cumbersome formula and huge computational efforts. Our developed technique can be employed as a general method to solve the bifurcation point including the problem of dealing with the bifurcation critical point of delay. Ultimately, numerical experiments test the key theoretical fruits of this paper.}
}
@article{HE2023706,
title = {Boosting adversarial robustness via self-paced adversarial training},
journal = {Neural Networks},
volume = {167},
pages = {706-714},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.063},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004938},
author = {Lirong He and Qingzhong Ai and Xincheng Yang and Yazhou Ren and Qifan Wang and Zenglin Xu},
keywords = {Adversarial training, Adversarial robustness, Self-paced learning},
abstract = {Adversarial training is considered one of the most effective methods to improve the adversarial robustness of deep neural networks. Despite the success, it still suffers from unsatisfactory performance and overfitting. Considering the intrinsic mechanism of adversarial training, recent studies adopt the idea of curriculum learning to alleviate overfitting. However, this also introduces new issues, that is, lacking the quantitative criterion for attacks’ strength and catastrophic forgetting. To mitigate such issues, we propose the self-paced adversarial training (SPAT), which explicitly builds the learning process of adversarial training based on adversarial examples of the whole dataset. Specifically, our model is first trained with “easy” adversarial examples, and then is continuously enhanced by gradually adding “complex” adversarial examples. This way strengthens the ability to fit “complex” adversarial examples while holding in mind “easy” adversarial samples. To balance adversarial examples between classes, we determine the difficulty of the adversarial examples locally in each class. Notably, this learning paradigm can also be incorporated into other advanced methods for further boosting adversarial robustness. Experimental results show the effectiveness of our proposed model against various attacks on widely-used benchmarks. Especially, on CIFAR100, SPAT provides a boost of 1.7% (relatively 5.4%) in robust accuracy on the PGD10 attack and 3.9% (relatively 7.2%) in natural accuracy for AWP.}
}
@article{CHEN2023394,
title = {Lower and upper bounds for numbers of linear regions of graph convolutional networks},
journal = {Neural Networks},
volume = {168},
pages = {394-404},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005191},
author = {Hao Chen and Yu Guang Wang and Huan Xiong},
keywords = {Graph convolutional networks, GCNs, Linear regions, Expressivity, ReLU, Graph neural networks},
abstract = {Graph neural networks (GNNs) have become a popular choice for analyzing graph data in the last few years, and characterizing their expressiveness has become an active area of research. One popular measure of expressiveness is the number of linear regions in neural networks with piecewise linear activations. In this paper, we present estimates for the number of linear regions in classic graph convolutional networks (GCNs) with one layer and multiple-layer scenarios and ReLU activation function. We derive an optimal upper bound for the maximum number of linear regions for one-layer GCNs and upper and lower bounds for multi-layer GCNs. Our simulated results suggest that the true maximum number of linear regions is likely closer to our estimated lower bound. These findings indicate that multi-layer GCNs have exponentially greater expressivity than one-layer GCNs per parameter, implying that deeper GCNs are more expressive than their shallow counterparts.}
}
@article{MOORTHY2023360,
title = {Learning dynamic spatial-temporal regularized correlation filter tracking with response deviation suppression via multi-feature fusion},
journal = {Neural Networks},
volume = {167},
pages = {360-379},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004380},
author = {Sathishkumar Moorthy and Young Hoon Joo},
keywords = {Feature fusion, Correlation filters, Spatial–temporal information, Response deviation-suppression, Visual tracking},
abstract = {Visual object tracking (VOT) for intelligent video surveillance has attracted great attention in the current research community, thanks to advances in computer vision and camera technology. Meanwhile, discriminative correlation filter (DCF) trackers garnered significant interest owing to their high accuracy and low computing cost. Many researchers have introduced spatial and temporal regularization into the DCF framework to achieve a more robust appearance model and further improve tracking performance. However, these algorithms typically set fixed spatial and temporal regularization parameters, which limit flexibility and adaptability under cluttered and challenging scenarios. To overcome these problems, in this work, we propose a new dynamic spatial–temporal regularization for the DCF tracking model that emphasizes the filter to concentrate on more reliable regions during the training stage. Furthermore, we present a response deviation-suppressed regularization term for responses to encourage temporal consistency and avoid model degradation by suppressing relative response changes between two consecutive frames. Moreover, we introduce a multi-memory tracking framework to exploit various features and each memory contributes to tracking the target across all frames. Significant experiments on the OTB-2013, OTB-2015, TC-128, UAV-123, UAVDT, and DTB-70 datasets have revealed that the performance thereof outperformed many state-of-the-art trackers based on DCF and deep-based frameworks in terms of tracking accuracy and tracking success rate.}
}
@article{ZHAO2023560,
title = {Deep graph reconstruction for multi-view clustering},
journal = {Neural Networks},
volume = {168},
pages = {560-568},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005531},
author = {Mingyu Zhao and Weidong Yang and Feiping Nie},
keywords = {Graph reconstruction, Deep learning, Multi-view clustering, Auto-weighted},
abstract = {Graph-based multi-view clustering methods have achieved impressive success by exploring a complemental or independent graph embedding with low-dimension among multiple views. The majority of them, however, are shallow models with limited ability to learn the nonlinear information in multi-view data. To this end, we propose a novel deep graph reconstruction (DGR) framework for multi-view clustering, which contains three modules. Specifically, a Multi-graph Fusion Module (MFM) is employed to obtain the consensus graph. Then node representation is learned by the Graph Embedding Network (GEN). To assign clusters directly, the Clustering Assignment Module (CAM) is devised to obtain the final low-dimensional graph embedding, which can serve as the indicator matrix. In addition, a simple and powerful loss function is designed in the proposed DGR. Extensive experiments on seven real-world datasets have been conducted to verify the superior clustering performance and efficiency of DGR compared with the state-of-the-art methods.}
}
@article{SACOUTO202332,
title = {Competitive learning to generate sparse representations for associative memory},
journal = {Neural Networks},
volume = {168},
pages = {32-43},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005014},
author = {Luis Sacouto and Andreas Wichert},
keywords = {Sparse coding, Associative memory, Autoencoders, Brain-inspired models},
abstract = {One of the most well established brain principles, Hebbian learning, has led to the theoretical concept of neural assemblies. Based on it, many interesting brain theories have spawned. Palm’s work implements this concept through multiple binary Willshaw associative memories, in a model that not only has a wide cognitive explanatory power but also makes neuroscientific predictions. Yet, Willshaw’s associative memory can only achieve top capacity when the stored vectors are extremely sparse (number of active bits can grow logarithmically with the vector’s length). This strict requirement makes it difficult to apply any model that uses this associative memory, like Palm’s, to real data. Hence the fact that most works apply the memory to optimal randomly generated codes that do not represent any information. This issue creates the need for encoders that can take real data, and produce sparse representations - a problem which is also raised following Barlow’s efficient coding principle. In this work, we propose a biologically-constrained network that encodes images into codes that are suitable for Willshaw’s associative memory. The network is organized into groups of neurons that specialize on local receptive fields, and learn through a competitive scheme. After conducting auto- and hetero-association experiments on two visual data sets, we can conclude that our network not only beats sparse coding baselines, but also that it comes close to the performance achieved using optimal random codes.}
}
@article{ZHU2023287,
title = {Synergetic learning for unknown nonlinear H∞ control using neural networks},
journal = {Neural Networks},
volume = {168},
pages = {287-299},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005257},
author = {Liao Zhu and Ping Guo and Qinglai Wei},
keywords = {H control, Nonlinear systems, Adaptive dynamic programming, Temporal difference, Neural network, Data-driven},
abstract = {The well-known H∞ control design gives robustness to a controller by rejecting perturbations from the external environment, which is difficult to do for completely unknown affine nonlinear systems. Accordingly, the immediate objective of this paper is to develop an on-line real-time synergetic learning algorithm, so that a data-driven H∞ controller can be received. By converting the H∞ control problem into a two-player zero-sum game, a model-free Hamilton–Jacobi–Isaacs equation (MF-HJIE) is first derived using off-policy reinforcement learning, followed by a proof of equivalence between the MF-HJIE and the conventional HJIE. Next, by applying the temporal difference to the MF-HJIE, a synergetic evolutionary rule with experience replay is designed to learn the optimal value function, the optimal control, and the worst perturbation, that can be performed on-line and in real-time along the system state trajectory. It is proven that the synergistic learning system constructed by the system plant and the evolutionary rule is uniformly ultimately bounded. Finally, simulation results on an F16 aircraft system and a nonlinear system back up the tractability of the proposed method.}
}
@article{LIU2023213,
title = {HMM-GDAN: Hybrid multi-view and multi-scale graph duplex-attention networks for drug response prediction in cancer},
journal = {Neural Networks},
volume = {167},
pages = {213-222},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004562},
author = {Youfa Liu and Shufan Tong and Yongyong Chen},
keywords = {Graph neural networks, Drug response prediction, Multi-view graph, Attention mechanism},
abstract = {Precision medicine is devoted to discovering personalized therapy for complex and difficult diseases like cancer. Many machine learning approaches have been developed for drug response prediction towards precision medicine. Notwithstanding, genetic profiles based multi-view graph learning schemes have not yet been explored for drug response prediction in previous works. Furthermore, multi-scale latent feature fusion is not considered sufficiently in the existing frameworks of graph neural networks (GNNs). Previous works on drug response prediction mainly depend on sequence data or single-view graph data. In this paper, we propose to construct multi-view graph by means of multi-omics data and STRING protein–protein association data, and develop a new architecture of GNNs for drug response prediction in cancer. Specifically, we propose hybrid multi-view and multi-scale graph duplex-attention networks (HMM-GDAN), in which both multi-view self-attention mechanism and view-level attention mechanism are devised to capture the complementary information of views and emphasize on the importance of each view collaboratively, and rich multi-scale features are constructed and integrated to further form high-level representations for better prediction. Experiments on GDSC2 dataset verify the superiority of the proposed HMM-GDAN when compared with state-of-the-art baselines. The effectiveness of multi-view and multi-scale strategies is demonstrated by the ablation study.}
}
@article{VOINA2023615,
title = {A biologically inspired architecture with switching units can learn to generalize across backgrounds},
journal = {Neural Networks},
volume = {168},
pages = {615-630},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005099},
author = {Doris Voina and Eric Shea-Brown and Stefan Mihalas},
keywords = {Switching network, Bio-inspired, Context, Generalization, Continual learning, Domain adaptation},
abstract = {Humans and other animals navigate different environments effortlessly, their brains rapidly and accurately generalizing across contexts. Despite recent progress in deep learning, this flexibility remains a challenge for many artificial systems. Here, we show how a bio-inspired network motif can explicitly address this issue. We do this using a dataset of MNIST digits of varying transparency, set on one of two backgrounds of different statistics that define two contexts: a pixel-wise noise or a more naturalistic background from the CIFAR-10 dataset. After learning digit classification when both contexts are shown sequentially, we find that both shallow and deep networks have sharply decreased performance when returning to the first background — an instance of the catastrophic forgetting phenomenon known from continual learning. To overcome this, we propose the bottleneck-switching network or switching network for short. This is a bio-inspired architecture analogous to a well-studied network motif in the visual cortex, with additional “switching” units that are activated in the presence of a new background, assuming a priori a contextual signal to turn these units on or off. Intriguingly, only a few of these switching units are sufficient to enable the network to learn the new context without catastrophic forgetting through inhibition of redundant background features. Further, the bottleneck-switching network can generalize to novel contexts similar to contexts it has learned. Importantly, we find that — again as in the underlying biological network motif, recurrently connecting the switching units to network layers is advantageous for context generalization.}
}
@article{LONG202314,
title = {FOESO-Net: A specific neural network for fast sensorless robot manipulator torque estimation},
journal = {Neural Networks},
volume = {168},
pages = {14-31},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005130},
author = {Shike Long and Xuanju Dang and Jia Huang},
keywords = {Contact torque sensing, Extended state observer, Neural network, Fractional order},
abstract = {Contact torque sensing allows robot manipulators to cooperate with humans and detect accidental collisions in real time to ensure safety. Most sensorless torque estimation schemes, which are based on linear observer approaches, cannot compromise between non-negligible noise and high observation bandwidth. Therefore, fast time-varying nonlinear torque observation cannot be satisfied. To achieve this challenge, a customized network called FOESO-Net based on a novel fractional-order extended state observer is carefully designed in this paper. The network firstly chooses momentum as the benchmark state for torque estimation, which can avoid joint acceleration and model’s inverse inertia matrix solution. Then, a fractional-order extended state observer (FOESO) is proposed from the perspective of momentum control to better adapt to the nonlinear fast time varying torque. In addition, a fractional-order neural network and a weight update neural network parallel architecture are constructed to enable fractional-order and dynamic weight-based adaptive learning of FOESO parameters. Formal analysis and proofs are made to show that the error of FOESO-Net is convergent. Finally, the effectiveness of the proposed method is verified by numerical simulations and a real collaborative robot platform. Moreover, compared with existing methods, the FOESO-Net based torque estimation method can reduce the estimation error and response time, which illustrates the superiority of the designed method.}
}
@article{ZHOU2023615,
title = {Hierarchical Knowledge Propagation and Distillation for Few-Shot Learning},
journal = {Neural Networks},
volume = {167},
pages = {615-625},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004604},
author = {Chunpeng Zhou and Haishuai Wang and Sheng Zhou and Zhi Yu and Danushka Bandara and Jiajun Bu},
keywords = {Few-Shot Learning, Knowledge Distillation, Inductive learning, Feature representation, Classification},
abstract = {Recent research efforts on Few-Shot Learning (FSL) have achieved extensive progress. However, the existing efforts primarily focus on the transductive setting of FSL, which is heavily challenged by the limited quantity of the unlabeled query set. Although a few inductive-based FSL methods have been studied, most of them emphasize learning superb feature extraction networks. As a result, they may ignore the relations between sample-level and class-level representations, which are particularly crucial when labeled samples are scarce. This paper proposes an inductive FSL framework that leverages the Hierarchical Knowledge Propagation and Distillation, named HKPD. To learn more discriminative sample-level representations, HKPD first constructs a sample-level information propagation module that explores pairwise sample relations. Subsequently, a class-level information propagation module is designed to obtain and update the class-level information. Moreover, a self-distillation module is adopted to further improve the learned representations by propagating the obtained knowledge across this hierarchical architecture. Extensive experiments conducted on the commonly used few-shot benchmark datasets demonstrate the superiority of the proposed HKPD method, which outperforms the current state-of-the-art methods.}
}
@article{HE2023602,
title = {Unsupervised Domain Adaptation with Asymmetrical Margin Disparity loss and Outlier Sample Extraction},
journal = {Neural Networks},
volume = {168},
pages = {602-614},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.045},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005415},
author = {Chunmei He and Xianjun Fan and Kang Zhou and Zhengchun Ye},
keywords = {Unsupervised domain adaptation, transfer learning, deep neural network, image classification, adversarial learning},
abstract = {ABSTRACT
Unsupervised domain adaptation (UDA) trains models using labeled data from a specific source domain and then transferring the knowledge to certain target domains that have few or no labels. Many prior measurement-based works achieve lots of progress, but their feature distinguishing abilities to classify target samples with similar features are not enough; they do not adequately consider the confusing samples in the target domain that are similar to the source domain; and they don't consider negative transfer of the outlier sample in source domain. We address these issues in our work and propose an UDA method with asymmetrical margin disparity loss and outlier sample extraction, called AMD-Net with OSE. We propose an Asymmetrical Margin Disparity Discrepancy (AMD) method and a training strategy based on sample selection mechanism to make the network have better feature extraction ability and the network gets rid of local optimal. Firstly, in the AMD method, we design a multi-label entropy metric to evaluate the marginal disparity loss of the confusing samples in the target domain. This asymmetric marginal disparity loss designment uses the different entropy measurement algorithms of the two domains to excavate the differences of the two domains as much as possible, so as to find the common features of the two domains. Secondly, A sample selection mechanism is designed to evaluate which part of the sample in target domain is confusable. We define the certainty of the sample in the target domain, adopt a progressive learning scheme, and adopt one-hot marginal disparity loss for most of the samples in the target domain with low uncertainty and easy to distinguish. The multi-label marginal calculation method is used only for the uncertainty samples in the target domain whose certainty is less than the threshold value, so that the network can get rid of the local optimal as much as possible. At last, we further propose an outlier sample extraction algorithm (OSE) based on weighted cosine similarity distance for source domain to reduce the negative migration effect caused by outlier samples in the source domain. Extensive experiments on four datasets Office-31, Office-Home, VisDA-2017 and DomainNet demonstrate that our method works well in various UDA settings and outperforms the state-of-the-art methods.}
}
@article{ZHANG2023730,
title = {Adv-BDPM: Adversarial attack based on Boundary Diffusion Probability Model},
journal = {Neural Networks},
volume = {167},
pages = {730-740},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.048},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004689},
author = {Dian Zhang and Yunwei Dong},
keywords = {Neural networks, Vulnerability, Boundary diffusion probability model, Transferability, Adversarial attack},
abstract = {Deep neural networks have become increasingly significant in our daily lives due to their remarkable performance. The issue of adversarial examples, which are responsible for the vulnerability problem of deep neural networks, has attracted the attention of researchers in the study of robustness of these networks. To address the issues caused by the restricted diversity and precision of adversarial perturbations in neural networks, we introduce a novel technique called Adversarial Boundary Diffusion Probability Modeling (Adv-BDPM). This approach combines boundary analysis and diffusion probability modeling. First, we combined the denoising diffusion probability model with the boundary loss to design the boundary diffusion probability model, which can generate corresponding boundary perturbations for a specific neural network. Then, through the iterative process of boundary perturbations and its corresponding orthogonal perturbations, we proposed a decision boundary search algorithm to generate adversarial samples. The comparison experiments with black-box attacks in ImageNet demonstrate that Adv-BDPM has better attack success rate and perturbation precision. The comparison experiments with white-box attacks in CIFAR-10 and CIFAR-100 demonstrate that Adv-BDPM has better attack success rate, attack diversity for the same sample, and can effectively defend against adversarial training with shorter running time.}
}
@article{LIN2023787,
title = {Efficient and accurate compound scaling for convolutional neural networks},
journal = {Neural Networks},
volume = {167},
pages = {787-797},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.053},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004720},
author = {Chengmin Lin and Pengfei Yang and Quan Wang and Zeyu Qiu and Wenkai Lv and Zhenyi Wang},
keywords = {Convolutional neural networks, Compound scaling, Dimensions relationship, Runtime prediction model},
abstract = {Designing efficient and accurate network architectures to support various workloads, from servers to edge devices, is a fundamental problem as the use of Convolutional Neural Networks (ConvNets) becomes increasingly widespread. One simple yet effective method is to scale ConvNets by systematically adjusting the dimensions of the baseline network, including width, depth, and resolution, enabling it to adapt to diverse workloads by varying its computational complexity and representation ability. However, current state-of-the-art (SOTA) scaling methods for neural network architectures overlook the inter-dimensional relationships within the network and the impact of scaling on inference speed, resulting in suboptimal trade-offs between accuracy and inference speed. To overcome those limitations, we propose a scaling method for ConvNets that utilizes dimension relationship and runtime proxy constraints to improve accuracy and inference speed. Specifically, our research notes that higher input resolutions in convolutional layers lead to redundant filters (convolutional width) due to increased similarity between information in different positions, suggesting a potential benefit in reducing filters while increasing input resolution. Based on this observation, the relationship between the width and resolution is empirically quantified in our work, enabling models with higher parametric efficiency to be prioritized through our scaling strategy. Furthermore, we introduce a novel runtime prediction model that focuses on fine-grained layer tasks with different computational properties for more accurate identification of efficient network configurations. Comprehensive experiments show that our method outperforms prior works in creating a set of models with a trade-off between accuracy and inference speed on the ImageNet datasets for various ConvNets.}
}
@article{GUI2023104,
title = {Cross-domain policy adaptation with dynamics alignment},
journal = {Neural Networks},
volume = {167},
pages = {104-117},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004446},
author = {Haiyuan Gui and Shanchen Pang and Shihang Yu and Sibo Qiao and Yufeng Qi and Xiao He and Min Wang and Xue Zhai},
keywords = {Reinforcement learning, Policy transfer, Cross domain, Reward function, Continuous control},
abstract = {The implementation of robotic reinforcement learning is hampered by problems such as an unspecified reward function and high training costs. Many previous works have used cross-domain policy transfer to obtain the policy of the problem domain. However, these researches require paired and aligned dynamics trajectories or other interactions with the environment. We propose a cross-domain dynamics alignment framework for the problem domain policy acquisition that can transfer the policy trained in the source domain to the problem domain. Our framework aims to learn dynamics alignment across two domains that differ in agents’ physical parameters (armature, rotation range, or torso mass) or agents’ morphologies (limbs). Most importantly, we learn dynamics alignment between two domains using unpaired and unaligned dynamics trajectories. For these two scenarios, we propose a cross-physics-domain policy adaptation algorithm (CPD) and a cross-morphology-domain policy adaptation algorithm (CMD) based on our cross-domain dynamics alignment framework. In order to improve the performance of policy in the source domain so that a better policy can be transferred to the problem domain, we propose the Boltzmann TD3 (BTD3) algorithm. We conduct diverse experiments on agent continuous control domains to demonstrate the performance of our approaches. Experimental results show that our approaches can obtain better policies and higher rewards for the agents in the problem domains even when the dataset of the problem domain is small.}
}
@article{HAMANO2023300,
title = {Exploring the role of texture features in deep convolutional neural networks: Insights from Portilla-Simoncelli statistics},
journal = {Neural Networks},
volume = {168},
pages = {300-312},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005245},
author = {Yusuke Hamano and Shoko Nagasaka and Hayaru Shouno},
keywords = {DCNN, Texture, Image processing, Portilla-Simoncelli Statistics (PSS), VGG},
abstract = {It is well-understood that the performance of Deep Convolutional Neural Networks (DCNNs) in image recognition tasks is influenced not only by shape but also by texture information. Despite this, understanding the internal representations of DCNNs remains a challenging task. This study employs a simplified version of the Portilla-Simoncelli Statistics, termed “minPS,” to explore how texture information is represented in a pre-trained VGG network. Using minPS features extracted from texture images, we perform a sparse regression on the activations across various channels in VGG layers. Our findings reveal that channels in the early to middle layers of the VGG network can be effectively described by minPS features. Additionally, we observe that the explanatory power of minPS sub-groups evolves as one ascends the network hierarchy. Specifically, sub-groups termed Linear Cross Scale (LCS) and Energy Cross Scale (ECS) exhibit weak explanatory power for VGG channels. To investigate the relationship further, we compare the original texture images with their synthesized counterparts, generated using VGG, in terms of minPS features. Our results indicate that the absence of certain minPS features suggests their non-utilization in VGG’s internal representations.}
}
@article{BURKHARDT2023473,
title = {A large-scale neurocomputational model of spatial cognition integrating memory with vision},
journal = {Neural Networks},
volume = {167},
pages = {473-488},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004550},
author = {Micha Burkhardt and Julia Bergelt and Lorenz Gönner and Helge Ülo Dinkelbach and Frederik Beuth and Alex Schwarz and Andrej Bicanski and Neil Burgess and Fred H. Hamker},
keywords = {Brain-inspired neural networks, Spatial reference transformation, Parietal cortex, Visual attention, Spatial memory and imagery},
abstract = {We introduce a large-scale neurocomputational model of spatial cognition called ’Spacecog’, which integrates recent findings from mechanistic models of visual and spatial perception. As a high-level cognitive ability, spatial cognition requires the processing of behaviourally relevant features in complex environments and, importantly, the updating of this information during processes of eye and body movement. The Spacecog model achieves this by interfacing spatial memory and imagery with mechanisms of object localisation, saccade execution, and attention through coordinate transformations in parietal areas of the brain. We evaluate the model in a realistic virtual environment where our neurocognitive model steers an agent to perform complex visuospatial tasks. Our modelling approach opens up new possibilities in the assessment of neuropsychological data and human spatial cognition.}
}
@article{ZHANG2023680,
title = {Novel results on asymptotic stability and synchronization of fractional-order memristive neural networks with time delays: The 0&lt;δ≤1 case},
journal = {Neural Networks},
volume = {167},
pages = {680-691},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005002},
author = {Jia-Rui Zhang and Jun-Guo Lu and Xiao-Chuang Jin and Xing-Yu Yang},
keywords = {Synchronization, Asymptotic stability, Fractional-order, Time delay, Memristive neural network},
abstract = {This paper investigates the asymptotic stability and synchronization of fractional-order (FO) memristive neural networks with time delays. Based on the FO comparison principle and inverse Laplace transform method, the novel sufficient conditions for the asymptotic stability of a FO nonlinear system are given. Then, based on the above conclusions, the sufficient conditions for the asymptotic stability and synchronization of FO memristive neural networks with time delays are investigated. The results in this paper have a wider coverage of situations and are more practical than the previous related results. Finally, the validity of the results is checked by two examples.}
}
@article{PHAM2023380,
title = {Mean-field neural networks: Learning mappings on Wasserstein space},
journal = {Neural Networks},
volume = {168},
pages = {380-393},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005087},
author = {Huyên Pham and Xavier Warin},
keywords = {Wasserstein space, Bin density neural network, Cylindrical function, Mean-field problems},
abstract = {We study the machine learning task for models with operators mapping between the Wasserstein space of probability measures and a space of functions, like e.g. in mean-field games/control problems. Two classes of neural networks based on bin density and on cylindrical approximation, are proposed to learn these so-called mean-field functions, and are theoretically supported by universal approximation theorems. We perform several numerical experiments for training these two mean-field neural networks, and show their accuracy and efficiency in the generalization error with various test distributions. Finally, we present different algorithms relying on mean-field neural networks for solving time-dependent mean-field problems, and illustrate our results with numerical tests for the example of a semi-linear partial differential equation in the Wasserstein space of probability measures.}
}
@article{ROLONMERETTE2023244,
title = {A multilayered bidirectional associative memory model for learning nonlinear tasks},
journal = {Neural Networks},
volume = {167},
pages = {244-265},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004392},
author = {Damiem Rolon-Mérette and Thaddé Rolon-Mérette and Sylvain Chartier},
keywords = {ANNs, Associative memory, BAM neural networks, Cognition, Multilayer, Nonlinear tasks},
abstract = {A multilayered bidirectional associative memory neural network is proposed to account for learning nonlinear types of association. The model (denoted as the MF-BAM) is composed of two modules, the Multi-Feature extracting bidirectional associative memory (MF), which contains various unsupervised network layers, and a modified Bidirectional Associative Memory (BAM), which consists of a single supervised network layer. The MF generates successive feature patterns from the original inputs. These patterns change the relationship between the inputs and targets in a way that the BAM can learn. The model was tested on different nonlinear tasks, such as the N-bit, Double Moon and its variants, and the 3-class spiral task. Behaviors were reported through learning errors, decision zones, and recall performances. Results showed that it was possible to learn all tasks consistently. By manipulating the number of units per layer and the number of unsupervised network layers in the MF, it was possible to change the level of nonlinearity observed in the decision boundaries. Furthermore, results indicated that different behaviors were achieved from the same set of inputs by using the different generated patterns. These findings are significant as they showed how a BAM-inspired model could solve nonlinear tasks in a more cognitively plausible fashion.}
}
@article{DEIHIM2023549,
title = {STTRE: A Spatio-Temporal Transformer with Relative Embeddings for multivariate time series forecasting},
journal = {Neural Networks},
volume = {168},
pages = {549-559},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.039},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005361},
author = {Azad Deihim and Eduardo Alonso and Dimitra Apostolopoulou},
keywords = {Multivariate time series, Transformer, Forecasting, Attention, Embeddings, Spatio-temporal},
abstract = {The prevalence of multivariate time series data across several disciplines fosters a demand and, subsequently, significant growth in the research and advancement of multivariate time series analysis. Drawing inspiration from a popular natural language processing model, the Transformer, we propose the Spatio-Temporal Transformer with Relative Embeddings (STTRE) to address multivariate time series forecasting. This work primarily focuses on developing a Transformer-based framework that can fully exploit the spatio-temporal nature of a multivariate time series by incorporating several of the Transformer’s key components, but with augmentations that allow them to excel in multivariate time series forecasting. Current Transformer-based models for multivariate time series often neglect the data’s spatial component(s) and utilize absolute position embeddings as their only means to detect the data’s temporal component(s), which we show is flawed for time series applications. The lack of emphasis on fully exploiting the spatio-temporality of the data can incur subpar results in terms of accuracy. We redesign relative position representations, which we rename to relative embeddings, to unveil a new method for detecting latent spatial, temporal, and spatio-temporal dependencies more effectively than previous Transformer-based models. We couple these relative embeddings with a restructuring of the Transformer’s primary sequence learning mechanism, multi-head attention, in a way that allows for full utilization of relative embeddings, thus achieving up to a 24% improvement in accuracy over other state-of-the-art multivariate time series models on a comprehensive selection of publicly available multivariate time series forecasting datasets.}
}
@article{YU2023539,
title = {Graph structure reforming framework enhanced by commute time distance for graph classification},
journal = {Neural Networks},
volume = {168},
pages = {539-548},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.044},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005403},
author = {Wenhang Yu and Xueqi Ma and James Bailey and Yibing Zhan and Jia Wu and Bo Du and Wenbin Hu},
keywords = {Graph neural networks, Commute time distance, Graph classification},
abstract = {As a graph data mining task, graph classification has high academic value and wide practical application. Among them, the graph neural network-based method is one of the mainstream methods. Most graph neural networks (GNNs) follow the message passing paradigm and can be called Message Passing Neural Networks (MPNNs), achieving good results in structural data-related tasks. However, it has also been reported that these methods suffer from over-squashing and limited expressive power. In recent years, many works have proposed different solutions to these problems separately, but none has yet considered these shortcomings in a comprehensive way. After considering these several aspects comprehensively, we identify two specific defects: information loss caused by local information aggregation, and an inability to capture higher-order structures. To solve these issues, we propose a plug-and-play framework based on Commute Time Distance (CTD), in which information is propagated in commute time distance neighborhoods. By considering both local and global graph connections, the commute time distance between two nodes is evaluated with reference to the path length and the number of paths in the whole graph. Moreover, the proposed framework CTD-MPNNs (Commute Time Distance-based Message Passing Neural Networks) can capture higher-order structural information by utilizing commute paths to enhance the expressive power of GNNs. Thus, our proposed framework can propagate and aggregate messages from defined important neighbors and model more powerful GNNs. We conduct extensive experiments using various real-world graph classification benchmarks. The experimental performance demonstrates the effectiveness of our framework. Codes are released on https://github.com/Haldate-Yu/CTD-MPNNs.}
}
@article{WANG2023798,
title = {A varying-parameter fixed-time gradient-based dynamic network for convex optimization},
journal = {Neural Networks},
volume = {167},
pages = {798-809},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.047},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004677},
author = {Dan Wang and Xin-Wei Liu},
keywords = {Gradient-based dynamic network, Activation function, Fixed-time convergence, Time-varying scaling parameter, Unbounded noise},
abstract = {We focus on the fixed-time convergence and robustness of gradient-based dynamic networks for solving convex optimization. Most of the existing gradient-based dynamic networks with fixed-time convergence have limited ability to resist interferences of noises. To improve the convergence of the gradient-based dynamic networks, we design a new activation function and propose a gradient-based dynamic network with fixed-time convergence. The proposed dynamic network has a smaller upper bound of the convergence time than the existing dynamic networks with fixed-time convergence. A time-varying scaling parameter is employed to speed up the convergence. Our gradient-based dynamic network is proved to be robust against bounded noises and is able to resist the interference of unbounded noises. The numerical tests illustrate the effectiveness and superiority of the proposed network.}
}
@article{KIM2023266,
title = {Bridged adversarial training},
journal = {Neural Networks},
volume = {167},
pages = {266-282},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004434},
author = {Hoki Kim and Woojin Lee and Sungyoon Lee and Jaewook Lee},
keywords = {Neural networks, Adversarial robustness, Adversarial training, Adversarial defense},
abstract = {Adversarial robustness is considered a required property of deep neural networks. In this study, we discover that adversarially trained models might have significantly different characteristics in terms of margin and smoothness, even though they show similar robustness. Inspired by the observation, we investigate the effect of different regularizers and discover the negative effect of the smoothness regularizer on maximizing the margin. Based on the analyses, we propose a new method called bridged adversarial training that mitigates the negative effect by bridging the gap between clean and adversarial examples. We provide theoretical and empirical evidence that the proposed method provides stable and better robustness, especially for large perturbations.}
}
@article{LI202359,
title = {Adaptive control-based synchronization of discrete-time fractional-order fuzzy neural networks with time-varying delays},
journal = {Neural Networks},
volume = {168},
pages = {59-73},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005129},
author = {Hong-Li Li and Jinde Cao and Cheng Hu and Long Zhang and Haijun Jiang},
keywords = {Complete synchronization, Discrete-time fractional-order, Fuzzy neural networks, Time-varying delays, Adaptive control},
abstract = {This paper is concerned with complete synchronization for discrete-time fractional-order fuzzy neural networks (DFFNNs) with time-varying delays. First, three original equalities and two Caputo σ-difference inequalities are established based on theory of discrete-time fractional Calculus. Next, a novel discrete-time adaptive controller with time-varying delay is designed, by virtue of 1-norm Lyapunov function and newly established lemmas herein as well as inequality techniques and contradiction method, some judgement conditions are derived to guarantee complete synchronization for the explored DFFNNs. Benefitting from discrete-time adaptive control strategy and our analysis method, the conservatism of the derived synchronization criteria is reduced. Ultimately, the effectiveness of our theoretical results and secure communication scheme are demonstrated through two numerical examples.}
}
@article{FAN2023508,
title = {CompNet: Complementary network for single-channel speech enhancement},
journal = {Neural Networks},
volume = {168},
pages = {508-517},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.041},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300535X},
author = {Cunhang Fan and Hongmei Zhang and Andong Li and Wang Xiang and Chengshi Zheng and Zhao Lv and Xiaopei Wu},
keywords = {Speech enhancement, Complementary, Filtering and refining, Time–frequency domain, Time-domain},
abstract = {Recent multi-domain processing methods have demonstrated promising performance for monaural speech enhancement tasks. However, few of them explain why they behave better over single-domain approaches. As an attempt to fill this gap, this paper presents a complementary single-channel speech enhancement network (CompNet) that demonstrates promising denoising capabilities and provides a unique perspective to understand the improvements introduced by multi-domain processing. Specifically, the noisy speech is initially enhanced through a time-domain network. However, despite the waveform can be feasibly recovered, the distribution of the time–frequency bins may still be partly different from the target spectrum when we reconsider the problem in the frequency domain. To solve this problem, we design a dedicated dual-path network as a post-processing module to independently filter the magnitude and refine the phase. This further drives the estimated spectrum to closely approximate the target spectrum in the time–frequency domain. We conduct extensive experiments with the WSJ0-SI84 and VoiceBank + Demand datasets. Objective test results show that the performance of the proposed system is highly competitive with existing systems.}
}
@article{ZHAO2023763,
title = {Sampled-data exponential consensus of multi-agent systems with Lipschitz nonlinearities},
journal = {Neural Networks},
volume = {167},
pages = {763-774},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004951},
author = {Wenqing Zhao and Guoliang Chen and Xiangpeng Xie and Jianwei Xia and Ju H. Park},
keywords = {Multi-agent systems, Consensus, Sampled-data, LMI},
abstract = {In this paper, the exponential consensus of leaderless and leader-following multi-agent systems with Lipschitz nonlinear dynamics is illustrated with aperiodic sampled-data control using a two-sided loop-based Lyapunov functional (LBLF). Firstly, applying input delay approach to reformulate the resulting sampled-data system as a continuous system with time-varying delay in the control input. A two-sided LBLF which captures the information on sampled-data pattern is constructed and the symmetry of the Laplacian matrix together with Newton–Leibniz formula have been employed to obtain reduced number of decision variables and decreased LMI dimensions for the exponential sampled-data consensus problem. Subsequently, an aperiodic sampled-data controller was designed to simplify and enhance stability conditions for computation and optimization purposes in the proposed approach. Finally, based on the controller design, simulation examples including the power system are proposed to illustrate the theoretical analysis, moreover, a larger sampled-data interval can be acquired by this method than other literature, thereby conserving bandwidth and reducing communication resources.}
}
@article{SUCCETTI2023715,
title = {An adaptive embedding procedure for time series forecasting with deep neural networks},
journal = {Neural Networks},
volume = {167},
pages = {715-729},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.051},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004719},
author = {Federico Succetti and Antonello Rosato and Massimo Panella},
keywords = {Deep neural network, Adaptive embedding, Long Short-Term Memory, Forecasting, Time series},
abstract = {Nowadays, solving time series prediction problems is an open and challenging task. Many solutions are based on the implementation of deep neural architectures, which are able to analyze the structure of the time series and to carry out the prediction. In this work, we present a novel deep learning scheme based on an adaptive embedding mechanism. The latter is exploited to extract a compressed representation of the input time series that is used for the subsequent forecasting. The proposed model is based on a two-layer bidirectional Long Short-Term Memory network, where the first layer performs the adaptive embedding and the second layer acts as a predictor. The performances of the proposed forecasting scheme are compared with several models in two different scenarios, considering both well-known time series and real-life application cases. The experimental results show the accuracy and the flexibility of the proposed approach, which can be used as a prediction tool for any actual application.}
}
@article{CHEN2023810,
title = {A knowledge-based learning framework for self-supervised pre-training towards enhanced recognition of biomedical microscopy images},
journal = {Neural Networks},
volume = {167},
pages = {810-826},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300494X},
author = {Wei Chen and Chen Li and Dan Chen and Xin Luo},
keywords = {Self-supervised neural network pre-training, Biomedical microscopy images, Classification, Segmentation, Generative learning, Contrastive learning},
abstract = {Self-supervised pre-training has become the priory choice to establish reliable neural networks for automated recognition of massive biomedical microscopy images, which are routinely annotation-free, without semantics, and without guarantee of quality. Note that this paradigm is still at its infancy and limited by closely related open issues: (1) how to learn robust representations in an unsupervised manner from unlabeled biomedical microscopy images of low diversity in samples? and (2) how to obtain the most significant representations demanded by a high-quality segmentation? Aiming at these issues, this study proposes a knowledge-based learning framework (TOWER) towards enhanced recognition of biomedical microscopy images, which works in three phases by synergizing contrastive learning and generative learning methods: (1) Sample Space Diversification: Reconstructive proxy tasks have been enabled to embed a priori knowledge with context highlighted to diversify the expanded sample space; (2) Enhanced Representation Learning: Informative noise-contrastive estimation loss regularizes the encoder to enhance representation learning of annotation-free images; (3) Correlated Optimization: Optimization operations in pre-training the encoder and the decoder have been correlated via image restoration from proxy tasks, targeting the need for semantic segmentation. Experiments have been conducted on public datasets of biomedical microscopy images against the state-of-the-art counterparts (e.g., SimCLR and BYOL), and results demonstrate that: TOWER statistically excels in all self-supervised methods, achieving a Dice improvement of 1.38 percentage points over SimCLR. TOWER also has potential in multi-modality medical image analysis and enables label-efficient semi-supervised learning, e.g., reducing the annotation cost by up to 99% in pathological classification.}
}
@article{ZHANG2023847,
title = {Addressing implicit bias in adversarial imitation learning with mutual information},
journal = {Neural Networks},
volume = {167},
pages = {847-864},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.058},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004860},
author = {Lihua Zhang and Quan Liu and Fei Zhu and Zhigang Huang},
keywords = {Adversarial imitation learning, Generative adversarial learning, Mutual information, Reward shaping, Unbiased reward function},
abstract = {Adversarial imitation learning (AIL) is a powerful method for automated decision systems due to training a policy efficiently by mimicking expert demonstrations. However, implicit bias is present in the reward function of these algorithms, which leads to sample inefficiency. To solve this issue, an algorithm, referred to as Mutual Information Generative Adversarial Imitation Learning (MI-GAIL), is proposed to correct the biases. In this study, we propose two guidelines for designing an unbiased reward function. Based on these guidelines, we shape the reward function from the discriminator by adding auxiliary information from a potential-based reward function. The primary insight is that the potential-based reward function provides more accurate rewards for actions identified in the two guidelines. We compare our algorithm with SOTA imitation learning algorithms on a family of continuous control tasks. Experiments results show that MI-GAIL is able to address the issue of bias in AIL reward functions and further improve sample efficiency and training stability.}
}
@article{ZHANG2023652,
title = {LaenNet: Learning robust GCNs by propagating labels},
journal = {Neural Networks},
volume = {168},
pages = {652-664},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005312},
author = {Chunxu Zhang and Ximing Li and Hongbin Pei and Zijian Zhang and Bing Liu and Bo Yang},
keywords = {Graph Convolutional Networks, Robustness, Label},
abstract = {Graph Convolutional Networks (GCNs) can be acknowledged as one of the most significant methodologies for graph representation learning, and the family of GCNs has recently achieved great success in the community. However, in real-world scenarios, the graph data may be imperfect, e.g., with noisy and sparse features or labels, which poses a great challenge to the robustness of GCNs. To meet this challenge, we propose a simple-yet-effective LAbel-ENhanced Networks (LaenNet) architecture for GCNs, where the basic spirit is to propagate labels together with features. Specifically, we add an extra LaenNet module at one hidden layer of GCNs, which propagates labels along the graph and then integrates them with the hidden representations as the inputs to the deeper layer. The proposed LaenNet can be directly generalized to the variants of GCNs. We conduct extensive experiments to verify LaenNet on semi-supervised node classification tasks under four noisy and sparse graph data scenarios, including the graphs with noisy features, sparse features, noisy labels, and sparse labels. Empirical results indicate the superiority and robustness of LaenNet compared to the state-of-the-art baseline models. The implementation code is available to ease reproducibility11https://github.com/Zhangcx19/LAENNet..}
}
@article{XIAO2023433,
title = {Word self-update contrastive adversarial networks for text-to-image synthesis},
journal = {Neural Networks},
volume = {167},
pages = {433-444},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.038},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004586},
author = {Jian Xiao and Yiwen Sun and Xiaojun Bi},
keywords = {Text-to-image synthesis, Contrastive learning, Word self-attention, Dual attention generator},
abstract = {Synthesizing realistic fine-grained images from text descriptions is a significant computer vision task. Although many GANs-based methods have been proposed to solve this task, generating high-quality images consistent with text information remains a difficult problem. These existing GANs-based methods ignore important words due to the use of fixed initial word features in generator, and neglect to learn semantic consistency between images and texts for discriminators. In this article, we propose a novel attentional generation and contrastive adversarial framework for fine-grained text-to-image synthesis, termed as Word Self-Update Contrastive Adversarial Networks (WSC-GAN). Specifically, we introduce a dual attention module for modeling color details and semantic information. With a new designed word self-update module, the generator can leverage visually important words to compute attention maps in the feature synthesis module. Furthermore, we contrive multi-branch contrastive discriminators to maintain better consistency between the generated image and text description. Two novel contrastive losses are proposed for our discriminators to impose image-sentence and image-word consistency constraints. Extensive experiments on CUB and MS-COCO datasets demonstrate that our method achieves better performance compared with state-of-the-art methods.}
}
@article{ZHU2023531,
title = {Tell me your position: Distantly supervised biomedical entity relation extraction using entity position marker},
journal = {Neural Networks},
volume = {168},
pages = {531-538},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.043},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005397},
author = {Jiran Zhu and Jikun Dong and Hongyun Du and Yanfang Geng and Shengyu Fan and Hui Yu and Zengzhen Shao and Xia Wang and Yaping Yang and Weizhi Xu},
keywords = {Deep neural network, Natural language processing, Distant supervision, Biomedical entity relation extraction, Position marker},
abstract = {A significant amount of textual data has been produced in the biomedical area recently as a result of the advancement of biomedical technologies. Large-scale biomedical data can be automatically obtained with the help of distant supervision. However, the noisy data brought by distant supervision methods makes relation extraction tasks more difficult. Previous work has focused more on how to restore mislabeled relationships, but little attention has been paid to the importance of labeled entity locations for relationship extraction tasks. In this paper, we present a “four-stage” model based on BioBERT and Multi-Instance Learning by using entity position markers. Firstly, the sentence is marked with position. Secondly, BioBERT, a biomedical pre-trained language model, is used in the final sentence feature vector representation not only with the global position marker but also with the start and end marker of both the head and tail entity. Thirdly, the aggregation of sentence vectors in the bag is used as the vector feature of the bag by three aggregation methods, and the performance of different sentence feature vectors combined with different bag encoding methods is discussed. At last, relation classification is performed at the bag level. According to experimental results, the presented model significantly outperforms all baseline models and contributes to noise reduction. In addition, different bag encoding methods need to match corresponding sentence encoding representation to achieve the best performance.}
}
@article{CHEN2023214,
title = {A dual-branch model with inter- and intra-branch contrastive loss for long-tailed recognition},
journal = {Neural Networks},
volume = {168},
pages = {214-222},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005154},
author = {Qiong Chen and Tianlin Huang and Geren Zhu and Enlu Lin},
keywords = {Neural network, Long-tailed recognition, Imbalanced learning, Contrastive learning},
abstract = {Real-world data often exhibits a long-tailed distribution, in which head classes occupy most of the data, while tail classes only have very few samples. Models trained on long-tailed datasets have poor adaptability to tail classes and the decision boundaries are ambiguous. Therefore, in this paper, we propose a simple yet effective model, named Dual-Branch Long-Tailed Recognition (DB-LTR), which includes an imbalanced learning branch and a Contrastive Learning Branch (CoLB). The imbalanced learning branch, which consists of a shared backbone and a linear classifier, leverages common imbalanced learning approaches to tackle the data imbalance issue. In CoLB, we learn a prototype for each tail class, and calculate an inter-branch contrastive loss, an intra-branch contrastive loss and a metric loss. CoLB can improve the capability of the model in adapting to tail classes and assist the imbalanced learning branch to learn a well-represented feature space and discriminative decision boundary. Extensive experiments on three long-tailed benchmark datasets, i.e., CIFAR100-LT, ImageNet-LT and Places-LT, show that our DB-LTR is competitive and superior to the comparative methods.}
}
@article{CHEN2023161,
title = {Joint learning of feature and topology for multi-view graph convolutional network},
journal = {Neural Networks},
volume = {168},
pages = {161-170},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004987},
author = {Yuhong Chen and Zhihao Wu and Zhaoliang Chen and Mianxiong Dong and Shiping Wang},
keywords = {Multi-view learning, Semi-supervised classification, Graph convolution network, Feature and topology fusion},
abstract = {Graph convolutional network has been extensively employed in semi-supervised classification tasks. Although some studies have attempted to leverage graph convolutional networks to explore multi-view data, they mostly consider the fusion of feature and topology individually, leading to the underutilization of the consistency and complementarity of multi-view data. In this paper, we propose an end-to-end joint fusion framework that aims to simultaneously conduct a consistent feature integration and an adaptive topology adjustment. Specifically, to capture the feature consistency, we construct a deep matrix decomposition module, which maps data from different views onto a feature space obtaining a consistent feature representation. Moreover, we design a more flexible graph convolution that allows to adaptively learn a more robust topology. A dynamic topology can greatly reduce the influence of unreliable information, which acquires a more adaptive representation. As a result, our method jointly designs an effective feature fusion module and a topology adjustment module, and lets these two modules mutually enhance each other. It takes full advantage of the consistency and complementarity to better capture the more intrinsic information. The experimental results indicate that our method surpasses state-of-the-art semi-supervised classification methods.}
}
@article{MUKHTAR2023363,
title = {STMMOT: Advancing multi-object tracking through spatiotemporal memory networks and multi-scale attention pyramids},
journal = {Neural Networks},
volume = {168},
pages = {363-379},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.047},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005439},
author = {Hamza Mukhtar and Muhammad Usman Ghani Khan},
keywords = {Multi-object tracking, Transformer, Cross-attention},
abstract = {Multi-object Tracking (MOT) is very important in human surveillance, sports analytics, autonomous driving, and cooperative robots. Current MOT methods do not perform well in non-uniform movements, occlusion and appearance–reappearance scenarios. We introduce a comprehensive MOT method that seamlessly merges object detection and identity linkage within an end-to-end trainable framework, designed with the capability to maintain object links over a long period of time. Our proposed model, named STMMOT, is architectured around 4 key modules: (1) Candidate proposal creation network, generates object proposals via vision-Transformer encoder–decoder architecture; (2) Scale variant pyramid, progressive pyramid structure to learn the self-scale and cross-scale similarities in multi-scale feature maps; (3) Spatio-temporal memory encoder, extracting the essential information from the memory associated with each object under tracking; and (4) Spatio-temporal memory decoder, simultaneously resolving the tasks of object detection and identity association for MOT. Our system leverages a robust spatio-temporal memory module that retains extensive historical object state observations and effectively encodes them using an attention-based aggregator. The uniqueness of STMMOT resides in representing objects as dynamic query embeddings that are updated continuously, which enables the prediction of object states with an attention mechanism and eradicates the need for post-processing. Experimental results show that STMMOT archives scores of 79.8 and 78.4 for IDF1, 79.3 and 74.1 for MOTA, 73.2 and 69.0 for HOTA, 61.2 and 61.5 for AssA, and maintained an ID switch count of 1529 and 1264 on MOT17 and MOT20, respectively. When evaluated on MOT20, it scored 78.4 in IDF1, 74.1 in MOTA, 69.0 in HOTA, and 61.5 in AssA, and kept the ID switch count to 1264. Compared with the previous best TransMOT, STMMOT achieves around a 4.58% and 4.25% increase in IDF1, and ID switching reduction to 5.79% and 21.05% on MOT17 and MOT20, respectively.}
}
@article{SONG2023668,
title = {Switching ETM-based neural adaptive output feedback control for nonaffine stochastic MIMO nonlinear systems subject to deferred constraint},
journal = {Neural Networks},
volume = {167},
pages = {668-679},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.054},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004744},
author = {Xiaona Song and Peng Sun and Choon Ki Ahn and Shuai Song},
keywords = {Deferred constraint, Fractional-order parameter, Filter state observer, Nonaffine stochastic multiple-input and multiple-output (MIMO) nonlinear plants, Switching event-triggered mechanism},
abstract = {This article focuses on the neural adaptive output feedback control study related to nonaffine stochastic multiple-input, multiple-output nonlinear plants. First, a K-filter state observer based on a radial basis function neural network is designed to estimate the remaining unavailable states. Then, a novel adaptive command-filtered backstepping output feedback control framework is established, where an improved command filter with a fractional-order parameter is applied to conquer the calculation size problem. Specifically, the highlight of this work is that it designs a modified error compensation signal and incorporates the concept of deferred constraint to eradicate the negative effect caused by the filter errors. In addition, the network bandwidth resources, control impulse, and control accuracy are synthesized using an amended switching event-triggered mechanism. The theoretical analysis proved that the proposed control approach guarantees that the tracking error can converge to a preassigned region within a user-defined time while the violation of the deferred output constraint can be excluded. Two illustrative studies are provided to demonstrate the validity and superiority of the developed control method.}
}
@article{WOJCIK2023580,
title = {Zero time waste in pre-trained early exit neural networks},
journal = {Neural Networks},
volume = {168},
pages = {580-601},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005555},
author = {Bartosz Wójcik and Marcin Przewiȩźlikowski and Filip Szatkowski and Maciej Wołczyk and Klaudia Bałazy and Bartłomiej Krzepkowski and Igor Podolak and Jacek Tabor and Marek Śmieja and Tomasz Trzciński},
keywords = {Early-exiting networks, Dynamic neural networks, Conditional computation, Zero waste models, Deep learning},
abstract = {The problem of reducing processing time of large deep learning models is a fundamental challenge in many real-world applications. Early exit methods strive towards this goal by attaching additional Internal Classifiers (ICs) to intermediate layers of a neural network. ICs can quickly return predictions for easy examples and, as a result, reduce the average inference time of the whole model. However, if a particular IC does not decide to return an answer early, its predictions are discarded, with its computations effectively being wasted. To solve this issue, we introduce Zero Time Waste (ZTW), a novel approach in which each IC reuses predictions returned by its predecessors by (1) adding direct connections between ICs and (2) combining previous outputs in an ensemble-like manner. We conduct extensive experiments across various multiple modes, datasets, and architectures to demonstrate that ZTW achieves a significantly better accuracy vs. inference time trade-off than other early exit methods. On the ImageNet dataset, it obtains superior results over the best baseline method in 11 out of 16 cases, reaching up to 5 percentage points of improvement on low computational budgets.}
}
@article{YANG2023237,
title = {Sweet Gradient matters: Designing consistent and efficient estimator for Zero-shot Architecture Search},
journal = {Neural Networks},
volume = {168},
pages = {237-255},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005038},
author = {Longxing Yang and Yanxin Fu and Shun Lu and Zihao Sun and Jilin Mei and Wenxiao Zhao and Yu Hu},
keywords = {Zero-shot Neural Architecture Search, Low Consistency, Sweet Gradient, Sweetimator, Sweet-enhanced estimators},
abstract = {Zero-shot Neural Architecture Search has garnered attention due to its training-free nature and rapid search speed. However, existing zero-shot estimators commonly suffer from low consistency, which hampers their practicality. In this work, we theoretically analyze that network generalization and convergence are highly correlated with Sweet Gradient of Parameter, i.e., the number of parameters whose gradient absolute values are within a certain interval. Empirical results indicate that Sweet Gradient of Parameter brings a higher consistency than the overall number of parameters. Additionally, we demonstrate a positive correlation between the network depth and the proportion of parameters with sweet gradients in each layer. Based on the analysis, we propose a training-free method to find the Sweet Gradient interval and obtain an estimator, named Sweetimator. Furthermore, Sweet Gradient can be an effective and general approach to promote the consistency of zero-shot estimators. Experiments show that Sweetimator and Sweet-enhanced estimators have significant consistency improvement in multiple benchmarks. Our method achieves state-of-the-art performance with 256x speedup in NAS-Bench-201 and maintains high competitiveness in DARTS, MobileNet, and Transformer search spaces. The source code is available at https://github.com/xingxing-123/SweetGradient.}
}
@article{ZHANG2023292,
title = {Hybrid learning mechanisms under a neural control network for various walking speed generation of a quadruped robot},
journal = {Neural Networks},
volume = {167},
pages = {292-308},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004501},
author = {Yanbin Zhang and Mathias Thor and Nat Dilokthanakul and Zhendong Dai and Poramate Manoonpong},
keywords = {Neural control, Quadruped robotics, Robot learning, Adaptive behavior},
abstract = {Legged robots that can instantly change motor patterns at different walking speeds are useful and can accomplish various tasks efficiently. However, state-of-the-art control methods either are difficult to develop or require long training times. In this study, we present a comprehensible neural control framework to integrate probability-based black-box optimization (PIBB) and supervised learning for robot motor pattern generation at various walking speeds. The control framework structure is based on a combination of a central pattern generator (CPG), a radial basis function (RBF) -based premotor network and a hypernetwork, resulting in a so-called neural CPG-RBF-hyper control network. First, the CPG-driven RBF network, acting as a complex motor pattern generator, was trained to learn policies (multiple motor patterns) for different speeds using PIBB. We also introduce an incremental learning strategy to avoid local optima. Second, the hypernetwork, which acts as a task/behavior to control parameter mapping, was trained using supervised learning. It creates a mapping between the internal CPG frequency (reflecting the walking speed) and motor behavior. This map represents the prior knowledge of the robot, which contains the optimal motor joint patterns at various CPG frequencies. Finally, when a user-defined robot walking frequency or speed is provided, the hypernetwork generates the corresponding policy for the CPG-RBF network. The result is a versatile locomotion controller which enables a quadruped robot to perform stable and robust walking at different speeds without sensory feedback. The policy of the controller was trained in the simulation (less than 1 h) and capable of transferring to a real robot. The generalization ability of the controller was demonstrated by testing the CPG frequencies that were not encountered during training.}
}
@article{SALAZARGONZALEZ2023489,
title = {Conditioned Cooperative training for semi-supervised weapon detection},
journal = {Neural Networks},
volume = {167},
pages = {489-501},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.043},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004628},
author = {Jose L. {Salazar González} and Juan A. Álvarez-García and Fernando J. Rendón-Segador and Fabio Carrara},
keywords = {Semi-supervised learning, Self-supervised learning, Supervised learning, Weapon detection, Knowledge transfer},
abstract = {Violent assaults and homicides occur daily, and the number of victims of mass shootings increases every year. However, this number can be reduced with the help of Closed Circuit Television (CCTV) and weapon detection models, as generic object detectors have become increasingly accurate with more data for training. We present a new semi-supervised learning methodology based on conditioned cooperative student–teacher training with optimal pseudo-label generation using a novel confidence threshold search method and improving both models by conditional knowledge transfer. Furthermore, a novel firearms image dataset of 458,599 images was collected using Instagram hashtags to evaluate our approach and compare the improvements obtained using a specific unsupervised dataset instead of a general one such as ImageNet. We compared our methodology with supervised, semi-supervised and self-supervised learning techniques, outperforming approaches such as YOLOv5 m (up to ＋19.86), YOLOv5l (up to ＋6.52) Unbiased Teacher (up to ＋10.5 AP), DETReg (up to ＋2.8 AP) and UP-DETR (up to ＋1.22 AP).}
}
@article{KALHAN2023631,
title = {Reward prediction-errors weighted by cue salience produces addictive behaviours in simulations, with asymmetrical learning and steeper delay discounting},
journal = {Neural Networks},
volume = {168},
pages = {631-651},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005282},
author = {Shivam Kalhan and Marta I. Garrido and Robert Hester and A. David Redish},
keywords = {Reinforcement learning, Dopamine, Addiction, Salience, Motivation, Reward prediction-errors},
abstract = {Dysfunction in learning and motivational systems are thought to contribute to addictive behaviours. Previous models have suggested that dopaminergic roles in learning and motivation could produce addictive behaviours through pharmacological manipulations that provide excess dopaminergic signalling towards these learning and motivational systems. Redish (2004) suggested a role based on dopaminergic signals of value prediction error, while (Zhang et al., 2009) suggested a role based on dopaminergic signals of motivation. However, both models present significant limitations. They do not explain the reduced sensitivity to drug-related costs/negative consequences, the increased impulsivity generally found in people with a substance use disorder, craving behaviours, and non-pharmacological dependence, all of which are key hallmarks of addictive behaviours. Here, we propose a novel mathematical definition of salience, that combines aspects of dopamine’s role in both learning and motivation within the reinforcement learning framework. Using a single parameter regime, we simulated addictive behaviours that the (Zhang et al., 2009; Redish, 2004) models also produce but we went further in simulating the downweighting of drug-related negative prediction-errors, steeper delay discounting of drug rewards, craving behaviours and aspects of behavioural/non-pharmacological addictions. The current salience model builds on our recently proposed conceptual theory that salience modulates internal representation updating and may contribute to addictive behaviours by producing misaligned internal representations (Kalhan et al., 2021). Critically, our current mathematical model of salience argues that the seemingly disparate learning and motivational aspects of dopaminergic functioning may interact through a salience mechanism that modulates internal representation updating.}
}
@article{ZHENG2023405,
title = {Quantized minimum error entropy with fiducial points for robust regression},
journal = {Neural Networks},
volume = {168},
pages = {405-418},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005300},
author = {Yunfei Zheng and Shiyuan Wang and Badong Chen},
keywords = {Minimum error entropy with fiducial points, Quantized method, Robust regression, Random vector functional link network, Broad learning system},
abstract = {Minimum error entropy with fiducial points (MEEF) has received a lot of attention, due to its outstanding performance to curb the negative influence caused by non-Gaussian noises in the fields of machine learning and signal processing. However, the estimate of the information potential of MEEF involves a double summation operator based on all available error samples, which can result in large computational burden in many practical scenarios. In this paper, an efficient quantization method is therefore adopted to represent the primary set of error samples with a smaller subset, generating a quantized MEEF (QMEEF). Some basic properties of QMEEF are presented and proved from theoretical perspectives. In addition, we have applied this new criterion to train a class of linear-in-parameters models, including the commonly used linear regression model, random vector functional link network, and broad learning system as special cases. Experimental results on various datasets are reported to demonstrate the desirable performance of the proposed methods to perform regression tasks with contaminated data.}
}
@article{WU2023601,
title = {MPCNet: Compressed multi-view video restoration via motion-parallax complementation network},
journal = {Neural Networks},
volume = {167},
pages = {601-614},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004574},
author = {Chang Wu and Gang He and Xinquan Lai and Yunsong Li},
keywords = {Multi-view video coding, Video compression restoration, Stereo information, Deep neural network},
abstract = {The performance in restoring compressed multi-view video (MVV) of the existing learning-based methods is limited because they only utilize information of temporally adjacent frames or parallax neighboring views. However, the compression artifacts caused by multi-view coding (MVC) may be related to the reference errors of intra-frame, inter-frame, and inter-view. In this paper, with delicately utilizing the stereo information from both temporal and parallax domains, a motion-parallax complementation network (MPCNet) is proposed to restore the quality of compressed MVV more efficiently. First, we introduce a motion-parallax complementation strategy consisting of a coarse stage and a fine stage. By mutually compensating the feature extracted from multiple domains, useful multi-frame information can be efficiently preserved and aggregated step by step. Second, an attention-based feature filtering and modulation module (AFFM) is proposed, which provides an efficient fusion method for two features by suppressing misleading information. By deploying it in most submodules of the proposed approach, the representational ability of MPCNet can be improved, resulting in a more substantial restoration performance. Experimental results prove the effectiveness of MPCNet by an average increase of 1.978 dB in PSNR, and 0.0282 in MS-SSIM. The BD-rate reduction can reach 47.342% on average. The subjective quality is greatly improved and lots of compression distortions are eliminated. Meanwhile, this work also benefits the accuracy improvement for high-level vision tasks, e.g., mIoU of semantic segmentation and mAP of object detection achieve 0.352 and 51.71, respectively. Quantitative and qualitative analyses demonstrate that MPCNet outperforms state-of-the-art approaches.}
}
@article{WU2023419,
title = {Enhancing neurodynamic approach with physics-informed neural networks for solving non-smooth convex optimization problems},
journal = {Neural Networks},
volume = {168},
pages = {419-430},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004331},
author = {Dawen Wu and Abdel Lisser},
keywords = {Non-smooth convex optimization problem, Neurodynamic optimization, Physics-informed neural network, Numerical integration method, Ordinary differential equation},
abstract = {This paper proposes a deep learning approach for solving non-smooth convex optimization problems (NCOPs), which have broad applications in computer science, engineering, and physics. Our approach combines neurodynamic optimization with physics-informed neural networks (PINNs) to provide an efficient and accurate solution. We first use neurodynamic optimization to formulate an initial value problem (IVP) that involves a system of ordinary differential equations for the NCOP. We then introduce a modified PINN as an approximate state solution to the IVP. Finally, we develop a dedicated algorithm to train the model to solve the IVP and minimize the NCOP objective simultaneously. Unlike existing numerical integration methods, a key advantage of our approach is that it does not require the computation of a series of intermediate states to produce a prediction of the NCOP. Our experimental results show that this computational feature results in fewer iterations being required to produce more accurate prediction solutions. Furthermore, our approach is effective in finding feasible solutions that satisfy the NCOP constraint.}
}
@article{DAN2023518,
title = {Trust-aware conditional adversarial domain adaptation with feature norm alignment},
journal = {Neural Networks},
volume = {168},
pages = {518-530},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005543},
author = {Jun Dan and Tao Jin and Hao Chi and Shunjie Dong and Haoran Xie and Keying Cao and Xinjing Yang},
keywords = {Transfer learning, Domain adaptation, Transferability, Feature norm, Re-weighted adversarial training},
abstract = {Adversarial learning has proven to be an effective method for capturing transferable features for unsupervised domain adaptation. However, some existing conditional adversarial domain adaptation methods assign equal importance to different samples, ignoring the fact that hard-to-transfer samples might damage the conditional adversarial adaptation procedure. Meanwhile, some methods can only roughly align marginal distributions across domains, but cannot ensure category distributions alignment, causing classifiers to make uncertain or even wrong predictions for some target data. Furthermore, we find that the feature norms of real images usually follow a complex distribution, so directly matching the mean feature norms of two domains cannot effectively reduce the statistical discrepancy of feature norms and may potentially induce feature degradation. In this paper, we develop a Trust-aware Conditional Adversarial Domain Adaptation (TCADA) method for solving the aforementioned issues. To quantify data transferability, we suggest utilizing posterior probability modeled by a Gaussian-uniform mixture, which effectively facilitates conditional domain alignment. Based on this posterior probability, a confidence-guided alignment strategy is presented to promote precise alignment of category distributions and accelerate the learning of shared features. Moreover, a novel optimal transport-based strategy is introduced to align the feature norms and facilitate shared features becoming more informative. To encourage classifiers to make more accurate predictions for target data, we also design a mixed information-guided entropy regularization term to promote deep features being away from the decision boundaries. Extensive experiments show that our method greatly improves transfer performance on various tasks.}
}
@article{WANG2023751,
title = {Dichotomy value iteration with parallel learning design towards discrete-time zero-sum games},
journal = {Neural Networks},
volume = {167},
pages = {751-762},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005026},
author = {Jiangyu Wang and Ding Wang and Xin Li and Junfei Qiao},
keywords = {Adaptive critic, Artificial neural networks, Nonlinear systems, Parallel learning, Value iteration, Zero-sum games},
abstract = {In this paper, a novel parallel learning framework is developed to solve zero-sum games for discrete-time nonlinear systems. Briefly, the purpose of this study is to determine a tentative function according to the prior knowledge of the value iteration (VI) algorithm. The learning process of the parallel controllers can be guided by the tentative function. That is to say, the neighborhood of the optimal cost function can be compressed within a small range via two typical exploration policies. Based on the parallel learning framework, a novel dichotomy VI algorithm is established to accelerate the learning speed. It is shown that the parallel controllers will converge to the optimal policy from contrary initial policies. Finally, two typical systems are used to demonstrate the learning performance of the constructed dichotomy VI algorithm.}
}
@article{TANG2023339,
title = {Generalized heterophily graph data augmentation for node classification},
journal = {Neural Networks},
volume = {168},
pages = {339-349},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005142},
author = {Bisheng Tang and Xiaojun Chen and Shaopu Wang and Yuexin Xuan and Zhendong Zhao},
keywords = {Heterophily, Graph data augmentation, Self-supervised},
abstract = {Graph data augmentations have demonstrated remarkable performance on homophilic graph neural networks (GNNs). Nevertheless, when transferred to a heterophilic graph, these augmentations are less effective for GNN models and lead to reduced performance. To address this issue, we propose a unified augmentation approach called GePHo, a regularization technique for heterophilic graph neural networks based on self-supervised learning, leveraging graph data augmentation to acquire extra information to guide model learning. Specifically, we propose to generate a pseudo-homophily graph that is type-agnostic, enabling us to apply GePHo to both homophilic and heterophilic graphs. Then, we regularize the neighbors with a sharpening technique for data augmentation and generate the auxiliary pseudo-labels to classify the original GNN’s output, whose operations are to constrain the local and global node representation, respectively. Extensive experiments on three homophilic graph and six heterophilic graph datasets demonstrate the competitive effectiveness of GePHo in node classification task, and the ablation experiments verify the efficacy of our GePHo in graph data augmentation.}
}
@article{ZHU2023450,
title = {Unsupervised anomaly detection by densely contrastive learning for time series data},
journal = {Neural Networks},
volume = {168},
pages = {450-458},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.038},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005385},
author = {Wei Zhu and Weijian Li and E. Ray Dorsey and Jiebo Luo},
keywords = {Unsupervised anomaly detection, Contrastive learning, Multivariate time series, Parkinson’s disease},
abstract = {Time series data continuously collected by different sensors play an essential role in monitoring and predicting events in many real-world applications, and anomaly detection for time series has received increasing attention during the past decades. In this paper, we propose an anomaly detection method by densely contrasting the whole time series with its sub-sequences at different timestamps in a latent space. Our approach leverages the locality property of convolutional neural networks (CNN) and integrates position embedding to effectively capture local features for sub-sequences. Simultaneously, we employ an attention mechanism to extract global features from the entire time series. By combining these local and global features, our model is trained using both instance-level contrastive learning loss and distribution-level alignment loss. Furthermore, we introduce a reconstruction loss applied to the extracted global features to prevent the potential loss of information. To validate the efficacy of our proposed technique, we conduct experiments on publicly available time-series datasets for anomaly detection. Additionally, we evaluate our method on an in-house mobile phone dataset aimed at monitoring the status of Parkinson’s disease, all within an unsupervised learning framework. Our results demonstrate the effectiveness and potential of the proposed approach in tackling anomaly detection in time series data, offering promising applications in real-world scenarios.}
}
@article{TARIGOPULA202389,
title = {Improved prediction of behavioral and neural similarity spaces using pruned DNNs},
journal = {Neural Networks},
volume = {168},
pages = {89-104},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.049},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004690},
author = {Priya Tarigopula and Scott Laurence Fairhall and Anna Bavaresco and Nhut Truong and Uri Hasson},
keywords = {DNNs, Pruning, Representational-similarity, Similarity},
abstract = {Deep Neural Networks (DNNs) have become an important tool for modeling brain and behavior. One key area of interest has been to apply these networks to model human similarity judgements. Several previous works have used the embeddings from the penultimate layer of vision DNNs and showed that a reweighting of these features improves the fit between human similarity judgments and DNNs. These studies underline the idea that these embeddings form a good basis set but lack the correct level of salience. Here we re-examined the grounds for this idea and on the contrary, we hypothesized that these embeddings, beyond forming a good basis set, also have the correct level of salience to account for similarity judgments. It is just that the huge dimensional embedding needs to be pruned to select those features relevant for the considered domain for which a similarity space is modeled. In Study 1 we supervised DNN pruning based on a subset of human similarity judgments. We found that pruning: i) improved out-of-sample prediction of human similarity judgments from DNN embeddings, ii) produced better alignment with WordNet hierarchy, and iii) retained much higher classification accuracy than reweighting. Study 2 showed that pruning by neurobiological data is highly effective in improving out-of-sample prediction of brain-derived representational dissimilarity matrices from DNN embeddings, at times fleshing out isomorphisms not otherwise observable. Using pruned DNNs, image-level heatmaps can be produced to identify image sections whose features load on dimensions coded by a brain area. Pruning supervised by human brain/behavior therefore effectively identifies alignable dimensions of knowledge between DNNs and humans and constitutes an effective method for understanding the organization of knowledge in neural networks.}
}
@article{HE2023572,
title = {Chaos and multi-layer attractors in asymmetric neural networks coupled with discrete fractional memristor},
journal = {Neural Networks},
volume = {167},
pages = {572-587},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.041},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004616},
author = {Shaobo He and D. Vignesh and Lamberto Rondoni and Santo Banerjee},
keywords = {Discrete fractional calculus, Neural networks, Memristor, Chaos},
abstract = {This article introduces a novel model of asymmetric neural networks combined with fractional difference memristors, which has both theoretical and practical implications in the rapidly evolving field of computational intelligence. The proposed model includes two types of fractional difference memristor elements: one with hyperbolic tangent memductance and the other with periodic memductance and memristor state described by sine functions. The authenticity of the constructed memristor is confirmed through fingerprint verification. The research extensively investigates the dynamics of a coupled neural network model, analyzing its stability at equilibrium states, studying bifurcation diagrams, and calculating the largest Lyapunov exponents. The results suggest that when incorporating sine memristors, the model demonstrates coexisting state variables depending on the initial conditions, revealing the emergence of multi-layer attractors. The article further demonstrates how the memristor state shifts through numerical simulations with varying memductance values. Notably, the study emphasizes the crucial role of memductance (synaptic weight) in determining the complex dynamical characteristics of neural network systems. To support the analytical results and demonstrate the chaotic response of state variables, the article includes appropriate numerical simulations. These simulations effectively validate the presented findings and provide concrete evidence of the system’s chaotic behavior.}
}
@article{WANG2023431,
title = {A self-training algorithm based on the two-stage data editing method with mass-based dissimilarity},
journal = {Neural Networks},
volume = {168},
pages = {431-449},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.046},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005427},
author = {Jikui Wang and Yiwen Wu and Shaobo Li and Feiping Nie},
keywords = {Self-training algorithm, Mass-based dissimilarity, Data editing, Relative node set},
abstract = {A self-training algorithm is a classical semi-supervised learning algorithm that uses a small number of labeled samples and a large number of unlabeled samples to train a classifier. However, the existing self-training algorithms consider only the geometric distance between data while ignoring the data distribution when calculating the similarity between samples. In addition, misclassified samples can severely affect the performance of a self-training algorithm. To address the above two problems, this paper proposes a self-training algorithm based on data editing with mass-based dissimilarity (STDEMB). First, the mass matrix with the mass-based dissimilarity is obtained, and then the mass-based local density of each sample is determined based on its k nearest neighbors. Inspired by density peak clustering (DPC), this study designs a prototype tree based on the prototype concept. In addition, an efficient two-stage data editing algorithm is developed to edit misclassified samples and efficiently select high-confidence samples during the self-training process. The proposed STDEMB algorithm is verified by experiments using accuracy and F-score as evaluation metrics. The experimental results on 18 benchmark datasets demonstrate the effectiveness of the proposed STDEMB algorithm.}
}
@article{TIAN2023626,
title = {Causal multi-label learning for image classification},
journal = {Neural Networks},
volume = {167},
pages = {626-637},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.052},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004732},
author = {Yingjie Tian and Kunlong Bai and Xiaotong Yu and Siyu Zhu},
keywords = {Causal inference, Multi-label image classification, Deep learning, Representation learning},
abstract = {In this paper, we investigate the problem of causal image classification with multi-label learning. As multi-label learning involves a diversity of supervision signals, it is considered a challenging issue to solve. Previous approaches have attempted to improve performance by identifying label-related image areas or exploiting the co-occurrence of labels. However, these methods are often characterized by complicated procedures, tedious computations, and a lack of intuitive interpretations. To overcome these limitations, we propose a novel approach that incorporates the concept of causal inference, which has been shown to be beneficial in other computer vision problems. Our method, called causal multi-label learning (CMLL), enables the selection of multiple objects from the original image through a multi-class attention module. These objects are then subjected to causal intervention to learn the causal relationships between different labels. Our proposed approach is both elegant and effective, with low computational cost and few parameters required for the multi-class causal intervention approach. Extensive tests and ablation studies demonstrate that the proposed method significantly improves prediction performance without a significant increase in training and inference times.}
}
@article{LEI2023171,
title = {RepCo: Replenish sample views with better consistency for contrastive learning},
journal = {Neural Networks},
volume = {168},
pages = {171-179},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004975},
author = {Xinyu Lei and Longjun Liu and Yi Zhang and Puhang Jia and Haonan Zhang and Nanning Zheng},
keywords = {Contrastive learning, Sampling strategy, Self-supervised pretraining},
abstract = {Contrastive learning methods aim to learn shared representations by minimizing distances between positive pairs, and maximizing distances between negative pairs in the embedding space. To achieve better performance of contrastive learning, one of the key problems is to design appropriate sample pairs. In most previous works, random cropping on the input image is utilized to obtain two views as positive pairs. However, such strategies lead to suboptimal performance since the sampled crops may have inconsistent semantic information, which consequently degrades the quality of contrastive views. To address this limitation, we explore to replenish sample views with better consistency of the image and propose a novel self-supervised learning (SSL) framework RepCo. Instead of searching for semantically consistent patches between two different views, we select patches on the same image as the replenishment of positive/negative pairs, encourage patches that are similar but come from different positions as positive pairs, and force patches that are dissimilar but come from adjacent positions to have different representations, i.e. construct negative pairs to enrich the learned representations. Our method effectively generates high-quality contrastive views, explores the untapped semantic consistency on images, and provides more informative representations for downstream tasks. Experiments on adequate downstream tasks have shown that, our approach achieves ＋2.1 AP50 (COCO pre-trained) and ＋1.6 AP50 (ImageNet pre-trained) gains on Pascal VOC object detection, ＋2.3 mIoU gains on Cityscapes semantic segmentation, respectively.}
}
@article{DOU2023484,
title = {Understanding neural network through neuron level visualization},
journal = {Neural Networks},
volume = {168},
pages = {484-495},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005269},
author = {Hui Dou and Furao Shen and Jian Zhao and Xinyu Mu},
keywords = {Interpretability, Neural network, Visualization},
abstract = {Neurons are the fundamental units of neural networks. In this paper, we propose a method for explaining neural networks by visualizing the learning process of neurons. For a trained neural network, the proposed method obtains the features learned by each neuron and displays the features in a human-understandable form. The features learned by different neurons are combined to analyze the working mechanism of different neural network models. The method is applicable to neural networks without requiring any changes to the architectures of the models. In this study, we apply the proposed method to both Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs) trained using the backpropagation learning algorithm. We conduct experiments on models for image classification tasks to demonstrate the effectiveness of the method. Through these experiments, we gain insights into the working mechanisms of various neural network architectures and evaluate neural network interpretability from diverse perspectives.}
}
@article{GAO2023551,
title = {Glimpse and focus: Global and local-scale graph convolution network for skeleton-based action recognition},
journal = {Neural Networks},
volume = {167},
pages = {551-558},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.051},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004458},
author = {Xuehao Gao and Shaoyi Du and Yang Yang},
keywords = {Global and local-scale graph, Graph convolution network, Skeleton-based action recognition},
abstract = {In the 3D skeleton-based action recognition task, learning rich spatial and temporal motion patterns from body joints are two foundational yet under-explored problems. In this paper, we propose two methods for improving these problems: (I) a novel glimpse-focus action recognition strategy that captures multi-range pose features from the whole body and key body parts jointly; (II) a powerful temporal feature extractor JD-TC that enriches trajectory features by inferring different inter-frame correlations for different joints. By coupling these two proposals, we develop a powerful skeleton-based action recognition system that extracts rich pose and trajectory features from a skeleton sequence and outperforms previous state-of-the-art methods on three large-scale datasets.}
}
@article{SPINELLI2023159,
title = {Drop edges and adapt: A fairness enforcing fine-tuning for graph neural networks},
journal = {Neural Networks},
volume = {167},
pages = {159-167},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004215},
author = {Indro Spinelli and Riccardo Bianchini and Simone Scardapane},
keywords = {Graph neural network, Fairness, Link prediction},
abstract = {The rise of graph representation learning as the primary solution for many different network science tasks led to a surge of interest in the fairness of this family of methods. Link prediction, in particular, has a substantial social impact. However, link prediction algorithms tend to increase the segregation in social networks by disfavouring the links between individuals in specific demographic groups. This paper proposes a novel way to enforce fairness on graph neural networks with a fine-tuning strategy. We Drop the unfair Edges and, simultaneously, we Adapt the model’s parameters to those modifications, DEA in short. We introduce two covariance-based constraints designed explicitly for the link prediction task. We use these constraints to guide the optimization process responsible for learning the new ‘fair’ adjacency matrix. One novelty of DEA is that we can use a discrete yet learnable adjacency matrix in our fine-tuning. We demonstrate the effectiveness of our approach on five real-world datasets and show that we can improve both the accuracy and the fairness of the link prediction tasks. In addition, we present an in-depth ablation study demonstrating that our training algorithm for the adjacency matrix can be used to improve link prediction performances during training. Finally, we compute the relevance of each component of our framework to show that the combination of both the constraints and the training of the adjacency matrix leads to optimal performances.}
}
@article{ZHUGE2023313,
title = {Single image denoising with a feature-enhanced network},
journal = {Neural Networks},
volume = {168},
pages = {313-325},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.056},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004859},
author = {Ruibin Zhuge and Jinghua Wang and Zenglin Xu and Yong Xu},
keywords = {Image denoising, Channel attention, Transformer},
abstract = {Recent Transformer-based networks have shown impressive performance on single image denoising tasks. While the Transformer model promotes the interaction of long-range features, it generally involves high computational complexity. In this paper, we propose a feature-enhanced denoising network (FEDNet) by combining CNN architectures with Transformers. Specifically, we propose an effective cross-channel attention to boost the interaction of channel information and enhance channel features. In order to fully exploit image features, we incorporate Transformer blocks into minimum-scale layers of the network, which can not only capture the long-distance dependency of low-resolution features but also reduce the multiplier-accumulator operations (MACs). Meanwhile, a structure-preserving block is designed to enhance the structural feature extraction. Experimental results on both synthetic and real-world datasets demonstrate that our model can achieve the state-of-the-art denoising performance with low computational costs.}
}
@article{ZHOU2023496,
title = {A multidimensional feature fusion network based on MGSE and TAAC for video-based human action recognition},
journal = {Neural Networks},
volume = {168},
pages = {496-507},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.09.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005270},
author = {Shuang Zhou and Hongji Xu and Zhiquan Bai and Zhengfeng Du and Jiaqi Zeng and Yang Wang and Yuhao Wang and Shijie Li and Mengmeng Wang and Yiran Li and Jianjun Li and Jie Xu},
keywords = {Human action recognition, Multidimensional feature, Multiscale convolution},
abstract = {With the maturity of intelligent technology such as human-computer interaction, human action recognition (HAR) technology has been widely used in virtual reality, video surveillance, and other fields. However, the current video-based HAR methods still cannot fully extract abstract action features, and there is still a lack of action collection and recognition for special personnel such as prisoners and elderly people living alone. To solve the above problems, this paper proposes a multidimensional feature fusion network, called P-MTSC3D, a parallel network based on context modeling and temporal adaptive attention module. It consists of three branches. The first branch serves as the basic network branch, which extracts basic feature information. The second branch consists of a feature pre-extraction layer and two multiscale-convolution-based global context modeling combined squeeze and excitation (MGSE) modules, which can extract spatial and channel features. The third branch consists of two temporal adaptive attention units based on convolution (TAAC) to extract temporal dimension features. In order to verify the validity of the proposed network, this paper conducts experiments on the University of Central Florida (UCF) 101 dataset and the human motion database (HMDB) 51 dataset. The recognition accuracy of the proposed P-MTSC3D network is 97.92% on the UCF101 dataset and 75.59% on the HMDB51 dataset, respectively. The FLOPs of the P-MTSC3D network is 30.85G, and the test time is 2.83 s/16 samples on the UCF101 dataset. The experimental results demonstrate that the P-MTSC3D network has better overall performance than the state-of-the-art networks. In addition, a prison action (PA) dataset is constructed in this paper to verify the application effect of the proposed network in actual scenarios.}
}