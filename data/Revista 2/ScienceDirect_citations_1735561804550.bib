@article{GOU2020104,
title = {Weighted discriminative collaborative competitive representation for robust image classification},
journal = {Neural Networks},
volume = {125},
pages = {104-120},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300228},
author = {Jianping Gou and Lei Wang and Zhang Yi and Yunhao Yuan and Weihua Ou and Qirong Mao},
keywords = {Collaborative representation-based classification, Collaborative representation, Representation-based classification, Image classification, Pattern recognition},
abstract = {Collaborative representation-based classification (CRC) is a famous representation-based classification method in pattern recognition. Recently, many variants of CRC have been designed for many classification tasks with the good classification performance. However, most of them ignore the inter-class pattern discrimination among the class-specific representations, which is very critical for strengthening the pattern discrimination of collaborative representation (CR). In this article, we propose a novel CR approach for image classification, called weighted discriminative collaborative competitive representation (WDCCR). The proposed WDCCR designs the discriminative and competitive collaborative representation among all the classes by fully considering the class information. On the one hand, we incorporate two discriminative constraints into the unified WDCCR model. Both constraints are the competitive class-specific representation residuals and the pairs of class-specific representations for each query sample. On the other hand, the constraint of the weighted categorical representation coefficients is introduced into the proposed model for further enhancing the power of discriminative and competitive representation. In the weighted constraint, we assume that the different classes of each query sample should have less contribution to the representation with the small representation coefficients, and then two types of weight factors are designed to constrain the representation coefficients. Furthermore, the robust WDCCR (R-WDCCR) is proposed with l1-norm representation fidelity for recognizing noisy images. Extensive experiments on six image data sets demonstrate the effective and robust superiorities of the proposed WDCCR and R-WDCCR over the related state-of-the-art representation-based classification methods.}
}
@article{DING202031,
title = {Event-triggered synchronization of discrete-time neural networks: A switching approach},
journal = {Neural Networks},
volume = {125},
pages = {31-40},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300344},
author = {Sanbo Ding and Zhanshan Wang},
keywords = {Discrete-time neural networks, Synchronization, Event-triggered control, Switching method, Actuator saturation},
abstract = {This paper investigates the event-triggered synchronization control of discrete-time neural networks. The main highlights are threefold: (1) a new event-triggered mechanism (ETM) is presented, which can be regarded as a switching between the discrete-time periodic sampled-data control and a continuous ETM; (2) a saturating controller which is equipped with two switching gains is designed to match the switching property of the proposed ETM; (3) a dedicated switching Lyapunov–Krasovskii functional is constructed, which takes the sawtooth constraints of control input into account. Based on these ingredients, the synchronization criteria are derived such that the considered error systems are locally stable. Whereafter, two co-design problems are discussed to maximize the set of admissible initial conditions and the triggering threshold, respectively. Finally, the effectiveness and advantages of the proposed method are validated by two numerical examples.}
}
@article{SCHMIDHUBER202058,
title = {Generative Adversarial Networks are special cases of Artificial Curiosity (1990) and also closely related to Predictability Minimization (1991)},
journal = {Neural Networks},
volume = {127},
pages = {58-66},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301283},
author = {Jürgen Schmidhuber},
keywords = {Artificial Curiosity, Predictability Minimization, Generative Adversarial Networks},
abstract = {I review unsupervised or self-supervised neural networks playing minimax games in game-theoretic settings: (i) Artificial Curiosity (AC, 1990) is based on two such networks. One network learns to generate a probability distribution over outputs, the other learns to predict effects of the outputs. Each network minimizes the objective function maximized by the other. (ii) Generative Adversarial Networks (GANs, 2010-2014) are an application of AC where the effect of an output is 1 if the output is in a given set, and 0 otherwise. (iii) Predictability Minimization (PM, 1990s) models data distributions through a neural encoder that maximizes the objective function minimized by a neural predictor of the code components. I correct a previously published claim that PM is not based on a minimax game.}
}
@article{GONG2020131,
title = {Preserving differential privacy in deep neural networks with relevance-based adaptive noise imposition},
journal = {Neural Networks},
volume = {125},
pages = {131-141},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300460},
author = {Maoguo Gong and Ke Pan and Yu Xie and A.K. Qin and Zedong Tang},
keywords = {Deep neural networks, Differential privacy, Relevance analysis},
abstract = {In recent years, deep learning achieves remarkable results in the field of artificial intelligence. However, the training process of deep neural networks may cause the leakage of individual privacy. Given the model and some background information of the target individual, the adversary can maliciously infer the sensitive feature of the target individual. Therefore, it is imperative to preserve the sensitive information in the training data. Differential privacy is a state-of-the-art paradigm for providing the privacy guarantee of datasets, which protects the private and sensitive information from the attack of adversaries significantly. However, the existing privacy-preserving models based on differential privacy are less than satisfactory since traditional approaches always inject the same amount of noise into parameters to preserve the sensitive information, which may impact the trade-off between the model utility and the privacy guarantee of training data. In this paper, we present a general differentially private deep neural networks learning framework based on relevance analysis, which aims to bridge the gap between private and non-private models while providing an effective privacy guarantee of sensitive information. The proposed model perturbs gradients according to the relevance between neurons in different layers and the model output. Specifically, during the process of backward propagation, more noise is added to gradients of neurons that have less relevance to the model output, and vice-versa. Experiments on five real datasets demonstrate that our mechanism not only bridges the gap between private and non-private models, but also prevents the disclosure of sensitive information effectively.}
}
@article{HAO2020172,
title = {Sequential vessel segmentation via deep channel attention network},
journal = {Neural Networks},
volume = {128},
pages = {172-187},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301672},
author = {Dongdong Hao and Song Ding and Linwei Qiu and Yisong Lv and Baowei Fei and Yueqi Zhu and Binjie Qin},
keywords = {X-ray coronary angiography, Deep learning, Vessel segmentation, temporal–spatial features, Channel attention blocks, Class imbalance},
abstract = {Accurately segmenting contrast-filled vessels from X-ray coronary angiography (XCA) image sequence is an essential step for the diagnosis and therapy of coronary artery disease. However, developing automatic vessel segmentation is particularly challenging due to the overlapping structures, low contrast and the presence of complex and dynamic background artifacts in XCA images. This paper develops a novel encoder–decoder deep network architecture which exploits the several contextual frames of 2D+t sequential images in a sliding window centered at current frame to segment 2D vessel masks from the current frame. The architecture is equipped with temporal–spatial feature extraction in encoder stage, feature fusion in skip connection layers and channel attention mechanism in decoder stage. In the encoder stage, a series of 3D convolutional layers are employed to hierarchically extract temporal–spatial features. Skip connection layers subsequently fuse the temporal–spatial feature maps and deliver them to the corresponding decoder stages. To efficiently discriminate vessel features from the complex and noisy backgrounds in the XCA images, the decoder stage effectively utilizes channel attention blocks to refine the intermediate feature maps from skip connection layers for subsequently decoding the refined features in 2D ways to produce the segmented vessel masks. Furthermore, Dice loss function is implemented to train the proposed deep network in order to tackle the class imbalance problem in the XCA data due to the wide distribution of complex background artifacts. Extensive experiments by comparing our method with other state-of-the-art algorithms demonstrate the proposed method’s superior performance over other methods in terms of the quantitative metrics and visual validation. To facilitate the reproductive research in XCA community, we publicly release our dataset and source codes at https://github.com/Binjie-Qin/SVS-net.}
}
@article{LENG202013,
title = {Common stochastic inputs induce neuronal transient synchronization with partial reset},
journal = {Neural Networks},
volume = {128},
pages = {13-21},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301398},
author = {Siyang Leng and Kazuyuki Aihara},
keywords = {Neural encoding, Stein’s model, Poisson process, Synchronization, Common inputs, Partial reset},
abstract = {Neuronal synchronization plays important roles in information encoding and transmission in the brain. Mathematical models of neurons have been widely used to simulate synchronization behavior and analyze its mechanisms. Common stochastic inputs are considered to be effective in facilitating synchronization. However, the mechanisms of how partial reset affects neuronal synchronization are still not well understood. In this paper, the synchronization of Stein’s model neurons with partial reset is studied. The differences in synchronization mechanisms between neurons with full reset and those with partial reset are analyzed, and the findings lead to the novel concept of transient synchronization. Furthermore, it is proven analytically that due to common stochastic inputs, Stein’s model neurons with different initial membrane potentials and partial reset achieve transient synchronization with probability 1. Additionally, a systematic numerical analysis is performed to explore the similarities and differences between full reset and partial reset regarding model parameters, synchronization time, and desynchronization behavior. Thus, partial reset is a powerful and flexible tool that facilitates neuronal synchronization while reserving the possibility of desynchronization. Our analysis also provides an alternative approach to analyze neurons of the integrate-and-fire family and a theoretical complement implying possible information encoding mechanisms in the brain.}
}
@article{LIAN202029,
title = {Randomized sketches for kernel CCA},
journal = {Neural Networks},
volume = {127},
pages = {29-37},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030126X},
author = {Heng Lian and Fode Zhang and Wenqi Lu},
keywords = {Canonical correlation analysis, Covariance/cross-covariance operator, Kernel method, Random projection},
abstract = {Kernel canonical correlation analysis (KCCA) is a popular tool as a nonlinear extension of canonical correlation analysis. Consistency and optimal convergence rate have been established in the literature. However, the time complexity of KCCA scales as O(n3) and is thus prohibitive when n is large. We propose an m-dimensional randomized sketches approach for KCCA with m<<n, based on the recent work on randomized sketches for kernel ridge regression (KRR). Technically we establish our theoretical results relying on an interesting connection between KCCA and KRR by utilizing a novel “duality tracking” device that alternates between the infinite-dimensional operator-theory-based view of KCCA and the finite-dimensional kernel-matrix-based view.}
}
@article{HAYASHI202065,
title = {Variational approximation error in non-negative matrix factorization},
journal = {Neural Networks},
volume = {126},
pages = {65-75},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300861},
author = {Naoki Hayashi},
keywords = {Non-negative matrix factorization (NMF), Real log canonical threshold (RLCT), Learning coefficient, Bayesian inference, Variational Bayesian method, Variational inference},
abstract = {Non-negative matrix factorization (NMF) is a knowledge discovery method that is used in many fields. Variational inference and Gibbs sampling methods for it are also well-known. However, the variational approximation error has not been clarified yet, because NMF is not statistically regular and the prior distribution used in variational Bayesian NMF (VBNMF) has zero or divergence points. In this paper, using algebraic geometrical methods, we theoretically analyze the difference in negative log evidence (a.k.a. free energy) between VBNMF and Bayesian NMF, i.e., the Kullback–Leibler divergence between the variational posterior and the true posterior. We derive an upper bound for the learning coefficient (a.k.a. the real log canonical threshold) in Bayesian NMF. By using the upper bound, we find a lower bound for the approximation error, asymptotically. The result quantitatively shows how well the VBNMF algorithm can approximate Bayesian NMF; the lower bound depends on the hyperparameters and the true non-negative rank. A numerical experiment demonstrates the theoretical result.}
}
@article{HART2020234,
title = {Embedding and approximation theorems for echo state networks},
journal = {Neural Networks},
volume = {128},
pages = {234-247},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301830},
author = {Allen Hart and James Hook and Jonathan Dawes},
keywords = {Reservoir computing, Lorenz equations, Dynamical system, Delay embedding, Persistent homology, Recurrent neural networks},
abstract = {Echo State Networks (ESNs) are a class of single-layer recurrent neural networks that have enjoyed recent attention. In this paper we prove that a suitable ESN, trained on a series of measurements of an invertible dynamical system, induces a C1 map from the dynamical system’s phase space to the ESN’s reservoir space. We call this the Echo State Map. We then prove that the Echo State Map is generically an embedding with positive probability. Under additional mild assumptions, we further conjecture that the Echo State Map is almost surely an embedding. For sufficiently large, and specially structured, but still randomly generated ESNs, we prove that there exists a linear readout layer that allows the ESN to predict the next observation of a dynamical system arbitrarily well. Consequently, if the dynamical system under observation is structurally stable then the trained ESN will exhibit dynamics that are topologically conjugate to the future behaviour of the observed dynamical system. Our theoretical results connect the theory of ESNs to the delay-embedding literature for dynamical systems, and are supported by numerical evidence from simulations of the traditional Lorenz equations. The simulations confirm that, from a one dimensional observation function, an ESN can accurately infer a range of geometric and topological features of the dynamics such as the eigenvalues of equilibrium points, Lyapunov exponents and homology groups.}
}
@article{FERNANDO202067,
title = {Neural memory plasticity for medical anomaly detection},
journal = {Neural Networks},
volume = {127},
pages = {67-81},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301313},
author = {Tharindu Fernando and Simon Denman and David Ahmedt-Aristizabal and Sridha Sridharan and Kristin R. Laurens and Patrick Johnston and Clinton Fookes},
keywords = {Neural Memory Networks, Anomaly detection, Neural plasticity, Abnormal EEG identification, MRI tumour type classification, Schizophrenia risk detection},
abstract = {In the domain of machine learning, Neural Memory Networks (NMNs) have recently achieved impressive results in a variety of application areas including visual question answering, trajectory prediction, object tracking, and language modelling. However, we observe that the attention based knowledge retrieval mechanisms used in current NMNs restrict them from achieving their full potential as the attention process retrieves information based on a set of static connection weights. This is suboptimal in a setting where there are vast differences among samples in the data domain; such as anomaly detection where there is no consistent criteria for what constitutes an anomaly. In this paper, we propose a plastic neural memory access mechanism which exploits both static and dynamic connection weights in the memory read, write and output generation procedures. We demonstrate the effectiveness and flexibility of the proposed memory model in three challenging anomaly detection tasks in the medical domain: abnormal EEG identification, MRI tumour type classification and schizophrenia risk detection in children. In all settings, the proposed approach outperforms the current state-of-the-art. Furthermore, we perform an in-depth analysis demonstrating the utility of neural plasticity for the knowledge retrieval process and provide evidence on how the proposed memory model generates sparse yet informative memory outputs.}
}
@article{XIAO2020303,
title = {CNN–MHSA: A Convolutional Neural Network and multi-head self-attention combined approach for detecting phishing websites},
journal = {Neural Networks},
volume = {125},
pages = {303-312},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300587},
author = {Xi Xiao and Dianyan Zhang and Guangwu Hu and Yong Jiang and Shutao Xia},
keywords = {Phishing, URL, Deep learning, Convolutional layer, Multi-head self-attention},
abstract = {Increasing phishing sites today have posed great threats due to their terribly imperceptible hazard. They expect users to mistake them as legitimate ones so as to steal user information and properties without notice. The conventional way to mitigate such threats is to set up blacklists. However, it cannot detect one-time Uniform Resource Locators (URL) that have not appeared in the list. As an improvement, deep learning methods are applied to increase detection accuracy and reduce the misjudgment ratio. However, some of them only focus on the characters in URLs but ignore the relationships between characters, which results in that the detection accuracy still needs to be improved. Considering the multi-head self-attention (MHSA) can learn the inner structures of URLs, in this paper, we propose CNN–MHSA, a Convolutional Neural Network (CNN) and the MHSA combined approach for highly-precise. To achieve this goal, CNN–MHSA first takes a URL string as the input data and feeds it into a mature CNN model so as to extract its features. In the meanwhile, MHSA is applied to exploit characters’ relationships in the URL so as to calculate the corresponding weights for the CNN learned features. Finally, CNN–MHSA can produce highly-precise detection result for a URL object by integrating its features and their weights. The thorough experiments on a dataset collected in real environment demonstrate that our method achieves 99.84% accuracy, which outperforms the classical method CNN–LSTM and at least 6.25% higher than other similar methods on average.}
}
@article{QI2020150,
title = {Synchronization criteria for quaternion-valued coupled neural networks with impulses},
journal = {Neural Networks},
volume = {128},
pages = {150-157},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301556},
author = {Xingnan Qi and Haibo Bao and Jinde Cao},
keywords = {Quaternion-valued, Coupled neural network, Synchronization, Impulses},
abstract = {We consider the global exponential synchronization of a category of quaternion-valued coupled neural networks (QVCNNs) with impulses in this article. It makes up for the gap of coupled neural networks with impulses in quaternion. On account of the product of two quaternions cannot be exchanged under normal circumstances, for convenience, we isolate the QVCNN into four real-valued coupled neural networks (RVCNNs) which are converted into an augmented system by defining a new augmented vector. By leveraging a distinctive Lyapunov–Krasovskii function and some matrix inequalities, several sufficient conditions for the global exponential synchronization of the system are attained. Ultimately, two examples are used to prove the validity of the theories in this paper.}
}
@article{CHEN2020165,
title = {Reachable set bounding for neural networks with mixed delays: Reciprocally convex approach},
journal = {Neural Networks},
volume = {125},
pages = {165-173},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300502},
author = {Ruihan Chen and Song Zhu and Yongqiang Qi and Yuxin Hou},
keywords = {Reachable set, Maximal Lyapunov functional, Mixed delays systems, Polytopic uncertainties, Reciprocally convex},
abstract = {This paper discusses the reachable set estimation problem of neural networks with mixed delays. Firstly, by means of the maximal Lyapunov–Krasovskii functional, we obtain a non-ellipsoid form of the reachable set. Further more, when calculating the derivative of the maximum Lyapunov functional, the lower bound lemma and reciprocally convex approach method are used to solve the reciprocally convex combination term, which reduce the related decision variables. Secondly, we extend the results to polytopic uncertainties neural networks and consider the case of uncertain differentiable parameters. Finally, two numerical examples and one application example are listed to show the validity of our methods.}
}
@article{FAYDASICOK2020330,
title = {New criteria for global stability of neutral-type Cohen–Grossberg neural networks with multiple delays},
journal = {Neural Networks},
volume = {125},
pages = {330-337},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300745},
author = {Ozlem Faydasicok},
keywords = {Neutral systems, Delayed neural networks, Stability analysis, Lyapunov stability theorems},
abstract = {The significant contribution of this paper is the addressing the stability issue of neutral-type Cohen–Grossberg neural networks possessing multiple time delays in the states of the neurons and multiple neutral delays in time derivative of states of the neurons. By making the use of a novel and enhanced Lyapunov functional, some new sufficient stability criteria are presented for this model of neutral-type neural systems. The obtained stability conditions are completely dependent of the parameters of the neural system and independent of time delays and neutral delays. A constructive numerical example is presented for the sake of proving the key advantages of the proposed stability results over the previously reported corresponding stability criteria for Cohen–Grossberg neural networks of neutral type. Since, stability analysis of Cohen–Grossberg neural networks involving multiple time delays and multiple neutral delays is a difficult problem to overcome, the investigations of the stability conditions of the neutral-type the stability analysis of this class of neural network models have not been given much attention. Therefore, the stability criteria derived in this work can be evaluated as a valuable contribution to the stability analysis of neutral-type Cohen–Grossberg neural systems involving multiple delays.}
}
@article{LONNQVIST2020262,
title = {Crowding in humans is unlike that in convolutional neural networks},
journal = {Neural Networks},
volume = {126},
pages = {262-274},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300988},
author = {Ben Lonnqvist and Alasdair D.F. Clarke and Ramakrishna Chakravarthi},
keywords = {Convolutional neural networks, Object recognition, Crowding},
abstract = {Object recognition is a primary function of the human visual system. It has recently been claimed that the highly successful ability to recognise objects in a set of emergent computer vision systems—Deep Convolutional Neural Networks (DCNNs)—can form a useful guide to recognition in humans. To test this assertion, we systematically evaluated visual crowding, a dramatic breakdown of recognition in clutter, in DCNNs and compared their performance to extant research in humans. We examined crowding in three architectures of DCNNs with the same methodology as that used among humans. We manipulated multiple stimulus factors including inter-letter spacing, letter colour, size, and flanker location to assess the extent and shape of crowding in DCNNs. We found that crowding followed a predictable pattern across architectures that was different from that in humans. Some characteristic hallmarks of human crowding, such as invariance to size, the effect of target-flanker similarity, and confusions between target and flanker identities, were completely missing, minimised or even reversed. These data show that DCNNs, while proficient in object recognition, likely achieve this competence through a set of mechanisms that are distinct from those in humans. They are not necessarily equivalent models of human or primate object recognition and caution must be exercised when inferring mechanisms derived from their operation.}
}
@article{HUANG2020143,
title = {SDARE: A stacked denoising autoencoder method for game dynamics network structure reconstruction},
journal = {Neural Networks},
volume = {126},
pages = {143-152},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030085X},
author = {Keke Huang and Shuo Li and Penglin Dai and Zhen Wang and Zhaofei Yu},
keywords = {Complex network, Network structure reconstruction, Deep learning, Stacked denoising autoencoder, Compressive sensing},
abstract = {Complex network is a general model to represent the interactions within technological, social, information, and biological interaction. Often, the direct detection of the interaction relationship is costly. Thus, network structure reconstruction, the inverse problem in complex networked systems, is of utmost importance for understanding many complex systems with unknown interaction structures. In addition, the data collected from real network system is often contaminated by noise, which makes the network structure inference task much more challenging. In this paper, we develop a new framework for the game dynamics network structure reconstruction based on deep learning method. In contrast to the compressive sensing methods that employ computationally complex convex/greedy algorithms to solve the network reconstruction task, we introduce a deep learning framework that can learn a structured representation from nodes data and efficiently reconstruct the game dynamics network structure with few observation data. Specifically, we propose the denoising autoencoders (DAEs) as the unsupervised feature learner to capture statistical dependencies between different nodes. Compared to the compressive sensing based method, the proposed method is a global network structure inference method, which can not only get the state-of-art performance, but also obtain the structure of network directly. Besides, the proposed method is robust to noise in the observation data. Moreover, the proposed method is also effective for the network which is not exactly sparse. Accordingly, the proposed method can extend to a wide scope of network reconstruction task in practice.}
}
@article{BETTI2020275,
title = {Learning visual features under motion invariance},
journal = {Neural Networks},
volume = {126},
pages = {275-299},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300903},
author = {Alessandro Betti and Marco Gori and Stefano Melacci},
keywords = {Convolutional networks, Invariance of visual features, Information-based learning, Neural differential equations, Principle of least cognitive action},
abstract = {Humans are continuously exposed to a stream of visual data with a natural temporal structure. However, most successful computer vision algorithms work at image level, completely discarding the precious information carried by motion. In this paper, we claim that processing visual streams naturally leads to formulate the motion invariance principle, which enables the construction of a new theory of learning that originates from variational principles, just like in physics. Such principled approach is well suited for a discussion on a number of interesting questions that arise in vision, and it offers a well-posed computational scheme for the discovery of convolutional filters over the retina. Differently from traditional convolutional networks, which need massive supervision, the proposed theory offers a truly new scenario for the unsupervised processing of video signals, where features are extracted in a multi-layer architecture with motion invariance. While the theory enables the implementation of novel computer vision systems, it also sheds light on the role of information-based principles to drive possible biological solutions.}
}
@article{2022II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {147},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00020-X},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200020X}
}
@article{HUA202047,
title = {Further results on finite-time synchronization of delayed inertial memristive neural networks via a novel analysis method},
journal = {Neural Networks},
volume = {127},
pages = {47-57},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301295},
author = {Lanfeng Hua and Shouming Zhong and Kaibo Shi and Xiaojun Zhang},
keywords = {Finite-time synchronization, Inertial memristive neural networks, New inequality methods, Mixed time-varying delays},
abstract = {In this paper, we propose a novel analysis method to investigate the finite-time synchronization (FTS) control problem of the drive–response inertial memristive neural networks (IMNNs) with mixed time-varying delays (MTVDs). Firstly, an improved control scheme is proposed under the delay-independent conditions, which can work even when the past state cannot be measured or the specific time delay function is unknown. Secondly, based on the assumption of bounded activation functions, we establish a new Lemma, which can effectively deal with the difficulties caused by memristive connection weights and MTVDs. Thirdly, by constructing a suitable Lyapunov functions and using a new inequality method, novel sufficient conditions to ensure the FTS for the discussed IMNNs are obtained. Compared with the existing results, our results obtained in a more general framework are more practical. Finally, some numerical simulations are given to substantiate the effectiveness of the theoretical results.}
}
@article{CHENG2020313,
title = {Improved multi-view GEPSVM via Inter-View Difference Maximization and Intra-view Agreement Minimization},
journal = {Neural Networks},
volume = {125},
pages = {313-329},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300472},
author = {Yawen Cheng and Hang Yin and Qiaolin Ye and Peng Huang and Liyong Fu and Zhangjing Yang and Yuan Tian},
keywords = {Multi-view learning, GEPSVM, L1-norm, IMvGEPSVM, Robustness},
abstract = {Multiview Generalized Eigenvalue Proximal Support Vector Machine (MvGEPSVM) is an effective method for multiview data classification proposed recently. However, it ignores discriminations between different views and the agreement of the same view. Moreover, there is no robustness guarantee. In this paper, we propose an improved multiview GEPSVM (IMvGEPSVM) method, which adds a multi-view regularization that can connect different views of the same class and simultaneously considers the maximization of the samples from different classes in heterogeneous views for promoting discriminations. This makes the classification more effective. In addition, L1-norm rather than squared L2-norm is employed to calculate the distances from each of the sample points to the hyperplane so as to reduce the effect of outliers in the proposed model. To solve the resulting objective, an efficient iterative algorithm is presented. Theoretically, we conduct the proof of the algorithm’s convergence. Experimental results show the effectiveness of the proposed method.}
}
@article{SIMA2020199,
title = {Analog neuron hierarchy},
journal = {Neural Networks},
volume = {128},
pages = {199-215},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301684},
author = {Jiří Šíma},
keywords = {Recurrent neural network, Analog neuron hierarchy, Deterministic context-free language, Turing machine, Chomsky hierarchy},
abstract = {In order to refine the analysis of the computational power of discrete-time recurrent neural networks (NNs) between the binary-state NNs which are equivalent to finite automata (level 3 in the Chomsky hierarchy), and the analog-state NNs with rational weights which are Turing-complete (Chomsky level 0), we study an intermediate model αANN of a binary-state NN that is extended with α≥0 extra analog-state neurons. For rational weights, we establish an analog neuron hierarchy 0ANNs ⊂ 1ANNs ⊂ 2ANNs ⊆ 3ANNs and separate its first two levels. In particular, 0ANNs coincide with the binary-state NNs (Chomsky level 3) being a proper subset of 1ANNs which accept at most context-sensitive languages (Chomsky level 1) including some non-context-free ones (above Chomsky level 2). We prove that the deterministic (context-free) language L#={0n1n∣n≥1} cannot be recognized by any 1ANN even with real weights. In contrast, we show that deterministic pushdown automata accepting deterministic languages can be simulated by 2ANNs with rational weights, which thus constitute a proper superset of 1ANNs. Finally, we prove that the analog neuron hierarchy collapses to 3ANNs by showing that any Turing machine can be simulated by a 3ANN having rational weights, with linear-time overhead.}
}
@article{WANG2020347,
title = {A fast conformal predictive system with regularized extreme learning machine},
journal = {Neural Networks},
volume = {126},
pages = {347-361},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301167},
author = {Di Wang and Ping Wang and Yue Yuan and Pingping Wang and Junzhi Shi},
keywords = {Conformal predictive system, Cross-conformal predictive system, Cumulative distribution function, Asymptotic validity, Regularized extreme learning machine},
abstract = {A conformal predictive system(CPS) is based on the learning framework of conformal prediction, which outputs cumulative distribution functions(CDFs) for labels in regression problems. The CDFs output by a CPS provide useful information for users, as they not only provide probability for the events related to the test labels, but also can be transformed to prediction intervals with the corresponding quantiles. Moreover, CPSs have the property of validity since the distributions and intervals they output have statistical compatibility with the realizations. This property is very useful for many risk-sensitive applications such as financial time series forecast and weather forecast. However, as based on conformal predictors, CPSs inherit the computational issue. To build a fast CPS, in this paper, we propose a CPS with regularized extreme learning machine as the underlying algorithm. To be specific, we combine the leave-one-out cross-conformal predictive system(Leave-One-Out CCPS), a variant of the original CPS, with regularized extreme learning machine(RELM), which is named as LOO-CCPS-RELM. We analyse the computational complexity of it and prove its asymptotic validity based on some regularity assumptions. We also prove that the error rate of the prediction interval output by LOO-CCPS-RELM is under control in the asymptotic setting. Experiments with 20 public data sets were conducted to test LOO-CCPS-RELM and the results showed that LOO-CCPS-RELM is empirically valid and compared favourably with the other CPSs.}
}
@article{ZHOU202052,
title = {Recommendation via Collaborative Autoregressive Flows},
journal = {Neural Networks},
volume = {126},
pages = {52-64},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300873},
author = {Fan Zhou and Yuhua Mo and Goce Trajcevski and Kunpeng Zhang and Jin Wu and Ting Zhong},
keywords = {Collaborative recommendation, Variational inference, Normalizing flows, Autoregressive flows, Generative models},
abstract = {Although it is one of the most widely used methods in recommender systems, Collaborative Filtering (CF) still has difficulties in modeling non-linear user–item interactions. Complementary to this, recently developed deep generative model variants (e.g., Variational Autoencoder (VAE)) allowing Bayesian inference and approximation of the variational posterior distributions in these models, have achieved promising performance improvement in many areas. However, the choices of variation distribution – e.g., the popular diagonal-covariance Gaussians – are insufficient to recover the true distributions, often resulting in biased maximum likelihood estimates of the model parameters. Aiming at more tractable and expressive variational families, in this work we extend the flow-based generative model to CF for modeling implicit feedbacks. We present the Collaborative Autoregressive Flows (CAF) for the recommender system, transforming a simple initial density into more complex ones via a sequence of invertible transformations, until a desired level of complexity is attained. CAF is a non-linear probabilistic approach allowing uncertainty representation and exact tractability of latent-variable inference in item recommendations. Compared to the agnostic-presumed prior approximation used in existing deep generative recommendation approaches, CAF is more effective in estimating the probabilistic posterior and achieves better recommendation accuracy. We conducted extensive experimental evaluations demonstrating that CAF can capture more effective representation of latent factors, resulting in a substantial gain on recommendation compared to the state-of-the-art approaches.}
}
@article{QIAN2020132,
title = {Micro-cracks detection of solar cells surface via combining short-term and long-term deep features},
journal = {Neural Networks},
volume = {127},
pages = {132-140},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301325},
author = {Xiaoliang Qian and Jing Li and Jinde Cao and Yuanyuan Wu and Wei Wang},
keywords = {Solar cell, Micro-cracks detection, Short-term deep features, Long-term deep features, Stacked denoising auto encoder, Convolutional neural networks},
abstract = {The machine vision based methods for micro-cracks detection of solar cells surface have become one of the main research directions with its efficiency and convenience. The existed methods are roughly classified into two categories: current viewing information based methods, prior knowledge based methods, however, the former usually adopt hand-designed features with poor generality and lacks the guidance of prior knowledge, the latter are usually implemented through the machine learning, and the generalization ability is also limited since the large-scale annotation dataset is scarce. To resolve above problems, a novel micro-cracks detection method via combining short-term and long-term deep features is proposed in this paper. The short-term deep features which represent the current viewing information are learned from the input image itself through stacked denoising auto encoder (SDAE), the long-term deep features which represent the prior knowledge are learned from a large number of natural scene images that people often see through convolutional neural networks (CNNs). The subjective and objective evaluations demonstrate that: 1) the performance of combining the short-term and long-term deep features is better than any of them alone, 2) the performance of proposed method is superior to the shallow learning based methods, 3) the proposed method can effectively detect various kinds of micro-cracks.}
}
@article{LU2020214,
title = {Hyper-Laplacian regularized multi-view subspace clustering with low-rank tensor constraint},
journal = {Neural Networks},
volume = {125},
pages = {214-223},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300599},
author = {Gui-Fu Lu and Qin-Ru Yu and Yong Wang and Ganyi Tang},
keywords = {Multi-view features, Subspace clustering, Manifold regularization, Low-rank tensor representation},
abstract = {In this paper, we propose a novel hyper-Laplacian regularized multiview subspace clustering with low-rank tensor constraint method, which is referred as HLR-MSCLRT. In the HLR-MSCLRT model, the subspace representation matrices of different views are stacked as a tensor, and then the high order correlations among data can be captured. To reduce the redundancy information of the learned subspace representations, a low-rank constraint is adopted to the constructed tensor. Since data in the real world often reside in multiple nonlinear subspaces, the HLR-MSCLRT model utilizes the hyper-Laplacian graph regularization to preserve the local geometry structure embedded in a high-dimensional ambient space. An efficient algorithm is also presented to solve the optimization problem of the HLR-MSCLRT model. The experimental results on some data sets show that the proposed HLR-MSCLRT model outperforms many state-of-the-art multi-view clustering approaches.}
}
@article{LI2020188,
title = {Fast Haar Transforms for Graph Neural Networks},
journal = {Neural Networks},
volume = {128},
pages = {188-198},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301568},
author = {Ming Li and Zheng Ma and Yu Guang Wang and Xiaosheng Zhuang},
keywords = {Graph Neural Networks, Haar basis, Graph convolution, Fast Haar Transforms, Geometric deep learning, Graph Laplacian},
abstract = {Graph Neural Networks (GNNs) have become a topic of intense research recently due to their powerful capability in high-dimensional classification and regression tasks for graph-structured data. However, as GNNs typically define the graph convolution by the orthonormal basis for the graph Laplacian, they suffer from high computational cost when the graph size is large. This paper introduces a Haar basis, which is a sparse and localized orthonormal system for a coarse-grained chain on the graph. The graph convolution under Haar basis, called Haar convolution, can be defined accordingly for GNNs. The sparsity and locality of the Haar basis allow Fast Haar Transforms (FHTs) on the graph, by which one then achieves a fast evaluation of Haar convolution between graph data and filters. We conduct experiments on GNNs equipped with Haar convolution, which demonstrates state-of-the-art results on graph-based regression and node classification tasks.}
}
@article{RASHED2020233,
title = {End-to-end semantic segmentation of personalized deep brain structures for non-invasive brain stimulation},
journal = {Neural Networks},
volume = {125},
pages = {233-244},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300514},
author = {Essam A. Rashed and Jose Gomez-Tames and Akimasa Hirata},
keywords = {End-to-end semantic segmentation, Convolutional neural network, Brain stimulation, MRI, tDCS},
abstract = {Electro-stimulation or modulation of deep brain regions is commonly used in clinical procedures for the treatment of several nervous system disorders. In particular, transcranial direct current stimulation (tDCS) is widely used as an affordable clinical application that is applied through electrodes attached to the scalp. However, it is difficult to determine the amount and distribution of the electric field (EF) in the different brain regions due to anatomical complexity and high inter-subject variability. Personalized tDCS is an emerging clinical procedure that is used to tolerate electrode montage for accurate targeting. This procedure is guided by computational head models generated from anatomical images such as MRI. Distribution of the EF in segmented head models can be calculated through simulation studies. Therefore, fast, accurate, and feasible segmentation of different brain structures would lead to a better adjustment for customized tDCS studies. In this study, a single-encoder multi-decoders convolutional neural network is proposed for deep brain segmentation. The proposed architecture is trained to segment seven deep brain structures using T1-weighted MRI. Network generated models are compared with a reference model constructed using a semi-automatic method, and it presents a high matching especially in Thalamus (Dice Coefficient (DC) = 94.70%), Caudate (DC = 91.98%) and Putamen (DC = 90.31%) structures. Electric field distribution during tDCS in generated and reference models matched well each other, suggesting its potential usefulness in clinical practice.}
}
@article{YI2020338,
title = {Constructing large-scale cortical brain networks from scalp EEG with Bayesian nonnegative matrix factorization},
journal = {Neural Networks},
volume = {125},
pages = {338-348},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300757},
author = {Chanlin Yi and Chunli Chen and Yajing Si and Fali Li and Tao Zhang and Yuanyuan Liao and Yuanling Jiang and Dezhong Yao and Peng Xu},
keywords = {Bayesian NMF, Large-scale network, Functional network connectivity, EEG, Decision-making},
abstract = {A large-scale network provides a high hierarchical level for understanding the adaptive adjustment of the human brain during cognition processes. Since high spatial resolution is required, most of the related works are based on functional magnetic resonance imaging (fMRI); however, fMRI lacks the temporal information that is important in investigating the high cognition processes. Although combining electroencephalography (EEG) inverse solution and independent component analysis (ICA), researchers detected large-scale functional subnetworks recently, few researchers focus on the unreasonable negative activation, which is biased from the nonnegative electrical source activations in the brain. In this study, considering the favorable nonnegative property of Bayesian nonnegative matrix factorization (Bayesian NMF) and combining EEG source imaging, we developed a robust approach for EEG large-scale network construction and applied it to two independent real EEG datasets (i.e., decision-making and P300). Eight and nine best-fit networks, including such important subnetworks as the somatosensory-motor network (SMN), the default mode network (DMN), etc., were successfully identified for decision-making and P300, respectively. Compared to the networks acquired with ICA, these networks not only lacked confusing negative activations but also showed clear spatial distributions that are compatible with specific brain function. Based on the constructed large-scale network, we further probed that the self-referential network (SRN), the primary visual network (PVN), and the visual network (VN) demonstrated different interaction patterns with other networks between different responses in decision-making. Our results confirm the possibility of probing the neural mechanisms of high cognition processes at a very high temporal and spatial resolution level.}
}
@article{OKUNO2020362,
title = {Hyperlink regression via Bregman divergence},
journal = {Neural Networks},
volume = {126},
pages = {362-383},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301209},
author = {Akifumi Okuno and Hidetoshi Shimodaira},
keywords = {Hypernetwork, Bregman divergence, Neural network, Graph embedding},
abstract = {A collection of U(∈N) data vectors is called a U-tuple, and the association strength among the vectors of a tuple is termed as the hyperlink weight, that is assumed to be symmetric with respect to permutation of the entries in the index. We herein propose Bregman hyperlink regression (BHLR), which learns a user-specified symmetric similarity function such that it predicts the tuple’s hyperlink weight from data vectors stored in the U-tuple. BHLR is a simple and general framework for hyper-relational learning, that minimizes Bregman-divergence (BD) between the hyperlink weights and estimated similarities defined for the corresponding tuples; BHLR encompasses various existing methods, such as logistic regression (U=1), Poisson regression (U=1), link prediction (U=2), and those for representation learning, such as graph embedding (U=2), matrix factorization (U=2), tensor factorization (U≥2), and their variants equipped with arbitrary BD. Nonlinear functions (e.g., neural networks), can be employed for the similarity functions. However, there are theoretical challenges such that some of different tuples of BHLR may share data vectors therein, unlike the i.i.d. setting of classical regression. We address these theoretical issues, and proved that BHLR equipped with arbitrary BD and U∈N is (P-1) statistically consistent, that is, it asymptotically recovers the underlying true conditional expectation of hyperlink weights given data vectors, and (P-2) computationally tractable, that is, it is efficiently computed by stochastic optimization algorithms using a novel generalized minibatch sampling procedure for hyper-relational data. Consequently, theoretical guarantees for BHLR including several existing methods, that have been examined experimentally, are provided in a unified manner.}
}
@article{SUN2020163,
title = {Exponential synchronization of memristive neural networks with time-varying delays via quantized sliding-mode control},
journal = {Neural Networks},
volume = {126},
pages = {163-169},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300915},
author = {Bo Sun and Shengbo Wang and Yuting Cao and Zhenyuan Guo and Tingwen Huang and Shiping Wen},
keywords = {Memristive neural network, Time-varying delay, Super-twisting algorithm, Quantization function, Exponential synchronization},
abstract = {In the paper, exponential synchronization issue is considered for memristive neural networks (MNNs) with time-varying delays via quantized sliding-mode algorithm. Quantized Sliding-mode controller is introduced to ensure the slave system can be exponentially synchronized with the host system via the super-twisting algorithm, which has been proved in the main results. Quantization function consists of uniform quantizer and logarithmic quantizer. Simulation results are given with comparisons between two quantizers in the end.}
}
@article{SHANG2020132,
title = {Cross-modal dual subspace learning with adversarial network},
journal = {Neural Networks},
volume = {126},
pages = {132-142},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300927},
author = {Fei Shang and Huaxiang Zhang and Jiande Sun and Liqiang Nie and Li Liu},
keywords = {Cross-modal retrieval, Adversarial network, Subspace learning},
abstract = {Cross-modal retrieval has recently attracted much interest along with the rapid development of multimodal data, and effectively utilizing the complementary relationship of different modal data and eliminating the heterogeneous gap as much as possible are the two key challenges. In this paper, we present a novel network model termed cross-modal Dual Subspace learning with Adversarial Network (DSAN). The main contributions are as follows: (1) Dual subspaces (visual subspace and textual subspace) are proposed, which can better mine the underlying structure information of different modalities as well as modality-specific information. (2) An improved quadruplet loss is proposed, which takes into account the relative distance and absolute distance between positive and negative samples, together with the introduction of the idea of hard sample mining. (3) Intra-modal constrained loss is proposed to maximize the distance of the most similar cross-modal negative samples and their corresponding cross-modal positive samples. In particular, feature preserving and modality classification act as two antagonists. DSAN tries to narrow the heterogeneous gap between different modalities, and distinguish the original modality of random samples in dual subspaces. Comprehensive experimental results demonstrate that, DSAN significantly outperforms 9 state-of-the-art methods on four cross-modal datasets.}
}
@article{LIU2020300,
title = {Extracting boolean and probabilistic rules from trained neural networks},
journal = {Neural Networks},
volume = {126},
pages = {300-311},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301180},
author = {Pengyu Liu and Avraham A. Melkman and Tatsuya Akutsu},
keywords = {Neural networks, Boolean functions, Rule extraction, Dynamic programming},
abstract = {This paper presents two approaches to extracting rules from a trained neural network consisting of linear threshold functions. The first one leads to an algorithm that extracts rules in the form of Boolean functions. Compared with an existing one, this algorithm outputs much more concise rules if the threshold functions correspond to 1-decision lists, majority functions, or certain combinations of these. The second one extracts probabilistic rules representing relations between some of the input variables and the output using a dynamic programming algorithm. The algorithm runs in pseudo-polynomial time if each hidden layer has a constant number of neurons. We demonstrate the effectiveness of these two approaches by computational experiments.}
}
@article{OREGI202061,
title = {Robust image classification against adversarial attacks using elastic similarity measures between edge count sequences},
journal = {Neural Networks},
volume = {128},
pages = {61-72},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301581},
author = {Izaskun Oregi and Javier {Del Ser} and Aritz Pérez and José A. Lozano},
keywords = {Adversarial machine learning, Deep neural networks, Time series analysis, Computer vision},
abstract = {Due to their unprecedented capacity to learn patterns from raw data, deep neural networks have become the de facto modeling choice to address complex machine learning tasks. However, recent works have emphasized the vulnerability of deep neural networks when being fed with intelligently manipulated adversarial data instances tailored to confuse the model. In order to overcome this issue, a major effort has been made to find methods capable of making deep learning models robust against adversarial inputs. This work presents a new perspective for improving the robustness of deep neural networks in image classification. In computer vision scenarios, adversarial images are crafted by manipulating legitimate inputs so that the target classifier is eventually fooled, but the manipulation is not visually distinguishable by an external observer. The reason for the imperceptibility of the attack is that the human visual system fails to detect minor variations in color space, but excels at detecting anomalies in geometric shapes. We capitalize on this fact by extracting color gradient features from input images at multiple sensitivity levels to detect possible manipulations. We resort to a deep neural classifier to predict the category of unseen images, whereas a discrimination model analyzes the extracted color gradient features with time series techniques to determine the legitimacy of input images. The performance of our method is assessed over experiments comprising state-of-the-art techniques for crafting adversarial attacks. Results corroborate the increased robustness of the classifier when using our discrimination module, yielding drastically reduced success rates of adversarial attacks that operate on the whole image rather than on localized regions or around the existing shapes of the image. Future research is outlined towards improving the detection accuracy of the proposed method for more general attack strategies.}
}
@article{SARRAF20201,
title = {A tight upper bound on the generalization error of feedforward neural networks},
journal = {Neural Networks},
volume = {127},
pages = {1-6},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301210},
author = {Aydin Sarraf},
keywords = {Feedforward neural networks, Generalization error},
abstract = {We give a tight upper bound on the generalization error of 2-times continuously differentiable feedforward neural networks if the loss function is 2-times continuously differentiable as well. The upper bound consists of two terms, the first term indicates how well the empirical error estimates the error at the mean of the sample space. The second term indicates the expected sensitivity of the error to the changes of the input. Furthermore, we provide explicit formulas for the calculation of the second term.}
}
@article{XU2020224,
title = {Synchronization of complex networks with time-varying delay of unknown bound via delayed impulsive control},
journal = {Neural Networks},
volume = {125},
pages = {224-232},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300484},
author = {Zhilu Xu and Xiaodi Li and Peiyong Duan},
keywords = {Time-varying delay, Delayed impulsive control, Complex networks, Synchronization, Impulsive differential inequality},
abstract = {The synchronization problem for complex networks with time-varying delays of unknown bound is investigated in this paper. From the impulsive control point of view, a novel delayed impulsive differential inequality is proposed, where the bounds of time-varying delays in continuous dynamic and discrete dynamic are both unknown. Based on the inequality, a class of delayed impulsive controllers is designed to achieve the synchronization of complex networks, where the restriction between impulses interval and time-varying delays is dropped. A numerical example is presented to illustrate the effectiveness of the obtained results.}
}
@article{GERUM2020305,
title = {Sparsity through evolutionary pruning prevents neuronal networks from overfitting},
journal = {Neural Networks},
volume = {128},
pages = {305-312},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301696},
author = {Richard C. Gerum and André Erpenbeck and Patrick Krauss and Achim Schilling},
keywords = {Evolution, Artificial neural networks, Maze task, Evolutionary algorithm, Overfitting, Biological plausibility},
abstract = {Modern Machine learning techniques take advantage of the exponentially rising calculation power in new generation processor units. Thus, the number of parameters which are trained to solve complex tasks was highly increased over the last decades. However, still the networks fail – in contrast to our brain – to develop general intelligence in the sense of being able to solve several complex tasks with only one network architecture. This could be the case because the brain is not a randomly initialized neural network, which has to be trained from scratch by simply investing a lot of calculation power, but has from birth some fixed hierarchical structure. To make progress in decoding the structural basis of biological neural networks we here chose a bottom-up approach, where we evolutionarily trained small neural networks in performing a maze task. This simple maze task requires dynamic decision making with delayed rewards. We were able to show that during the evolutionary optimization random severance of connections leads to better generalization performance of the networks compared to fully connected networks. We conclude that sparsity is a central property of neural networks and should be considered for modern Machine learning approaches.}
}
@article{KHAN2020384,
title = {Automatic detection of tympanic membrane and middle ear infection from oto-endoscopic images via convolutional neural networks},
journal = {Neural Networks},
volume = {126},
pages = {384-394},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301179},
author = {Mohammad Azam Khan and Soonwook Kwon and Jaegul Choo and Seok Min Hong and Sung Hun Kang and Il-Ho Park and Sung Kyun Kim and Seok Jin Hong},
keywords = {Otoscope, Tympanic membrane, Otitis media, Convolutional neural networks},
abstract = {Convolutional neural networks (CNNs), a popular type of deep neural network, have been actively applied to image recognition, object detection, object localization, semantic segmentation, and object instance segmentation. Accordingly, the applicability of deep learning to the analysis of medical images has increased. This paper presents a novel application of state-of-the-art CNN models, such as DenseNet, to the automatic detection of the tympanic membrane (TM) and middle ear (ME) infection. We collected 2,484 oto-endoscopic images (OEIs) and classified them into one of three categories: normal, chronic otitis media (COM) with TM perforation, and otitis media with effusion (OME). Our results indicate that CNN models have significant potential for the automatic recognition of TM and ME infections, demonstrating a competitive accuracy of 95% in classifying TM and middle ear effusion (MEE) from OEIs. In addition to accuracy measurement, our approach achieves nearly perfect measures of 0.99 in terms of the average area under the receiver operating characteristics curve (AUROC). All these results indicate robust performance when recognizing TM and ME effusions in OEIs. Visualization through a class activation mapping (CAM) heatmap demonstrates that our proposed model performs prediction based on the correct region of OEIs. All these outcomes ensure the reliability of our method; hence, the study can aid otolaryngologists and primary care physicians in real-world scenarios.}
}
@article{UDHAYAKUMAR202285,
title = {Corrigendum to “Fractional-order discontinuous systems with indefinite LKFs: An application to fractional-order neural networks with time delays” [Neural Networks 145 (2022) 319–330]},
journal = {Neural Networks},
volume = {148},
pages = {85},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000089},
author = {K. Udhayakumar and Fathalla A. Rihan and R. Rakkiyappan and Jinde Cao}
}
@article{HUANG202082,
title = {Novel deep neural network based pattern field classification architectures},
journal = {Neural Networks},
volume = {127},
pages = {82-95},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300885},
author = {Kaizhu Huang and Shufei Zhang and Rui Zhang and Amir Hussain},
keywords = {Neural network, Field classification, Deep learning},
abstract = {Field classification is a new extension of traditional classification frameworks that attempts to utilize consistent information from a group of samples (termed fields). By forgoing the independent identically distributed (i.i.d.) assumption, field classification can achieve remarkably improved accuracy compared to traditional classification methods. Most studies of field classification have been conducted on traditional machine learning methods. In this paper, we propose integration with a Bayesian framework, for the first time, in order to extend field classification to deep learning and propose two novel deep neural network architectures: the Field Deep Perceptron (FDP) and the Field Deep Convolutional Neural Network (FDCNN). Specifically, we exploit a deep perceptron structure, typically a 6-layer structure, where the first 3 layers remove (learn) a ‘style’ from a group of samples to map them into a more discriminative space and the last 3 layers are trained to perform classification. For the FDCNN, we modify the AlexNet framework by adding style transformation layers within the hidden layers. We derive a novel learning scheme from a Bayesian framework and design a novel and efficient learning algorithm with guaranteed convergence for training the deep networks. The whole framework is interpreted with visualization features showing that the field deep neural network can better learn the style of a group of samples. Our developed models are also able to achieve transfer learning and learn transformations for newly introduced fields. We conduct extensive comparative experiments on benchmark data (including face, speech, and handwriting data) to validate our learning approach. Experimental results demonstrate that our proposed deep frameworks achieve significant improvements over other state-of-the-art algorithms, attaining new benchmark performance.}
}
@article{SANTIAGO202096,
title = {On the boundary conditions of avoidance memory reconsolidation: An attractor network perspective},
journal = {Neural Networks},
volume = {127},
pages = {96-109},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301337},
author = {Rodrigo M.M. Santiago and Adriano B.L. Tort},
keywords = {Attractor network, Inhibitory avoidance, Reconsolidation, Extinction, Boundary condition, Synaptic plasticity},
abstract = {The reconsolidation and extinction of aversive memories and their boundary conditions have been extensively studied. Knowing their network mechanisms may lead to the development of better strategies for the treatment of fear and anxiety-related disorders. In 2011, Osan et al. developed a computational model for exploring such phenomena based on attractor dynamics, Hebbian plasticity and synaptic degradation induced by prediction error. This model was able to explain, in a single formalism, experimental findings regarding the freezing behavior of rodents submitted to contextual fear conditioning. In 2017, through the study of inhibitory avoidance in rats, Radiske et al. showed that the previous knowledge of a context as non-aversive is a boundary condition for the reconsolidation of the shock memory subsequently experienced in that context. In the present work, by adapting the model of Osan et al. (2011) to simulate the experimental protocols of Radiske et al. (2017), we show that such boundary condition is compatible with the dynamics of an attractor network that supports synaptic labilization common to reconsolidation and extinction. Additionally, by varying parameters such as the levels of protein synthesis and degradation, we predict behavioral outcomes, and thus boundary conditions that can be tested experimentally.}
}
@article{ZHENG202042,
title = {Probabilistic inference of binary Markov random fields in spiking neural networks through mean-field approximation},
journal = {Neural Networks},
volume = {126},
pages = {42-51},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300800},
author = {Yajing Zheng and Shanshan Jia and Zhaofei Yu and Tiejun Huang and Jian K. Liu and Yonghong Tian},
keywords = {Probabilistic inference, Markov Random Fields (MRFs), Spiking Neural Networks (SNNs), Recurrent Neural Networks (RNNs), Mean-field approximation},
abstract = {Recent studies have suggested that the cognitive process of the human brain is realized as probabilistic inference and can be further modeled by probabilistic graphical models like Markov random fields. Nevertheless, it remains unclear how probabilistic inference can be implemented by a network of spiking neurons in the brain. Previous studies have tried to relate the inference equation of binary Markov random fields to the dynamic equation of spiking neural networks through belief propagation algorithm and reparameterization, but they are valid only for Markov random fields with limited network structure. In this paper, we propose a spiking neural network model that can implement inference of arbitrary binary Markov random fields. Specifically, we design a spiking recurrent neural network and prove that its neuronal dynamics are mathematically equivalent to the inference process of Markov random fields by adopting mean-field theory. Furthermore, our mean-field approach unifies previous works. Theoretical analysis and experimental results, together with the application to image denoising, demonstrate that our proposed spiking neural network can get comparable results to that of mean-field inference.}
}
@article{LU2020245,
title = {Low-rank discriminative regression learning for image classification},
journal = {Neural Networks},
volume = {125},
pages = {245-257},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300526},
author = {Yuwu Lu and Zhihui Lai and Wai Keung Wong and Xuelong Li},
keywords = {Regression, Low-rank, Discriminative, Robust, Image representation},
abstract = {As a famous multivariable analysis technique, regression methods, such as ridge regression, are widely used for image representation and dimensionality reduction. However, the metric of ridge regression and its variants is always the Frobenius norm (F-norm), which is sensitive to outliers and noise in data. At the same time, the performance of the ridge regression and its extensions is limited by the class number of the data. To address these problems, we propose a novel regression learning method which named low-rank discriminative regression learning (LDRL) for image representation. LDRL assumes that the input data is corrupted and thus the L1 norm can be used as a sparse constraint on the noised matrix to recover the clean data for regression, which can improve the robustness of the algorithm. Due to learn a novel project matrix that is not limited by the number of classes, LDRL is suitable for classifying the data set no matter whether there is a small or large number of classes. The performance of the proposed LDRL is evaluated on six public image databases. The experimental results prove that LDRL obtains better performance than existing regression methods.}
}
@article{PANDEY202036,
title = {Modeling coherence by ordering paragraphs using pointer networks},
journal = {Neural Networks},
volume = {126},
pages = {36-41},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300769},
author = {Divesh Pandey and C. Ravindranath Chowdary},
keywords = {Ordering paragraphs, Pointer networks, Paragraph embeddings},
abstract = {Coherence is a distinctive feature in well-written documents. One method to study coherence is to analyze how sentences are ordered in a document. In Multi-document Summarization, sentences from different sources need to be ordered. Cluster-based ordering algorithms aim to study various themes or topics that are present in a set of sentences. After the clusters of sentences have been identified, sentences are ordered within each cluster in isolation. One challenge that remains is to order these clusters or paragraphs to obtain a coherent ordering of information. Inspired by the success of deep neural networks in several NLP tasks, we propose an RNN-based encoder–decoder system to predict order for a given set of loose clusters or paragraphs. Universal Sentence Encoder (USE) is used to encode paragraphs into high dimensional embeddings, which are then fed into an LSTM encoder and consecutively passed to a pointer network, which finally outputs the paragraph order. Since Wikipedia is a source of well- structured articles, it is used to generate multiple datasets. Based on our experimental results, the proposed model satisfactorily outperforms the baseline model across multiple datasets. We observe a two-fold increase in Kendall’s tau values for the final paragraph orderings.}
}
@article{OTT2020235,
title = {Learning in the machine: To share or not to share?},
journal = {Neural Networks},
volume = {126},
pages = {235-249},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300939},
author = {Jordan Ott and Erik Linstead and Nicholas LaHaye and Pierre Baldi},
keywords = {Deep learning, Convolutional neural networks, Weight-sharing, Biologically plausible architectures},
abstract = {Weight-sharing is one of the pillars behind Convolutional Neural Networks and their successes. However, in physical neural systems such as the brain, weight-sharing is implausible. This discrepancy raises the fundamental question of whether weight-sharing is necessary. If so, to which degree of precision? If not, what are the alternatives? The goal of this study is to investigate these questions, primarily through simulations where the weight-sharing assumption is relaxed. Taking inspiration from neural circuitry, we explore the use of Free Convolutional Networks and neurons with variable connection patterns. Using Free Convolutional Networks, we show that while weight-sharing is a pragmatic optimization approach, it is not a necessity in computer vision applications. Furthermore, Free Convolutional Networks match the performance observed in standard architectures when trained using properly translated data (akin to video). Under the assumption of translationally augmented data, Free Convolutional Networks learn translationally invariant representations that yield an approximate form of weight-sharing.}
}
@article{FANG2020182,
title = {DART: Domain-Adversarial Residual-Transfer networks for unsupervised cross-domain image classification},
journal = {Neural Networks},
volume = {127},
pages = {182-192},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301192},
author = {Xianghong Fang and Haoli Bai and Ziyi Guo and Bin Shen and Steven Hoi and Zenglin Xu},
keywords = {Transfer learning, Residue network, Adversarial domain adaptation},
abstract = {The accuracy of deep learning (e.g., convolutional neural networks) for an image classification task critically relies on the amount of labeled training data. Aiming to solve an image classification task on a new domain that lacks labeled data but gains access to cheaply available unlabeled data, unsupervised domain adaptation is a promising technique to boost the performance without incurring extra labeling cost, by assuming images from different domains share some invariant characteristics. In this paper, we propose a new unsupervised domain adaptation method named Domain-Adversarial Residual-Transfer (DART) learning of deep neural networks to tackle cross-domain image classification tasks. In contrast to the existing unsupervised domain adaption approaches, the proposed DART not only learns domain-invariant features via adversarial training, but also achieves robust domain-adaptive classification via a residual-transfer strategy, all in an end-to-end training framework. We evaluate the performance of the proposed method for cross-domain image classification tasks on several well-known benchmark data sets, in which our method clearly outperforms the state-of-the-art approaches.}
}
@article{VIDNEROVA2020168,
title = {Vulnerability of classifiers to evolutionary generated adversarial examples},
journal = {Neural Networks},
volume = {127},
pages = {168-181},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301350},
author = {Petra Vidnerová and Roman Neruda},
keywords = {Supervised learning, Neural networks, Kernel methods, Genetic algorithms, Adversarial examples},
abstract = {This paper deals with the vulnerability of machine learning models to adversarial examples and its implication for robustness and generalization properties. We propose an evolutionary algorithm that can generate adversarial examples for any machine learning model in the black-box attack scenario. This way, we can find adversarial examples without access to model’s parameters, only by querying the model at hand. We have tested a range of machine learning models including deep and shallow neural networks. Our experiments have shown that the vulnerability to adversarial examples is not only the problem of deep networks, but it spreads through various machine learning architectures. Rather, it depends on the type of computational units. Local units, such as Gaussian kernels, are less vulnerable to adversarial examples.}
}
@article{ZENG202021,
title = {NeuroBayesSLAM: Neurobiologically inspired Bayesian integration of multisensory information for robot navigation},
journal = {Neural Networks},
volume = {126},
pages = {21-35},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300770},
author = {Taiping Zeng and Fengzhen Tang and Daxiong Ji and Bailu Si},
keywords = {Bayesian, Multisensory integration, Attractor dynamics, Head direction cells, Grid cells, Monocular SLAM},
abstract = {Spatial navigation depends on the combination of multiple sensory cues from idiothetic and allothetic sources. The computational mechanisms of mammalian brains in integrating different sensory modalities under uncertainty for navigation is enlightening for robot navigation. We propose a Bayesian attractor network model to integrate visual and vestibular inputs inspired by the spatial memory systems of mammalian brains. In the model, the pose of the robot is encoded separately by two sub-networks, namely head direction network for angle representation and grid cell network for position representation, using similar neural codes of head direction cells and grid cells observed in mammalian brains. The neural codes in each of the sub-networks are updated in a Bayesian manner by a population of integrator cells for vestibular cue integration, as well as a population of calibration cells for visual cue calibration. The conflict between vestibular cue and visual cue is resolved by the competitive dynamics between the two populations. The model, implemented on a monocular visual simultaneous localization and mapping (SLAM) system, termed NeuroBayesSLAM, successfully builds semi-metric topological maps and self-localizes in outdoor and indoor environments of difference characteristics, achieving comparable performance as previous neurobiologically inspired navigation systems but with much less computation complexity. The proposed multisensory integration method constitutes a concise yet robust and biologically plausible method for robot navigation in large environments. The model provides a viable Bayesian mechanism for multisensory integration that may pertain to other neural subsystems beyond spatial cognition.}
}
@article{WANG202038,
title = {Synchronization of coupled neural networks under mixed impulsive effects: A novel delay inequality approach},
journal = {Neural Networks},
volume = {127},
pages = {38-46},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301222},
author = {Yaqi Wang and Jianquan Lu and Xiaodi Li and Jinling Liang},
keywords = {Mixed impulses, Coupled neural network, Delayed impulsive inequality, Average delay impulsive gain, Exponential synchronization},
abstract = {In this paper, the synchronization problems of an array of coupled neural networks with mixed impulses are considered. Here mixed impulses contain desynchronizing delay-free impulses, synchronizing delay-free impulses, desynchronizing delayed impulses and synchronizing delayed impulses. A novel concept named average delayed impulsive gain is proposed to quantify the effects of mixed impulses. Besides, we establish a delayed impulsive differential inequality which extends famous Halanay inequality, and apply it to study the synchronization problems of delayed neural networks with mixed impulses. It is interesting to notice that both delay-free impulses and delayed impulses can contribute to the synchronization of coupled neural networks. Meanwhile, we also discuss the synchronization of neural networks only with delay-dependent impulses. Some sufficient conditions are derived to ensure the exponential synchronization of delayed neural networks. Finally, some numerical examples are provided to illustrate the validity and superiority of the obtained results.}
}
@article{QIAO20201,
title = {Finite-time synchronization of fractional-order gene regulatory networks with time delay},
journal = {Neural Networks},
volume = {126},
pages = {1-10},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300496},
author = {Yuanhua Qiao and Hongyun Yan and Lijuan Duan and Jun Miao},
keywords = {Fractional-order, Gene regulatory networks, Feedback control, Finite-time synchronization},
abstract = {As multi-gene networks transmit signals and products by synchronous cooperation, investigating the synchronization of gene regulatory networks may help us to explore the biological rhythm and internal mechanisms at molecular and cellular levels. We aim to induce a type of fractional-order gene regulatory networks to synchronize at finite-time point by designing feedback controls. Firstly, a unique equilibrium point of the network is proved by applying the principle of contraction mapping. Secondly, some sufficient conditions for finite-time synchronization of fractional-order gene regulatory networks with time delay are explored based on two kinds of different control techniques and fractional Lyapunov function approach, and the corresponding setting time is estimated. Finally, some numerical examples are given to demonstrate the effectiveness of the theoretical results.}
}
@article{LIN2020107,
title = {Multi-projection of unequal dimension optimal transport theory for Generative Adversary Networks},
journal = {Neural Networks},
volume = {128},
pages = {107-125},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.029},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030157X},
author = {Judy Yangjun Lin and Shaoyan Guo and Longhan Xie and Gu Xu},
keywords = {Generative adversarial networks, Unequal dimension, Multi-projection, Optimal transport},
abstract = {As a major step forward in machine learning, generative adversarial networks (GANs) employ the Wasserstein distance as a metric between the generative distribution and target data distribution, and thus can be viewed as optimal transport (OT) problems to reflect the underlying geometry of the probability distribution. However, the unequal dimensions between the source random distribution and the target data, result in often instability in the training processes, and lack of diversity in the generative images. To resolve the challenges, we propose here a multiple-projection approach, to project the source and target probability measures into multiple different low-dimensional subspaces. Moreover, we show that the original problem can be transformed into a variant multi-marginal OT problem, and we provide the explicit properties of the solutions. In addition, we employ parameterized approximation for the objective, and study the corresponding differentiability and convergence properties, ensuring that the problem can indeed be computed.}
}
@article{ROQUETTE2020170,
title = {Prediction of admission in pediatric emergency department with deep neural networks and triage textual data},
journal = {Neural Networks},
volume = {126},
pages = {170-177},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300897},
author = {Bruno P. Roquette and Hitoshi Nagano and Ernesto C. Marujo and Alexandre C. Maiorano},
keywords = {Deep neural networks, Emergency department admission, Gradient boosting, Prediction model, Triage, Unstructured data},
abstract = {Emergency department (ED) overcrowding is a global condition that severely worsens attention to patients, increases clinical risks and affects hospital cost management. A correct and early prediction of ED’s admission is of high value and a motivation to adopt machine learning models. However, several of these studies do not consider data collected in textual form, which is a feature set that contains detailed information about patients and presents great potential for medical health care improvement. To this end, we propose and compare predictive models for admission that use both structured and unstructured data available at triage time. In total, our dataset comprised 499,853 pediatric ED’s presentations (with an admission rate of 5.76%) of patients with age up to 18 years old observed over 3.5 years. Our best model consists of a 2-stage architecture with a deep neural network (DNN) to extract information from textual data followed by a gradient boosting classifier. This combined model achieved a value of 0.892 for the Area Under the Curve (AUC) in the test data. We highlight the importance of DNN-based text processing for better prediction, since the absence of text features resulted in AUC reduction of approximately two percentage points. Also, the feature importance of text was higher than that of the Manchester Triage System (MTS), which is a widely used risk classification protocol. These results suggest that activations from a trained DNN should be used in transfer learning setups in future studies.}
}
@article{OUYANG2020158,
title = {Impulsive synchronization of coupled delayed neural networks with actuator saturation and its application to image encryption},
journal = {Neural Networks},
volume = {128},
pages = {158-171},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301866},
author = {Deqiang Ouyang and Jie Shao and Haijun Jiang and Sing Kiong Nguang and Heng Tao Shen},
keywords = {Coupled neural networks, Impulsive control, Exponential synchronization, Actuator saturation, Time-varying delays, Image encryption},
abstract = {The actuator of any physical control systems is constrained by amplitude and energy, which causes the control systems to be inevitably affected by actuator saturation. In this paper, impulsive synchronization of coupled delayed neural networks with actuator saturation is presented. A new controller is designed to introduce actuator saturation term into impulsive controller. Based on sector nonlinearity model approach, impulsive controls with actuator saturation and with partial actuator saturation are studied, respectively, and some effective sufficient conditions are obtained. Numerical simulation is presented to verify the validity of the theoretical analysis results. Finally, the impulsive synchronization is applied to image encryption. The experimental results show that the proposed image encryption system has high security properties.}
}
@article{PENG2020110,
title = {Dendrite P systems},
journal = {Neural Networks},
volume = {127},
pages = {110-120},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301349},
author = {Hong Peng and Tingting Bao and Xiaohui Luo and Jun Wang and Xiaoxiao Song and Agustín Riscos-Núñez and Mario J. Pérez-Jiménez},
keywords = {P systems, Neural-like P systems, Dendrite P systems, Computational power},
abstract = {It was recently found that dendrites are not just a passive channel. They can perform mixed computation of analog and digital signals, and therefore can be abstracted as information processors. Moreover, dendrites possess a feedback mechanism. Motivated by these computational and feedback characteristics, this article proposes a new variant of neural-like P systems, dendrite P (DeP) systems, where neurons simulate the computational function of dendrites and perform a firing–storing process instead of the storing–firing process in spiking neural P (SNP) systems. Moreover, the behavior of the neurons is characterized by dendrite rules that are abstracted by two characteristics of dendrites. Different from the usual firing rules in SNP systems, the firing of a dendrite rule is controlled by the states of the corresponding source neurons. Therefore, DeP systems can provide a collaborative control capability for neurons. We discuss the computational power of DeP systems. In particular, it is proven that DeP systems are Turing-universal number generating/accepting devices. Moreover, we construct a small universal DeP system consisting of 115 neurons for computing functions.}
}
@article{JANG2020118,
title = {Deep neural networks with a set of node-wise varying activation functions},
journal = {Neural Networks},
volume = {126},
pages = {118-131},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300812},
author = {Jinhyeok Jang and Hyunjoong Cho and Jaehong Kim and Jaeyeon Lee and Seungjoon Yang},
keywords = {Deep network, Principal component analysis, Pruning, Varying activation},
abstract = {In this study, we present deep neural networks with a set of node-wise varying activation functions. The feature-learning abilities of the nodes are affected by the selected activation functions, where the nodes with smaller indices become increasingly more sensitive during training. As a result, the features learned by the nodes are sorted by the node indices in order of their importance such that more sensitive nodes are related to more important features. The proposed networks learn input features but also the importance of the features. Nodes with lower importance in the proposed networks can be pruned to reduce the complexity of the networks, and the pruned networks can be retrained without incurring performance losses. We validated the feature-sorting property of the proposed method using both shallow and deep networks as well as deep networks transferred from existing networks.}
}
@article{CHEN2020174,
title = {Chaos in fractional-order discrete neural networks with application to image encryption},
journal = {Neural Networks},
volume = {125},
pages = {174-184},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300538},
author = {Liping Chen and Hao Yin and Tingwen Huang and Liguo Yuan and Song Zheng and Lisheng Yin},
keywords = {Fractional-order discrete systems, Neural networks, Synchronization, Image encryption},
abstract = {In this paper, a three-dimensional fractional-order (FO) discrete Hopfield neural network (FODHNN) in the left Caputo discrete delta’s sense is proposed, the dynamic behavior and synchronization of FODHNN are studied, and the system is applied to image encryption. First, FODHNN is shown to exhibit rich nonlinear dynamics behaviors. Phase portraits, bifurcation diagrams and Lyapunov exponents are carried out to verify chaotic dynamics in this system. Moreover, by using stability theorem of FO discrete linear systems, a suitable control scheme is designed to achieve synchronization of the FODHNN. Finally, image encryption system based on the chaotic FODHNN is presented. Some security analysis and tests are given to show the effective of the encryption system.}
}
@article{XIAO202041,
title = {Skeleton-based Chinese sign language recognition and generation for bidirectional communication between deaf and hearing people},
journal = {Neural Networks},
volume = {125},
pages = {41-55},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.030},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030040X},
author = {Qinkun Xiao and Minying Qin and Yuting Yin},
keywords = {CSL, Recognition, Generation, RNN, Bidirectional communication, Probability model},
abstract = {Chinese sign language (CSL) is one of the most widely used sign language systems in the world. As such, the automatic recognition and generation of CSL is a key technology enabling bidirectional communication between deaf and hearing people. Most previous studies have focused solely on sign language recognition (SLR), which only addresses communication in a single direction. As such, there is a need for sign language generation (SLG) to enable communication in the other direction (i.e., from hearing people to deaf people). To achieve a smoother exchange of ideas between these two groups, we propose a skeleton-based CSL recognition and generation framework based on a recurrent neural network (RNN), to support bidirectional CSL communication. This process can also be extended to other sequence-to-sequence information interactions. The core of the proposed framework is a two-level probability generative model. Compared with previous techniques, this approach offers a more flexible approximate posterior distribution, which can produce skeletal sequences of varying styles that are recognizable to humans. In addition, the proposed generation method compensated for a lack of training data. A series of experiments in bidirectional communication were conducted on the large 500 CSL dataset. The proposed algorithm achieved high recognition accuracy for both real and synthetic data, with a reduced runtime. Furthermore, the generated data improved the performance of the discriminator. These results suggest the proposed bidirectional communication framework and generation algorithm to be an effective new approach to CSL recognition.}
}
@article{2022I,
title = {Current Events},
journal = {Neural Networks},
volume = {147},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00019-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000193}
}
@article{VLACHAS2020191,
title = {Backpropagation algorithms and Reservoir Computing in Recurrent Neural Networks for the forecasting of complex spatiotemporal dynamics},
journal = {Neural Networks},
volume = {126},
pages = {191-217},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300708},
author = {P.R. Vlachas and J. Pathak and B.R. Hunt and T.P. Sapsis and M. Girvan and E. Ott and P. Koumoutsakos},
keywords = {Time series forecasting, RNN, LSTM, GRU, Reservoir Computing, Kuramoto–Sivashinsky, Lorenz-96, Complex systems},
abstract = {We examine the efficiency of Recurrent Neural Networks in forecasting the spatiotemporal dynamics of high dimensional and reduced order complex systems using Reservoir Computing (RC) and Backpropagation through time (BPTT) for gated network architectures. We highlight advantages and limitations of each method and discuss their implementation for parallel computing architectures. We quantify the relative prediction accuracy of these algorithms for the long-term forecasting of chaotic systems using as benchmarks the Lorenz-96 and the Kuramoto–Sivashinsky (KS) equations. We find that, when the full state dynamics are available for training, RC outperforms BPTT approaches in terms of predictive performance and in capturing of the long-term statistics, while at the same time requiring much less training time. However, in the case of reduced order data, large scale RC models can be unstable and more likely than the BPTT algorithms to diverge. In contrast, RNNs trained via BPTT show superior forecasting abilities and capture well the dynamics of reduced order systems. Furthermore, the present study quantifies for the first time the Lyapunov Spectrum of the KS equation with BPTT, achieving similar accuracy as RC. This study establishes that RNNs are a potent computational framework for the learning and forecasting of complex spatiotemporal systems.}
}
@article{SONG202083,
title = {PET image super-resolution using generative adversarial networks},
journal = {Neural Networks},
volume = {125},
pages = {83-91},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300393},
author = {Tzu-An Song and Samadrita Roy Chowdhury and Fan Yang and Joyita Dutta},
keywords = {Super-resolution, Self-supervised, CNN, GAN, PET, Multimodality imaging},
abstract = {The intrinsically low spatial resolution of positron emission tomography (PET) leads to image quality degradation and inaccurate image-based quantitation. Recently developed supervised super-resolution (SR) approaches are of great relevance to PET but require paired low- and high-resolution images for training, which are usually unavailable for clinical datasets. In this paper, we present a self-supervised SR (SSSR) technique for PET based on dual generative adversarial networks (GANs), which precludes the need for paired training data, ensuring wider applicability and adoptability. The SSSR network receives as inputs a low-resolution PET image, a high-resolution anatomical magnetic resonance (MR) image, spatial information (axial and radial coordinates), and a high-dimensional feature set extracted from an auxiliary CNN which is separately-trained in a supervised manner using paired simulation datasets. The network is trained using a loss function which includes two adversarial loss terms, a cycle consistency term, and a total variation penalty on the SR image. We validate the SSSR technique using a clinical neuroimaging dataset. We demonstrate that SSSR is promising in terms of image quality, peak signal-to-noise ratio, structural similarity index, contrast-to-noise ratio, and an additional no-reference metric developed specifically for SR image quality assessment. Comparisons with other SSSR variants suggest that its high performance is largely attributable to simulation guidance.}
}
@article{GUO2020250,
title = {Multi-way backpropagation for training compact deep neural networks},
journal = {Neural Networks},
volume = {126},
pages = {250-261},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300782},
author = {Yong Guo and Jian Chen and Qing Du and Anton {Van Den Hengel} and Qinfeng Shi and Mingkui Tan},
keywords = {Backpropagation, Supervision vanishing, Compact model},
abstract = {Depth is one of the key factors behind the success of convolutional neural networks (CNNs). Since ResNet (He et al., 2016), we are able to train very deep CNNs as the gradient vanishing issue has been largely addressed by the introduction of skip connections. However, we observe that, when the depth is very large, the intermediate layers (especially shallow layers) may fail to receive sufficient supervision from the loss due to severe transformation through long backpropagation path. As a result, the representation power of intermediate layers can be very weak and the model becomes very redundant with limited performance. In this paper, we first investigate the supervision vanishing issue in existing backpropagation (BP) methods. And then, we propose to address it via an effective method, called Multi-way BP (MW-BP), which relies on multiple auxiliary losses added to the intermediate layers of the network. The proposed MW-BP method can be applied to most deep architectures with slight modifications, such as ResNet and MobileNet. Our method often gives rise to much more compact models (denoted by “Mw+Architecture”) than existing methods. For example, MwResNet-44 with 44 layers performs better than ResNet-110 with 110 layers on CIFAR-10 and CIFAR-100. More critically, the resultant models even outperform the light models obtained by state-of-the-art model compression methods. Last, our method inherently produces multiple compact models with different depths at the same time, which is helpful for model selection. Extensive experiments on both image classification and face recognition demonstrate the superiority of the proposed method.}
}
@article{WEI20207,
title = {Finite-time synchronization of memristor neural networks via interval matrix method},
journal = {Neural Networks},
volume = {127},
pages = {7-18},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301234},
author = {Fei Wei and Guici Chen and Wenbo Wang},
keywords = {Nonlinear feedback controllers, Memristor neural networks, Finite-time synchronization, Interval matrix method},
abstract = {In this paper, the finite-time synchronization problems of two types of driven-response memristor neural networks (MNNs) without time-delay and with time-varying delays are investigated via interval matrix method, respectively. Based on interval matrix transformation, the driven-response MNNs are transformed into a kind of system with interval parameters, which is different from the previous research approaches. Several sufficient conditions in terms of linear matrix inequalities (LMIs) are driven to guarantee finite-time synchronization for MNNs. Correspondingly, two types of nonlinear feedback controllers are designed. Meanwhile, the upper-bounded of the settling time functions are estimated. Finally, two numerical examples with simulations are given to illustrate the correctness of the theoretical results and the effectiveness of the proposed controllers.}
}
@article{SHAHAMAT2020218,
title = {Brain MRI analysis using a deep learning based evolutionary approach},
journal = {Neural Networks},
volume = {126},
pages = {218-234},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300940},
author = {Hossein Shahamat and Mohammad {Saniee Abadeh}},
keywords = {3D-CNN, Genetic algorithm, Deep learning, Interpretable classifier, Brain MRI classification},
abstract = {Convolutional neural network (CNN) models have recently demonstrated impressive performance in medical image analysis. However, there is no clear understanding of why they perform so well, or what they have learned. In this paper, a three-dimensional convolutional neural network (3D-CNN) is employed to classify brain MRI scans into two predefined groups. In addition, a genetic algorithm based brain masking (GABM) method is proposed as a visualization technique that provides new insights into the function of the 3D-CNN. The proposed GABM method consists of two main steps. In the first step, a set of brain MRI scans is used to train the 3D-CNN. In the second step, a genetic algorithm (GA) is applied to discover knowledgeable brain regions in the MRI scans. The knowledgeable regions are those areas of the brain which the 3D-CNN has mostly used to extract important and discriminative features from them. For applying GA on the brain MRI scans, a new chromosome encoding approach is proposed. The proposed framework has been evaluated using ADNI (including 140 subjects for Alzheimer’s disease classification) and ABIDE (including 1000 subjects for Autism classification) brain MRI datasets. Experimental results show a 5-fold classification accuracy of 0.85 for the ADNI dataset and 0.70 for the ABIDE dataset. The proposed GABM method has extracted 6 to 65 knowledgeable brain regions in ADNI dataset (and 15 to 75 knowledgeable brain regions in ABIDE dataset). These regions are interpreted as the segments of the brain which are mostly used by the 3D-CNN to extract features for brain disease classification. Experimental results show that besides the model interpretability, the proposed GABM method has increased final performance of the classification model in some cases with respect to model parameters.}
}
@article{BELKAID202010,
title = {Modeling uncertainty-seeking behavior mediated by cholinergic influence on dopamine},
journal = {Neural Networks},
volume = {125},
pages = {10-18},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300423},
author = {Marwen Belkaid and Jeffrey L. Krichmar},
keywords = {Decision-making, Acetylcholine, Dopamine, Uncertainty},
abstract = {Recent findings suggest that acetylcholine mediates uncertainty-seeking behaviors through its projection to dopamine neurons — another neuromodulatory system known for its major role in reinforcement learning and decision-making. In this paper, we propose a leaky-integrate-and-fire model of this mechanism. It implements a softmax-like selection with an uncertainty bonus by a cholinergic drive to dopaminergic neurons, which in turn influence synaptic currents of downstream neurons. The model is able to reproduce experimental data in two decision-making tasks. It also predicts that: (i) in the absence of cholinergic input, dopaminergic activity would not correlate with uncertainty, and that (ii) the adaptive advantage brought by the implemented uncertainty-seeking mechanism is most useful when sources of reward are not highly uncertain. Moreover, this modeling work allows us to propose novel experiments which might shed new light on the role of acetylcholine in both random and directed exploration. Overall, this study contributes to a more comprehensive understanding of the role of the cholinergic system and, in particular, its involvement in decision-making.}
}
@article{XU202082,
title = {BPGAN: Bidirectional CT-to-MRI prediction using multi-generative multi-adversarial nets with spectral normalization and localization},
journal = {Neural Networks},
volume = {128},
pages = {82-96},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301635},
author = {Liming Xu and Xianhua Zeng and He Zhang and Weisheng Li and Jianbo Lei and Zhiwei Huang},
keywords = {Bidirectional prediction, Cross modality, Generative adversarial nets, Pathological invariance, Spectral normalization},
abstract = {Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) are widely used detection technology in screening, diagnosis, and image-guided therapy for both clinical and research. However, CT imposes ionizing radiation to patients during acquisition. Compared to CT, MRI is much safer and does not involve any radiations, but it is more expensive and has prolonged acquisition time. Therefore, it is necessary to estimate one modal image from another given modal image of the same subject for the case of radiotherapy planning. Considering that there is currently no bidirectional prediction model between MRI and CT images, we propose a bidirectional prediction by using multi-generative multi-adversarial nets (BPGAN) for the prediction of any modal from another modal image in paired and unpaired fashion. In BPGAN, two nonlinear maps are learned by projecting same pathological features from one domain to another with cycle consistency strategy. Technologically, pathological prior information is introduced to constrain the feature generation to attack the potential risk of pathological variance, and edge retention metric is adopted to preserve geometrically distortion and anatomical structure. Algorithmically, spectral normalization is designed to control the performance of discriminator and to make predictor learn better and faster, and the localization is proposed to impose regularizer on predictor to reduce generalization error. Experimental results show that BPGAN generates better predictions than recently state-of-the-art methods. Specifically, BPGAN achieves average increment of MAE 33.2% and 37.4%, and SSIM 24.5% and 44.6% on two baseline datasets than comparisons.}
}
@article{SONG202095,
title = {Dynamic resource allocation during reinforcement learning accounts for ramping and phasic dopamine activity},
journal = {Neural Networks},
volume = {126},
pages = {95-107},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300824},
author = {Minryung R. Song and Sang Wan Lee},
keywords = {Prediction error, Salience, Temporal-difference learning model, Pearce-Hall model, Habit, Striatum},
abstract = {For an animal to learn about its environment with limited motor and cognitive resources, it should focus its resources on potentially important stimuli. However, too narrow focus is disadvantageous for adaptation to environmental changes. Midbrain dopamine neurons are excited by potentially important stimuli, such as reward-predicting or novel stimuli, and allocate resources to these stimuli by modulating how an animal approaches, exploits, explores, and attends. The current study examined the theoretical possibility that dopamine activity reflects the dynamic allocation of resources for learning. Dopamine activity may transition between two patterns: (1) phasic responses to cues and rewards, and (2) ramping activity arising as the agent approaches the reward. Phasic excitation has been explained by prediction errors generated by experimentally inserted cues. However, when and why dopamine activity transitions between the two patterns remain unknown. By parsimoniously modifying a standard temporal difference (TD) learning model to accommodate a mixed presentation of both experimental and environmental stimuli, we simulated dopamine transitions and compared them with experimental data from four different studies. The results suggested that dopamine transitions from ramping to phasic patterns as the agent focuses its resources on a small number of reward-predicting stimuli, thus leading to task dimensionality reduction. The opposite occurs when the agent re-distributes its resources to adapt to environmental changes, resulting in task dimensionality expansion. This research elucidates the role of dopamine in a broader context, providing a potential explanation for the diverse repertoire of dopamine activity that cannot be explained solely by prediction error.}
}
@article{HOOK202097,
title = {Deep Multi-Critic Network for accelerating Policy Learning in multi-agent environments},
journal = {Neural Networks},
volume = {128},
pages = {97-106},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301519},
author = {Joosep Hook and Varuna De Silva and Ahmet Kondoz},
keywords = {Deep Multi-Critic Network, Policy Learning, Football player analysis},
abstract = {Humans live among other humans, not in isolation. Therefore, the ability to learn and behave in multi-agent environments is essential for any autonomous system that intends to interact with people. Due to the presence of multiple simultaneous learners in a multi-agent learning environment, the Markov assumption used for single-agent environments is not tenable, necessitating the development of new Policy Learning algorithms. Recent Actor–Critic algorithms proposed for multi-agent environments, such as Multi-Agent Deep Deterministic Policy Gradients and Counterfactual Multi-Agent Policy Gradients, find a way to use the same mathematical framework as single agent environments by augmenting the Critic with extra information. However, this extra information can slow down the learning process and afflict the Critic with Curse of Dimensionality. To combat this, we propose a novel Deep Neural Network configuration called Deep Multi-Critic Network. This architecture works by taking a weighted sum over the outputs of multiple critic networks of varying complexity and size. The configuration was tested on data collected from a real-world multi-agent environment. The results illustrate that by using Deep Multi-Critic Network, less data is needed to reach the same level of performance as when not using the configuration. This suggests that as the configuration learns faster from less data, then the Critic may be able to learn Q-values faster, accelerating Actor training as well.}
}
@article{KEJANI2020160,
title = {Graph Convolution Networks with manifold regularization for semi-supervised learning},
journal = {Neural Networks},
volume = {127},
pages = {160-167},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301362},
author = {M. Tavassoli Kejani and F. Dornaika and H. Talebi},
keywords = {Graph-based semisupervised learning, Graph Convolution Networks (GCN), Label prediction, Manifold regularization, Semisupervised image classification},
abstract = {In recent times, Graph Convolution Networks (GCN) have been proposed as a powerful tool for graph-based semi-supervised learning. In this paper, we introduce a model that enhances label propagation of Graph Convolution Networks (GCN). More precisely, we propose GCNs with Manifold Regularization (GCNMR). The objective function of the proposed GCNMR is composed by a supervised term and an unsupervised term. The supervised term enforces the fitting term between the predicted labels and the known labels. The unsupervised term imposes the smoothness of the predicted labels of the whole data samples. By learning a Graph Convolution Network with the proposed objective function, we are able to derive a more powerful semi-supervised learning. The proposed model retains the advantages of the classic GCN, yet it can improve it with no increase in time complexity. Experiments on three public image datasets show that the proposed model is superior to the GCN and several competing existing graph-based semi-supervised learning methods.}
}
@article{WANG2020205,
title = {Collaborative learning with corrupted labels},
journal = {Neural Networks},
volume = {125},
pages = {205-213},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300551},
author = {Yulin Wang and Rui Huang and Gao Huang and Shiji Song and Cheng Wu},
keywords = {Deep neural networks, Corrupted labels, Robustness},
abstract = {Deep neural networks (DNNs) have been very successful for supervised learning. However, their high generalization performance often comes with the high cost of annotating data manually. Collecting low-quality labeled dataset is relatively cheap, e.g., using web search engines, while DNNs tend to overfit to corrupted labels easily. In this paper, we propose a collaborative learning (co-learning) approach to improve the robustness and generalization performance of DNNs on datasets with corrupted labels. This is achieved by designing a deep network with two separate branches, coupled with a relabeling mechanism. Co-learning could safely recover the true labels of most mislabeled samples, not only preventing the model from overfitting the noise, but also exploiting useful information from all the samples. Although being very simple, the proposed algorithm is able to achieve high generalization performance even a large portion of the labels are corrupted. Experiments show that co-learning consistently outperforms existing state-of-the-art methods on three widely used benchmark datasets.}
}
@article{ZHANG2020126,
title = {A unified robust framework for multi-view feature extraction with L2,1-norm constraint},
journal = {Neural Networks},
volume = {128},
pages = {126-141},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301520},
author = {Jinxin Zhang and Liming Liu and Ling Zhen and Ling Jing},
keywords = {Multi-view, Feature extraction, L2,1-norm, Robust feature extraction framework},
abstract = {Multi-view feature extraction methods mainly focus on exploiting the consistency and complementary information between multi-view samples, and most of the current methods apply the F-norm or L2-norm as the metric, which are sensitive to the outliers or noises. In this paper, based on L2,1-norm, we propose a unified robust feature extraction framework, which includes four special multi-view feature extraction methods, and extends the state-of-art methods to a more generalized form. The proposed methods are less sensitive to outliers or noises. An efficient iterative algorithm is designed to solve L2,1-norm based methods. Comprehensive analyses, such as convergence analysis, rotational invariance analysis and relationship between our methods and previous F-norm based methods illustrate the effectiveness of our proposed methods. Experiments on two artificial datasets and six real datasets demonstrate that the proposed L2,1-norm based methods have better performance than the related methods.}
}
@article{CALIM2020108,
title = {Chimera states in hybrid coupled neuron populations},
journal = {Neural Networks},
volume = {126},
pages = {108-117},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300794},
author = {Ali Calim and Joaquin J. Torres and Mahmut Ozer and Muhammet Uzuntarla},
keywords = {Chimera state, Hybrid coupling, Chaotic population behavior},
abstract = {Here we study the emergence of chimera states, a recently reported phenomenon referring to the coexistence of synchronized and unsynchronized dynamical units, in a population of Morris–Lecar neurons which are coupled by both electrical and chemical synapses, constituting a hybrid synaptic architecture, as in actual brain connectivity. This scheme consists of a nonlocal network where the nearest neighbor neurons are coupled by electrical synapses, while the synapses from more distant neurons are of the chemical type. We demonstrate that peculiar dynamical behaviors, including chimera state and traveling wave, exist in such a hybrid coupled neural system, and analyze how the relative abundance of chemical and electrical synapses affects the features of chimera and different synchrony states (i.e. incoherent, traveling wave and coherent) and the regions in the space of relevant parameters for their emergence. Additionally, we show that, when the relative population of chemical synapses increases further, a new intriguing chaotic dynamical behavior appears above the region for chimera states. This is characterized by the coexistence of two distinct synchronized states with different amplitude, and an unsynchronized state, that we denote as a chaotic amplitude chimera. We also discuss about the computational implications of such state.}
}
@article{KOSKO2020359,
title = {Noise can speed backpropagation learning and deep bidirectional pretraining},
journal = {Neural Networks},
volume = {129},
pages = {359-384},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301246},
author = {Bart Kosko and Kartik Audhkhasi and Osonde Osoba},
keywords = {Backpropagation, Noise benefit, Stochastic resonance, Expectation–Maximization algorithm, Bidirectional associative memory, Contrastive divergence},
abstract = {We show that the backpropagation algorithm is a special case of the generalized Expectation–Maximization (EM) algorithm for iterative maximum likelihood estimation. We then apply the recent result that carefully chosen noise can speed the average convergence of the EM algorithm as it climbs a hill of probability or log-likelihood. Then injecting such noise can speed the average convergence of the backpropagation algorithm for both the training and pretraining of multilayer neural networks. The beneficial noise adds to the hidden and visible neurons and related parameters. The noise also applies to regularized regression networks. This beneficial noise is just that noise that makes the current signal more probable. We show that such noise also tends to improve classification accuracy. The geometry of the noise-benefit region depends on the probability structure of the neurons in a given layer. The noise-benefit region in noise space lies above the noisy-EM (NEM) hyperplane for classification and involves a hypersphere for regression. Simulations demonstrate these noise benefits using MNIST digit classification. The NEM noise benefits substantially exceed those of simply adding blind noise to the neural network. We further prove that the noise speed-up applies to the deep bidirectional pretraining of neural-network bidirectional associative memories (BAMs) or their functionally equivalent restricted Boltzmann machines. We then show that learning with basic contrastive divergence also reduces to generalized EM for an energy-based network probability. The optimal noise adds to the input visible neurons of a BAM in stacked layers of trained BAMs. Global stability of generalized BAMs guarantees rapid convergence in pretraining where neural signals feed back between contiguous layers. Bipolar coding of inputs further improves pretraining performance.}
}
@article{ALECSA2020178,
title = {New optimization algorithms for neural network training using operator splitting techniques},
journal = {Neural Networks},
volume = {126},
pages = {178-190},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300952},
author = {Cristian Daniel Alecsa and Titus Pinţa and Imre Boros},
keywords = {Neural network, MNIST, CIFAR10, Splitting, Nesterov, Dynamical system},
abstract = {In the following paper we present a new type of optimization algorithms adapted for neural network training. These algorithms are based upon sequential operator splitting technique for some associated dynamical systems. Furthermore, we investigate through numerical simulations the empirical rate of convergence of these iterative schemes toward a local minimum of the loss function, with some suitable choices of the underlying hyper-parameters. We validate the convergence of these optimizers using the results of the accuracy and of the loss function on the MNIST, MNIST-Fashion and CIFAR 10 classification datasets.}
}
@article{ZHANG202019,
title = {Reconstruction of natural visual scenes from neural spikes with deep neural networks},
journal = {Neural Networks},
volume = {125},
pages = {19-30},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300435},
author = {Yichen Zhang and Shanshan Jia and Yajing Zheng and Zhaofei Yu and Yonghong Tian and Siwei Ma and Tiejun Huang and Jian K. Liu},
keywords = {Vision, Natural scenes, Neural decoding, Neural spikes, Deep learning, Artificial retina},
abstract = {Neural coding is one of the central questions in systems neuroscience for understanding how the brain processes stimulus from the environment, moreover, it is also a cornerstone for designing algorithms of brain–machine interface, where decoding incoming stimulus is highly demanded for better performance of physical devices. Traditionally researchers have focused on functional magnetic resonance imaging (fMRI) data as the neural signals of interest for decoding visual scenes. However, our visual perception operates in a fast time scale of millisecond in terms of an event termed neural spike. There are few studies of decoding by using spikes. Here we fulfill this aim by developing a novel decoding framework based on deep neural networks, named spike-image decoder (SID), for reconstructing natural visual scenes, including static images and dynamic videos, from experimentally recorded spikes of a population of retinal ganglion cells. The SID is an end-to-end decoder with one end as neural spikes and the other end as images, which can be trained directly such that visual scenes are reconstructed from spikes in a highly accurate fashion. Our SID also outperforms on the reconstruction of visual stimulus compared to existing fMRI decoding models. In addition, with the aid of a spike encoder, we show that SID can be generalized to arbitrary visual scenes by using the image datasets of MNIST, CIFAR10, and CIFAR100. Furthermore, with a pre-trained SID, one can decode any dynamic videos to achieve real-time encoding and decoding of visual scenes by spikes. Altogether, our results shed new light on neuromorphic computing for artificial visual systems, such as event-based visual cameras and visual neuroprostheses.}
}
@article{XIAO20201,
title = {Fixed-time synchronization of delayed Cohen–Grossberg neural networks based on a novel sliding mode},
journal = {Neural Networks},
volume = {128},
pages = {1-12},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301404},
author = {Jian Xiao and Zhigang Zeng and Ailong Wu and Shiping Wen},
keywords = {Cohen–Grossberg neural networks, Fixed-time synchronization, Sliding-mode surface, Discontinuous activations},
abstract = {This paper has discussed fixed-time synchronization of discontinuous Cohen–Grossberg neural networks with time-varying delays and matched disturbances based on sliding mode control technology. First, a novel sliding-mode surface is established. And, the dynamics on the sliding-mode surface can be achieved in the fixed time by employing the Gudermannian function. Then, considering the effect of delay, two different control schemes are introduced to ensure the fixed time reachability of the sliding mode. In addition, some useful criteria are given out for fixed-time synchronization of neural networks, and the setting time is formulated in a straightforward way. Finally, some examples and simulations are presented to verify the validity of the proposed results.}
}
@article{UKITA2020185,
title = {Causal importance of low-level feature selectivity for generalization in image recognition},
journal = {Neural Networks},
volume = {125},
pages = {185-193},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030054X},
author = {Jumpei Ukita},
keywords = {Neural network, Orientation selectivity, Causality},
abstract = {Although our brain and deep neural networks (DNNs) can perform high-level sensory-perception tasks, such as image or speech recognition, the inner mechanism of these hierarchical information-processing systems is poorly understood in both neuroscience and machine learning. Recently, Morcos et al. (2018) examined the effect of class-selective units in DNNs, i.e., units with high-level selectivity, on network generalization, concluding that hidden units that are selectively activated by specific input patterns may harm the network’s performance. In this study, we revisited their hypothesis, considering units with selectivity for lower-level features, and argue that selective units are not always harmful to the network performance. Specifically, by using DNNs trained for image classification, we analyzed the orientation selectivity of individual units, a low-level selectivity widely studied in visual neuroscience. We found that orientation-selective units exist in both lower and higher layers of these DNNs, as in our brain. In particular, units in lower layers became more orientation-selective as the generalization performance improved during the course of training. Consistently, networks that generalized better were more orientation-selective in the lower layers. We finally revealed that ablating these selective units in the lower layers substantially degraded the generalization performance of the networks, at least by disrupting the shift-invariance of the higher layers. These results suggest that orientation selectivity can play a causally important role in object recognition, and that, contrary to the triviality of units with high-level selectivity, lower-layer units with selectivity for low-level features may be indispensable for generalization, at least for the several network architectures.}
}
@article{SHI202011,
title = {Global exponential stabilization and lag synchronization control of inertial neural networks with time delays},
journal = {Neural Networks},
volume = {126},
pages = {11-20},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300836},
author = {Jichen Shi and Zhigang Zeng},
keywords = {Stabilization, Lag synchronization, Inertial neural networks (INNs), Time delays},
abstract = {The global exponential stabilization and lag synchronization control of delayed inertial neural networks (INNs) are investigated. By constructing nonnegative function and employing inequality techniques, several new results about exponential stabilization and exponential lag synchronization are derived via adaptive control. And the theoretical outcomes are developed directly from the INNs themselves without variable substitution. In addition, the synchronization results are also applied to image encryption and decryption. Finally, an example is presented to illustrate the validity of the derived results.}
}
@article{GAO2020290,
title = {Multiple Discrimination and Pairwise CNN for view-based 3D object retrieval},
journal = {Neural Networks},
volume = {125},
pages = {290-302},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030071X},
author = {Zan Gao and Haixin Xue and Shaohua Wan},
keywords = {MDPCNN, Pairwise CNN, 3D object retrieval, Multi-view Discrimination},
abstract = {With the rapid development and wide application of computer, camera device, network and hardware technology, 3D object (or model) retrieval has attracted widespread attention and it has become a hot research topic in the computer vision domain. Deep learning features already available in 3D object retrieval have been proven to be better than the retrieval performance of hand-crafted features. However, most existing networks do not take into account the impact of multi-view image selection on network training, and the use of contrastive loss alone only forcing the same-class samples to be as close as possible. In this work, a novel solution named Multi-view Discrimination and Pairwise CNN (MDPCNN) for 3D object retrieval is proposed to tackle these issues. It can simultaneously input multiple batches and multiple views by adding the Slice layer and the Concat layer. Furthermore, a highly discriminative network is obtained by training samples that are not easy to be classified by clustering. Lastly, we deploy the contrastive-center loss and contrastive loss as the optimization objective that has better intra-class compactness and inter-class separability. Large-scale experiments show that the proposed MDPCNN can achieve a significant performance over the state-of-the-art algorithms in 3D object retrieval.}
}
@article{SMIEJA2020193,
title = {A classification-based approach to semi-supervised clustering with pairwise constraints},
journal = {Neural Networks},
volume = {127},
pages = {193-203},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301374},
author = {Marek Śmieja and Łukasz Struski and Mário A.T. Figueiredo},
keywords = {Semi-supervised clustering, Deep learning, Neural networks, Pairwise constraints, Siamese neural networks},
abstract = {In this paper, we introduce a neural network framework for semi-supervised clustering with pairwise (must-link or cannot-link) constraints. In contrast to existing approaches, we decompose semi-supervised clustering into two simpler classification tasks: the first stage uses a pair of Siamese neural networks to label the unlabeled pairs of points as must-link or cannot-link; the second stage uses the fully pairwise-labeled dataset produced by the first stage in a supervised neural-network-based clustering method. The proposed approach is motivated by the observation that binary classification (such as assigning pairwise relations) is usually easier than multi-class clustering with partial supervision. On the other hand, being classification-based, our method solves only well-defined classification problems, rather than less well specified clustering tasks. Extensive experiments on various datasets demonstrate the high performance of the proposed method.}
}
@article{WANG2020258,
title = {Supervised learning in spiking neural networks: A review of algorithms and evaluations},
journal = {Neural Networks},
volume = {125},
pages = {258-280},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300563},
author = {Xiangwen Wang and Xianghong Lin and Xiaochao Dang},
keywords = {Spiking neural network, Spike train, Spiking neuron, Supervised learning, Performance evaluation},
abstract = {As a new brain-inspired computational model of the artificial neural network, a spiking neural network encodes and processes neural information through precisely timed spike trains. Spiking neural networks are composed of biologically plausible spiking neurons, which have become suitable tools for processing complex temporal or spatiotemporal information. However, because of their intricately discontinuous and implicit nonlinear mechanisms, the formulation of efficient supervised learning algorithms for spiking neural networks is difficult, and has become an important problem in this research field. This article presents a comprehensive review of supervised learning algorithms for spiking neural networks and evaluates them qualitatively and quantitatively. First, a comparison between spiking neural networks and traditional artificial neural networks is provided. The general framework and some related theories of supervised learning for spiking neural networks are then introduced. Furthermore, the state-of-the-art supervised learning algorithms in recent years are reviewed from the perspectives of applicability to spiking neural network architecture and the inherent mechanisms of supervised learning algorithms. A performance comparison of spike train learning of some representative algorithms is also made. In addition, we provide five qualitative performance evaluation criteria for supervised learning algorithms for spiking neural networks and further present a new taxonomy for supervised learning algorithms depending on these five performance evaluation criteria. Finally, some future research directions in this research field are outlined.}
}
@article{YAN2020142,
title = {Training memristor-based multilayer neuromorphic networks with SGD, momentum and adaptive learning rates},
journal = {Neural Networks},
volume = {128},
pages = {142-149},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301532},
author = {Zheng Yan and Jiadong Chen and Rui Hu and Tingwen Huang and Yiran Chen and Shiping Wen},
keywords = {Memristor, Neural network, Adaptive learning rate},
abstract = {Neural networks implemented with traditional hardware face inherent limitation of memory latency. Specifically, the processing units like GPUs, FPGAs, and customized ASICs, must wait for inputs to read from memory and outputs to write back. This motivates memristor-based neuromorphic computing in which the memory units (i.e., memristors) have computing capabilities. However, training a memristor-based neural network is difficult since memristors work differently from CMOS hardware. This paper proposes a new training approach that enables prevailing neural network training techniques to be applied for memristor-based neuromorphic networks. Particularly, we introduce momentum and adaptive learning rate to the circuit training, both of which are proven methods that significantly accelerate the convergence of neural network parameters. Furthermore, we show that this circuit can be used for neural networks with arbitrary numbers of layers, neurons, and parameters. Simulation results on four classification tasks demonstrate that the proposed circuit achieves both high accuracy and fast speed. Compared with the SGD-based training circuit, on the WBC data set, the training speed of our circuit is increased by 37.2% while the accuracy is only reduced by 0.77%. On the MNIST data set, the new circuit even leads to improved accuracy.}
}
@article{ZHONG202019,
title = {Generative adversarial networks with decoder–encoder output noises},
journal = {Neural Networks},
volume = {127},
pages = {19-28},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301258},
author = {Guoqiang Zhong and Wei Gao and Yongbin Liu and Youzhao Yang and Da-Han Wang and Kaizhu Huang},
keywords = {Image generation, Generative models, Generative adversarial networks, Variational autoencoders, Noise},
abstract = {In recent years, research on image generation has been developing very fast. The generative adversarial network (GAN) emerges as a promising framework, which uses adversarial training to improve the generative ability of its generator. However, since GAN and most of its variants use randomly sampled noises as the input of their generators, they have to learn a mapping function from a whole random distribution to the image manifold. As the structures of the random distribution and the image manifold are generally different, this results in GAN and its variants difficult to train and converge. In this paper, we propose a novel deep model called generative adversarial networks with decoder–encoder output noises (DE-GANs), which take advantage of both the adversarial training and the variational Bayesian inference to improve GAN and its variants on image generation performances. DE-GANs use a pre-trained decoder–encoder architecture to map the random noise vectors to informative ones and feed them to the generator of the adversarial networks. Since the decoder–encoder architecture is trained with the same data set as the generator, its output vectors, as the inputs of the generator, could carry the intrinsic distribution information of the training images, which greatly improves the learnability of the generator and the quality of the generated images. Extensive experiments demonstrate the effectiveness of the proposed model, DE-GANs.}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {147},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00016-8},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000168}
}
@article{WU2020153,
title = {NFN＋: A novel network followed network for retinal vessel segmentation},
journal = {Neural Networks},
volume = {126},
pages = {153-162},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300721},
author = {Yicheng Wu and Yong Xia and Yang Song and Yanning Zhang and Weidong Cai},
keywords = {Retinal vessel segmentation, Deep learning, Cascaded networks, Skip connections},
abstract = {In the early diagnosis of diabetic retinopathy, the morphological attributes of blood vessels play an essential role to construct a retinal computer-aided diagnosis system. However, due to the challenges including limited densely annotated data, inter-vessel differences and structured prediction problem, it remains challenging to segment accurately the retinal vessels, particularly the capillaries on color fundus images. To address these issues, in this paper, we propose a novel deep learning-based model called NFN＋ to effectively extract multi-scale information and make full use of deep feature maps. In NFN＋, the front network converts an image patch into a probabilistic retinal vessel map, and the followed network further refines the map to achieve a better post-processing module, which helps represent the vessel structures implicitly. We employ the inter-network skip connections to unite two identical multi-scale backbones, which enables the useful multi-scale features to be directly transferred from shallow layers to deeper layers. The refined probabilistic retinal vessel maps produced from the augmented images are then averaged to construct the segmentation results. We evaluated this model on the digital retinal images for vessel extraction (DRIVE), structured analysis of the retina (STARE), and the child heart and health study (CHASE) databases. Our results indicate that the elaborated cascaded designs can produce performance gain and the proposed NFN＋ model, to our best knowledge, achieved the state-of-the-art retinal vessel segmentation accuracy on color fundus images (AUC: 98.30%, 98.75% and 98.94%, respectively).}
}
@article{CABESSA2020312,
title = {Automata complete computation with Hodgkin–Huxley neural networks composed of synfire rings},
journal = {Neural Networks},
volume = {126},
pages = {312-334},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300964},
author = {Jérémie Cabessa and Aubin Tchaptchet},
keywords = {Neural computation, Recurrent neural networks, Cell assemblies, Synfire rings, Hodgkin–Huxley equations, Finite state automata},
abstract = {Synfire rings are neural circuits capable of conveying synchronous, temporally precise and self-sustained activities in a robust manner. We propose a cell assembly based paradigm for abstract neural computation centered on the concept of synfire rings. More precisely, we empirically show that Hodgkin–Huxley neural networks modularly composed of synfire rings are automata complete. We provide an algorithmic construction which, starting from any given finite state automaton, builds a corresponding Hodgkin–Huxley neural network modularly composed of synfire rings and capable of simulating it. We illustrate the correctness of the construction on two specific examples. We further analyze the stability and robustness of the construction as a function of changes in the ring topologies as well as with respect to cell death and synaptic failure mechanisms, respectively. These results establish the possibility of achieving abstract computation with bio-inspired neural networks. They might constitute a theoretical ground for the realization of biological neural computers.}
}
@article{YANG2020121,
title = {On the localness modeling for the self-attention based end-to-end speech synthesis},
journal = {Neural Networks},
volume = {125},
pages = {121-130},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300447},
author = {Shan Yang and Heng Lu and Shiyin Kang and Liumeng Xue and Jinba Xiao and Dan Su and Lei Xie and Dong Yu},
keywords = {Speech synthesis, Self attention, Localness modeling, Relative-position-aware, Gaussian bias},
abstract = {Attention based end-to-end speech synthesis achieves better performance in both prosody and quality compared to the conventional “front-end”–“back-end” structure. But training such end-to-end framework is usually time-consuming because of the use of recurrent neural networks. To enable parallel calculation and long-range dependency modeling, a solely self-attention based framework named Transformer is proposed recently in the end-to-end family. However, it lacks position information in sequential modeling, so that the extra position representation is crucial to achieve good performance. Besides, the weighted sum form of self-attention is conducted over the whole input sequence when computing latent representation, which may disperse the attention to the whole input sequence other than focusing on the more important neighboring input states, resulting in generation errors. In this paper, we introduce two localness modeling methods to enhance the self-attention based representation for speech synthesis, which maintain the abilities of parallel computation and global-range dependency modeling in self-attention while improving the generation stability. We systematically analyze the solely self-attention based end-to-end speech synthesis framework, and unveil the importance of local context. Then we add the proposed relative-position-aware method to enhance local edges and experiment with different architectures to examine the effectiveness of localness modeling. In order to achieve query-specific window and discard the hyper-parameter of the relative-position-aware approach, we further conduct Gaussian-based bias to enhance localness. Experimental results indicate that the two proposed localness enhanced methods can both improve the performance of the self-attention model, especially when applied to the encoder part. And the query-specific window of Gaussian bias approach is more robust compared with the fixed relative edges.}
}
@article{BEJANI202033,
title = {Theory of adaptive SVD regularization for deep neural networks},
journal = {Neural Networks},
volume = {128},
pages = {33-46},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301416},
author = {Mohammad Mahdi Bejani and Mehdi Ghatee},
keywords = {Deep networks, Adaptive regularization, Overfitting, Singular values decomposition, Matrix decomposition},
abstract = {Deep networks can learn complex problems, however, they suffer from overfitting. To solve this problem, regularization methods have been proposed that are not adaptable to the dynamic changes in the training process. With a different approach, this paper presents a regularization method based on the Singular Value Decomposition (SVD) that adjusts the learning model adaptively. To this end, the overfitting can be evaluated by condition numbers of the synaptic matrices. When the overfitting is high, the matrices are substituted with their SVD approximations. Some theoretical results are derived to show the performance of this regularization method. It is proved that SVD approximation cannot solve overfitting after several iterations. Thus, a new Tikhonov term is added to the loss function to converge the synaptic weights to the SVD approximation of the best-found results. Following this approach, an Adaptive SVD Regularization (ASR) is proposed to adjust the learning model with respect to the dynamic training characteristics. ASR results are visualized to show how ASR overcomes overfitting. The different configurations of Convolutional Neural Networks (CNN) are implemented with different augmentation schemes to compare ASR with state-of-the-art regularization methods. The results show that on MNIST, F-MNIST, SVHN, CIFAR-10 and CIFAR-100, the accuracies of ASR are 99.4%, 95.7%, 97.1%, 93.2% and 55.6%, respectively. Although ASR improves the overfitting and validation loss, its elapsed time is not significantly greater than the learning without regularization.}
}
@article{DAS202047,
title = {Automated classification of cells into multiple classes in epithelial tissue of oral squamous cell carcinoma using transfer learning and convolutional neural network},
journal = {Neural Networks},
volume = {128},
pages = {47-60},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301659},
author = {Navarun Das and Elima Hussain and Lipi B. Mahanta},
keywords = {Oral squamous cell carcinoma, Deep learning, Convolution neural network, Transfer learning, Biopsy},
abstract = {The analysis of tissue of a tumor in the oral cavity is essential for the pathologist to ascertain its grading. Recent studies using biopsy images reveal computer-aided diagnosis for oral sub-mucous fibrosis (OSF) carried out using machine learning algorithms, but no research has yet been outlined for multi-class grading of oral squamous cell carcinoma (OSCC). Pertinently, with the advent of deep learning in digital imaging and computational aid in the diagnosis, multi-class classification of OSCC biopsy images can help in timely and effective prognosis and multi-modal treatment protocols for oral cancer patients, thus reducing the operational workload of pathologists while enhancing management of the disease. With this motivation, this study attempts to classify OSCC into its four classes as per the Broder’s system of histological grading. The study is conducted on oral biopsy images applying two methods: (i) through the application of transfer learning using pre-trained deep convolutional neural network (CNN) wherein four candidate pre-trained models, namely Alexnet, VGG-16, VGG-19 and Resnet-50, were chosen to find the most suitable model for our classification problem, and (ii) by a proposed CNN model. Although the highest classification accuracy of 92.15% is achieved by Resnet-50 model, the experimental findings highlight that the proposed CNN model outperformed the transfer learning approaches displaying accuracy of 97.5%. It can be concluded that the proposed CNN based multi-class grading method of OSCC could be used for diagnosis of patients with OSCC.}
}
@article{BALDEONCALISTO202076,
title = {AdaEn-Net: An ensemble of adaptive 2D–3D Fully Convolutional Networks for medical image segmentation},
journal = {Neural Networks},
volume = {126},
pages = {76-94},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300848},
author = {Maria {Baldeon Calisto} and Susana K. Lai-Yuen},
keywords = {Medical image segmentation, Deep learning, Neural architecture search, Hyperparameter optimization, Multiobjective optimization},
abstract = {Fully Convolutional Networks (FCNs) have emerged as powerful segmentation models but are usually designed manually, which requires extensive time and can result in large and complex architectures. There is a growing interest to automatically design efficient architectures that can accurately segment 3D medical images. However, most approaches either do not fully exploit volumetric information or do not optimize the model’s size. To address these problems, we propose a self-adaptive 2D–3D ensemble of FCNs called AdaEn-Net for 3D medical image segmentation that incorporates volumetric data and adapts to a particular dataset by optimizing both the model’s performance and size. The AdaEn-Net consists of a 2D FCN that extracts intra-slice information and a 3D FCN that exploits inter-slice information. The architecture and hyperparameters of the 2D and 3D architectures are found through a multiobjective evolutionary based algorithm that maximizes the expected segmentation accuracy and minimizes the number of parameters in the network. The main contribution of this work is a model that fully exploits volumetric information and automatically searches for a high-performing and efficient architecture. The AdaEn-Net was evaluated for prostate segmentation on the PROMISE12 Grand Challenge and for cardiac segmentation on the MICCAI ACDC challenge. In the first challenge, the AdaEn-Net ranks 9 out of 297 submissions and surpasses the performance of an automatically-generated segmentation network while producing an architecture with 13× fewer parameters. In the second challenge, the proposed model is ranked within the top 8 submissions and outperforms an architecture designed with reinforcement learning while having 1.25× fewer parameters.}
}
@article{MAEDA2020109,
title = {Phase portraits as movement primitives for fast humanoid robot control},
journal = {Neural Networks},
volume = {129},
pages = {109-122},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301271},
author = {Guilherme Maeda and Okan Koç and Jun Morimoto},
keywords = {Imitation learning, Reinforcement learning, Movement primitives, Phase estimation, Coupled oscillators},
abstract = {Currently, usual approaches for fast robot control are largely reliant on solving online optimal control problems. Such methods are known to be computationally intensive and sensitive to model accuracy. On the other hand, animals plan complex motor actions not only fast but seemingly with little effort even on unseen tasks. This natural sense to infer temporal dynamics and coordination motivates us to approach robot control from a motor skill learning perspective to design fast and computationally light controllers that can be learned autonomously by the robot under mild modeling assumptions. This article introduces Phase Portrait Movement Primitives (PPMP), a primitive that predicts dynamics on a low dimensional phase space which in turn is used to govern the high dimensional kinematics of the task. The stark difference with other primitive formulations is a built-in mechanism for phase prediction in the form of coupled oscillators that replaces model-based state estimators such as Kalman filters. The policy is trained by optimizing the parameters of the oscillators whose output is connected to a kinematic distribution in the form of a phase portrait. The drastic reduction in dimensionality allows us to efficiently train and execute PPMPs on a real human-sized, dual-arm humanoid upper body on a task involving 20 degrees-of-freedom. We demonstrate PPMPs in interactions requiring fast reactions times while generating anticipative pose adaptation in both discrete and cyclic tasks.}
}
@article{MYGDALIS2020296,
title = {K-Anonymity inspired adversarial attack and multiple one-class classification defense},
journal = {Neural Networks},
volume = {124},
pages = {296-307},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300174},
author = {Vasileios Mygdalis and Anastasios Tefas and Ioannis Pitas},
keywords = {K-Anonymity, Adversarial defense, Adversarial attack, Deep SVDD, Kernel learning},
abstract = {A novel adversarial attack methodology for fooling deep neural network classifiers in image classification tasks is proposed, along with a novel defense mechanism to counter such attacks. Two concepts are introduced, namely the K-Anonymity-inspired Adversarial Attack (K-A3) and the Multiple Support Vector Data Description Defense (M-SVDD-D). The proposed K-A3 introduces novel optimization criteria to standard adversarial attack methodologies, inspired by the K-Anonymity principles. Its generated adversarial examples are not only misclassified by the neural network classifier, but are uniformly spread along K different ranked output positions. The proposed M-SVDD-D consists of a deep neural architecture layer consisting of multiple non-linear one-class classifiers based on Support Vector Data Description that can be used to replace the final linear classification layer of a deep neural architecture, and an additional class verification mechanism. Its application decreases the effectiveness of adversarial attacks, by increasing the noise energy required to deceive the protected model, attributed to the introduced non-linearity. In addition, M-SVDD-D can be used to prevent adversarial attacks in black-box attack settings.}
}
@article{ZHOU2020194,
title = {Resilient fault-tolerant anti-synchronization for stochastic delayed reaction–diffusion neural networks with semi-Markov jump parameters},
journal = {Neural Networks},
volume = {125},
pages = {194-204},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300691},
author = {Jianping Zhou and Yamin Liu and Jianwei Xia and Zhen Wang and Sabri Arik},
keywords = {Anti-synchronization, Semi-Markov process, Fault-tolerant control, Resilient control, Neural networks},
abstract = {This paper deals with the anti-synchronization issue for stochastic delayed reaction–diffusion neural networks subject to semi-Markov jump parameters. A resilient fault-tolerant controller is utilized to ensure the anti-synchronization in the presence of actuator failures as well as gain perturbations, simultaneously. Firstly, by means of the Lyapunov functional and stochastic analysis methods, a mean-square exponential stability criterion is derived for the resulting error system. It is shown the obtained criterion improves a previously reported result. Then, based on the present analysis result and using several decoupling techniques, a strategy for designing the desired resilient fault-tolerant controller is proposed. At last, two numerical examples are given to illustrate the superiority of the present stability analysis method and the applicability of the proposed resilient fault-tolerant anti-synchronization control strategy, respectively.}
}
@article{KRONER2020261,
title = {Contextual encoder–decoder network for visual saliency prediction},
journal = {Neural Networks},
volume = {129},
pages = {261-270},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301660},
author = {Alexander Kroner and Mario Senden and Kurt Driessens and Rainer Goebel},
keywords = {Saliency prediction, Human fixations, Convolutional neural networks, Computer vision, Deep learning},
abstract = {Predicting salient regions in natural images requires the detection of objects that are present in a scene. To develop robust representations for this challenging task, high-level visual features at multiple spatial scales must be extracted and augmented with contextual information. However, existing models aimed at explaining human fixation maps do not incorporate such a mechanism explicitly. Here we propose an approach based on a convolutional neural network pre-trained on a large-scale image classification task. The architecture forms an encoder–decoder structure and includes a module with multiple convolutional layers at different dilation rates to capture multi-scale features in parallel. Moreover, we combine the resulting representations with global scene information for accurately predicting visual saliency. Our model achieves competitive and consistent results across multiple evaluation metrics on two public saliency benchmarks and we demonstrate the effectiveness of the suggested approach on five datasets and selected examples. Compared to state of the art approaches, the network is based on a lightweight image classification backbone and hence presents a suitable choice for applications with limited computational resources, such as (virtual) robotic systems, to estimate human fixations across complex natural scenes. Our TensorFlow implementation is openly available at https://github.com/alexanderkroner/saliency.}
}
@article{DORNAIKA2020141,
title = {Linear embedding by joint Robust Discriminant Analysis and Inter-class Sparsity},
journal = {Neural Networks},
volume = {127},
pages = {141-159},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301386},
author = {F. Dornaika and A. Khoder},
keywords = {Linear discriminant analysis, Feature extraction, Feature selection, Inter-class sparsity, Image classification},
abstract = {Linear Discriminant Analysis (LDA) and its variants are widely used as feature extraction methods. They have been used for different classification tasks. However, these methods have some limitations that need to be overcome. The main limitation is that the projection obtained by LDA does not provide a good interpretability for the features. In this paper, we propose a novel supervised method used for multi-class classification that simultaneously performs feature selection and extraction. The targeted projection transformation focuses on the most discriminant original features, and at the same time, makes sure that the transformed features (extracted features) belonging to each class have common sparsity. Our proposed method is called Robust Discriminant Analysis with Feature Selection and Inter-class Sparsity (RDA_FSIS). The corresponding model integrates two types of sparsity. The first type is obtained by imposing the ℓ2,1 constraint on the projection matrix in order to perform feature selection. The second type of sparsity is obtained by imposing the inter-class sparsity constraint used for ensuring a common sparsity structure in each class. An orthogonal matrix is also introduced in our model in order to guarantee that the extracted features can retain the main variance of the original data and thus improve the robustness to noise. The proposed method retrieves the LDA transformation by taking into account the two types of sparsity. Various experiments are conducted on several image datasets including faces, objects and digits. The projected features are used for multi-class classification. Obtained results show that the proposed method outperforms other competing methods by learning a more compact and discriminative transformation.}
}
@article{PAHIC2020121,
title = {Training of deep neural networks for the generation of dynamic movement primitives},
journal = {Neural Networks},
volume = {127},
pages = {121-131},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301301},
author = {Rok Pahič and Barry Ridge and Andrej Gams and Jun Morimoto and Aleš Ude},
keywords = {Training of deep neural networks, Dynamic movement primitives, Robot skill learning},
abstract = {Dynamic movement primitives (DMPs) have proven to be an effective movement representation for motor skill learning. In this paper, we propose a new approach for training deep neural networks to synthesize dynamic movement primitives. The distinguishing property of our approach is that it can utilize a novel loss function that measures the physical distance between movement trajectories as opposed to measuring the distance between the parameters of DMPs that have no physical meaning. This was made possible by deriving differential equations that can be applied to compute the gradients of the proposed loss function, thus enabling an effective application of backpropagation to optimize the parameters of the underlying deep neural network. While the developed approach is applicable to any neural network architecture, it was evaluated on two different architectures based on encoder–decoder networks and convolutional neural networks. Our results show that the minimization of the proposed loss function leads to better results than when more conventional loss functions are used.}
}
@article{CHENG2020281,
title = {Parametric Deformable Exponential Linear Units for deep neural networks},
journal = {Neural Networks},
volume = {125},
pages = {281-289},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300575},
author = {Qishang Cheng and HongLiang Li and Qingbo Wu and Lei Ma and King Ngi Ngan},
keywords = {Rectified activation, Deformable exponential, Image classification, Deep learning},
abstract = {Rectified activation units make an important contribution to the success of deep neural networks in many computer vision tasks. In this paper, we propose a Parametric Deformable Exponential Linear Unit (PDELU) and theoretically verify its effectiveness for improving the convergence speed of learning procedure. By means of flexible map shape, the proposed PDELU could push the mean value of activation responses closer to zero, which ensures the steepest descent in training a deep neural network. We verify the effectiveness of the proposed method in the image classification task. Extensive experiments on three classical databases (i.e., CIFAR-10, CIFAR-100, and ImageNet-2015) indicate that the proposed method leads to higher convergence speed and better accuracy when it is embedded into different CNN architectures (i.e., NIN, ResNet, WRN, and DenseNet). Meanwhile, the proposed PDELU outperforms many existing shape-specific activation functions (i.e., Maxout, ReLU, LeakyReLU, ELU, SELU, SoftPlus, Swish) and the shape-adaptive activation functions (i.e., APL, PReLU, MPELU, FReLU).}
}
@article{SHI202073,
title = {Deep learning from label proportions with labeled samples},
journal = {Neural Networks},
volume = {128},
pages = {73-81},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301544},
author = {Yong Shi and Jiabin Liu and Bo Wang and Zhiquan Qi and YingJie Tian},
keywords = {Learning from label proportions (LLP), Convolutional neural networks (convNets), Multi-class problem, Random sampling},
abstract = {Learning from label proportions (LLP), where the training data is in form of bags, and only the proportions of classes in each bag are available, has attracted wide interest in machine learning community. In general, most LLP algorithms adopt random sampling to obtain the proportional information of different categories, which correspondingly obtains some labeled samples in each bag. However, LLP training process always fails to leverage these labeled samples, which may contain essential data distribution information. To address this issue, in this paper, we propose end-to-end LLP solver based on convolutional neural networks (ConvNets), called LLP with labeled samples (LLP-LS). First, we reshape the cross entropy loss in ConvNets, so that it can combine the proportional information and labeled samples in each bag. Second, in order to comply with the training data in a bag manner, ADAM based on batch is employed to train LLP-LS. Hence, the batch size in training process is in accordance with the bag size. Compared with up-to-date methods on multi-class problem, our algorithm can obtain the state-of-the-art on several image datasets.}
}
@article{SOUSA2020349,
title = {SOMprocessor: A high throughput FPGA-based architecture for implementing Self-Organizing Maps and its application to video processing},
journal = {Neural Networks},
volume = {125},
pages = {349-362},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.02.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300733},
author = {Miguel Angelo de Abreu de Sousa and Ricardo Pires and Emilio Del-Moral-Hernandez},
keywords = {Self-organizing Maps, Neuromorphic chip, Unsupervised learning, FPGA, Video surveillance},
abstract = {The design of neuromorphic chips aims to develop electronic circuits dedicated to executing artificial neural networks, mainly by exploring parallel processing. Unsupervised learning models, such as Self-organizing Maps (SOM), may benefit from massively concurrent hardware-based implementations to meet the requirements of real-time and embedded applications. This work first presents a theoretical analysis of the algorithms implemented in hardware to compute SOM learning and recall phases. This is important because, albeit similar, the processing steps executed in hardware are not necessarily identical to those executed in software. Then, the proposed FPGA architecture entitled SOMprocessor is shown in detail. The circuit of the processor explores two different computational strategies for increasing the performance of current state-of-the-art works. These computational strategies aim to improve the data flow through the processor and its flexibility to implement different network topologies. Finally, this work presents the application of the SOMprocessor to a video categorization task. The results show that topographic and quantization errors are similar between hardware and software implementations, as well as the overall accuracy. Moreover, the proposed FPGA architecture achieves acceleration of 3 to 4 orders of magnitude as compared to CPU executions.}
}
@article{GAO2020335,
title = {Multi-view projected clustering with graph learning},
journal = {Neural Networks},
volume = {126},
pages = {335-346},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.03.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300976},
author = {Quanxue Gao and Zhizhen Wan and Ying Liang and Qianqian Wang and Yang Liu and Ling Shao},
keywords = {Multi-view, Subspace learning, Clustering, Feature selection, Local structure},
abstract = {Graph based multi-view learning is well known due to its effectiveness and good clustering performance. However, most existing methods directly construct graph from original high-dimensional data which always contain redundancy, noise and outlying entries in real applications, resulting in unreliable and inaccurate graph. Moreover, they do not effectively select some useful features which are important for graph learning and clustering. To solve these limits, we propose a novel model that combines dimensionality reduction, manifold structure learning and feature selection into a framework. We map high-dimensional data into low-dimensional space to reduce the complexity of the algorithm and reduce the effect of noise and redundance. Therefore, we can adaptively learn a more accurate graph. Further more, ℓ21-norm regularization is adopted to adaptively select some important features which help improve clustering performance. Finally, an efficiently algorithm is proposed to solve the optimal solution. Extensive experimental results on some benchmark datasets demonstrate the superiority of the proposed method.}
}
@article{YAO2020142,
title = {Fast discrete cross-modal hashing with semantic consistency},
journal = {Neural Networks},
volume = {125},
pages = {142-152},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300459},
author = {Tao Yao and Lianshan Yan and Yilan Ma and Hong Yu and Qingtang Su and Gang Wang and Qi Tian},
keywords = {Cross-modal retrieval, Semantic consistency, Discrete optimization, Hashing},
abstract = {Supervised cross-modal hashing has attracted widespread concentrations for large-scale retrieval task due to its promising retrieval performance. However, most existing works suffer from some of following issues. Firstly, most of them only leverage the pair-wise similarity matrix to learn hash codes, which may result in class information loss. Secondly, the pair-wise similarity matrix generally lead to high computing complexity and memory cost. Thirdly, most of them relax the discrete constraints during optimization, which generally results in large cumulative quantization error and consequent inferior hash codes. To address above problems, we present a Fast Discrete Cross-modal Hashing method in this paper, FDCH for short. Specifically, it firstly leverages both class labels and the pair-wise similarity matrix to learn a sharing Hamming space where the semantic consistency can be better preserved. Then we propose an asymmetric hash codes learning model to avoid the challenging issue of symmetric matrix factorization. Finally, an effective and efficient discrete optimal scheme is designed to generate discrete hash codes directly, and the computing complexity and memory cost caused by the pair-wise similarity matrix are reduced from O(n2) to O(n), where n denotes the size of training set. Extensive experiments conducted on three real world datasets highlight the superiority of FDCH compared with several cross-modal hashing methods and demonstrate its effectiveness and efficiency.}
}
@article{CHEN202022,
title = {Performance metrics for online seizure prediction},
journal = {Neural Networks},
volume = {128},
pages = {22-32},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301428},
author = {Hsiang-Han Chen and Vladimir Cherkassky},
keywords = {Online seizure prediction, iEEG signal, Lead seizure, Prediction horizon, Prediction period, Sensitivity},
abstract = {Many recent studies on online seizure prediction from iEEG signal describe various prediction algorithms and their prediction performance. In contrast, this paper focuses on proper specification of system parameters, such as prediction period, prediction horizon and data-driven characterization of lead seizures. Whereas prediction performance clearly depends on these system parameters many researchers simply set the values of these parameters in an ad hoc manner. Our paper investigates the effect of these system parameters on online prediction performance, using both synthetic and real-life data sets. Therefore, meaningful comparison of methods/algorithms (for online seizure prediction) should consider proper specification of system parameters.}
}