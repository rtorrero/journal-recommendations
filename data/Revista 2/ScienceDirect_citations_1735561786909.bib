@article{WANG20201,
title = {A novel feature representation: Aggregating convolution kernels for image retrieval},
journal = {Neural Networks},
volume = {130},
pages = {1-10},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302252},
author = {Qi Wang and Jinxing Lai and Luc Claesen and Zhenguo Yang and Liang Lei and Wenyin Liu},
keywords = {Image representation, Feature aggregating, Distance measurement, Image retrieval},
abstract = {Activated hidden units in convolutional neural networks (CNNs), known as feature maps, dominate image representation, which is compact and discriminative. For ultra-large datasets, high dimensional feature maps in float format not only result in high computational complexity, but also occupy massive memory space. To this end, a new image representation by aggregating convolution kernels (ACK) is proposed, where some convolution kernels capturing certain patterns are activated. The top-n index numbers of the convolution kernels are extracted directly as image representation in discrete integer values, which rebuild relationship between convolution kernels and image. Furthermore, a distance measurement is defined from the perspective of ordered sets to calculate position-sensitive similarities between image representations. Extensive experiments conducted on Oxford Buildings, Paris, and Holidays, etc., manifest that the proposed ACK achieves competitive performance on image retrieval with much lower computational cost, outperforming the ones using feature maps for image representation.}
}
@article{XIA202050,
title = {Unsupervised multi-domain multimodal image-to-image translation with explicit domain-constrained disentanglement},
journal = {Neural Networks},
volume = {131},
pages = {50-63},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302641},
author = {Weihao Xia and Yujiu Yang and Jing-Hao Xue},
keywords = {Deep neural networks, Generative adversarial network, Image-to-image translation},
abstract = {Image-to-image translation has drawn great attention during the past few years. It aims to translate an image in one domain to a target image in another domain. However, three big challenges remain in image-to-image translation: (1) the lack of large amounts of aligned training pairs for various tasks; (2) the ambiguity of multiple possible outputs from a single input image; and (3) the lack of simultaneous training for multi-domain translation with a single network. Therefore in this paper, we propose a unified framework for learning to generate diverse outputs using unpaired training data and allow for simultaneous multi-domain translation via a single model. Moreover, we also observed from experiments that the implicit disentanglement of content and style could lead to undesirable results. Thus we investigate how to extract domain-level signal as explicit supervision so as to achieve better image-to-image translation. Extensive experiments show that the proposed method outperforms or is comparable with the state-of-the-art methods for various applications.}
}
@article{JIANG2020276,
title = {SVM-Boosting based on Markov resampling: Theory and algorithm},
journal = {Neural Networks},
volume = {131},
pages = {276-290},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302884},
author = {Hongwei Jiang and Bin Zou and Chen Xu and Jie Xu and Yuan Yan Tang},
keywords = {Boosting, Consistency, Uniformly ergodic Markov chain (u.e.M.c.), Resampling},
abstract = {In this article we introduce the idea of Markov resampling for Boosting methods. We first prove that Boosting algorithm with general convex loss function based on uniformly ergodic Markov chain (u.e.M.c.) examples is consistent and establish its fast convergence rate. We apply Boosting algorithm based on Markov resampling to Support Vector Machine (SVM), and introduce two new resampling-based Boosting algorithms: SVM-Boosting based on Markov resampling (SVM-BM) and improved SVM-Boosting based on Markov resampling (ISVM-BM). In contrast with SVM-BM, ISVM-BM uses the support vectors to calculate the weights of base classifiers. The numerical studies based on benchmark datasets show that the proposed two resampling-based SVM Boosting algorithms for linear base classifiers have smaller misclassification rates, less total time of sampling and training compared to three classical AdaBoost algorithms: Gentle AdaBoost, Real AdaBoost, Modest AdaBoost. In addition, we compare the proposed SVM-BM algorithm with the widely used and efficient gradient Boosting algorithm-XGBoost (eXtreme Gradient Boosting), SVM-AdaBoost and present some useful discussions on the technical parameters.}
}
@article{ARSLAN202060,
title = {Controller design for finite-time and fixed-time stabilization of fractional-order memristive complex-valued BAM neural networks with uncertain parameters and time-varying delays},
journal = {Neural Networks},
volume = {130},
pages = {60-74},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302367},
author = {Emel Arslan and G. Narayanan and M. Syed Ali and Sabri Arik and Sumit Saroha},
keywords = {Fractional-order, Complex-valued BAM neural networks(CVBAMNNs), Memristor, Uncertain parameters, Time-varying delays},
abstract = {In this paper we investigate controller design problem for finite-time and fixed-time stabilization of fractional-order memristive complex-valued BAM neural networks (FMCVBAMNNs) with uncertain parameters and time-varying delays. By using the Lyapunov theory, differential inclusion theory, and fractional calculus theory, finite-time stabilization condition for fractional-order memristive complex-valued BAM neural networks and the upper bound of the settling time for stabilization are obtained. The nonlinear complex-valued activation functions are split into two (real and imaginary) components. Moreover, the settling time of fixed time stabilization, that does not depend upon the initial values, is merely calculated. A novel criterion for guaranteeing the fixed-time stabilization of FMCVBAMNNs is derived. Our control scheme achieves system stabilization within bounded time and has an advantage in convergence rate. Numerical simulations are furnished to demonstrate the effectiveness of the theoretical analysis.}
}
@article{PENG2020297,
title = {Discretely-constrained deep network for weakly supervised segmentation},
journal = {Neural Networks},
volume = {130},
pages = {297-308},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302525},
author = {Jizong Peng and Hoel Kervadec and Jose Dolz and Ismail {Ben Ayed} and Marco Pedersoli and Christian Desrosiers},
keywords = {Weakly-supervised learning, Segmentation, Discrete optimization, Convolutional neural networks},
abstract = {An efficient strategy for weakly-supervised segmentation is to impose constraints or regularization priors on target regions. Recent efforts have focused on incorporating such constraints in the training of convolutional neural networks (CNN), however this has so far been done within a continuous optimization framework. Yet, various segmentation constraints and regularization priors can be modeled and optimized more efficiently in a discrete formulation. This paper proposes a method, based on the alternating direction method of multipliers (ADMM) algorithm, to train a CNN with discrete constraints and regularization priors. This method is applied to the segmentation of medical images with weak annotations, where both size constraints and boundary length regularization are enforced. Experiments on two benchmark datasets for medical image segmentation show our method to provide significant improvements compared to existing approaches in terms of segmentation accuracy, constraint satisfaction and convergence speed.}
}
@article{KANG2020138,
title = {Structure learning with similarity preserving},
journal = {Neural Networks},
volume = {129},
pages = {138-148},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302008},
author = {Zhao Kang and Xiao Lu and Yiwei Lu and Chong Peng and Wenyu Chen and Zenglin Xu},
keywords = {Similarity preserving, Clustering, Semisupervised classification, Similarity measure, Deep auto-encoder},
abstract = {Leveraging on the underlying low-dimensional structure of data, low-rank and sparse modeling approaches have achieved great success in a wide range of applications. However, in many applications the data can display structures beyond simply being low-rank or sparse. Fully extracting and exploiting hidden structure information in the data is always desirable and favorable. To reveal more underlying effective manifold structure, in this paper, we explicitly model the data relation. Specifically, we propose a structure learning framework that retains the pairwise similarities between the data points. Rather than just trying to reconstruct the original data based on self-expression, we also manage to reconstruct the kernel matrix, which functions as similarity preserving. Consequently, this technique is particularly suitable for the class of learning problems that are sensitive to sample similarity, e.g., clustering and semisupervised classification. To take advantage of representation power of deep neural network, a deep auto-encoder architecture is further designed to implement our model. Extensive experiments on benchmark data sets demonstrate that our proposed framework can consistently and significantly improve performance on both evaluation tasks. We conclude that the quality of structure learning can be enhanced if similarity information is incorporated.}
}
@article{LIU2020300,
title = {Memristor-based LSTM network with in situ training and its applications},
journal = {Neural Networks},
volume = {131},
pages = {300-311},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302768},
author = {Xiaoyang Liu and Zhigang Zeng and Donald C. {Wunsch II}},
keywords = {Memristor, Memristor-based neural network, Recurrent neural network, Long short-term memory, Sequence data processing},
abstract = {Artificial neural networks (ANNs), such as the convolutional neural network (CNN) and long short-term memory (LSTM), have high complexity and contain large numbers of parameters. Memristor-based neural networks, which have the ability of in-memory and parallel computing, are therefore proposed to accelerate the operations of ANNs. In this paper, a memristor-based hardware realization of long short-term memory (LSTM) network with in situ training is presented. The designed memristor-based LSTM (MbLSTM) network is composed of memristor-based LSTM cell and memristor-based dense layer. Sigmoid and tanh (hyperbolic tangent) activation functions are approximately implemented through intentionally designing circuit parameters. A weight update scheme with row-parallel characteristic is put forward to update the conductance of memristors in crossbars. The highlights of MbLSTM include an effective hardware-based inference process and in situ training. The validity of MbLSTM is substantiated through classification tasks. The robustness of MbLSTM to conductance variations is also analyzed.}
}
@article{COHEN202064,
title = {ASSAF: Advanced and Slim StegAnalysis Detection Framework for JPEG images based on deep convolutional denoising autoencoder and Siamese networks},
journal = {Neural Networks},
volume = {131},
pages = {64-77},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.022},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030263X},
author = {Assaf Cohen and Aviad Cohen and Nir Nissim},
keywords = {Steganography, Steganalysis, Deep learning, Autoencoder, Siamese neural network, Convolution neural network},
abstract = {Steganography is the art of embedding a confidential message within a host message. Modern steganography is focused on widely used multimedia file formats, such as images, video files, and Internet protocols. Recently, cyber attackers have begun to include steganography (for communication purposes) in their arsenal of tools for evading detection. Steganalysis is the counter-steganography domain which aims at detecting the existence of steganography within a host file. The presence of steganography in files raises suspicion regarding the file itself, as well as its origin and receiver, and might be an indication of a sophisticated attack. The JPEG file format is one of the most popular image file formats and thus is an attractive and commonly used carrier for steganography embedding. State-of-the-art JPEG steganalysis methods, which are mainly based on neural networks, are limited in their ability to detect sophisticated steganography use cases. In this paper, we propose ASSAF, a novel deep neural network architecture composed of a convolutional denoising autoencoder and a Siamese neural network, specially designed to detect steganography in JPEG images. We focus on detecting the J-UNIWARD method, which is one of the most sophisticated adaptive steganography methods used today. We evaluated our novel architecture using the BOSSBase dataset, which contains 10,000 JPEG images, in eight different use cases which combine different JPEG’s quality factors and embedding rates (bpnzAC). Our results show that ASSAF can detect stenography with high accuracy rates, outperforming, in all eight use cases, the state-of-the-art steganalysis methods by 6% to 40%.}
}
@article{AGLIARI2020254,
title = {Generalized Guerra’s interpolation schemes for dense associative neural networks},
journal = {Neural Networks},
volume = {128},
pages = {254-267},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301714},
author = {Elena Agliari and Francesco Alemanno and Adriano Barra and Alberto Fachechi},
keywords = {Associative neural networks, Statistical mechanics, PDE-theory, Hebbian learning, Pattern recognition},
abstract = {In this work we develop analytical techniques to investigate a broad class of associative neural networks set in the high-storage regime. These techniques translate the original statistical–mechanical problem into an analytical–mechanical one which implies solving a set of partial differential equations, rather than tackling the canonical probabilistic route. We test the method on the classical Hopfield model – where the cost function includes only two-body interactions (i.e., quadratic terms) – and on the “relativistic” Hopfield model — where the (expansion of the) cost function includes p-body (i.e., of degree p) contributions. Under the replica symmetric assumption, we paint the phase diagrams of these models by obtaining the explicit expression of their free energy as a function of the model parameters (i.e., noise level and memory storage). Further, since for non-pairwise models ergodicity breaking is non necessarily a critical phenomenon, we develop a fluctuation analysis and find that criticality is preserved in the relativistic model.}
}
@article{ELYAN202091,
title = {Deep learning for symbols detection and classification in engineering drawings},
journal = {Neural Networks},
volume = {129},
pages = {91-102},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301957},
author = {Eyad Elyan and Laura Jamieson and Adamu Ali-Gombe},
keywords = {Deep learning, YOLO, P&ID, Engineering drawings, Symbols recognition, GANs},
abstract = {Engineering drawings are commonly used in different industries such as Oil and Gas, construction, and other types of engineering. Digitising these drawings is becoming increasingly important. This is mainly due to the need to improve business practices such as inventory, assets management, risk analysis, and other types of applications. However, processing and analysing these drawings is a challenging task. A typical diagram often contains a large number of different types of symbols belonging to various classes and with very little variation among them. Another key challenge is the class-imbalance problem, where some types of symbols largely dominate the data while others are hardly represented in the dataset. In this paper, we propose methods to handle these two challenges. First, we propose an advanced bounding-box detection method for localising and recognising symbols in engineering diagrams. Our method is end-to-end with no user interaction. Thorough experiments on a large collection of diagrams from an industrial partner proved that our methods accurately recognise more than 94% of the symbols. Secondly, we present a method based on Deep Generative Adversarial Neural Network for handling class-imbalance. The proposed GAN model proved to be capable of learning from a small number of training examples. Experiment results showed that the proposed method greatly improved the classification of symbols in engineering drawings.}
}
@article{NGUYEN2020111,
title = {A learning approach with incomplete pixel-level labels for deep neural networks},
journal = {Neural Networks},
volume = {130},
pages = {111-125},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302409},
author = {Nhu-Van Nguyen and Christophe Rigaud and Arnaud Revel and Jean-Christophe Burie},
keywords = {Incomplete labels, Loss function, Image segmentation, Comic speech balloon extraction, Nuclei segmentation},
abstract = {Learning with incomplete labels in Neural Networks has been actively investigated these last years. Among different kinds of incomplete labels, we investigate incomplete pixel-level labels which are tackled in many concrete problems. One of the challenges for incomplete pixel-level labels is the missing information at local-level. Most of the current researches with incomplete labels in Neural Network focus on the incompleteness of global labels, only a few works focus on the incompleteness of local labels. To deal with the local incompleteness, we propose a learning approach which uses two dynamic weighted maps in parallel: one for object pixels and another one for background pixels. The two maps are integrated into the loss function of the target Neural Networks, to optimize the model by the present labels and to minimize the damage of the missing labels. We validate our approach on the speech balloon extraction problem in comic book images. Our approach uses the output of a balloon extraction algorithm as incomplete labels. The results are comparable with the state of the art supervised approach with manual labels. The results are very promising because our method does not require any manual labels. In addition, we apply our method to the medical image segmentation task to confirm the generalization of our approach.}
}
@article{LI2020143,
title = {Delay-distribution-dependent state estimation for neural networks under stochastic communication protocol with uncertain transition probabilities},
journal = {Neural Networks},
volume = {130},
pages = {143-151},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302380},
author = {Jiahui Li and Zidong Wang and Hongli Dong and Weiyin Fei},
keywords = {Artificial neural networks, Random delays, Stochastic communication protocol, Markov chain, Uncertain transition probability},
abstract = {In this paper, the protocol-based remote state estimation problem is considered for a kind of delayed artificial neural networks. The random time-varying delays fall into certain intervals with known probability distributions. For the sake of reducing the data collisions in communication channel from the sensors to the estimator, the stochastic communication protocol (SCP) is employed to decide which sensor is allowed to transmit its data to the remote estimator through the channel at each fixed instant. The scheduling principle of the SCP is governed by a Markov chain whose transition probability is allowed to be uncertain so as to reflect the possible imprecision when implementing the SCP. Through a combination of Lyapunov–Krasovskii functional method and the stochastic analysis technique, a sufficient criterion is obtained for the existence of the desired remote state estimator ensuring that the corresponding augmented estimation error dynamics is asymptotically stable with a prescribed H∞ performance index. Furthermore, the estimator parameter is acquired by solving a convex optimization problem. Finally, the validity of the established theoretical results is demonstrated via a numerical simulation example.}
}
@article{BORRA202055,
title = {Interpretable and lightweight convolutional neural network for EEG decoding: Application to movement execution and imagination},
journal = {Neural Networks},
volume = {129},
pages = {55-74},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302021},
author = {Davide Borra and Silvia Fantozzi and Elisa Magosso},
keywords = {Electroencephalography, Convolutional neural network, Sinc-convolutional layer, Feature learning, Interpretability},
abstract = {Convolutional neural networks (CNNs) are emerging as powerful tools for EEG decoding: these techniques, by automatically learning relevant features for class discrimination, improve EEG decoding performances without relying on handcrafted features. Nevertheless, the learned features are difficult to interpret and most of the existing CNNs introduce many trainable parameters. Here, we propose a lightweight and interpretable shallow CNN (Sinc-ShallowNet), by stacking a temporal sinc-convolutional layer (designed to learn band-pass filters, each having only the two cut-off frequencies as trainable parameters), a spatial depthwise convolutional layer (reducing channel connectivity and learning spatial filters tied to each band-pass filter), and a fully-connected layer finalizing the classification. This convolutional module limits the number of trainable parameters and allows direct interpretation of the learned spectral–spatial​ features via simple kernel visualizations. Furthermore, we designed a post-hoc gradient-based technique to enhance interpretation by identifying the more relevant and more class-specific features. Sinc-ShallowNet was evaluated on benchmark motor-execution and motor-imagery datasets and against different design choices and training strategies. Results show that (i) Sinc-ShallowNet outperformed a traditional machine learning algorithm and other CNNs for EEG decoding; (ii) The learned spectral–spatial features matched well-known EEG motor-related activity; (iii) The proposed architecture performed better with a larger number of temporal kernels still maintaining a good compromise between accuracy and parsimony, and with a trialwise rather than a cropped training strategy. In perspective, the proposed approach, with its interpretative capacity, can be exploited to investigate cognitive/motor aspects whose EEG correlates are yet scarcely known, potentially characterizing their relevant features.}
}
@article{NIKOLENTZOS2020195,
title = {k-hop graph neural networks},
journal = {Neural Networks},
volume = {130},
pages = {195-205},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302495},
author = {Giannis Nikolentzos and George Dasoulas and Michalis Vazirgiannis},
keywords = {Graph neural networks, Graph mining, Expressivity},
abstract = {Graph neural networks (GNNs) have emerged recently as a powerful architecture for learning node and graph representations. Standard GNNs have the same expressive power as the Weisfeiler–Lehman test of graph isomorphism in terms of distinguishing non-isomorphic graphs. However, it was recently shown that this test cannot identify fundamental graph properties such as connectivity and triangle freeness. We show that GNNs also suffer from the same limitation. To address this limitation, we propose a more expressive architecture, k-hop GNNs, which updates a node’s representation by aggregating information not only from its direct neighbors, but from its k-hop neighborhood. We show that the proposed architecture can identify fundamental graph properties. We evaluate the proposed architecture on standard node classification and graph classification datasets. Our experimental evaluation confirms our theoretical findings since the proposed model achieves performance better or comparable to standard GNNs and to state-of-the-art algorithms.}
}
@article{KIM2020176,
title = {Hybrid neural network with cost-sensitive support vector machine for class-imbalanced multimodal data},
journal = {Neural Networks},
volume = {130},
pages = {176-184},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302410},
author = {Kyung Hye Kim and So Young Sohn},
keywords = {Deep learning (DL), Class-imbalance problem, Cost-sensitive approach, Multimodal analysis, Heterogeneous data, High-dimensional data},
abstract = {Although deep learning exhibits advantages in various applications involving multimodal data, it cannot effectively solve the class-imbalance problem. Herein, we propose a hybrid neural network with a cost-sensitive support vector machine (hybrid NN-CSSVM) for class-imbalanced multimodal data. We used a fused multiple-network structure obtained by extracting the features of different modality data, and used cost-sensitive support vector machines (SVMs) as a classifier. To alleviate the insufficiency of learning from minority-class data, our proposed cost-sensitive SVM loss function reflects different weights of misclassification errors from both majority and minority classes, by controlling cost parameters. Additionally, we present a theoretical setting of the cost parameters in our model. The proposed model is validated on real datasets that range from low to high imbalance ratios. By exploiting the complementary advantages of two architectures, the hybrid NN-CSSVM performs excellently, even with data having a minor-class proportion of only 2%.}
}
@article{XIAO2020172,
title = {Hungarian layer: A novel interpretable neural layer for paraphrase identification},
journal = {Neural Networks},
volume = {131},
pages = {172-184},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302653},
author = {Han Xiao},
keywords = {Neural Graph, Hungarian Layer, Paraphrase Identification},
abstract = {Paraphrase identification serves as an important topic in natural language processing while sequence alignment and matching underlie the principle of this task. Traditional alignment methods take advantage of attention mechanism. Attention mechanism, i.e. weighting technique, could pick out the most similar/dissimilar parts, but is weak in modeling the aligned unmatched parts, which are the crucial evidence to identify paraphrases. In this paper, we empower neural architecture with Hungarian algorithm to extract the aligned unmatched parts. Specifically, first, our model applies BiLSTM/BERT to encode the input sentences into hidden representations. Then, Hungarian layer leverages the hidden representations to extract the aligned unmatched parts. Last, we apply cosine similarity to metric the aligned unmatched parts for a final discrimination. Extensive experiments show that our model outperforms other baselines, substantially and significantly.}
}
@article{YI2020231,
title = {Synthesis of recurrent neural dynamics for monotone inclusion with application to Bayesian inference},
journal = {Neural Networks},
volume = {131},
pages = {231-241},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302896},
author = {Peng Yi and ShiNung Ching},
keywords = {Recurrent neural networks, Poisson spiking neuron, Monotone inclusion, Normative approach, Network synthesis, Bayesian casual inference},
abstract = {We propose a top-down approach to construct recurrent neural circuit dynamics for the mathematical problem of monotone inclusion (MoI). MoI in a general optimization framework that encompasses a wide range of contemporary problems, including Bayesian inference and Markov decision making. We show that in a recurrent neural circuit/network with Poisson neurons, each neuron’s firing curve can be understood as a proximal operator of a local objective function, while the overall circuit dynamics constitutes an operator-splitting system of ordinary differential equations whose equilibrium point corresponds to the solution of the MoI problem. Our analysis thus establishes that neural circuits are a substrate for solving a broad class of computational tasks. In this regard, we provide an explicit synthesis procedure for building neural circuits for specific MoI problems and demonstrate it for the specific case of Bayesian inference and sparse neural coding.}
}
@article{ARAUJO2020253,
title = {Self-organizing subspace clustering for high-dimensional and multi-view data},
journal = {Neural Networks},
volume = {130},
pages = {253-268},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302379},
author = {Aluizio F.R. Araújo and Victor O. Antonino and Karina L. Ponce-Guevara},
keywords = {Subspace clustering, Multi-view clustering, High-dimensional data, Self-organizing maps},
abstract = {A surge in the availability of data from multiple sources and modalities is correlated with advances in how to obtain, compress, store, transfer, and process large amounts of complex high-dimensional data. The clustering challenge increases with the growth of data dimensionality which decreases the discriminate power of the distance metrics. Subspace clustering aims to group data drawn from a union of subspaces. In such a way, there is a large number of state-of-the-art approaches and we divide them into families regarding the method used in the clustering. We introduce a soft subspace clustering algorithm, a Self-organizing Map (SOM) with a time-varying structure, to cluster data without any prior knowledge of the number of categories or of the neural network topology, both determined during the training process. The model also assigns proper relevancies (weights) to different dimensions, capturing from the learning process the influence of each dimension on uncovering clusters. We employ a number of real-world datasets to validate the model. This algorithm presents a competitive performance in a diverse range of contexts among them data mining, gene expression, multi-view, computer vision and text clustering problems which include high-dimensional data. Extensive experiments suggest that our method very often outperforms the state-of-the-art approaches in all types of problems considered.}
}
@article{WANG2020288,
title = {Generalized norm for existence, uniqueness and stability of Hopfield neural networks with discrete and distributed delays},
journal = {Neural Networks},
volume = {128},
pages = {288-293},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301842},
author = {Huamin Wang and Guoliang Wei and Shiping Wen and Tingwen Huang},
keywords = {Hopfield neural networks, Exponential stability, -norm, Discrete-distributed delays},
abstract = {In this paper, the existence, uniqueness and stability criteria of solutions for Hopfield neural networks with discrete and distributed delays (DDD HNNs) are investigated by the definitions of three kinds of generalized norm (ξ-norm). A general DDD HNN model is firstly introduced, where the discrete delays τpq(t) are asynchronous time-varying delays. Then, {ξ,1}-norm, {ξ,2}-norm and {ξ,∞}-norm are successively used to derive the existence, uniqueness and stability criteria of solutions for the DDD HNNs. In the proof of theorems, special functions and assumptions are given to deal with discrete and distributed delays. Furthermore, a corollary is concluded for the existence and stability criteria of solutions. The methods given in this paper can also be used to study the synchronization and μ-stability of different DDD NNs. Finally, two numerical examples and their simulation figures are given to illustrate the effectiveness of these results.}
}
@article{ZHOU2020229,
title = {Asynchronous dissipative filtering for nonhomogeneous Markov switching neural networks with variable packet dropouts},
journal = {Neural Networks},
volume = {130},
pages = {229-237},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302537},
author = {Xia Zhou and Jun Cheng and Jinde Cao and Minvydas Ragulskis},
keywords = {Nonhomogeneous Markov switching, Neural network, Asynchronous filter, Variable packet dropout},
abstract = {This work focuses on the problem of asynchronous filtering for nonhomogeneous Markov switching neural networks with variable packet dropouts (VPDs). The discrete-time nonhomogeneous Markov process is adopted to depict the modes switching of target plant, where time-varying transition probabilities are revealed by utilizing a polytope technology. By means of the Bernoulli distributed sequence, the randomly occurring packet dropouts are presented, where VPD rates are mode-dependent and remain variable. Unlike the existing results, the hidden Markov model scheme is formulated to describe the asynchronization between nonhomogeneous neural networks and filter, and resilient filters are presented, which makes the designed filters more general. Eventually, a simulation example is established to verify the effectiveness of the developed filter scheme.}
}
@article{SHI202075,
title = {Group visualization of class-discriminative features},
journal = {Neural Networks},
volume = {129},
pages = {75-90},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301969},
author = {Rui Shi and Tianxing Li and Yasushi Yamaguchi},
keywords = {Convolutional neural networks, Shapley values, Matrix decomposition, Feature visualization},
abstract = {Research explaining the behavior of convolutional neural networks (CNNs) has gained a lot of attention over the past few years. Although many visualization methods have been proposed to explain network predictions, most fail to provide clear correlations between the target output and the features extracted by convolutional layers. In this work, we define a concept, i.e., class-discriminative feature groups, to specify features that are extracted by groups of convolutional kernels correlated with a particular image class. We propose a detection method to detect class-discriminative feature groups and a visualization method to highlight image regions correlated with particular output and to interpret class-discriminative feature groups intuitively. The experiments showed that the proposed method can disentangle features based on image classes and shed light on what feature groups are extracted from which regions of the image. We also applied this method to visualize “lost” features in adversarial samples and features in an image containing a non-class object to demonstrate its ability to debug why the network failed or succeeded.}
}
@article{JIN202085,
title = {Quantifying the generalization error in deep learning in terms of data distribution and neural network smoothness},
journal = {Neural Networks},
volume = {130},
pages = {85-99},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302392},
author = {Pengzhan Jin and Lu Lu and Yifa Tang and George Em Karniadakis},
keywords = {Neural networks, Generalization error, Learnability, Data distribution, Cover complexity, Neural network smoothness},
abstract = {The accuracy of deep learning, i.e., deep neural networks, can be characterized by dividing the total error into three main types: approximation error, optimization error, and generalization error. Whereas there are some satisfactory answers to the problems of approximation and optimization, much less is known about the theory of generalization. Most existing theoretical works for generalization fail to explain the performance of neural networks in practice. To derive a meaningful bound, we study the generalization error of neural networks for classification problems in terms of data distribution and neural network smoothness. We introduce the cover complexity (CC) to measure the difficulty of learning a data set and the inverse of the modulus of continuity to quantify neural network smoothness. A quantitative bound for expected accuracy/error is derived by considering both the CC and neural network smoothness. Although most of the analysis is general and not specific to neural networks, we validate our theoretical assumptions and results numerically for neural networks by several data sets of images. The numerical results confirm that the expected error of trained networks scaled with the square root of the number of classes has a linear relationship with respect to the CC. We also observe a clear consistency between test loss and neural network smoothness during the training process. In addition, we demonstrate empirically that the neural network smoothness decreases when the network size increases whereas the smoothness is insensitive to training dataset size.}
}
@article{JAVANMARDI2020334,
title = {Appearance variation adaptation tracker using adversarial network},
journal = {Neural Networks},
volume = {129},
pages = {334-343},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302264},
author = {Mohammadreza Javanmardi and Xiaojun Qi},
keywords = {Visual tracking, Convolutional neural network, Adversarial learning},
abstract = {Visual trackers using deep neural networks have demonstrated favorable performance in object tracking. However, training a deep classification network using overlapped initial target regions may lead an overfitted model. To increase the model generalization, we propose an appearance variation adaptation (AVA) tracker that aligns the feature distributions of target regions over time by learning an adaptation mask in an adversarial network. The proposed adversarial network consists of a generator and a discriminator network that compete with each other over optimizing a discriminator loss in a mini-max optimization problem. Specifically, the discriminator network aims to distinguish recent target regions from earlier ones by minimizing the discriminator loss, while the generator network aims to produce an adaptation mask to maximize the discriminator loss. We incorporate a gradient reverse layer in the adversarial network to solve the aforementioned mini-max optimization in an end-to-end manner. We compare the performance of the proposed AVA tracker with the most recent state-of-the-art trackers by doing extensive experiments on OTB50, OTB100, and VOT2016 tracking benchmarks. Among the compared methods, AVA yields the highest area under curve (AUC) score of 0.712 and the highest average precision score of 0.951 on the OTB50 tracking benchmark. It achieves the second best AUC score of 0.688 and the best precision score of 0.924 on the OTB100 tracking benchmark. AVA also achieves the second best expected average overlap (EAO) score of 0.366, the best failure rate of 0.68, and the second best accuracy of 0.53 on the VOT2016 tracking benchmark.}
}
@article{TAHIR2020385,
title = {Prediction of N6-methyladenosine sites using convolution neural network model based on distributed feature representations},
journal = {Neural Networks},
volume = {129},
pages = {385-391},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301970},
author = {Muhammad Tahir and Maqsood Hayat and Kil To Chong},
keywords = {CNN, Natural language processing, word2vec, 10-fold cross-validation},
abstract = {N6-methyladenosine (m6A) is a well-studied and most common interior messenger RNA (mRNA) modification that plays an important function in cell development. N6A is found in all kingdoms​ of life and many other cellular processes such as RNA splicing, immune tolerance, regulatory functions, RNA processing, and cancer. Despite the crucial role of m6A in cells, it was targeted computationally, but unfortunately, the obtained results were unsatisfactory. It is imperative to develop an efficient computational model that can truly represent m6A sites. In this regard, an intelligent and highly discriminative computational model namely: m6A-word2vec is introduced for the discrimination of m6A sites. Here, a concept of natural language processing in the form of word2vec is used to represent the motif of the target class automatically. These motifs (numerical descriptors) are automatically targeted from the human genome without any clear definition. Further, the extracted feature space is then forwarded to the convolution neural network model as input for prediction. The developed computational model obtained 83.17%, 92.69%, and 90.50% accuracy for benchmark datasets S1, S2, and S3, respectively, using a 10-fold cross-validation test. The predictive outcomes validate that the developed intelligent computational model showed better performance compared to existing computational models. It is thus greatly estimated that the introduced computational model “m6A-word2vec” may be a supportive and practical tool for elementary and pharmaceutical research such as in drug design along with academia.}
}
@article{SHEN2020126,
title = {Hybrid multi-mode machine learning-based fault diagnosis strategies with application to aircraft gas turbine engines},
journal = {Neural Networks},
volume = {130},
pages = {126-142},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302422},
author = {Yanyan Shen and Khashayar Khorasani},
keywords = {Fault diagnosis, Machine learning, Self-organizing maps, Health monitoring, Aircraft gas turbine engines},
abstract = {In this work, a novel data-driven fault diagnostic framework is developed by using hybrid multi-mode machine learning strategies to monitor system health status. The coexistence of multi-mode and concurrent faults and their adverse coupling effects pose serious limitations for developing reliable diagnostic methodologies. A novel framework is proposed by exploiting inherent embedded health information contained in the I/O sensor data. The proposed hybrid strategies consist of optimal integration of recurrent neural network-based feature generation and self-organizing map diagnostic modules. To construct reliable fault diagnostic modules, a systematic clustering and modeling methodology is developed that has two primary advantages: (i) it does not require any a priori knowledge of data set characteristics or system mathematical model, and (ii) it does address and resolve the key limitations and challenges in conventional self-organizing map approaches. The effectiveness of our proposed framework is validated by utilizing sensor data including healthy and various degradation modes in application to compressor and turbine of an aircraft gas turbine engine. Comparisons with other machine learning-based methods in the literature are provided to demonstrate the performance and superiority of our proposed framework in fault diagnostic accuracy, false alarm rates, and in dealing with multi-mode and concurrent fault scenarios.}
}
@article{TIAN2020251,
title = {Deep learning on image denoising: An overview},
journal = {Neural Networks},
volume = {131},
pages = {251-275},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302665},
author = {Chunwei Tian and Lunke Fei and Wenxian Zheng and Yong Xu and Wangmeng Zuo and Chia-Wen Lin},
keywords = {Deep learning, Image denoising, Real noisy images, Blind denoising, Hybrid noisy images},
abstract = {Deep learning techniques have received much attention in the area of image denoising. However, there are substantial differences in the various types of deep learning methods dealing with image denoising. Specifically, discriminative learning based on deep learning can ably address the issue of Gaussian noise. Optimization models based on deep learning are effective in estimating the real noise. However, there has thus far been little related research to summarize the different deep learning techniques for image denoising. In this paper, we offer a comparative study of deep techniques in image denoising. We first classify the deep convolutional neural networks (CNNs) for additive white noisy images; the deep CNNs for real noisy images; the deep CNNs for blind denoising and the deep CNNs for hybrid noisy images, which represents the combination of noisy, blurred and low-resolution images. Then, we analyze the motivations and principles of the different types of deep learning methods. Next, we compare the state-of-the-art methods on public denoising datasets in terms of quantitative and qualitative analyses. Finally, we point out some potential challenges and directions of future research.}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {148},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00052-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000521}
}
@article{PENG2020298,
title = {Batch process fault detection for multi-stage broad learning system},
journal = {Neural Networks},
volume = {129},
pages = {298-312},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030201X},
author = {Chang Peng and RuiWei Lu and Olivia Kang and Wang Kai},
keywords = {Affinity propagation algorithm, Broad learning system, Penicillin fermentation process, Fault detection},
abstract = {In the real industrial production process, some minor faults are difficult to be detected by multivariate statistical analysis methods with mean and variance as detection indicators due to the aging equipment and catalyst deactivation. With structural characteristics, deep neural networks can better extract data features to detect such faults. However, most deep learning models contain a large number of connection parameters between layers, which causes the training time-consuming and thus makes it difficult to achieve a fast-online response. The Broad Learning System (BLS) network structure is expanded without a retraining process and thus saves a lot of training time. Considering that different stages of the batch production process have different production characteristics, we use the Affinity Propagation (AP) algorithm to separate the different stages of the production process. This paper conducts research on a multi-stage process monitoring framework that integrates AP and the BLS. Compared with other monitoring models, the monitoring results in the penicillin fermentation process have verified the superiority of the AP-BLS model.}
}
@article{WU202043,
title = {An end-to-end exemplar association for unsupervised person Re-identification},
journal = {Neural Networks},
volume = {129},
pages = {43-54},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301854},
author = {Jinlin Wu and Yang Yang and Zhen Lei and Jinqiao Wang and Stan Z. Li and Prayag Tiwari and Hari Mohan Pandey},
keywords = {End-to-end exemplar-based training, Exemplar association, Dynamic selection threshold},
abstract = {Tracklet association methods learn the cross camera retrieval ability though associating underlying cross camera positive samples, which have proven to be successful in unsupervised person re-identification task. However, most of them use poor-efficiency association strategies which costs long training hours but gains the low performance. To solve this, we propose an effective end-to-end exemplar associations (EEA) framework in this work. EEA mainly adapts three strategies to improve efficiency: (1) end-to-end exemplar-based training, (2) exemplar association and (3) dynamic selection threshold. The first one is to accelerate the training process, while the others aim to improve the tracklet association precision. Compared with existing tracklet associating methods, EEA obviously reduces the training cost and achieves the higher performance. Extensive experiments and ablation studies on seven RE-ID datasets demonstrate the superiority of the proposed EEA over most state-of-the-art unsupervised and domain adaptation RE-ID methods.}
}
@article{DENG202022,
title = {Heart sound classification based on improved MFCC features and convolutional recurrent neural networks},
journal = {Neural Networks},
volume = {130},
pages = {22-32},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302306},
author = {Muqing Deng and Tingting Meng and Jiuwen Cao and Shimin Wang and Jing Zhang and Huijie Fan},
keywords = {Heart sound classification, Convolutional neural network, Recurrent neural network, Improved MFCC features},
abstract = {Heart sound classification plays a vital role in the early detection of cardiovascular disorders, especially for small primary health care clinics. Despite that much progress has been made for heart sound classification in recent years, most of them are based on conventional segmented features and shallow structure based classifiers. These conventional acoustic representation and classification methods may be insufficient in characterizing heart sound, and generally suffer from a degraded performance due to the complicated and changeable cardiac acoustic environment. In this paper, we propose a new heart sound classification method based on improved Mel-frequency cepstrum coefficient (MFCC) features and convolutional recurrent neural networks. The Mel-frequency cepstrums are firstly calculated without dividing the heart sound signal. A new improved feature extraction scheme based on MFCC is proposed to elaborate the dynamic characteristics among consecutive heart sound signals. Finally, the MFCC-based features are fed to a deep convolutional and recurrent neural network (CRNN) for feature learning and later classification task. The proposed deep learning framework can take advantage of the encoded local characteristics extracted from the convolutional neural network (CNN) and the long-term dependencies captured by the recurrent neural network (RNN). Comprehensive studies on the performance of different network parameters and different network connection strategies are presented in this paper. Performance comparisons with state-of-the-art algorithms are given for discussions. Experiments show that, for the two-class classification problem (pathological or non-pathological), a classification accuracy of 98% has been achieved on the 2016 PhysioNet/CinC Challenge database.}
}
@article{FEDERER2020103,
title = {Improved object recognition using neural networks trained to mimic the brain’s statistical properties},
journal = {Neural Networks},
volume = {131},
pages = {103-114},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302549},
author = {Callie Federer and Haoyan Xu and Alona Fyshe and Joel Zylberberg},
abstract = {The current state-of-the-art object recognition algorithms, deep convolutional neural networks (DCNNs), are inspired by the architecture of the mammalian visual system, and are capable of human-level performance on many tasks. As they are trained for object recognition tasks, it has been shown that DCNNs develop hidden representations that resemble those observed in the mammalian visual system (Razavi and Kriegeskorte, 2014; Yamins and Dicarlo, 2016; Gu and van Gerven, 2015; Mcclure and Kriegeskorte, 2016). Moreover, DCNNs trained on object recognition tasks are currently among the best models we have of the mammalian visual system. This led us to hypothesize that teaching DCNNs to achieve even more brain-like representations could improve their performance. To test this, we trained DCNNs on a composite task, wherein networks were trained to: (a) classify images of objects; while (b) having intermediate representations that resemble those observed in neural recordings from monkey visual cortex. Compared with DCNNs trained purely for object categorization, DCNNs trained on the composite task had better object recognition performance and are more robust to label corruption. Interestingly, we found that neural data was not required for this process, but randomized data with the same statistical properties as neural data also boosted performance. While the performance gains we observed when training on the composite task vs the “pure” object recognition task were modest, they were remarkably robust. Notably, we observed these performance gains across all network variations we studied, including: smaller (CORNet-Z) vs larger (VGG-16) architectures; variations in optimizers (Adam vs gradient descent); variations in activation function (ReLU vs ELU); and variations in network initialization. Our results demonstrate the potential utility of a new approach to training object recognition networks, using strategies in which the brain – or at least the statistical properties of its activation patterns – serves as a teacher signal for training DCNNs.}
}
@article{2022II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {149},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00088-0},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000880}
}
@article{FANG2020154,
title = {Theory of deep convolutional neural networks II: Spherical analysis},
journal = {Neural Networks},
volume = {131},
pages = {154-162},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302707},
author = {Zhiying Fang and Han Feng and Shuo Huang and Ding-Xuan Zhou},
keywords = {Deep learning, Convolutional neural networks, Approximation theory, Spherical analysis, Sobolev spaces},
abstract = {Deep learning based on deep neural networks of various structures and architectures has been powerful in many practical applications, but it lacks enough theoretical verifications. In this paper, we consider a family of deep convolutional neural networks applied to approximate functions on the unit sphere Sd−1 of Rd. Our analysis presents rates of uniform approximation when the approximated function lies in the Sobolev space W∞r(Sd−1) with r>0 or takes an additive ridge form. Our work verifies theoretically the modelling and approximation ability of deep convolutional neural networks followed by downsampling and one fully connected layer or two. The key idea of our spherical analysis is to use the inner product form of the reproducing kernels of the spaces of spherical harmonics and then to apply convolutional factorizations of filters to realize the generated linear features.}
}
@article{MAJUMDAR2020248,
title = {Graph transform learning},
journal = {Neural Networks},
volume = {128},
pages = {248-253},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301908},
author = {Angshul Majumdar},
keywords = {Transform learning, Graphical model, Clustering, Signal processing},
abstract = {Transform learning is a new representation learning framework where we learn an operator/transform that analyses the data to generate the coefficient/representation. We propose a variant of it called the graph transform learning; in this we explicitly account for the correlation in the dataset in terms of graph Laplacian. We will give two variants; in the first one the graph is computed from the data and fixed during the operation. In the second, the graph is learnt iteratively from the data during operation. The first technique will be applied for clustering, and the second one for solving inverse problems.}
}
@article{2022I,
title = {Current Events},
journal = {Neural Networks},
volume = {149},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00087-9},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000879}
}
@article{KANG202093,
title = {Relation-Guided Representation Learning},
journal = {Neural Networks},
volume = {131},
pages = {93-102},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302550},
author = {Zhao Kang and Xiao Lu and Jian Liang and Kun Bai and Zenglin Xu},
keywords = {Deep auto-encoder, Unsupervised representation learning, Subspace clustering, Pairwise relation},
abstract = {Deep auto-encoders (DAEs) have achieved great success in learning data representations via the powerful representability of neural networks. But most DAEs only focus on the most dominant structures which are able to reconstruct the data from a latent space and neglect rich latent structural information. In this work, we propose a new representation learning method that explicitly models and leverages sample relations, which in turn is used as supervision to guide the representation learning. Different from previous work, our framework well preserves the relations between samples. Since the prediction of pairwise relations themselves is a fundamental problem, our model adaptively learns them from data. This provides much flexibility to encode real data manifold. The important role of relation and representation learning is evaluated on the clustering task. Extensive experiments on benchmark data sets demonstrate the superiority of our approach. By seeking to embed samples into subspace, we further show that our method can address the large-scale and out-of-sample problem. Our source code is publicly available at: https://github.com/nbShawnLu/RGRL.}
}
@article{TERADA2020344,
title = {Fast generalization error bound of deep learning without scale invariance of activation functions},
journal = {Neural Networks},
volume = {129},
pages = {344-358},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302033},
author = {Yoshikazu Terada and Ryoma Hirose},
keywords = {Deep learning, Fast learning rate, Empirical risk minimizer, Sigmoid activation function, Exponential linear unit},
abstract = {In the theoretical analysis of deep learning, discovering which features of deep learning lead to good performance is an important task. Using the framework for analyzing the generalization error developed by Suzuki (2018), we derive a fast learning rate for deep neural networks with general activation functions. According to Suzuki (2018), scale invariance of the activation functions is essential to derive tight error bounds. While the rectified linear unit (ReLU; Nair and Hinton, 2010) satisfies scale invariance, the other famous activation functions, such as the sigmoid, the hyperbolic tangent functions, and the exponential linear unit (ELU; Clevert et al., 2016), do not satisfy this condition. The existing analysis indicates the possibility that deep learning with non scale invariant activations may have a slower convergence rate of O(1∕n) whereas with scale invariant activation functions it can reach a faster rate. In this paper, without scale invariance of activation functions, we derive the tight generalization error bound which is essentially the same as that of Suzuki (2018). From this result, at least in the framework of Suzuki (2018), we show that scale invariance of the activation functions is not essential to obtain a fast rate of convergence. We also conclude that the theoretical framework proposed by Suzuki (2018) can be widely applied to the analysis of deep learning with general activation functions.}
}
@article{LIU2020280,
title = {A neurodynamic optimization approach for complex-variables programming problem},
journal = {Neural Networks},
volume = {129},
pages = {280-287},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302276},
author = {Shuxin Liu and Haijun Jiang and Liwei Zhang and Xuehui Mei},
keywords = {Complex variables, Nonsmooth optimization, Convex programming, Neural networks, CR calculus},
abstract = {A neural network model upon differential inclusion is designed for solving the complex-variables convex programming, and the chain rule for real-valued function with the complex-variables is established in this paper. The model does not need to choose penalty parameters when applied to practical problems, which makes it easier to design. The result is obtained that its state reaches the feasible region in finite time. Furthermore, the convergence for its state to an optimal solution is proved. Some typical examples are shown for the effectiveness of the designed model.}
}
@article{MA2020123,
title = {Image style transfer with collection representation space and semantic-guided reconstruction},
journal = {Neural Networks},
volume = {129},
pages = {123-137},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301982},
author = {Zhuoqi Ma and Jie Li and Nannan Wang and Xinbo Gao},
keywords = {Style transfer, Collection representation space, Semantic guidance},
abstract = {Image style transfer renders the content of an image into different styles. Current methods made decent progress with transferring the style of single image, however, visual statistics from one image cannot reflect the full scope of an artist. Also, previous work did not put content preservation in the important position, which would result in poor structure integrity, thus deteriorating the comprehensibility of generated image. These two problems would limit the visual quality improvement of style transfer results. Targeting at style resemblance and content preservation problems, we propose a style transfer system composed of collection representation space and semantic-guided reconstruction. We train an encoder–decoder network with art collections to construct a representation space that can reflect the style of the artist. Then, we use semantic information as guidance to reconstruct the target representation of the input image for better content preservation. We conduct both quantitative analysis and qualitative evaluation to assess the proposed method. Experiment results demonstrate that our approach well balanced the trade-off between capturing artistic characteristics and preserving content information in style transfer tasks.}
}
@article{REN2020165,
title = {Fixed-time synchronization of stochastic memristor-based neural networks with adaptive control},
journal = {Neural Networks},
volume = {130},
pages = {165-175},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302434},
author = {Hongwei Ren and Zhiping Peng and Yu Gu},
keywords = {Fixed-time synchronization, Stochastic synchronization, Memristor-based neural networks, Time delays, Adaptive control},
abstract = {In this study, we consider the fixed-time synchronization problem for stochastic memristor-based neural networks (MNNs) via two different controllers. First, a new stochastic differential equation is established using differential inclusions and set-valued maps. Next, two kinds of control protocols are designed, including a nonlinear delayed state feedback control scheme and a novel adaptive control strategy, by which fixed-time synchronization of MNNs can be achieved. Then based on stochastic analysis techniques and a Lyapunov function, some sufficient criteria are obtained to ensure that stochastic MNNs achieve stochastic fixed-time synchronization in probability. In addition, the upper bound of the settling time is estimated. Finally, simulation results are provided to demonstrate the validity of the proposed schemes.}
}
@article{SINHA2020127,
title = {DANTE: Deep alternations for training neural networks},
journal = {Neural Networks},
volume = {131},
pages = {127-143},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302677},
author = {Vaibhav B. Sinha and Sneha Kudugunta and Adepu Ravi Sankar and Surya Teja Chavali and Vineeth N. Balasubramanian},
keywords = {Neural nets, Deep learning, Backpropagation, Machine learning},
abstract = {We present DANTE, a novel method for training neural networks using the alternating minimization principle. DANTE provides an alternate perspective to traditional gradient-based backpropagation techniques commonly used to train deep networks. It utilizes an adaptation of quasi-convexity to cast training a neural network as a bi-quasi-convex optimization problem. We show that for neural network configurations with both differentiable (e.g. sigmoid) and non-differentiable (e.g. ReLU) activation functions, we can perform the alternations effectively in this formulation. DANTE can also be extended to networks with multiple hidden layers. In experiments on standard datasets, neural networks trained using the proposed method were found to be promising and competitive to traditional backpropagation techniques, both in terms of quality of the solution, as well as training speed.}
}
@article{JING202039,
title = {Learning explicitly transferable representations for domain adaptation},
journal = {Neural Networks},
volume = {130},
pages = {39-48},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302318},
author = {Mengmeng Jing and Jingjing Li and Ke Lu and Lei Zhu and Yang Yang},
keywords = {Domain adaptation, Transfer learning, Transferable representation},
abstract = {Domain adaptation tackles the problem where the training source domain and the test target domain have distinctive data distributions, and therefore improves the generalization ability of deep models. The very popular mechanism of domain adaptation is to learn a new feature representation which is supposed to be domain-invariant, so that the classifiers trained on the source domain can be directly applied to the target domain. However, recent work reveals that learning new feature representations may potentially deteriorate the adaptability of the original features and increase the expected error bound of the target domain. To address this, we propose to adapt classifiers rather than features. Specifically, we fill in the distribution gaps between domains by some additional transferable representations which are explicitly learned from the original features while keeping the original features unchanged. In addition, we argue that transferable representations should be able to be translated from one domain to the other with appropriate mappings. At the same time, we introduce conditional entropy to mitigate the semantic confusion during mapping. Experiments on both standard and large-scale datasets verify that our method is able to achieve the new state-of-the-art results on unsupervised domain adaptation.}
}
@article{YANG2020201,
title = {Twin minimax probability machine for pattern classification},
journal = {Neural Networks},
volume = {131},
pages = {201-214},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302719},
author = {Liming Yang and Yakun Wen and Min Zhang and Xue Wang},
keywords = {Minimax probability machine, Fractional programming, Concave maximization problem, Twin support vector machine, Nonparallel separation hyperplane},
abstract = {We propose a new distribution-free Bayes optimal classifier, called the twin minimax probability machine (TWMPM), which combines the benefits of both minimax probability machine(MPM) and twin support vector machine (TWSVM). TWMPM tries to construct two nonparallel hyperplanes such that each hyperplane separates one class samples with maximal probability, and is distant from the other class samples simultaneously. Moreover, the proposed TWMPM can control the misclassification error of samples in a worst-case setting by minimizing the upper bound on misclassification probability. An efficient algorithm for TWMPM is first proposed, which transforms TWMPM into concave fractional programming by applying multivariate Chebyshev inequality. Then the proposed TWMPM is reformulated as a pair of convex quadric programming (QP) by proper mathematical transformations. This guarantees TWMPM to have global optimal solution and be solved simply and effectively. In addition, we develop also an iterative algorithm for the proposed TWMPM. By comparing the two proposed algorithms theoretically, it is easy to know that the convex quadric programming algorithm is with lower computation burden than iterative algorithm for the TWMPM. A linear TWMPM version is first built, and then we show how to exploit mercer kernel to obtain nonlinear TWMPM version. The computation complexity for QP algorithm of TWMPM is in the same order as the traditional twin support vector machine (TWSVM). Experiments are carried out on three databases: UCI benchmark database, a practical application database and an artificial database. With low computation complexity and fewer parameters, experiments show the feasibility and effectiveness of the proposed TWMPM and its QP algorithm.}
}
@article{MONTANELLI20201,
title = {Error bounds for deep ReLU networks using the Kolmogorov–Arnold superposition theorem},
journal = {Neural Networks},
volume = {129},
pages = {1-6},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2019.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608019304058},
author = {Hadrien Montanelli and Haizhao Yang},
keywords = {Deep ReLU networks, Curse of dimensionality, Approximation theory, Kolmogorov–Arnold superposition theorem},
abstract = {We prove a theorem concerning the approximation of multivariate functions by deep ReLU networks, for which the curse of the dimensionality is lessened. Our theorem is based on a constructive proof of the Kolmogorov–Arnold superposition theorem, and on a subset of multivariate continuous functions whose outer superposition functions can be efficiently approximated by deep ReLU networks.}
}
@article{WANG2020215,
title = {Compressing 3DCNNs based on tensor train decomposition},
journal = {Neural Networks},
volume = {131},
pages = {215-230},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302690},
author = {Dingheng Wang and Guangshe Zhao and Guoqi Li and Lei Deng and Yang Wu},
keywords = {Tensor train decomposition, 3DCNN, Neural network compression, Tensorizing},
abstract = {Three-dimensional convolutional neural networks (3DCNNs) have been applied in many tasks, e.g., video and 3D point cloud recognition. However, due to the higher dimension of convolutional kernels, the space complexity of 3DCNNs is generally larger than that of traditional two-dimensional convolutional neural networks (2DCNNs). To miniaturize 3DCNNs for the deployment in confining environments such as embedded devices, neural network compression is a promising approach. In this work, we adopt the tensor train (TT) decomposition, a straightforward and simple in situ training compression method, to shrink the 3DCNN models. Through proposing tensorizing 3D convolutional kernels in TT format, we investigate how to select appropriate TT ranks for achieving higher compression ratio. We have also discussed the redundancy of 3D convolutional kernels for compression, core significance and future directions of this work, as well as the theoretical computation complexity versus practical executing time of convolution in TT. In the light of multiple contrast experiments based on VIVA challenge, UCF11, UCF101, and ModelNet40 datasets, we conclude that TT decomposition can compress 3DCNNs by around one hundred times without significant accuracy loss, which will enable its applications in extensive real world scenarios.}
}
@article{LONG2020193,
title = {Novel results on finite-time stabilization of state-based switched chaotic inertial neural networks with distributed delays},
journal = {Neural Networks},
volume = {129},
pages = {193-202},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302173},
author = {Changqing Long and Guodong Zhang and Zhigang Zeng},
keywords = {Finite-time stabilization, Distributed time-varying delays, Neural networks, Non-smooth analysis, State-based switched},
abstract = {The p-norm finite-time stabilization (FTS) issue of a class of state-based switched inertial chaotic neural networks (SBSCINNs) with distributed time-varying delays is investigated. By using a suitable variable transformation, such second-order SBSCINNs are turned into the first-order differential equations. Then some novel criteria are obtained to stabilize SBSCINNs in a finite time based on the theory of finite-time control and non-smooth analysis together with designing two proper delay-dependent feedback controllers. Besides, the settling time of FTS is also estimated and discussed. Finally, the validity and practicability of the deduced theoretical results are verified by examples and applications.}
}
@article{HUANG2020115,
title = {Bifurcations in a fractional-order neural network with multiple leakage delays},
journal = {Neural Networks},
volume = {131},
pages = {115-126},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302562},
author = {Chengdai Huang and Heng Liu and Xiangyun Shi and Xiaoping Chen and Min Xiao and Zhengxin Wang and Jinde Cao},
keywords = {Multiple leakage delays, Stability, Hopf bifurcation, Fractional-order neural networks},
abstract = {This paper expatiates the stability and bifurcation for a fractional-order neural network (FONN) with double leakage delays. Firstly, the characteristic equation of the developed FONN is circumspectly researched by employing inequable delays as bifurcation parameters. Simultaneously the bifurcation criteria are correspondingly extrapolated. Then, unequal delays-spurred-bifurcation diagrams are primarily delineated to confirm the precision and correctness for the values of bifurcation points. Furthermore, it lavishly illustrates from the evidence that the stability performance of the proposed FONN can be demolished with the presence of leakage delays in accordance with comparative studies. Eventually, two numerical examples are exploited to underpin the feasibility of the developed theory. The results derived in this paper have perfected the retrievable outcomes on bifurcations of FONNs embodying unique leakage delay, which can nicely serve a benchmark deliberation and provide a comparatively credible guidance for the influence of multiple leakage delays on bifurcations of FONNs.}
}
@article{YE202011,
title = {Block-term tensor neural networks},
journal = {Neural Networks},
volume = {130},
pages = {11-21},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302045},
author = {Jinmian Ye and Guangxi Li and Di Chen and Haiqin Yang and Shandian Zhe and Zenglin Xu},
keywords = {Tensor networks, Network compression, Neural networks, Deep learning},
abstract = {Deep neural networks (DNNs) have achieved outstanding performance in a wide range of applications, e.g., image classification, natural language processing, etc. Despite the good performance, the huge number of parameters in DNNs brings challenges to efficient training of DNNs and also their deployment in low-end devices with limited computing resources. In this paper, we explore the correlations in the weight matrices, and approximate the weight matrices with the low-rank block-term tensors. We name the new corresponding structure as block-term tensor layers (BT-layers), which can be easily adapted to neural network models, such as CNNs and RNNs. In particular, the inputs and the outputs in BT-layers are reshaped into low-dimensional high-order tensors with a similar or improved representation power. Sufficient experiments have demonstrated that BT-layers in CNNs and RNNs can achieve a very large compression ratio on the number of parameters while preserving or improving the representation power of the original DNNs.}
}
@article{FAYDASICOK2020288,
title = {A new Lyapunov functional for stability analysis of neutral-type Hopfield neural networks with multiple delays},
journal = {Neural Networks},
volume = {129},
pages = {288-297},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302288},
author = {Ozlem Faydasicok},
keywords = {Neutral-type Hopfield systems, Multiple delays, Lyapunov theorems, Stability analysis},
abstract = {This research paper conducts an investigation into the stability issue for a more general class of neutral-type Hopfield neural networks that involves multiple time delays in the states of neurons and multiple neutral delays in the time derivatives of the states of neurons. By constructing a new proper Lyapunov functional, an alternative easily verifiable algebraic criterion for global asymptotic stability of this type of Hopfield neural systems is derived. This new stability condition is entirely independent of time and neutral delays. Two instructive examples are employed to indicate that the result obtained in this paper reveals a new set of sufficient stability criteria when it is compared with the previously reported stability results. Therefore, the proposed stability result enlarges the application domain of Hopfield neural systems of neutral types.}
}
@article{FONTANINI2020185,
title = {MetalGAN: Multi-domain label-less image synthesis using cGANs and meta-learning},
journal = {Neural Networks},
volume = {131},
pages = {185-200},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302720},
author = {Tomaso Fontanini and Eleonora Iotti and Luca Donati and Andrea Prati},
keywords = {Generative adversarial networks, Meta-learning, Image-to-image translation, Few-shots, Multi-domain},
abstract = {Image synthesis is currently one of the most addressed image processing topic in computer vision and deep learning fields of study. Researchers have tackled this problem focusing their efforts on its several challenging problems, e.g. image quality and size, domain and pose changing, architecture of the networks, and so on. Above all, producing images belonging to different domains by using a single architecture is a very relevant goal for image generation. In fact, a single multi-domain network would allow greater flexibility and robustness in the image synthesis task than other approaches. This paper proposes a novel architecture and a training algorithm, which are able to produce multi-domain outputs using a single network. A small portion of a dataset is intentionally used, and there are no hard-coded labels (or classes). This is achieved by combining a conditional Generative Adversarial Network (cGAN) for image generation and a Meta-Learning algorithm for domain switch, and we called our approach MetalGAN. The approach has proved to be appropriate for solving the multi-domain label-less problem and it is validated on facial attribute transfer, using CelebA dataset.}
}
@article{DRIX202037,
title = {Sparse coding with a somato-dendritic rule},
journal = {Neural Networks},
volume = {131},
pages = {37-49},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302203},
author = {Damien Drix and Verena V. Hafner and Michael Schmuker},
keywords = {Sparse Coding, Neural Plasticity, Hebbian Learning, Dendrites, Inhibitory plasticity, Spiking Neurons},
abstract = {Cortical neurons are silent most of the time: sparse activity enables low-energy computation in the brain, and promises to do the same in neuromorphic hardware. Beyond power efficiency, sparse codes have favourable properties for associative learning, as they can store more information than local codes but are easier to read out than dense codes. Auto-encoders with a sparse constraint can learn sparse codes, and so can single-layer networks that combine recurrent inhibition with unsupervised Hebbian learning. But the latter usually require fast homeostatic plasticity, which could lead to catastrophic forgetting in embodied agents that learn continuously. Here we set out to explore whether plasticity at recurrent inhibitory synapses could take up that role instead, regulating both the population sparseness and the firing rates of individual neurons. We put the idea to the test in a network that employs compartmentalised inputs to solve the task: rate-based dendritic compartments integrate the feedforward input, while spiking integrate-and-fire somas compete through recurrent inhibition. A somato-dendritic learning rule allows somatic inhibition to modulate nonlinear Hebbian learning in the dendrites. Trained on MNIST digits and natural images, the network discovers independent components that form a sparse encoding of the input and support linear decoding. These findings confirm that intrinsic homeostatic plasticity is not strictly required for regulating sparseness: inhibitory synaptic plasticity can have the same effect. Our work illustrates the usefulness of compartmentalised inputs, and makes the case for moving beyond point neuron models in artificial spiking neural networks.}
}
@article{BING2020323,
title = {Energy-efficient and damage-recovery slithering gait design for a snake-like robot based on reinforcement learning and inverse reinforcement learning},
journal = {Neural Networks},
volume = {129},
pages = {323-333},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301994},
author = {Zhenshan Bing and Christian Lemke and Long Cheng and Kai Huang and Alois Knoll},
keywords = {, Reinforcement learning, Inverse reinforcement learning, Motion planning, Damage recovery},
abstract = {Similar to real snakes in nature, the flexible trunks of snake-like robots enhance their movement capabilities and adaptabilities in diverse environments. However, this flexibility corresponds to a complex control task involving highly redundant degrees of freedom, where traditional model-based methods usually fail to propel the robots energy-efficiently and adaptively to unforeseeable joint damage. In this work, we present an approach for designing an energy-efficient and damage-recovery slithering gait for a snake-like robot using the reinforcement learning (RL) algorithm and the inverse reinforcement learning (IRL) algorithm. Specifically, we first present an RL-based controller for generating locomotion gaits at a wide range of velocities, which is trained using the proximal policy optimization (PPO) algorithm. Then, by taking the RL-based controller as an expert and collecting trajectories from it, we train an IRL-based controller using the adversarial inverse reinforcement learning (AIRL) algorithm. For the purpose of comparison, a traditional parameterized gait controller is presented as the baseline and the parameter sets are optimized using the grid search and Bayesian optimization algorithm. Based on the analysis of the simulation results, we first demonstrate that this RL-based controller exhibits very natural and adaptive movements, which are also substantially more energy-efficient than the gaits generated by the parameterized controller. We then demonstrate that the IRL-based controller cannot only exhibit similar performances as the RL-based controller, but can also recover from the unpredictable damage body joints and still outperform the model-based controller, which has an undamaged body, in terms of energy efficiency. Videos can be viewed at https://videoviewsite.wixsite.com/rlsnake.}
}
@article{KOVALEV20201,
title = {A robust algorithm for explaining unreliable machine learning survival models using the Kolmogorov–Smirnov bounds},
journal = {Neural Networks},
volume = {132},
pages = {1-18},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302963},
author = {Maxim S. Kovalev and Lev V. Utkin},
keywords = {Interpretable model, Explainable AI, Survival analysis, Censored data, The Cox model, Kolmogorov–Smirnov bounds},
abstract = {A new robust algorithm based on the explanation method SurvLIME called SurvLIME-KS is proposed for explaining machine learning survival models. The algorithm is developed to ensure robustness to cases of a small amount of training data or outliers of survival data. The first idea behind SurvLIME-KS is to apply the Cox proportional hazards model to approximate the black-box survival model at the local area around a test example due to the linear relationship of covariates in the model. The second idea is to incorporate the well-known Kolmogorov–Smirnov bounds for constructing sets of predicted cumulative hazard functions. As a result, the robust maximin strategy is used, which aims to minimize the average distance between cumulative hazard functions of the explained black-box model and of the approximating Cox model, and to maximize the distance over all cumulative hazard functions in the interval produced by the Kolmogorov–Smirnov bounds. The maximin optimization problem is reduced to the quadratic program. Various numerical experiments with synthetic and real datasets demonstrate the SurvLIME-KS efficiency.}
}
@article{LI2020152,
title = {Quantum neural networks model based on swap test and phase estimation},
journal = {Neural Networks},
volume = {130},
pages = {152-164},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302446},
author = {Panchi Li and Bing Wang},
keywords = {Quantum computing, Swap test, Phase estimation, Quantum neuron, Quantum neural networks},
abstract = {In this paper, a neural networks model for quantum computer is proposed. The core of this model is quantum neuron. Firstly, the inner product of the input qubits and the weight qubits is mapped to the phase of the control qubits in the neuron by the swap test technology, and then these phases are obtained by the phase estimation method, which are further used as the phase of the output qubit in the neuron. In this way, the mapping of input qubits to output qubit in quantum neuron is completed. The quantum neurons mentioned above can be used to construct quantum neural networks. In this paper, the quantum circuit for each operation step are given. The simulation results on the classic computer verify the effectiveness of the proposed model.}
}
@article{HE2020312,
title = {Leveraging maximum entropy and correlation on latent factors for learning representations},
journal = {Neural Networks},
volume = {131},
pages = {312-323},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302689},
author = {Zhicheng He and Jie Liu and Kai Dang and Fuzhen Zhuang and Yalou Huang},
keywords = {Non-negative Matrix Factorization, Maximum entropy, Correlated latent factor learning},
abstract = {Many tasks involve learning representations from matrices, and Non-negative Matrix Factorization (NMF) has been widely used due to its excellent interpretability. Through factorization, sample vectors are reconstructed as additive combinations of latent factors, which are represented as non-negative distributions over the raw input features. NMF models are significantly affected by latent factors’ distribution characteristics and the correlations among them. And NMF models are faced with the challenge of learning robust latent factor. To this end, we propose to learn representations with an awareness of the semantic quality evaluated from the aspects of intra- and inter-factors. On the one hand, a Maximum Entropy-based function is devised for the intra-factor semantic quality. On the other hand, the semantic uniqueness is evaluated via inter-factor correlation, which reinforces the aim of semantic compactness. Moreover, we present a novel non-linear NMF framework. The learning algorithm is presented and the convergence is theoretically analyzed and proved. Extensive experimental results on multiple datasets demonstrate that our method can be successfully applied to representative NMF models and boost performances over state-of-the-art models.}
}
@article{LIU20201,
title = {Intermittent boundary stabilization of stochastic reaction–diffusion Cohen–Grossberg neural networks},
journal = {Neural Networks},
volume = {131},
pages = {1-13},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302604},
author = {Xiao-Zhen Liu and Kai-Ning Wu and Weihai Zhang},
keywords = {Aperiodically intermittent boundary control, Stochastic reaction–diffusion systems, Cohen–Grossberg neural networks, Time-delays, Exponential stability},
abstract = {Cohen–Grossberg neural networks (CGNNs) play an important role in many applications and the stabilization of this system has been well studied. This study considers the exponential stabilization for stochastic reaction–diffusion Cohen–Grossberg neural networks (SRDCGNNs) by means of an aperiodically intermittent boundary control. Both SRDCGNNs without and with time-delays are discussed. By employing the spatial integral functional method and Poincare’s inequality, criteria are derived to ensure the controlled systems achieve mean square exponential stabilization. Based on these criteria, the effects of diffusion item, control gains, the minimum control proportion and time-delays on exponential stability are analyzed. Examples are given to illustrate the effectiveness of the obtained theoretical results.}
}
@article{HAMMAM2020331,
title = {Real-time multiple spatiotemporal action localization and prediction approach using deep learning},
journal = {Neural Networks},
volume = {128},
pages = {331-344},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301878},
author = {Ahmed Ali Hammam and Mona M. Soliman and Aboul Ella Hassanien},
keywords = {Deep learning, Action localization, Action prediction, Spatiotemporal, YOLO network, Optical flow},
abstract = {Detecting the locations of multiple actions in videos and classifying them in real-time are challenging problems termed ”action localization and prediction” problem. Convolutional neural networks (ConvNets) have achieved great success for action localization and prediction in still images. A major advance occurred when the AlexNet architecture was introduced in the ImageNet competition. ConvNets have since achieved state-of-the-art performances across a wide variety of machine vision tasks, including object detection, image segmentation, image classification, facial recognition, human pose estimation, and tracking. However, few works exist that address action localization and prediction in videos. The current action localization research primarily focuses on the classification of temporally trimmed videos in which only one action occurs per frame. Moreover, nearly all the current approaches work only offline and are too slow to be useful in real-world environments. In this work, we propose a fast and accurate deep-learning approach to perform real-time action localization and prediction. The proposed approach uses convolutional neural networks to localize multiple actions and predict their classes in real time. This approach starts by using appearance and motion detection networks (known as ”you only look once” (YOLO) networks) to localize and classify actions from RGB frames and optical flow frames using a two-stream model. We then propose a fusion step that increases the localization accuracy of the proposed approach. Moreover, we generate an action tube based on frame level detection. The frame by frame processing introduces an early action detection and prediction with top performance in terms of detection speed and precision. The experimental results demonstrate this superiority of our proposed approach in terms of both processing time and accuracy compared to recent offline and online action localization and prediction approaches on the challenging UCF-101-24 and J-HMDB-21 benchmarks.}
}
@article{ZONG202019,
title = {Multi-view clustering on data with partial instances and clusters},
journal = {Neural Networks},
volume = {129},
pages = {19-30},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030191X},
author = {Linlin Zong and Xianchao Zhang and Xinyue Liu and Hong Yu},
keywords = {Multi-view, Non-negative matrix factorization, Partial data},
abstract = {Most multi-view clustering algorithms apply to data with complete instances and clusters in the views. Recently, multi-view clustering on data with partial instances has been studied. In this paper, we study the more general version of the problem, i.e., multi-view clustering on data with partial instances and clusters in the views. We propose a non-negative matrix factorization (NMF) based algorithm. For the special case with partial instances, it introduces an instance-view-indicator matrix to indicate whether an instance exists in a view. Then, it maps the instances representing the same object to the same vector, and maps the instances representing different objects to different vectors. For the general case with partial instances and clusters, it further introduces a cluster-view-indicator matrix to indicate whether a cluster exists in a view. In each view, it also maps the instances representing the same object to the same vector, but it further makes the elements of the vector 0 if the elements correspond to missing clusters. Then it minimizes the disagreements between the approximated indicator vectors of instances representing the same object. Experimental results show that the proposed algorithm performs well on data with partial instances and clusters, and outperforms existing algorithms on data with partial instances.}
}
@article{SPINELLI2020249,
title = {Missing data imputation with adversarially-trained graph convolutional networks},
journal = {Neural Networks},
volume = {129},
pages = {249-260},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302185},
author = {Indro Spinelli and Simone Scardapane and Aurelio Uncini},
keywords = {Imputation, Graph neural network, Graph data, Convolutional network},
abstract = {Missing data imputation (MDI) is the task of replacing missing values in a dataset with alternative, predicted ones. Because of the widespread presence of missing data, it is a fundamental problem in many scientific disciplines. Popular methods for MDI use global statistics computed from the entire dataset (e.g., the feature-wise medians), or build predictive models operating independently on every instance. In this paper we propose a more general framework for MDI, leveraging recent work in the field of graph neural networks (GNNs). We formulate the MDI task in terms of a graph denoising autoencoder, where each edge of the graph encodes the similarity between two patterns. A GNN encoder learns to build intermediate representations for each example by interleaving classical projection layers and locally combining information between neighbors, while another decoding GNN learns to reconstruct the full imputed dataset from this intermediate embedding. In order to speed-up training and improve the performance, we use a combination of multiple losses, including an adversarial loss implemented with the Wasserstein metric and a gradient penalty. We also explore a few extensions to the basic architecture involving the use of residual connections between layers, and of global statistics computed from the dataset to improve the accuracy. On a large experimental evaluation with varying levels of artificial noise, we show that our method is on par or better than several alternative imputation methods. On three datasets with pre-existing missing values, we show that our method is robust to the choice of a downstream classifier, obtaining similar or slightly higher results compared to other choices.}
}
@article{SHAH202075,
title = {Dynamical system based compact deep hybrid network for classification of Parkinson disease related EEG signals},
journal = {Neural Networks},
volume = {130},
pages = {75-84},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302331},
author = {Syed Aamir Ali Shah and Lei Zhang and Abdul Bais},
keywords = {Convolutional neural network, Long short-term memory, Chaotic systems, Parkinson disease, Embedding reconstruction, Electroencephalogram},
abstract = {Electroencephalogram (EEG) signals accumulate the brain’s spiking activities using standardized electrodes placed at the scalp. These cumulative brain signals are chaotic in nature and vary depending upon current physical and/or mental activities. The anatomy of the brain is altered when dopamine releasing neurons die because of Parkinson Disease (PD), a neurodegenerative disorder. The resulting alterations force synchronized neuronal activity in β frequency components deep within motor region of the brain. This synchronization in the motor region affects the dynamical behavior of the brain activities, which induce motor related impairments in patient’s limbs. Identification of reliable bio-markers for PD is active research area since there are no tests or scans to diagnose PD. We use embedding reconstruction, a tool from chaos theory, to highlight PD-related alterations in dynamical properties of EEG and present it as a potentially reliable bio-marker for PD related classification. We use Individual Component Analysis (ICA) to demonstrate that the strengthened synchronizations can be cumulatively collected from EEG channels over the motor region of the brain. We use this information to select the 12 EEG channels for classification of On and Off medication PD patients. Additionally, there is the strong synchronization between amplitude of higher frequency components and phase of β components for PD patients. This information is used to improve the performance of this classification. We apply embedding reconstruction to design a new architecture of a deep neural network called Dynamical system Generated Hybrid Network. We report that this network outperforms the state of the art in terms of classification accuracy of 99.2%(+0.52%) with approximately 24% of the computational resources. Apart from classification accuracy, we use well known statistical measures like specificity, sensitivity, Matthews Correlation Coefficient (MCC), F1 score, and Cohen Kappa score for the analysis and comparison of classification performances.}
}
@article{XUE2020144,
title = {Integral reinforcement learning based event-triggered control with input saturation},
journal = {Neural Networks},
volume = {131},
pages = {144-153},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302574},
author = {Shan Xue and Biao Luo and Derong Liu},
keywords = {Adaptive dynamic programming, Integral reinforcement learning, Neural networks, Event-triggered control, Input saturation},
abstract = {In this paper, a novel integral reinforcement learning (IRL)-based event-triggered adaptive dynamic programming scheme is developed for input-saturated continuous-time nonlinear systems. By using the IRL technique, the learning system does not require the knowledge of the drift dynamics. Then, a single critic neural network is designed to approximate the unknown value function and its learning is not subjected to the requirement of an initial admissible control. In order to reduce computational and communication costs, the event-triggered control law is designed. The triggering threshold is given to guarantee the asymptotic stability of the control system. Two examples are employed in the simulation studies, and the results verify the effectiveness of the developed IRL-based event-triggered control method.}
}
@article{BERTINI2020174,
title = {Graph embedded rules for explainable predictions in data streams},
journal = {Neural Networks},
volume = {129},
pages = {174-192},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302057},
author = {João Roberto Bertini},
keywords = {Rule-based classifiers, Data stream, Interpretable machine learning, Attribute-based Decision Graphs},
abstract = {Understanding the reason why a prediction has been made by a machine is crucial to grant trust to a human decision-maker. However, data mining based decision support systems are, in general, not designed to promote interpretability; instead, they are developed to improve accuracy. Interpretability becomes a more challenging issue in the context of data stream mining. Where the prediction model has to deal with enormous volumes of data gathered continuously at a fast rate and whose underlying distribution may change over time. On the one hand, the majority of the methods that address classification in a data stream are black-box models or white-box models into ensembles. Either do not provide a clear view of why a particular decision has been made. On the other hand, white-box models, such as rule-based models, do not provide acceptable accuracy to be considered in many applications. This paper proposes modeling the data as a special graph, which is built over the attribute space, and from which interpretable rules can be extracted. To overcome concept drift and enhance model accuracy, different variants of such graphs are considered within an ensemble that is updated over time. The proposed approach has shown the best overall classification results when compared to six rule-based algorithms in twelve streaming domains.}
}
@article{CHEN2020163,
title = {Finite-time stabilization and energy consumption estimation for delayed neural networks with bounded activation function},
journal = {Neural Networks},
volume = {131},
pages = {163-171},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302732},
author = {Chongyang Chen and Song Zhu and Min Wang and Chunyu Yang and Zhigang Zeng},
keywords = {Nonlinear neural networks, Time delay, Finite-time stability, Energy consumption},
abstract = {This paper concentrates on finite-time stabilization and energy consumption estimation for one type of delayed neural networks (DNNs) with bounded activation function. Under the bounded activation function condition and using the comparison theorem, a new switch controller is proposed to ensure the finite-time stability of the considered DNNs. Furthermore, the energy consumption produced in system controlling is estimated by inequality techniques. We generalize the previous results about the problem of finite-time stabilization and energy consumption estimation for neural networks. Ultimately, two numerical simulations are carried out to verify the validity of our results.}
}
@article{MARIC2020222,
title = {A neurodynamic model of the interaction between color perception and color memory},
journal = {Neural Networks},
volume = {129},
pages = {222-248},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302215},
author = {Mateja Marić and Dražen Domijan},
keywords = {Adaptive resonance theory, Cognitive impenetrability of vision, Color vision, Memory color effect, Predictive coding},
abstract = {The memory color effect and Spanish castle illusion have been taken as evidence of the cognitive penetrability of vision. In the same manner, the successful decoding of color-related brain signals in functional neuroimaging studies suggests the retrieval of memory colors associated with a perceived gray object. Here, we offer an alternative account of these findings based on the design principles of adaptive resonance theory (ART). In ART, conscious perception is a consequence of a resonant state. Resonance emerges in a recurrent cortical circuit when a bottom-up spatial pattern agrees with the top-down expectation. When they do not agree, a special control mechanism is activated that resets the network and clears off erroneous expectation, thus allowing the bottom-up activity to always dominate in perception. We developed a color ART circuit and evaluated its behavior in computer simulations. The model helps to explain how traces of erroneous expectations about incoming color are eventually removed from the color perception, although their transient effect may be visible in behavioral responses or in brain imaging. Our results suggest that the color ART circuit, as a predictive computational system, is almost never penetrable, because it is equipped with computational mechanisms designed to constrain the impact of the top-down predictions on ongoing perceptual processing.}
}
@article{LI202078,
title = {Global μ-synchronization of impulsive pantograph neural networks},
journal = {Neural Networks},
volume = {131},
pages = {78-92},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302458},
author = {Xuechen Li and Nan Wang and Jungang Lou and Jianquan Lu},
keywords = {Impulsive pantograph neural networks, -synchronization criterion, -asymptotic periodic impulsive interval},
abstract = {This paper investigates the problem of global μ-synchronization of impulsive pantograph neural networks. In this paper, new concept of ν-asymptotic periodic impulsive interval Tasyν is proposed for pantograph networks. By employing the Lyapunov method combined with the mathematical analysis approach for impulsive systems, some useful criteria are derived to guarantee the global μ-synchronization of coupled pantograph neural networks when the asymptotic logarithmic periodic impulsive interval Tasyln<∞ and Tasyln=∞, respectively. Especially when Tasyln=∞, as long as the networks are unstable, impulsive control cannot achieve synchronization regardless of the size of the impulse gain. Numerical simulations are exploited to illustrate our theoretical results.}
}
@article{CHEN2020392,
title = {Pinning bipartite synchronization for inertial coupled delayed neural networks with signed digraph via non-reduced order method},
journal = {Neural Networks},
volume = {129},
pages = {392-402},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.017},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030232X},
author = {Shanshan Chen and Haijun Jiang and Binglong Lu and Zhiyong Yu and Liang Li},
keywords = {Bipartite synchronization, Inertial coupled delayed neural network, Strongly connected network, Directed spanning tree, Pinning control},
abstract = {The study investigates bipartite synchronization of inertial coupled delayed neural networks (ICDNNs) with signed digraph by non-reduced order method and pinning control. The second-order CDNNs will not be converted into a first-order differential system by introducing variable substitution. Instead, a novel Lyapunov–Krasovskii functional is proposed which depends on the topology of the ICDNNs. Some sufficient conditions for linear matrix inequalities (LMI) are derived to realize bipartite synchronization, which is based on matrix decomposition theory and Barbalat Lemma in strongly connected signed networks. And then, M-matrix theory is utilized to generalize the results to networks containing directed spanning trees. Finally, two examples are used to verify the validity of the derived theoretical results.}
}
@article{LI20207,
title = {DLPNet: A deep manifold network for feature extraction of hyperspectral imagery},
journal = {Neural Networks},
volume = {129},
pages = {7-18},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301921},
author = {Zhengying Li and Hong Huang and Yule Duan and Guangyao Shi},
keywords = {Hyperspectral imagery, Deep learning, Feature extraction, Deep manifold network, Graph embedding},
abstract = {Deep learning has received increasing attention in recent years and it has been successfully applied for feature extraction (FE) of hyperspectral images. However, most deep learning methods fail to explore the manifold structure in hyperspectral image (HSI). To tackle this issue, a novel graph-based deep learning model, termed deep locality preserving neural network (DLPNet), was proposed in this paper. Traditional deep learning methods use random initialization to initialize network parameters. Different from that, DLPNet initializes each layer of the network by exploring the manifold structure in hyperspectral data. In the stage of network optimization, it designed a deep-manifold learning joint loss function to exploit graph embedding process while measuring the difference between the predictive value and the actual value, then the proposed model can take into account the extraction of deep features and explore the manifold structure of data simultaneously. Experimental results on real-world HSI datasets indicate that the proposed DLPNet performs significantly better than some state-of-the-art methods.}
}
@article{JUN2020216,
title = {T-Net: Nested encoder–decoder architecture for the main vessel segmentation in coronary angiography},
journal = {Neural Networks},
volume = {128},
pages = {216-233},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301647},
author = {Tae Joon Jun and Jihoon Kweon and Young-Hak Kim and Daeyoung Kim},
keywords = {Convolutional neural network, Main vessel segmentation, Coronary angiography, Encoder and decoder},
abstract = {In this paper, we proposed nested encoder–decoder architecture named T-Net. T-Net consists of several small encoder–decoders for each block constituting convolutional network. T-Net overcomes the limitation that U-Net can only have a single set of the concatenate layer between encoder and decoder block. To be more precise, the U-Net symmetrically forms the concatenate layers, so the low-level feature of the encoder is connected to the latter part of the decoder, and the high-level feature is connected to the beginning of the decoder. T-Net arranges the pooling and up-sampling appropriately during the encoding process, and likewise during the decoding process so that feature-maps of various sizes are obtained in a single block. As a result, all features from the low-level to the high-level extracted from the encoder are delivered from the beginning of the decoder to predict a more accurate mask. We evaluated T-Net for the problem of segmenting three main vessels in coronary angiography images. The experiment consisted of a comparison of U-Net and T-Nets under the same conditions, and an optimized T-Net for the main vessel segmentation. As a result, T-Net recorded a Dice Similarity Coefficient score (DSC) of 83.77%, 10.69% higher than that of U-Net, and the optimized T-Net recorded a DSC of 88.97% which was 15.89% higher than that of U-Net. In addition, we visualized the weight activation of the convolutional layer of T-Net and U-Net to show that T-Net actually predicts the mask from earlier decoders. Therefore, we expect that T-Net can be effectively applied to other similar medical image segmentation problems.}
}
@article{LIAN2020286,
title = {Landslide displacement interval prediction using lower upper bound estimation method with pre-trained random vector functional link network initialization},
journal = {Neural Networks},
volume = {130},
pages = {286-296},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302616},
author = {Cheng Lian and Zhigang Zeng and Xiaoping Wang and Wei Yao and Yixin Su and Huiming Tang},
keywords = {Prediction interval, Lower upper bound estimation, Random vector functional link network, Population initialization, Landslide displacement prediction},
abstract = {Interval prediction is an efficient approach to quantifying the uncertainties associated with landslide evolution. In this paper, a novel method, termed lower upper bound estimation (LUBE), of constructing prediction intervals (PIs) based on neural networks (NNs) is applied and extended to landslide displacement prediction. A random vector functional link network (RVFLN) is adopted as the NN used in the improved LUBE. A hybrid evolutionary algorithm, termed PSOGSA, that combines particle swarm optimization (PSO) and gravitational search algorithm (GSA) is utilized to train LUBE. The loss function of LUBE is redesigned by considering the quality of PI centre, which allows for a more comprehensive evaluation of PIs. The population initialization in the training process of LUBE is implemented by transferring the weights of a series of pre-trained RVFLNs. The performance of the improved LUBE method is validated by considering a comprehensive set of cases using seven benchmark datasets. In addition, a hybrid method that integrates ensemble empirical mode decomposition (EEMD) with the improved LUBE is proposed for the special case of landslide displacement prediction. Six real-world reservoir-induced landslides are considered to validate the capability and merit of the proposed hybrid method.}
}
@article{VONG2020268,
title = {Accurate and efficient sequential ensemble learning for highly imbalanced multi-class data},
journal = {Neural Networks},
volume = {128},
pages = {268-278},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301805},
author = {Chi-Man Vong and Jie Du},
keywords = {Sequential ensemble learning, Multi-class classification, Highly imbalanced data},
abstract = {Multi-class classification for highly imbalanced data is a challenging task in which multiple issues must be resolved simultaneously, including (i) accuracy on classifying highly imbalanced multi-class data; (ii) training efficiency for large data; and (iii) sensitivity to high imbalance ratio (IR). In this paper, a novel sequential ensemble learning (SEL) framework is designed to simultaneously resolve these issues. SEL framework provides a significant property over traditional AdaBoost, in which the majority samples can be divided into multiple small and disjoint subsets for training multiple weak learners without compromising accuracy (while AdaBoost cannot). To ensure the class balance and majority-disjoint property of subsets, a learning strategy called balanced and majority-disjoint subsets division (BMSD) is developed. Unfortunately it is difficult to derive a general learner combination method (LCM) for any kind of weak learner. In this work, LCM is specifically designed for extreme learning machine, called LCM-ELM. The proposed SEL framework with BMSD and LCM-ELM has been compared with state-of-the-art methods over 16 benchmark datasets. In the experiments, under highly imbalanced multi-class data (IR up to 14K; data size up to 493K), (i) the proposed works improve the performance in different measures including G-mean, macro-F, micro-F, MAUC; (ii) training time is significantly reduced.}
}
@article{HAN2020149,
title = {Self-organization of action hierarchy and compositionality by reinforcement learning with recurrent neural networks},
journal = {Neural Networks},
volume = {129},
pages = {149-162},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302070},
author = {Dongqi Han and Kenji Doya and Jun Tani},
keywords = {Recurrent neural network, Reinforcement learning, Partially observable Markov decision process, Multiple timescale, Compositionality},
abstract = {Recurrent neural networks (RNNs) for reinforcement learning (RL) have shown distinct advantages, e.g., solving memory-dependent tasks and meta-learning. However, little effort has been spent on improving RNN architectures and on understanding the underlying neural mechanisms for performance gain. In this paper, we propose a novel, multiple-timescale, stochastic RNN for RL. Empirical results show that the network can autonomously learn to abstract sub-goals and can self-develop an action hierarchy using internal dynamics in a challenging continuous control task. Furthermore, we show that the self-developed compositionality of the network enhances faster re-learning when adapting to a new task that is a re-composition of previously learned sub-goals, than when starting from scratch. We also found that improved performance can be achieved when neural activities are subject to stochastic rather than deterministic dynamics.}
}
@article{GUEHAIRIA2020238,
title = {Feature fusion via Deep Random Forest for facial age estimation},
journal = {Neural Networks},
volume = {130},
pages = {238-252},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302471},
author = {O. Guehairia and A. Ouamane and F. Dornaika and A. Taleb-Ahmed},
keywords = {Age estimation, Cascade of classification trees ensembles, Deep Random Forest, Face descriptors, Deep features},
abstract = {In the last few years, human age estimation from face images attracted the attention of many researchers in computer vision and machine learning fields. This is due to its numerous applications. In this paper, we propose a new architecture for age estimation based on facial images. It is mainly based on a cascade of classification trees ensembles, which are known recently as a Deep Random Forest. Our architecture is composed of two types of DRF. The first type extends and enhances the feature representation of a given facial descriptor. The second type operates on the fused form of all enhanced representations in order to provide a prediction for the age while taking into account the fuzziness property of the human age. While the proposed methodology is able to work with all kinds of image features, the face descriptors adopted in this work used off-the-shelf deep features allowing to retain both the rich deep features and the powerful enhancement and decision provided by the proposed architecture. Experiments conducted on six public databases prove the superiority of the proposed architecture over other state-of-the-art methods.}
}
@article{BACCIU2020203,
title = {A gentle introduction to deep learning for graphs},
journal = {Neural Networks},
volume = {129},
pages = {203-221},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302197},
author = {Davide Bacciu and Federico Errica and Alessio Micheli and Marco Podda},
keywords = {Deep learning for graphs, Graph neural networks, Learning for structured data},
abstract = {The adaptive processing of graph data is a long-standing research topic that has been lately consolidated as a theme of major interest in the deep learning community. The snap increase in the amount and breadth of related research has come at the price of little systematization of knowledge and attention to earlier literature. This work is a tutorial introduction to the field of deep learning for graphs. It favors a consistent and progressive presentation of the main concepts and architectural aspects over an exposition of the most recent literature, for which the reader is referred to available surveys. The paper takes a top-down view of the problem, introducing a generalized formulation of graph representation learning based on a local and iterative approach to structured information processing. Moreover, it introduces the basic building blocks that can be combined to design novel and effective neural models for graphs. We complement the methodological exposition with a discussion of interesting research challenges and applications in the field.}
}
@article{LI2020313,
title = {Partial transfer learning in machinery cross-domain fault diagnostics using class-weighted adversarial networks},
journal = {Neural Networks},
volume = {129},
pages = {313-322},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030229X},
author = {Xiang Li and Wei Zhang and Hui Ma and Zhong Luo and Xu Li},
keywords = {Fault diagnosis, Partial transfer learning, Deep learning, Rotating machinery, Domain adversarial network},
abstract = {Recently, transfer learning has been receiving growing interests in machinery fault diagnosis due to its strong generalization across different industrial scenarios. The existing methods generally assume identical label spaces, and propose minimizing marginal distribution discrepancy between source and target domains. However, this assumption usually does not hold in real industries, where testing data mostly contain a subspace of the source label space. Therefore, transferring diagnosis knowledge from a comprehensive source domain to a target domain with limited machine conditions is motivated. This challenging partial transfer learning problem is addressed in this study using deep learning-based domain adaptation method. A class weighted adversarial neural network is proposed to encourage positive transfer of the shared classes and ignore the source outliers. Experimental results on two rotating machinery datasets suggest the proposed method is promising for partial transfer learning.}
}
@article{SIEGEL2020313,
title = {Approximation rates for neural networks with general activation functions},
journal = {Neural Networks},
volume = {128},
pages = {313-321},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301891},
author = {Jonathan W. Siegel and Jinchao Xu},
keywords = {Approximation theory, Stratified sampling, Neural networks},
abstract = {We prove some new results concerning the approximation rate of neural networks with general activation functions. Our first result concerns the rate of approximation of a two layer neural network with a polynomially-decaying non-sigmoidal activation function. We extend the dimension independent approximation rates previously obtained to this new class of activation functions. Our second result gives a weaker, but still dimension independent, approximation rate for a larger class of activation functions, removing the polynomial decay assumption. This result applies to any bounded, integrable activation function. Finally, we show that a stratified sampling approach can be used to improve the approximation rate for polynomially decaying activation functions under mild additional assumptions.}
}
@article{WEI2020100,
title = {Visual interaction networks: A novel bio-inspired computational model for image classification},
journal = {Neural Networks},
volume = {130},
pages = {100-110},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302343},
author = {Bing Wei and Haibo He and Kuangrong Hao and Lei Gao and Xue-song Tang},
keywords = {Biologically inspired computing, Convolutional neural network (CNN), Visual interaction mechanism, Textile defect, Image classification},
abstract = {Inspired by biological mechanisms and structures in neuroscience, many biologically inspired visual computational models have been presented to provide new solutions for visual recognition task. For example, convolutional neural network (CNN) was proposed according to the hierarchical structure of biological vision, which could achieve superior performance in large-scale image classification. In this paper, we propose a new framework called visual interaction networks (VIN-Net), which is inspired by visual interaction mechanisms. More specifically, self-interaction, mutual-interaction, multi-interaction, and adaptive interaction are proposed in VIN-Net, forming the first interactive completeness of the visual interaction model. To further enhance the representation ability of visual features, the adaptive adjustment mechanism is integrated into the VIN-Net model. Finally, our model is evaluated on three benchmark datasets and two self-built textile defect datasets. The experimental results demonstrate that the proposed model exhibits its efficiency on visual classification tasks. Furthermore, a textile industrial application shows that the proposed architecture outperforms the state-of-the-art approaches in classification performance.}
}
@article{2022II,
title = {NN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {148},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00056-9},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000569}
}
@article{LI2020269,
title = {A pruning feedforward small-world neural network based on Katz centrality for nonlinear system modeling},
journal = {Neural Networks},
volume = {130},
pages = {269-285},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302586},
author = {Wenjing Li and Minghui Chu and Junfei Qiao},
keywords = {Small-world neural network, Pruning algorithm, Katz centrality, Nonlinear system modeling},
abstract = {Approaching to the biological neural network, small-world neural networks have been demonstrated to improve the generalization performance of artificial neural networks. However, the architecture of small-world neural networks is typically large and predefined. This may cause the problems of overfitting and time consuming, and cannot obtain an optimal network structure automatically for a given problem. To solve the above problems, this paper proposes a pruning feedforward small-world neural network (PFSWNN), and applies it to nonlinear system modeling. Firstly, a feedforward small-world neural network (FSWNN) is constructed according to the rewiring rule of Watts–Strogatz. Secondly, the importance of each hidden neuron is evaluated based on its Katz centrality. If the Katz centrality of a hidden neuron is below the predefined threshold, this neuron is considered to be an unimportant node and then merged with its most correlated neuron in the same hidden layer. The connection weights are trained using the gradient-based algorithm, and the convergence of the proposed PFSWNN is theoretically analyzed in this paper. Finally, the PFSWNN model is tested on some problems for nonlinear system modeling, including the approximation for a rapidly changing function, CATS missing time-series prediction, four benchmark problems of UCI public datasets and a practical problem for wastewater treatment process. Experimental results demonstrate that PFSWNN exhibits superior generalization performance by small-world property as well as the pruning algorithm, and the training time of PFSWNN is shortened owning to a compact structure.}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {149},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00084-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000843}
}
@article{CAPIZZI2020271,
title = {A spiking neural network-based long-term prediction system for biogas production},
journal = {Neural Networks},
volume = {129},
pages = {271-279},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302069},
author = {Giacomo Capizzi and Grazia {Lo Sciuto} and Christian Napoli and Marcin Woźniak and Gianluca Susi},
keywords = {Spiking neural networks, Training algorithms, Neural models, NeuCube, Biogas, Anaerobic process models},
abstract = {Efficient energy production from biomass is a central issue in the context of clean alternative energy resource. In this work we propose a novel model based on spiking neural networks cubes in order to model the chemical processes that goes on in a digestor for the production of usable biogas. For the implementation of the predictive structure, we have used the NeuCube computational framework. The goals of the proposed model were: develop a tool for real applications (low-cost and efficient), generalize the data when the system presents high sensitivity to small differences on the initial conditions, take in account the “multi-scale” temporal dynamics of the chemical processes occurring in the digestor, since the variations present in the early stages of the processes are very quick, whereas in the later stages are slower. By using the first ten days of observation the implemented system has been proven able to predict the evolution of the chemical process up to the 100th day obtaining a high degree of accuracy with respect to the experimental data measured in laboratory. This is due to the fact that the spiking neural networks have shown to be able to modeling complex information processes and then it has been shown that spiking neurons are able to handle patterns of activity that spans different time scales. Thanks to such properties, our system is able to capture the multi-scale trend of the time series associated to the early-stage evolutions, as well as their interaction, which are crucial in the point of view of the information content to obtain a good long-term prediction.}
}
@article{MOREIRA2020190,
title = {Quantum-like influence diagrams for decision-making},
journal = {Neural Networks},
volume = {132},
pages = {190-210},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302501},
author = {Catarina Moreira and Prayag Tiwari and Hari Mohan Pandey and Peter Bruza and Andreas Wichert},
keywords = {Quantum-like Bayesian networks, Quantum-like influence diagrams, Decision-making, Cognition, Assembly theory},
abstract = {This article proposes a novel and comprehensive framework on how to describe the probabilistic nature of decision-making process. We suggest extending the quantum-like Bayesian network formalism to incorporate the notion of maximum expected utility to model human paradoxical, sub-optimal and irrational decisions. What distinguishes this work is that we take advantage of the quantum interference effects produced in quantum-like Bayesian Networks during the inference process to influence the probabilities used to compute the maximum expected utility of some decision. The proposed quantum-like decision model is able to (1) predict the probability distributions found in different experiments reported in the literature by modelling uncertainty through quantum interference, (2) to identify decisions that the decision-makers perceive to be optimal within their belief space, but that are actually irrational with respect to expected utility theory, (3) gain an understanding of how the decision-maker’s beliefs evolve within a decision-making scenario. The proposed model has the potential to provide new insights in decision science, as well as having direct implications for decision support systems that deal with human data, such as in the fields of economics, finance, psychology, etc.}
}
@article{SU2020291,
title = {Improved recurrent neural network-based manipulator control with remote center of motion constraints: Experimental results},
journal = {Neural Networks},
volume = {131},
pages = {291-299},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302744},
author = {Hang Su and Yingbai Hu and Hamid Reza Karimi and Alois Knoll and Giancarlo Ferrigno and Elena {De Momi}},
keywords = {Recurrent neural network, Remote center of motion, Redundant manipulator, Robot-assisted minimally invasive surgery},
abstract = {In this paper, an improved recurrent neural network (RNN) scheme is proposed to perform the trajectory control of redundant robot manipulators using remote center of motion (RCM) constraints. Firstly, learning by demonstration is implemented to model the surgical operation skills in the Cartesian space. After that, considering the kinematic constraints associated with the optimization control of redundant manipulators, we propose a novel RNN-based approach to facilitate accurate task tracking based on the general quadratic performance index, which includes managing the constraints on RCM joint angle, and joint velocity, simultaneously. The results of the conducted theoretical analysis confirm that the RCM constraint has been established successfully, and accordingly. The corresponding end-effector tracking errors asymptotically converge to zero. Finally, demonstration experiments are conducted in a laboratory setup environment using KUKA LWR4+ to validate the effectiveness of the proposed control strategy.}
}
@article{HO2020279,
title = {Uni-image: Universal image construction for robust neural model},
journal = {Neural Networks},
volume = {128},
pages = {279-287},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030188X},
author = {Jiacang Ho and Byung-Gook Lee and Dae-Ki Kang},
keywords = {Adversarial machine learning, Uni-Image Procedure, Defense technique, Semantic adversarial example, Image classification},
abstract = {Deep neural networks have shown high performance in prediction, but they are defenseless when they predict on adversarial examples which are generated by adversarial attack techniques. In image classification, those attack techniques usually perturb the pixel of an image to fool the deep neural networks. To improve the robustness of the neural networks, many researchers have introduced several defense techniques against those attack techniques. To the best of our knowledge, adversarial training is one of the most effective defense techniques against the adversarial examples. However, the defense technique could fail against a semantic adversarial image that performs arbitrary perturbation to fool the neural networks, where the modified image semantically represents the same object as the original image. Against this background, we propose a novel defense technique, Uni-Image Procedure (UIP) method. UIP generates a universal-image (uni-image) from a given image, which can be a clean image or a perturbed image by some attacks. The generated uni-image preserves its own characteristics (i.e. color) regardless of the transformations of the original image. Note that those transformations include inverting the pixel value of an image, modifying the saturation, hue, and value of an image, etc. Our experimental results using several benchmark datasets show that our method not only defends well known adversarial attacks and semantic adversarial attack but also boosts the robustness of the neural network.}
}
@article{WEI2020322,
title = {Regularized least squares locality preserving projections with applications to image recognition},
journal = {Neural Networks},
volume = {128},
pages = {322-330},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301933},
author = {Wei Wei and Hua Dai and Weitai Liang},
keywords = {Locality preserving projection, Dimensionality reduction, Small-sample-size problem, Regularized least squares},
abstract = {Locality preserving projection (LPP), as a well-known technique for dimensionality reduction, is designed to preserve the local structure of the original samples which usually lie on a low-dimensional manifold in the real world. However, it suffers from the undersampled or small-sample-size problem, when the dimension of the features is larger than the number of samples which causes the corresponding generalized eigenvalue problem to be ill-posed. To address this problem, we show that LPP is equivalent to a multivariate linear regression under a mild condition, and establish the connection between LPP and a least squares problem with multiple columns on the right-hand side. Based on the developed connection, we propose two regularized least squares methods for solving LPP. Experimental results on real-world databases illustrate the performance of our methods.}
}
@article{HE2020108,
title = {Comparing SNNs and RNNs on neuromorphic vision datasets: Similarities and differences},
journal = {Neural Networks},
volume = {132},
pages = {108-120},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302902},
author = {Weihua He and YuJie Wu and Lei Deng and Guoqi Li and Haoyu Wang and Yang Tian and Wei Ding and Wenhui Wang and Yuan Xie},
keywords = {Spiking neural networks, Recurrent neural networks, Long short-term memory, Neuromorphic dataset, Spatiotemporal dynamics},
abstract = {Neuromorphic data, recording frameless spike events, have attracted considerable attention for the spatiotemporal information components and the event-driven processing fashion. Spiking neural networks (SNNs) represent a family of event-driven models with spatiotemporal dynamics for neuromorphic computing, which are widely benchmarked on neuromorphic data. Interestingly, researchers in the machine learning community can argue that recurrent (artificial) neural networks (RNNs) also have the capability to extract spatiotemporal features although they are not event-driven. Thus, the question of “what will happen if we benchmark these two kinds of models together on neuromorphic data” comes out but remains unclear. In this work, we make a systematic study to compare SNNs and RNNs on neuromorphic data, taking the vision datasets as a case study. First, we identify the similarities and differences between SNNs and RNNs (including the vanilla RNNs and LSTM) from the modeling and learning perspectives. To improve comparability and fairness, we unify the supervised learning algorithm based on backpropagation through time (BPTT), the loss function exploiting the outputs at all timesteps, the network structure with stacked fully-connected or convolutional layers, and the hyper-parameters during training. Especially, given the mainstream loss function used in RNNs, we modify it inspired by the rate coding scheme to approach that of SNNs. Furthermore, we tune the temporal resolution of datasets to test model robustness and generalization. At last, a series of contrast experiments are conducted on two types of neuromorphic datasets: DVS-converted (N-MNIST) and DVS-captured (DVS Gesture). Extensive insights regarding recognition accuracy, feature extraction, temporal resolution and contrast, learning generalization, computational complexity and parameter volume are provided, which are beneficial for the model selection on different workloads and even for the invention of novel neural models in the future.}
}
@article{PALUZOHIDALGO202029,
title = {Two-hidden-layer feed-forward networks are universal approximators: A constructive approach},
journal = {Neural Networks},
volume = {131},
pages = {29-36},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302628},
author = {Eduardo Paluzo-Hidalgo and Rocio Gonzalez-Diaz and Miguel A. Gutiérrez-Naranjo},
keywords = {Universal Approximation Theorem, Simplicial Approximation Theorem, Multi-layer feed-forward network, Triangulations},
abstract = {It is well-known that artificial neural networks are universal approximators. The classical existence result proves that, given a continuous function on a compact set embedded in an n-dimensional space, there exists a one-hidden-layer feed-forward network that approximates the function. In this paper, a constructive approach to this problem is given for the case of a continuous function on triangulated spaces. Once a triangulation of the space is given, a two-hidden-layer feed-forward network with a concrete set of weights is computed. The level of the approximation depends on the refinement of the triangulation.}
}
@article{FAYEK2020345,
title = {Progressive learning: A deep learning framework for continual learning},
journal = {Neural Networks},
volume = {128},
pages = {345-357},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301817},
author = {Haytham M. Fayek and Lawrence Cavedon and Hong Ren Wu},
keywords = {Continual learning, Computer vision, Deep learning, Machine learning, Neural networks, Speech recognition},
abstract = {Continual learning is the ability of a learning system to solve new tasks by utilizing previously acquired knowledge from learning and performing prior tasks without having significant adverse effects on the acquired prior knowledge. Continual learning is key to advancing machine learning and artificial intelligence. Progressive learning is a deep learning framework for continual learning that comprises three procedures: curriculum, progression, and pruning. The curriculum procedure is used to actively select a task to learn from a set of candidate tasks. The progression procedure is used to grow the capacity of the model by adding new parameters that leverage parameters learned in prior tasks, while learning from data available for the new task at hand, without being susceptible to catastrophic forgetting. The pruning procedure is used to counteract the growth in the number of parameters as further tasks are learned, as well as to mitigate negative forward transfer, in which prior knowledge unrelated to the task at hand may interfere and worsen performance. Progressive learning is evaluated on a number of supervised classification tasks in the image recognition and speech recognition domains to demonstrate its advantages compared with baseline methods. It is shown that, when tasks are related, progressive learning leads to faster learning that converges to better generalization performance using a smaller number of dedicated parameters.}
}
@article{MU202031,
title = {Quasi-bipartite synchronization of signed delayed neural networks under impulsive effects},
journal = {Neural Networks},
volume = {129},
pages = {31-42},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301829},
author = {Guohong Mu and Lulu Li and Xiaodi Li},
keywords = {Quasi-bipartite synchronization, Delayed neural networks, Impulsive control, Disturbance},
abstract = {This paper mainly studies quasi-bipartite synchronization (QBPS) of signed delayed neural networks (SDNNs) under impulsive effects, in which the nodes have cooperative as well as antagonistic interactions. It is assumed that disturbance occurs in the communication channels between some neighboring agents at impulsive occurring instants. Under the balanced network topology, some sufficient criteria to achieve QBPS of SDNNs are proposed by utilizing algebraic graph theory and extended Halanay differential inequality. Moreover, for the QBPS error of SDNNs, the upper bound of the final error state is also provided explicitly. Two numerical examples are presented to demonstrate the correctness of the theoretical results.}
}
@article{XIONG2020163,
title = {Encoding primitives generation policy learning for robotic arm to overcome catastrophic forgetting in sequential multi-tasks learning},
journal = {Neural Networks},
volume = {129},
pages = {163-173},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302082},
author = {Fangzhou Xiong and Zhiyong Liu and Kaizhu Huang and Xu Yang and Hong Qiao and Amir Hussain},
keywords = {Sequential multi-tasks learning, Continual learning, Catastrophic forgetting, Robotics},
abstract = {Continual learning, a widespread ability in people and animals, aims to learn and acquire new knowledge and skills continuously. Catastrophic forgetting usually occurs in continual learning when an agent attempts to learn different tasks sequentially without storing or accessing previous task information. Unfortunately, current learning systems, e.g., neural networks, are prone to deviate the weights learned in previous tasks after training new tasks, leading to catastrophic forgetting, especially in a sequential multi-tasks scenario. To address this problem, in this paper, we propose to overcome catastrophic forgetting with the focus on learning a series of robotic tasks sequentially. Particularly, a novel hierarchical neural network’s framework called Encoding Primitives Generation Policy Learning (E-PGPL) is developed to enable continual learning with two components. By employing a variational autoencoder to project the original state space into a meaningful low-dimensional feature space, representative state primitives could be sampled to help learn corresponding policies for different tasks. In learning a new task, the feature space is required to be close to the previous ones so that previously learned tasks can be protected. Extensive experiments on several simulated robotic tasks demonstrate our method’s efficacy to learn control policies for handling sequentially arriving multi-tasks, delivering improvement substantially over some other continual learning methods, especially for the tasks with more diversity.}
}
@article{ZHANG202049,
title = {R-ELMNet: Regularized extreme learning machine network},
journal = {Neural Networks},
volume = {130},
pages = {49-59},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302240},
author = {Guanghao Zhang and Yue Li and Dongshun Cui and Shangbo Mao and Guang-Bin Huang},
keywords = {Shallow network, PCANet, ELM auto-encoder, ELMNet, R-ELMNet},
abstract = {Principal component analysis network (PCANet), as an unsupervised shallow network, demonstrates noticeable effectiveness on datasets of various volumes. It carries a two-layer convolution with PCA as filter learning method, followed by a block-wise histogram post-processing stage. Following the structure of PCANet, extreme learning machine auto-encoder (ELM-AE) variants are employed to replace the PCA’s role, which come from extreme learning machine network (ELMNet) and hierarchical ELMNet. ELMNet emphasizes the importance of orthogonal projection while overlooking non-linearity. The latter introduces complex pre-processing to overcome drawback of non-linear ELM-AE. In this paper, we analyze intrinsic characteristics of ELM-AE variants and accordingly propose a regularized ELM-AE, which combines non-linearity learning capability and approximately orthogonal projection. Experiments on image classification show the effectiveness compared to supervised convolutional neural networks and related shallow networks on unsupervised feature learning.}
}
@article{VANSTEENKISTE2020309,
title = {Investigating object compositionality in Generative Adversarial Networks},
journal = {Neural Networks},
volume = {130},
pages = {309-325},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302483},
author = {Sjoerd {van Steenkiste} and Karol Kurach and Jürgen Schmidhuber and Sylvain Gelly},
keywords = {Generative Adversarial Networks, Objects, Compositionality, Generative modeling, Instance segmentation, Representation learning},
abstract = {Deep generative models seek to recover the process with which the observed data was generated. They may be used to synthesize new samples or to subsequently extract representations. Successful approaches in the domain of images are driven by several core inductive biases. However, a bias to account for the compositional way in which humans structure a visual scene in terms of objects has frequently been overlooked. In this work, we investigate object compositionality as an inductive bias for Generative Adversarial Networks (GANs). We present a minimal modification of a standard generator to incorporate this inductive bias and find that it reliably learns to generate images as compositions of objects. Using this general design as a backbone, we then propose two useful extensions to incorporate dependencies among objects and background. We extensively evaluate our approach on several multi-object image datasets and highlight the merits of incorporating structure for representation learning purposes. In particular, we find that our structured GANs are better at generating multi-object images that are more faithful to the reference distribution. More so, we demonstrate how, by leveraging the structure of the learned generative process, one can ‘invert’ the learned generative model to perform unsupervised instance segmentation. On the challenging CLEVR dataset, it is shown how our approach is able to improve over other recent purely unsupervised object-centric approaches to image generation.}
}
@article{XIAO202033,
title = {Stability of delayed inertial neural networks on time scales: A unified matrix-measure approach},
journal = {Neural Networks},
volume = {130},
pages = {33-38},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302355},
author = {Qiang Xiao and Tingwen Huang},
keywords = {Stability, Inertial neural network, Time scale, Unified matrix-measure, Time delay},
abstract = {This note introduces a unified matrix-measure concept to study the stability of a class of inertial neural networks with bounded time delays on time scales. The novel matrix-measure concept unifies the classic matrix-measure and the generalized matrix-measure concept. One sufficient global exponential stability criterion is obtained based on this key matrix-measure and no Lyapunov function is required. To make the stability performance better, another stability criterion in which more detailed information is involved has been acquired. The theoretical results in this note contain and extend some existing continuous-time and discrete-time works. A numerical example is given to show the validity of the results.}
}
@article{2022I,
title = {Current Events},
journal = {Neural Networks},
volume = {148},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00055-7},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000557}
}
@article{DASILVA202014,
title = {Fast Deep Stacked Networks based on Extreme Learning Machine applied to regression problems},
journal = {Neural Networks},
volume = {131},
pages = {14-28},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302598},
author = {Bruno Légora Souza {da Silva} and Fernando Kentaro Inaba and Evandro Ottoni Teatini Salles and Patrick Marques Ciarelli},
keywords = {Extreme Learning Machine, Stacking principle, Deep Stacked Network, Regression},
abstract = {Deep learning techniques are commonly used to process large amounts of data, and good results are obtained in many applications. Those methods, however, can lead to long training times. An alternative to simultaneously tune all parameters of a large network is to stack smaller modules, improving the model efficiency. However, methods such as Deep Stacked Network (DSN) have some problems that increase its training time and memory usage. To deal with these problems, Fast DSN (FDSN) was proposed, where the modules are trained using an Extreme Learning Machine (ELM) variant. Nonetheless, to speed-up the FDSN training, the ELM random feature mapping is shared among the modules, which can impact the network performance if the weights are not properly chosen. In this paper, we focus on the weight initialization of FDSN in order to improve its performance. We also propose FKDSN, a kernel-based variant of FDSN, besides discussing the theoretical complexity of the methods. We evaluate three different initialization approaches on ELM-trained neural networks over 50 public real-world regression datasets. Our experiments show that FDSN when combined with a more complex initialization method achieves similar results to ELM algorithms applied to large SLFNs, besides having a shorter training time and memory usage, implying that it can be suitable to be used on systems with restrict resources, such as Internet of Things devices. FKDSN also obtained similar results and training time to the large SLFNs, requiring less memory.}
}
@article{MRABAH2020206,
title = {Deep clustering with a Dynamic Autoencoder: From reconstruction towards centroids construction},
journal = {Neural Networks},
volume = {130},
pages = {206-228},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030246X},
author = {Nairouz Mrabah and Naimul Mefraz Khan and Riadh Ksantini and Zied Lachiri},
keywords = {Unsupervised learning, Deep learning, Clustering, Autoencoders},
abstract = {In unsupervised learning, there is no apparent straightforward cost function that can capture the significant factors of variations and similarities. Since natural systems have smooth dynamics, an opportunity is lost if an unsupervised objective function remains static. The absence of concrete supervision suggests that smooth dynamics should be integrated during the training process. Compared to classical static cost functions, dynamic objective functions allow to better make use of the gradual and uncertain knowledge acquired through pseudo-supervision. In this paper, we propose Dynamic Autoencoder (DynAE), a novel model for deep clustering that addresses a clustering–reconstruction trade-off, by gradually and smoothly eliminating the reconstruction objective function in favor of a construction one. Experimental evaluations on benchmark datasets show that our approach achieves state-of-the-art results compared to the most relevant deep clustering methods.}
}
@article{ANGELOV2020185,
title = {Towards explainable deep neural networks (xDNN)},
journal = {Neural Networks},
volume = {130},
pages = {185-194},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302513},
author = {Plamen Angelov and Eduardo Soares},
keywords = {Explainable AI, Interpretability, Prototype-based models, Deep-learning},
abstract = {In this paper, we propose an elegant solution that is directly addressing the bottlenecks of the traditional deep learning approaches and offers an explainable internal architecture that can outperform the existing methods, requires very little computational resources (no need for GPUs) and short training times (in the order of seconds). The proposed approach, xDNN is using prototypes. Prototypes are actual training data samples (images), which are local peaks of the empirical data distribution called typicality as well as of the data density. This generative model is identified in a closed form and equates to the pdf but is derived automatically and entirely from the training data with no user- or problem-specific thresholds, parameters or intervention. The proposed xDNN offers a new deep learning architecture that combines reasoning and learning in a synergy. It is non-iterative and non-parametric, which explains its efficiency in terms of time and computational resources. From the user perspective, the proposed approach is clearly understandable to human users. We tested it on challenging problems as the classification of different lighting conditions for driving scenes (iROADS), object detection (Caltech-256, and Caltech-101), and SARS-CoV-2 identification via computed tomography scan (COVID CT-scans dataset). xDNN outperforms the other methods including deep learning in terms of accuracy, time to train and offers an explainable classifier.}
}
@article{YANG2020242,
title = {Exponential synchronization of stochastic delayed memristive neural networks via a novel hybrid control},
journal = {Neural Networks},
volume = {131},
pages = {242-250},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302756},
author = {Nijing Yang and Yongbin Yu and Shouming Zhong and Xiangxiang Wang and Kaibo Shi and Jingye Cai},
keywords = {Exponential synchronization, Memristive neural networks, Event-based impulsive control, Hybrid control, Stochastic perturbations},
abstract = {This paper investigates the exponential synchronization issue of stochastic delayed memristive neural networks (SDMNNs) via a novel hybrid control (HC), where impulsive instants are determined by the state-dependent trigger condition. The switching and quantification strategies are applied to the event-based impulsive controller to cope with the challenges induced concurrently by interval parameters, impulses, stochastic disturbance and time-varying delays. Furthermore, the control costs can be reduced and communication channels and bandwidths can be saved by using this designed controller. Then, novel Lyapunov functions and new analytical methods are constructed, which can be used to realize the exponential synchronization of SDMNNs via HC. Finally, a numerical simulation is provided to demonstrate our theoretical results.}
}
@article{WANG2020294,
title = {Cross-modality paired-images generation and augmentation for RGB-infrared person re-identification},
journal = {Neural Networks},
volume = {128},
pages = {294-304},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301702},
author = {Guan’an Wang and Yang Yang and Tianzhu Zhang and Jian Cheng and Zengguang Hou and Prayag Tiwari and Hari Mohan Pandey},
keywords = {Person re-identification, Cross-modality, Feature disentanglement, Image generation, Adversarial learning},
abstract = {RGB-Infrared (IR) person re-identification is very challenging due to the large cross-modality variations between RGB and IR images. Considering no correspondence labels between every pair of RGB and IR images, most methods try to alleviate the variations with set-level alignment by reducing marginal distribution divergence between the entire RGB and IR sets. However, this set-level alignment strategy may lead to misalignment of some instances, which limit the performance for RGB–IR Re-ID. Different from existing methods, in this paper, we propose to generate cross-modality paired-images and perform both global set-level and fine-grained instance-level alignments. Our proposed method enjoys several merits. First, our method can perform set-level alignment by disentangling modality-specific and modality-invariant features. Compared with conventional methods, ours can explicitly remove the modality-specific features and the modality variation can be better reduced. Second, given cross-modality unpaired-images of a person, our method can generate cross-modality paired images from exchanged features. With them, we can directly perform instance-level alignment by minimizing distances of every pair of images. Third, our method learns a latent manifold space. In the space, we can random sample and generate lots of images of unseen classes. Training with those images, the learned identity feature space is more smooth can generalize better when test. Finally, extensive experimental results on two standard benchmarks demonstrate that the proposed model favorably against state-of-the-art methods.}
}
@article{PASSALIS2020103,
title = {Initializing photonic feed-forward neural networks using auxiliary tasks},
journal = {Neural Networks},
volume = {129},
pages = {103-108},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301945},
author = {Nikolaos Passalis and George Mourgias-Alexandris and Nikos Pleros and Anastasios Tefas},
keywords = {Photonic deep learning, Neural network initialization, Photonic activation functions},
abstract = {Photonics is among the most promising emerging technologies for providing fast and energy-efficient Deep Learning (DL) implementations. Despite their advantages, these photonic DL accelerators also come with certain important limitations. For example, the majority of existing photonic accelerators do not currently support many of the activation functions that are commonly used in DL, such as the ReLU activation function. Instead, sinusoidal and sigmoidal nonlinearities are usually employed, rendering the training process unstable and difficult to tune, mainly due to vanishing gradient phenomena. Thus, photonic DL models usually require carefully fine-tuning all their training hyper-parameters in order to ensure that the training process will proceed smoothly. Despite the recent advances in initialization schemes, as well as in optimization algorithms, training photonic DL models is still especially challenging. To overcome these limitations, we propose a novel adaptive initialization method that employs auxiliary tasks to estimate the optimal initialization variance for each layer of a network. The effectiveness of the proposed approach is demonstrated using two different datasets, as well as two recently proposed photonic activation functions and three different initialization methods. Apart from significantly increasing the stability of the training process, the proposed method can be directly used with any photonic activation function, without further requiring any other kind of fine-tuning, as also demonstrated through the conducted experiments.}
}
@article{MATSUKI202019,
title = {Adaptive balancing of exploration and exploitation around the edge of chaos in internal-chaos-based learning},
journal = {Neural Networks},
volume = {132},
pages = {19-29},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302914},
author = {Toshitaka Matsuki and Katsunari Shibata},
keywords = {Chaotic neural network, Reservoir computing, Reward-modulated Hebbian learning, Edge of chaos, Exploration–exploitation dilemma},
abstract = {This paper addresses learning with exploration driven by chaotic internal dynamics of a neural network. Hoerzer et al. showed that a chaotic reservoir network (RN) can learn with exploration driven by external random noise and a sequential reward. In this paper, we demonstrate that a chaotic RN can learn without external noise because the output fluctuation originated from its internal chaotic dynamics functions as exploration. As learning progresses, the chaoticity decreases and the network can automatically switch from exploration mode to exploitation mode. Furthermore, the network can resume exploration when presented with a new situation. In addition, we found that even when the two parameters that influence the chaoticity are varied, learning performance always improves around the edge of chaos. From these results, we think that exploration is generated from internal chaotic dynamics, and exploitation appears in the process of forming attractors on the chaotic dynamics through learning. Consequently, exploration and exploitation are well-balanced around the edge of chaos, which leads to good learning performance.}
}