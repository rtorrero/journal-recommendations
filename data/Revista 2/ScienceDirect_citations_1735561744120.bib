@article{2023ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {163},
pages = {ii},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00246-0},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023002460}
}
@article{2023ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {161},
pages = {ii},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00149-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001491}
}
@article{MALIK2021201,
title = {Self-organized operational neural networks for severe image restoration problems},
journal = {Neural Networks},
volume = {135},
pages = {201-211},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304391},
author = {Junaid Malik and Serkan Kiranyaz and Moncef Gabbouj},
keywords = {Image restoration, Image denoising, Artificial neural networks, Operational neural networks},
abstract = {Discriminative learning based on convolutional neural networks (CNNs) aims to perform image restoration by learning from training examples of noisy-clean image pairs. It has become the go-to methodology for tackling image restoration and has outperformed the traditional non-local class of methods. However, the top-performing networks are generally composed of many convolutional layers and hundreds of neurons, with trainable parameters in excess of several million. We claim that this is due to the inherently linear nature of convolution-based transformation, which is inadequate for handling severe restoration problems. Recently, a non-linear generalization of CNNs, called the operational neural networks (ONN), has been shown to outperform CNN on AWGN denoising. However, its formulation is burdened by a fixed collection of well-known non-linear operators and an exhaustive search to find the best possible configuration for a given architecture, whose efficacy is further limited by a fixed output layer operator assignment. In this study, we leverage the Taylor series-based function approximation to propose a self-organizing variant of ONNs, Self-ONNs, for image restoration, which synthesizes novel nodal transformations on-the-fly as part of the learning process, thus eliminating the need for redundant training runs for operator search. In addition, it enables a finer level of operator heterogeneity by diversifying individual connections of the receptive fields and weights. We perform a series of extensive ablation experiments across three severe image restoration tasks. Even when a strict equivalence of learnable parameters is imposed, Self-ONNs surpass CNNs by a considerable margin across all problems, improving the generalization performance by up to 3 dB in terms of PSNR.}
}
@article{2023II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {161},
pages = {II},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00153-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001533}
}
@article{PANDEY2021177,
title = {Generative Restricted Kernel Machines: A framework for multi-view generation and disentangled feature learning},
journal = {Neural Networks},
volume = {135},
pages = {177-191},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304275},
author = {Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},
keywords = {Generative models, Latent variable models, Deep learning, Restricted kernel machines},
abstract = {This paper introduces a novel framework for generative models based on Restricted Kernel Machines (RKMs) with joint multi-view generation and uncorrelated feature learning, called Gen-RKM. To enable joint multi-view generation, this mechanism uses a shared representation of data from various views. Furthermore, the model has a primal and dual formulation to incorporate both kernel-based and (deep convolutional) neural network based models within the same setting. When using neural networks as explicit feature-maps, a novel training procedure is proposed, which jointly learns the features and shared subspace representation. The latent variables are given by the eigen-decomposition of the kernel matrix, where the mutual orthogonality of eigenvectors represents the learned uncorrelated features. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of generated samples on various standard datasets.}
}
@article{SEO2021140,
title = {Self-augmentation: Generalizing deep networks to unseen classes for few-shot learning},
journal = {Neural Networks},
volume = {138},
pages = {140-149},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000496},
author = {Jin-Woo Seo and Hong-Gyu Jung and Seong-Whan Lee},
keywords = {Few-shot learning, Classification, Generalization, Knowledge distillation},
abstract = {Few-shot learning aims to classify unseen classes with a few training examples. While recent works have shown that standard mini-batch training with carefully designed training strategies can improve generalization ability for unseen classes, well-known problems in deep networks such as memorizing training statistics have been less explored for few-shot learning. To tackle this issue, we propose self-augmentation that consolidates self-mix and self-distillation. Specifically, we propose a regional dropout technique called self-mix, in which a patch of an image is substituted into other values in the same image. With this dropout effect, we show that the generalization ability of deep networks can be improved as it prevents us from learning specific structures of a dataset. Then, we employ a backbone network that has auxiliary branches with its own classifier to enforce knowledge sharing. This sharing of knowledge forces each branch to learn diverse optimal points during training. Additionally, we present a local representation learner to further exploit a few training examples of unseen classes by generating fake queries and novel weights. Experimental results show that the proposed method outperforms the state-of-the-art methods for prevalent few-shot benchmarks and improves the generalization ability.}
}
@article{LI202117,
title = {μ-law SGAN for generating spectra with more details in speech enhancement},
journal = {Neural Networks},
volume = {136},
pages = {17-27},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304421},
author = {Hongfeng Li and Yanyan Xu and Dengfeng Ke and Kaile Su},
keywords = {Signal processing, Speech enhancement, Deep neural networks, Generative adversarial networks, -law SGAN},
abstract = {The goal of monaural speech enhancement is to separate clean speech from noisy speech. Recently, many studies have employed generative adversarial networks (GAN) to deal with monaural speech enhancement tasks. When using generative adversarial networks for this task, the output of the generator is a speech waveform or a spectrum, such as a magnitude spectrum, a mel-spectrum or a complex-valued spectrum. The spectra generated by current speech enhancement methods in the time–frequency domain usually lack details, such as consonants and harmonics with low energy. In this paper, we propose a new type of adversarial training framework for spectrum generation, named μ-law spectrum generative adversarial networks (μ-law SGAN). We introduce a trainable μ-law spectrum compression layer (USCL) into the proposed discriminator to compress the dynamic range of the spectrum. As a result, the compressed spectrum can display more detailed information. In addition, we use the spectrum transformed by USCL to regularize the generator’s training, so that the generator can pay more attention to the details of the spectrum. Experimental results on the open dataset Voice Bank + DEMAND show that μ-law SGAN is an effective generative adversarial architecture for speech enhancement. Moreover, visual spectrogram analysis suggests that μ-law SGAN pays more attention to the enhancement of low energy harmonics and consonants.}
}
@article{CHEN2021126,
title = {Multi-scale Attention Convolutional Neural Network for time series classification},
journal = {Neural Networks},
volume = {136},
pages = {126-140},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000010},
author = {Wei Chen and Ke Shi},
keywords = {Time series classification, Convolutional neural network, Multi-scale attention mechanism},
abstract = {With the rapid increase of data availability, time series classification (TSC) has arisen in a wide range of fields and drawn great attention of researchers. Recently, hundreds of TSC approaches have been developed, which can be classified into two categories: traditional and deep learning based TSC methods. However, it remains challenging to improve accuracy and model generalization ability. Therefore, we investigate a novel end-to-end model based on deep learning named as Multi-scale Attention Convolutional Neural Network (MACNN) to solve the TSC problem. We first apply the multi-scale convolution to capture different scales of information along the time axis by generating different scales of feature maps. Then an attention mechanism is proposed to enhance useful feature maps and suppress less useful ones by learning the importance of each feature map automatically. MACNN addresses the limitation of single-scale convolution and equal weight feature maps. We conduct a comprehensive evaluation of 85 UCR standard datasets and the experimental results show that our proposed approach achieves the best performance and outperforms the other traditional and deep learning based methods by a large margin.}
}
@article{GAO2021163,
title = {State bounding for fuzzy memristive neural networks with bounded input disturbances},
journal = {Neural Networks},
volume = {134},
pages = {163-172},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304147},
author = {Yu Gao and Song Zhu and Chunyu Yang and Shiping Wen},
keywords = {Memristor, Neural networks, Fuzzy systems, State bounding, Bounded disturbances},
abstract = {This paper investigates the state bounding problem of fuzzy memristive neural networks (FMNNs) with bounded input disturbances. By using the characters of Metzler, Hurwitz and nonnegative matrices, this paper obtains the exact delay-independent and delay-dependent boundary ranges of the solution, which have less conservatism than the results in existing literatures. The validity of the results is verified by two numerical examples.}
}
@article{2023ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {159},
pages = {ii},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00031-X},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300031X}
}
@article{ZHANG20211,
title = {Adaptive transfer learning for EEG motor imagery classification with deep Convolutional Neural Network},
journal = {Neural Networks},
volume = {136},
pages = {1-10},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304305},
author = {Kaishuo Zhang and Neethu Robinson and Seong-Whan Lee and Cuntai Guan},
keywords = {Transfer learning, Brain–computer interface (BCI), Electroencephalography (EEG), Convolutional Neural Network (CNN)},
abstract = {In recent years, deep learning has emerged as a powerful tool for developing Brain–Computer Interface (BCI) systems. However, for deep learning models trained entirely on the data from a specific individual, the performance increase has only been marginal owing to the limited availability of subject-specific data. To overcome this, many transfer-based approaches have been proposed, in which deep networks are trained using pre-existing data from other subjects and evaluated on new target subjects. This mode of transfer learning however faces the challenge of substantial inter-subject variability in brain data. Addressing this, in this paper, we propose 5 schemes for adaptation of a deep convolutional neural network (CNN) based electroencephalography (EEG)-BCI system for decoding hand motor imagery (MI). Each scheme fine-tunes an extensively trained, pre-trained model and adapt it to enhance the evaluation performance on a target subject. We report the highest subject-independent performance with an average (N=54) accuracy of 84.19% (±9.98%) for two-class motor imagery, while the best accuracy on this dataset is 74.15% (±15.83%) in the literature. Further, we obtain a statistically significant improvement (p=0.005) in classification using the proposed adaptation schemes compared to the baseline subject-independent model.}
}
@article{ECKE2021158,
title = {Exploitation of image statistics with sparse coding in the case of stereo vision},
journal = {Neural Networks},
volume = {135},
pages = {158-176},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030441X},
author = {Gerrit A. Ecke and Harald M. Papp and Hanspeter A. Mallot},
keywords = {Sparse coding, Locally Competitive Algorithm (LCA), Efficient coding, Compact code, Probabilistic inference, Stereo vision},
abstract = {The sparse coding algorithm has served as a model for early processing in mammalian vision. It has been assumed that the brain uses sparse coding to exploit statistical properties of the sensory stream. We hypothesize that sparse coding discovers patterns from the data set, which can be used to estimate a set of stimulus parameters by simple readout. In this study, we chose a model of stereo vision to test our hypothesis. We used the Locally Competitive Algorithm (LCA), followed by a naïve Bayes classifier, to infer stereo disparity. From the results we report three observations. First, disparity inference was successful with this naturalistic processing pipeline. Second, an expanded, highly redundant representation is required to robustly identify the input patterns. Third, the inference error can be predicted from the number of active coefficients in the LCA representation. We conclude that sparse coding can generate a suitable general representation for subsequent inference tasks.}
}
@article{GUO2021158,
title = {Improved deep CNNs based on Nonlinear Hybrid Attention Module for image classification},
journal = {Neural Networks},
volume = {140},
pages = {158-166},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000137},
author = {Nan Guo and Ke Gu and Junfei Qiao and Jing Bi},
keywords = {Convolutional neural networks, Hybrid attention mechanism, Feature map combination, General module},
abstract = {Recent years have witnessed numerous successful applications of incorporating attention module into feed-forward convolutional neural networks. Along this line of research, we design a novel lightweight general-purpose attention module by simultaneously taking channel attention and spatial attention into consideration. Specifically, inspired by the characteristics of channel attention and spatial attention, a nonlinear hybrid method is proposed to combine such two types of attention feature maps, which is highly beneficial to better network fine-tuning. Further, the parameters of each attention branch can be adjustable for the purpose of making the attention module more flexible and adaptable. From another point of view, we found that the currently popular SE, and CBAM modules are actually two particular cases of our proposed attention module. We also explore the latest attention module ADCM. To validate the module, we conduct experiments on CIFAR10, CIFAR100, Fashion MINIST datasets. Results show that, after integrating with our attention module, existing networks tend to be more efficient in training process and have better performance as compared with state-of-the-art competitors. Also, it is worthy to stress the following two points: (1) our attention module can be used in existing state-of-the-art deep architectures and get better performance at a small computational cost; (2) the module can be added to existing deep architectures in a simple way through stacking the integration of networks block and our module.}
}
@article{IDEI2021150,
title = {Paradoxical sensory reactivity induced by functional disconnection in a robot model of neurodevelopmental disorder},
journal = {Neural Networks},
volume = {138},
pages = {150-163},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000411},
author = {Hayato Idei and Shingo Murata and Yuichi Yamashita and Tetsuya Ogata},
keywords = {Computational psychiatry, Neurodevelopmental disorder, Neurorobotics, Predictive coding, Uncertainty, Disconnection},
abstract = {Neurodevelopmental disorders are characterized by heterogeneous and non-specific nature of their clinical symptoms. In particular, hyper- and hypo-reactivity to sensory stimuli are diagnostic features of autism spectrum disorder and are reported across many neurodevelopmental disorders. However, computational mechanisms underlying the unusual paradoxical behaviors remain unclear. In this study, using a robot controlled by a hierarchical recurrent neural network model with predictive processing and learning mechanism, we simulated how functional disconnection altered the learning process and subsequent behavioral reactivity to environmental change. The results show that, through the learning process, long-range functional disconnection between distinct network levels could simultaneously lower the precision of sensory information and higher-level prediction. The alteration caused a robot to exhibit sensory-dominated and sensory-ignoring behaviors ascribed to sensory hyper- and hypo-reactivity, respectively. As long-range functional disconnection became more severe, a frequency shift from hyporeactivity to hyperreactivity was observed, paralleling an early sign of autism spectrum disorder. Furthermore, local functional disconnection at the level of sensory processing similarly induced hyporeactivity due to low sensory precision. These findings suggest a computational explanation for paradoxical sensory behaviors in neurodevelopmental disorders, such as coexisting hyper- and hypo-reactivity to sensory stimulus. A neurorobotics approach may be useful for bridging various levels of understanding in neurodevelopmental disorders and providing insights into mechanisms underlying complex clinical symptoms.}
}
@article{2023II,
title = {Editorial Board},
journal = {Neural Networks},
volume = {159},
pages = {II},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00039-4},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000394}
}
@article{XIE202198,
title = {Towards effective deep transfer via attentive feature alignment},
journal = {Neural Networks},
volume = {138},
pages = {98-109},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000307},
author = {Zheng Xie and Zhiquan Wen and Yaowei Wang and Qingyao Wu and Mingkui Tan},
keywords = {Deep transfer, Knowledge distillation, Attention mechanism},
abstract = {Training a deep convolutional network from scratch requires a large amount of labeled data, which however may not be available for many practical tasks. To alleviate the data burden, a practical approach is to adapt a pre-trained model learned on the large source domain to the target domain, but the performance can be limited when the source and target domain data distributions have large differences. Some recent works attempt to alleviate this issue by imposing feature alignment over the intermediate feature maps between the source and target networks. However, for a source model, many of the channels/spatial-features for each layer can be irrelevant to the target task. Thus, directly applying feature alignment may not achieve promising performance. In this paper, we propose an Attentive Feature Alignment (AFA) method for effective domain knowledge transfer by identifying and attending on the relevant channels and spatial features between two domains. To this end, we devise two learnable attentive modules at both the channel and spatial levels. We then sequentially perform attentive spatial- and channel-level feature alignments between the source and target networks, in which the target model and attentive module are learned simultaneously. Moreover, we theoretically analyze the generalization performance of our method, which confirms its superiority to existing methods. Extensive experiments on both image classification and face recognition demonstrate the effectiveness of our method. The source code and the pre-trained models are available at https://github.com/xiezheng-cs/AFAhttps://github.com/xiezheng-cs/AFA.}
}
@article{LI202113,
title = {Artificial fly visual joint perception neural network inspired by multiple-regional collision detection},
journal = {Neural Networks},
volume = {135},
pages = {13-28},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304160},
author = {Lun Li and Zhuhong Zhang and Jiaxuan Lu},
keywords = {Fly visual neurophysiology, Fly’s vision system, Feedforward neural networks, Multi-regional collision detection, Perceptual region division},
abstract = {The biological visual system includes multiple types of motion sensitive neurons which preferentially respond to specific perceptual regions. However, it still keeps open how to borrow such neurons to construct bio-inspired computational models for multiple-regional collision detection. To fill this gap, this work proposes a visual joint perception neural network with two subnetworks — presynaptic and postsynaptic neural networks, inspired by the preferential perception characteristics of three horizontal and vertical motion sensitive neurons. Related to the neural network and three hazard detection mechanisms, an artificial fly visual synthesized collision detection model for multiple-regional collision detection is originally developed to monitor possible danger occurrence in the case where one or more moving objects appear in the whole field of view. The experiments can clearly draw two conclusions: (i) the acquired neural network can effectively display the characteristics of visual movement, and (ii) the collision detection model, which outperforms the compared models, can effectively perform multiple-regional collision detection at a high success rate, and only takes about 0.24s to complete the process of collision detection for each virtual or actual image frame with resolution 110×60.}
}
@article{2023ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {160},
pages = {ii},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00095-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000953}
}
@article{TSILIGKARIDIS2021105,
title = {Information Aware max-norm Dirichlet networks for predictive uncertainty estimation},
journal = {Neural Networks},
volume = {135},
pages = {105-114},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304287},
author = {Theodoros Tsiligkaridis},
keywords = {Predictive uncertainty, Neural networks, Deep learning, Uncertainty quantification, Dirichlet},
abstract = {Precise estimation of uncertainty in predictions for AI systems is a critical factor in ensuring trust and safety. Deep neural networks trained with a conventional method are prone to over-confident predictions. In contrast to Bayesian neural networks that learn approximate distributions on weights to infer prediction confidence, we propose a novel method, Information Aware Dirichlet networks, that learn an explicit Dirichlet prior distribution on predictive distributions by minimizing a bound on the expected max norm of the prediction error and penalizing information associated with incorrect outcomes. Properties of the new cost function are derived to indicate how improved uncertainty estimation is achieved. Experiments using real datasets show that our technique outperforms, by a large margin, state-of-the-art neural networks for estimating within-distribution and out-of-distribution uncertainty, and detecting adversarial examples.}
}
@article{2023I,
title = {CURRENT EVENTS},
journal = {Neural Networks},
volume = {161},
pages = {I},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00152-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001521}
}
@article{SHANNON202186,
title = {Comparative study using inverse ontology cogency and alternatives for concept recognition in the annotated National Library of Medicine database},
journal = {Neural Networks},
volume = {139},
pages = {86-104},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000265},
author = {George J. Shannon and Naga Rayapati and Steven M. Corns and Donald C. Wunsch},
keywords = {Cogent confabulation, Natural language processing, Concept recognition, Language model},
abstract = {This paper introduces inverse ontology cogency, a concept recognition process and distance function that is biologically-inspired and competitive with alternative methods. The paper introduces inverse ontology cogency as a new alternative method. It is a novel distance measure used in selecting the optimum mapping between ontology-specified concepts and phrases in free-form text. We also apply a multi-layer perceptron and text processing method for named entity recognition as an alternative to recurrent neural network methods. Automated named entity recognition, or concept recognition, is a common task in natural language processing. Similarities between confabulation theory and existing language models are discussed. This paper provides comparisons to MetaMap from the National Library of Medicine (NLM), a popular tool used in medicine to map free-form text to concepts in a medical ontology. The NLM provides a manually annotated database from the medical literature with concepts labeled, a unique, valuable source of ground truth, permitting comparison with MetaMap performance. Comparisons for different feature set combinations are made to demonstrate the effectiveness of inverse ontology cogency for entity recognition. Results indicate that using both inverse ontology cogency and corpora cogency improved concept recognition precision 20% over the best published MetaMap results. This demonstrates a new, effective approach for identifying medical concepts in text. This is the first time cogency has been explicitly invoked for reasoning with ontologies, and the first time it has been used on medical literature where high-quality ground truth is available for quality assessment.}
}
@article{SHI202154,
title = {A conditional Triplet loss for few-shot learning and its application to image co-segmentation},
journal = {Neural Networks},
volume = {137},
pages = {54-62},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000022},
author = {Daming Shi and Maysam Orouskhani and Yasin Orouskhani},
keywords = {Conditional Triplet loss, Few-shot learning, Metric learning, Siamese network, Co-segmentation},
abstract = {Few-shot learning tries to solve the problems that suffer the limited number of samples. In this paper we present a novel conditional Triplet loss for solving few-shot problems using deep metric learning. While the conventional Triplet loss suffers the limitation of random sampling of triplets which leads to slow convergence in training process, our proposed network tries to distinguish between samples so that it improves the training speed. Our main contributions are two-fold. (i) We propose a conditional Triplet loss to train a deep Triplet network for deep metric embedding. The proposed Triplet loss employs a penalty–reward technique to enhance the convergence of standard Triplet loss. (ii) We improve the performance of the existing image co-segmentation model by replacing the conventional loss function by our proposed conditional Triplet loss. To demonstrate the performance of the proposed network, experiments carry out on MNIST and CIFAR. Simulation results are evaluated by AUC and Recall (sensitivity) and indicate that the proposed conditional Triplet network achieves higher accuracy in comparison to state-of-the-arts.}
}
@article{HAO2021127,
title = {Semi-supervised disentangled framework for transferable named entity recognition},
journal = {Neural Networks},
volume = {135},
pages = {127-138},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304159},
author = {Zhifeng Hao and Di Lv and Zijian Li and Ruichu Cai and Wen Wen and Boyan Xu},
keywords = {Named entity recognition, Semi-supervised learning, Transfer learning, Disentanglement},
abstract = {Named entity recognition (NER) for identifying proper nouns in unstructured text is one of the most important and fundamental tasks in natural language processing. However, despite the widespread use of NER models, they still require a large-scale labeled data set, which incurs a heavy burden due to manual annotation. Domain adaptation is one of the most promising solutions to this problem, where rich labeled data from the relevant source domain are utilized to strengthen the generalizability of a model based on the target domain. However, the mainstream cross-domain NER models are still affected by the following two challenges (1) Extracting domain-invariant information such as syntactic information for cross-domain transfer. (2) Integrating domain-specific information such as semantic information into the model to improve the performance of NER. In this study, we present a semi-supervised framework for transferable NER, which disentangles the domain-invariant latent variables and domain-specific latent variables. In the proposed framework, the domain-specific information is integrated with the domain-specific latent variables by using a domain predictor. The domain-specific and domain-invariant latent variables are disentangled using three mutual information regularization terms, i.e., maximizing the mutual information between the domain-specific latent variables and the original embedding, maximizing the mutual information between the domain-invariant latent variables and the original embedding, and minimizing the mutual information between the domain-specific and domain-invariant latent variables. Extensive experiments demonstrated that our model can obtain state-of-the-art performance with cross-domain and cross-lingual NER benchmark data sets.}
}
@article{CUNHASERGIO202187,
title = {Stacked DeBERT: All attention in incomplete data for text classification},
journal = {Neural Networks},
volume = {136},
pages = {87-96},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304433},
author = {Gwenaelle {Cunha Sergio} and Minho Lee},
keywords = {Incomplete text classification, Incomplete data, Speech-to-Text error, BERT, Transformers, Denoising},
abstract = {In this paper, we propose Stacked DeBERT, short for Stacked Denoising Bidirectional Encoder Representations from Transformers. This novel model improves robustness in incomplete data, when compared to existing systems, by designing a novel encoding scheme in BERT, a powerful language representation model solely based on attention mechanisms. Incomplete data in natural language processing refer to text with missing or incorrect words, and its presence can hinder the performance of current models that were not implemented to withstand such noises, but must still perform well even under duress. This is due to the fact that current approaches are built for and trained with clean and complete data, and thus are not able to extract features that can adequately represent incomplete data. Our proposed approach consists of obtaining intermediate input representations by applying an embedding layer to the input tokens followed by vanilla transformers. These intermediate features are given as input to novel denoising transformers which are responsible for obtaining richer input representations. The proposed approach takes advantage of stacks of multilayer perceptrons for the reconstruction of missing words’ embeddings by extracting more abstract and meaningful hidden feature vectors, and bidirectional transformers for improved embedding representation. We consider two datasets for training and evaluation: the Chatbot Natural Language Understanding Evaluation Corpus and Kaggle’s Twitter Sentiment Corpus. Our model shows improved F1-scores and better robustness in informal/incorrect texts present in tweets and in texts with Speech-to-Text error in the sentiment and intent classification tasks.11https://github.com/gcunhase/StackedDeBERT.}
}
@article{KAMBARA2021179,
title = {Computational reproductions of external force field adaption without assuming desired trajectories},
journal = {Neural Networks},
volume = {139},
pages = {179-198},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000381},
author = {Hiroyuki Kambara and Atsushi Takagi and Haruka Shimizu and Toshihiro Kawase and Natsue Yoshimura and Nicolas Schweighofer and Yasuharu Koike},
keywords = {Reaching movement, Motor learning, Force-field adaptation, Reinforcement learning},
abstract = {Optimal feedback control is an established framework that is used to characterize human movement. However, it is not fully understood how the brain computes optimal gains through interactions with the environment. In the past study, we proposed a model of motor learning that identifies a set of feedback and feedforward controllers and a state predictor of the arm musculoskeletal system to control free reaching movements. In this study, we applied the model to force field adaptation tasks where normal reaching movements are disturbed by an external force imposed on the hand. Without a priori knowledge about the arm and environment, the model was able to adapt to the force field by generating counteracting forces to overcome it in a manner similar to what is reported in the behavioral literature. The kinematics of the movements generated by our model share characteristic features of human movements observed before and after force field adaptation. In addition, we demonstrate that the structure and learning algorithm introduced in our model induced a shift in the end-point’s equilibrium position and a static force modulation, accompanied by a fast and a slow learning process. Importantly, our model does not require desired trajectories, yields movements without specifying movement duration, and predicts force generation patterns by exploring the environment. Our model demonstrates a possible mechanism through which the central nervous system may control and adapt a point-to-point reaching movement without specifying a desired trajectory by continuously updating the body’s musculoskeletal model.}
}
@article{ZANG2021138,
title = {Controllable stroke-based sketch synthesis from a self-organized latent space},
journal = {Neural Networks},
volume = {137},
pages = {138-150},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000149},
author = {Sicong Zang and Shikui Tu and Lei Xu},
keywords = {Controllable synthesis, Stroke-based free-hand sketches, Self-organized latent space, Rival penalized competitive learning, Model selection},
abstract = {Learning to synthesize free-hand sketches controllably according to specified categories and sketching styles is a challenging task, due to the lack of training data with category labels and style labels. One choice to control the synthesis is by self-organizing a latent coding space to preserve the similarity of structural patterns of the observed data. A practical way is introducing a Gaussian mixture prior over the latent codes, where each Gaussian component represents a specific categorical or stylistic pattern. As a result, we can generate sketches by sampling the latent variables from the Gaussian components or continuously manipulating the latent representations by interpolation. To achieve robust controllable sketch synthesis, it is critical to determine an appropriate Gaussian number. An underestimated Gaussian number cannot fully represent all the sketch patterns, i.e., some clusters have to contain sketches with more than one pattern. An overestimated one introduces redundant components, usually representing a chaotic collection of sketches with diverse patterns featured by other components. Both cases disturb pattern clustering over the coding space and make the internal code generation difficult to control for specific patterns. However, the Gaussian number is unavailable in this unsupervised task. In this paper, we present Rival Penalized Competitive Learning pixel to sequence (RPCL-pix2seq) to automatically determine the Gaussian number. Both quantitative and qualitative experimental results show RPCL-pix2seq can partition the codes for the sketches into an approximate stable number of clusters. Hence, we are able to do synthesis reasoning over the latent space, generating novel but reasonable sketches which neither appear in the training dataset nor exist in real life.}
}
@article{GRECHUK202133,
title = {General stochastic separation theorems with optimal bounds},
journal = {Neural Networks},
volume = {138},
pages = {33-56},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000423},
author = {Bogdan Grechuk and Alexander N. Gorban and Ivan Y. Tyukin},
keywords = {AI, Blessing of dimensionality, Curse of dimensionality, Concentration of measure, AI errors, Discriminant},
abstract = {Phenomenon of stochastic separability was revealed and used in machine learning to correct errors of Artificial Intelligence (AI) systems and analyze AI instabilities. In high-dimensional datasets under broad assumptions each point can be separated from the rest of the set by simple and robust Fisher’s discriminant (is Fisher separable). Errors or clusters of errors can be separated from the rest of the data. The ability to correct an AI system also opens up the possibility of an attack on it, and the high dimensionality induces vulnerabilities caused by the same stochastic separability that holds the keys to understanding the fundamentals of robustness and adaptivity in high-dimensional data-driven AI. To manage errors and analyze vulnerabilities, the stochastic separation theorems should evaluate the probability that the dataset will be Fisher separable in given dimensionality and for a given class of distributions. Explicit and optimal estimates of these separation probabilities are required, and this problem is solved in the present work. The general stochastic separation theorems with optimal probability estimates are obtained for important classes of distributions: log-concave distribution, their convex combinations and product distributions. The standard i.i.d. assumption was significantly relaxed. These theorems and estimates can be used both for correction of high-dimensional data driven AI systems and for analysis of their vulnerabilities. The third area of application is the emergence of memories in ensembles of neurons, the phenomena of grandmother’s cells and sparse coding in the brain, and explanation of unexpected effectiveness of small neural ensembles in high-dimensional brain.}
}
@article{NAKAMURA2021198,
title = {Explanation of emotion regulation mechanism of mindfulness using a brain function model},
journal = {Neural Networks},
volume = {138},
pages = {198-214},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100037X},
author = {Haruka Nakamura and Yoshimasa Tawatsuji and Siyuan Fang and Tatsunori Matsui},
keywords = {Emotion regulation in mindfulness, Mechanism, Brain function model, Top-down, Bottom-up},
abstract = {The emotion regulation mechanism of mindfulness plays an important role in the stress reduction effect. Many researchers in the fields of cognitive psychology and cognitive neuroscience have attempted to elucidate this mechanism by documenting the cognitive processes that occur and the neural activities that characterize each process. However, previous findings have not revealed the mechanism of information propagation in the brain that achieves emotion regulation during mindfulness. In this study, we constructed a functional brain model based on its anatomical network structure and a computational model representing the propagation of information between brain regions. We then examined the effects of mindfulness meditation on information propagation in the brain using simulations of changes in the activity of each region. These simulations of changes represent the degree of processing resource allocation to the neural activity via changes in the weights of each region’s output. As a result of the simulations, we reveal how the neural activity characteristic of emotion regulation in mindfulness, which has been reported in previous studies, is realized in the brain. Mindfulness meditation increases the weight of the output from each region of the thalamus and sensory cortex, which processes sensory stimuli from the external world. This sensory information activates the insula and anterior cingulate cortex (ACC). The orbitofrontal cortex and dorsolateral prefrontal cortex inhibit amygdala activity (i.e., top-down emotion regulation). However, when mindfulness meditation dominates bottom-up processing via sensory stimuli from the external world, amygdala activity increases through the insula and ACC activation.}
}
@article{DEMIN202164,
title = {Necessary conditions for STDP-based pattern recognition learning in a memristive spiking neural network},
journal = {Neural Networks},
volume = {134},
pages = {64-75},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303907},
author = {V.A. Demin and D.V. Nekhaev and I.A. Surazhevsky and K.E. Nikiruy and A.V. Emelyanov and S.N. Nikolaev and V.V. Rylkov and M.V. Kovalchuk},
keywords = {Memristor, Hardware analog neuron, Spiking neural network, Memristive STDP, Unsupervised learning, Probabilistic generative model},
abstract = {This work is aimed to study experimental and theoretical approaches for searching effective local training rules for unsupervised pattern recognition by high-performance memristor-based Spiking Neural Networks (SNNs). First, the possibility of weight change using Spike-Timing-Dependent Plasticity (STDP) is demonstrated with a pair of hardware analog neurons connected through a (CoFeB)x(LiNbO3)1−x nanocomposite memristor. Next, the learning convergence to a solution of binary clusterization task is analyzed in a wide range of memristive STDP parameters for a single-layer fully connected feedforward SNN. The memristive STDP behavior supplying convergence in this simple task is shown also to provide it in the handwritten digit recognition domain by the more complex SNN architecture with a Winner-Take-All competition between neurons. To investigate basic conditions necessary for training convergence, an original probabilistic generative model of a rate-based single-layer network with independent or competing neurons is built and thoroughly analyzed. The main result is a statement of “correlation growth-anticorrelation decay” principle which prompts near-optimal policy to configure model parameters. This principle is in line with requiring the binary clusterization convergence which can be defined as the necessary condition for optimal learning and used as the simple benchmark for tuning parameters of various neural network realizations with population-rate information coding. At last, a heuristic algorithm is described to experimentally find out the convergence conditions in a memristive SNN, including robustness to a device variability. Due to the generality of the proposed approach, it can be applied to a wide range of memristors and neurons of software- or hardware-based rate-coding single-layer SNNs when searching for local rules that ensure their unsupervised learning convergence in a pattern recognition task domain.}
}
@article{WANG202154,
title = {Supervised and semi-supervised probabilistic learning with deep neural networks for concurrent process-quality monitoring},
journal = {Neural Networks},
volume = {136},
pages = {54-62},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303919},
author = {Kai Wang and Xiaofeng Yuan and Junghui Chen and Yalin Wang},
keywords = {Nonlinear process monitoring, Quality-relevant monitoring, Semi-supervised variational autoencoders, Supervised variational autoencoders},
abstract = {Concurrent process-quality monitoring helps discover quality-relevant process anomalies and quality-irrelevant process anomalies. It especially works well in chemical plants with faults that cause quality problems. Traditional monitoring strategies are limitedly applied in chemical plants because quality targets in training data are insufficient. It is hard for inflexible models to fully capture the strongly nonlinear process-quality correlations. Also, deterministic models are mapped from process variables to qualities without any consideration of uncertainties. Simultaneously, a slow sampling rate for quality variables is ubiquitous in chemical plants since a product quality test is often time-consuming and expensive. Motivated by these limitations, this paper proposes a new concurrent process-quality monitoring scheme based on a probabilistic generative deep learning model developed from variational autoencoder. The supervised model is firstly developed and then the semi-supervised version is extended to solve the issue of missing targets. Especially, the semi-supervised learning algorithm is accomplished with an optimal parameter estimation in the light of maximum likelihood principle and no any hyperparameters are introduced. Two case studies validate that the proposed method effectively outperforms the other comparative methods in concurrent process-quality monitoring.}
}
@article{KOIDEMAJIMA202155,
title = {Quantum-inspired canonical correlation analysis for exponentially large dimensional data},
journal = {Neural Networks},
volume = {135},
pages = {55-67},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304172},
author = {Naoko Koide-Majima and Kei Majima},
keywords = {Canonical correlation analysis, Quantum-inspired computation, High-dimensional data, Machine learning},
abstract = {Canonical correlation analysis (CCA) serves to identify statistical dependencies between pairs of multivariate data. However, its application to high-dimensional data is limited due to considerable computational complexity. As an alternative to the conventional CCA approach that requires polynomial computational time, we propose an algorithm that approximates CCA using quantum-inspired computations with computational time proportional to the logarithm of the input dimensionality. The computational efficiency and performance of the proposed quantum-inspired CCA (qiCCA) algorithm are experimentally evaluated on synthetic and real datasets. Furthermore, the fast computation provided by qiCCA allows directly applying CCA even after nonlinearly mapping raw input data into high-dimensional spaces. The conducted experiments demonstrate that, as a result of mapping raw input data into the high-dimensional spaces with the use of second-order monomials, qiCCA extracts more correlations compared with the linear CCA and achieves comparable performance with state-of-the-art nonlinear variants of CCA on several datasets. These results confirm the appropriateness of the proposed qiCCA and the high potential of quantum-inspired computations in analyzing high-dimensional data.}
}
@article{HUANG2021106,
title = {Stochastic configuration network ensembles with selective base models},
journal = {Neural Networks},
volume = {137},
pages = {106-118},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000198},
author = {Changqin Huang and Ming Li and Dianhui Wang},
keywords = {Stochastic configuration networks, Randomized learner models, Neural network ensemble, Educational data analytics},
abstract = {Studies have demonstrated that stochastic configuration networks (SCNs) have good potential for rapid data modeling because of their sufficient adequate learning power, which is theoretically guaranteed. Empirical studies have verified that the learner models produced by SCNs can usually achieve favorable test performance in practice but more in-depth theoretical analysis of their generalization power would be useful for constructing SCN-based ensemble models with enhanced generalization capacities. In particular, given a collection of independently developed SCN-based learner models, it is useful to select certain base learners that can potentially obtain preferable test results rather than considering all of the base models together, before simply taking their average in order to build an effective ensemble model. In this study, we propose a novel framework for building SCN ensembles by exploring key factors that might potentially affect the generalization performance of the base model. Under a mild assumption, we provide a comprehensive theoretical framework for examining a learner model’s generalization error, as well as formulating a novel indicator that contains measurement information for the training errors, output weights, and a hidden layer output matrix, which can be used by our proposed algorithm to find a subset of appropriate base models from a pool of randomized learner models. A toy example of one-dimensional function approximation, a case study for developing a predictive model for forecasting student learning performance, and two large-scale data sets were used in our experiments. The experimental results indicate that our proposed method has some remarkable advantages for building ensemble models.}
}
@article{PAPAGIANNOPOULOS2021152,
title = {How to teach neural networks to mesh: Application on 2-D simplicial contours},
journal = {Neural Networks},
volume = {136},
pages = {152-179},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304445},
author = {Alexis Papagiannopoulos and Pascal Clausen and François Avellan},
keywords = {Mesh generation, Simplicial mesh, Neural networks, Machine learning},
abstract = {A machine learning meshing scheme for the generation of 2-D simplicial meshes is proposed based on the predictions of neural networks. The data extracted from meshed contours are utilized to train neural networks which are used to approximate the number of vertices to be inserted inside the contour cavity, their location, and connectivity. The accuracy of the scheme is evaluated by comparing the quality of the mesh generated by the neural networks with that generated by a reference mesher. Based on an element quality metric, after conducting tests on contours for a various number of edges, the results show a maximum average deviation of 15.2% on the mean quality and 27.3% on the minimum quality between the elements of the meshes generated by the scheme and the ones generated from the reference mesher; the scheme is able to produce good quality meshes that are suitable for meshing purposes. The meshing scheme is also applied to generate larger scale meshes with a recursive implementation. The findings encourage the adaption of the scheme for 3-D mesh generation.}
}
@article{BELOUADAH202138,
title = {A comprehensive study of class incremental learning algorithms for visual tasks},
journal = {Neural Networks},
volume = {135},
pages = {38-54},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304202},
author = {Eden Belouadah and Adrian Popescu and Ioannis Kanellos},
keywords = {Incremental learning, Catastrophic forgetting, Imbalanced learning, Image classification, Convolutional neural networks},
abstract = {The ability of artificial agents to increment their capabilities when confronted with new data is an open challenge in artificial intelligence. The main challenge faced in such cases is catastrophic forgetting, i.e., the tendency of neural networks to underfit past data when new ones are ingested. A first group of approaches tackles forgetting by increasing deep model capacity to accommodate new knowledge. A second type of approaches fix the deep model size and introduce a mechanism whose objective is to ensure a good compromise between stability and plasticity of the model. While the first type of algorithms were compared thoroughly, this is not the case for methods which exploit a fixed size model. Here, we focus on the latter, place them in a common conceptual and experimental framework and propose the following contributions: (1) define six desirable properties of incremental learning algorithms and analyze them according to these properties, (2) introduce a unified formalization of the class-incremental learning problem, (3) propose a common evaluation framework which is more thorough than existing ones in terms of number of datasets, size of datasets, size of bounded memory and number of incremental states, (4) investigate the usefulness of herding for past exemplars selection, (5) provide experimental evidence that it is possible to obtain competitive performance without the use of knowledge distillation to tackle catastrophic forgetting and (6) facilitate reproducibility by integrating all tested methods in a common open-source repository. The main experimental finding is that none of the existing algorithms achieves the best results in all evaluated settings. Important differences arise notably if a bounded memory of past classes is allowed or not.}
}
@article{BHATTACHARYA2021151,
title = {Statistical foundation of Variational Bayes neural networks},
journal = {Neural Networks},
volume = {137},
pages = {151-173},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000356},
author = {Shrijita Bhattacharya and Tapabrata Maiti},
keywords = {Neural networks, Variational posterior, Mean-field family, Hellinger neighborhood, Kullback–Leibler divergence, Prior mass},
abstract = {Despite the popularism of Bayesian neural networks (BNNs) in recent years, its use is somewhat limited in complex and big data situations due to the computational cost associated with full posterior evaluations. Variational Bayes (VB) provides a useful alternative to circumvent the computational cost and time complexity associated with the generation of samples from the true posterior using Markov Chain Monte Carlo (MCMC) techniques. The efficacy of the VB methods is well established in machine learning literature. However, its potential broader impact is hindered due to a lack of theoretical validity from a statistical perspective. In this paper, we establish the fundamental result of posterior consistency for the mean-field variational posterior (VP) for a feed-forward artificial neural network model. The paper underlines the conditions needed to guarantee that the VP concentrates around Hellinger neighborhoods of the true density function. Additionally, the role of the scale parameter and its influence on the convergence rates has also been discussed. The paper mainly relies on two results (1) the rate at which the true posterior grows (2) the rate at which the Kullback–Leibler (KL) distance between the posterior and variational posterior grows. The theory provides a guideline for building prior distributions for BNNs along with an assessment of accuracy of the corresponding VB implementation.}
}
@article{2023I,
title = {Current Events},
journal = {Neural Networks},
volume = {158},
pages = {I},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00519-6},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005196}
}
@article{WANG2021115,
title = {Modular deep reinforcement learning from reward and punishment for robot navigation},
journal = {Neural Networks},
volume = {135},
pages = {115-126},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304184},
author = {Jiexin Wang and Stefan Elfwing and Eiji Uchibe},
keywords = {Modular reinforcement learning, Deep reinforcement learning, Max pain, Robot navigation, Maze solving},
abstract = {Modular Reinforcement Learning decomposes a monolithic task into several tasks with sub-goals and learns each one in parallel to solve the original problem. Such learning patterns can be traced in the brains of animals. Recent evidence in neuroscience shows that animals utilize separate systems for processing rewards and punishments, illuminating a different perspective for modularizing Reinforcement Learning tasks. MaxPain and its deep variant, Deep MaxPain, showed the advances of such dichotomy-based decomposing architecture over conventional Q-learning in terms of safety and learning efficiency. These two methods differ in policy derivation. MaxPain linearly unified the reward and punishment value functions and generated a joint policy based on unified values; Deep MaxPain tackled scaling problems in high-dimensional cases by linearly forming a joint policy from two sub-policies obtained from their value functions. However, the mixing weights in both methods were determined manually, causing inadequate use of the learned modules. In this work, we discuss the signal scaling of reward and punishment related to discounting factor γ, and propose a weak constraint for signaling design. To further exploit the learning models, we propose a state-value dependent weighting scheme that automatically tunes the mixing weights: hard-max and softmax based on a case analysis of Boltzmann distribution. We focus on maze-solving navigation tasks and investigate how two metrics (pain-avoiding and goal-reaching) influence each other’s behaviors during learning. We propose a sensor fusion network structure that utilizes lidar and images captured by a monocular camera instead of lidar-only and image-only sensing. Our results, both in the simulation of three types of mazes with different complexities and a real robot experiment of an L-maze on Turtlebot3 Waffle Pi, showed the improvements of our methods.}
}
@article{CLAY202123,
title = {Learning sparse and meaningful representations through embodiment},
journal = {Neural Networks},
volume = {134},
pages = {23-41},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303890},
author = {Viviane Clay and Peter König and Kai-Uwe Kühnberger and Gordon Pipa},
keywords = {Reinforcement learning, Deep learning, Embodiment, Embodied cognition, Representation learning, Sparse coding},
abstract = {How do humans acquire a meaningful understanding of the world with little to no supervision or semantic labels provided by the environment? Here we investigate embodiment with a closed loop between action and perception as one key component in this process. We take a close look at the representations learned by a deep reinforcement learning agent that is trained with high-dimensional visual observations collected in a 3D environment with very sparse rewards. We show that this agent learns stable representations of meaningful concepts such as doors without receiving any semantic labels. Our results show that the agent learns to represent the action relevant information, extracted from a simulated camera stream, in a wide variety of sparse activation patterns. The quality of the representations learned shows the strength of embodied learning and its advantages over fully supervised approaches.}
}
@article{CHU2021192,
title = {Constraints on Hebbian and STDP learned weights of a spiking neuron},
journal = {Neural Networks},
volume = {135},
pages = {192-200},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304299},
author = {Dominique Chu and Huy {Le Nguyen}},
keywords = {Hebbian learning, Spike-timing dependent plasticity, Stochastic systems, Novelty detection, MNIST},
abstract = {We analyse mathematically the constraints on weights resulting from Hebbian and STDP learning rules applied to a spiking neuron with weight normalisation. In the case of pure Hebbian learning, we find that the normalised weights equal the promotion probabilities of weights up to correction terms that depend on the learning rate and are usually small. A similar relation can be derived for STDP algorithms, where the normalised weight values reflect a difference between the promotion and demotion probabilities of the weight. These relations are practically useful in that they allow checking for convergence of Hebbian and STDP algorithms. Another application is novelty detection. We demonstrate this using the MNIST dataset.}
}
@article{ZHANG2021110,
title = {A new recursive least squares-based learning algorithm for spiking neurons},
journal = {Neural Networks},
volume = {138},
pages = {110-125},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000241},
author = {Yun Zhang and Hong Qu and Xiaoling Luo and Yi Chen and Yuchen Wang and Malu Zhang and Zefang Li},
keywords = {Supervised learning, Spiking neural networks, Spiking neurons, Recursive least squares},
abstract = {Spiking neural networks (SNNs) are regarded as effective models for processing spatio-temporal information. However, their inherent complexity of temporal coding makes it an arduous task to put forward an effective supervised learning algorithm, which still puzzles researchers in this area. In this paper, we propose a Recursive Least Squares-Based Learning Rule (RLSBLR) for SNN to generate the desired spatio-temporal spike train. During the learning process of our method, the weight update is driven by the cost function defined by the difference between the membrane potential and the firing threshold. The amount of weight modification depends not only on the impact of the current error function, but also on the previous error functions which are evaluated by current weights. In order to improve the learning performance, we integrate a modified synaptic delay learning to the proposed RLSBLR. We conduct experiments in different settings, such as spiking lengths, number of inputs, firing rates, noises and learning parameters, to thoroughly investigate the performance of this learning algorithm. The proposed RLSBLR is compared with competitive algorithms of Perceptron-Based Spiking Neuron Learning Rule (PBSNLR) and Remote Supervised Method (ReSuMe). Experimental results demonstrate that the proposed RLSBLR can achieve higher learning accuracy, higher efficiency and better robustness against different types of noise. In addition, we apply the proposed RLSBLR to open source database TIDIGITS, and the results show that our algorithm has a good practical application performance.}
}
@article{ZHU2021139,
title = {Deep-gKnock: Nonlinear group-feature selection with deep neural networks},
journal = {Neural Networks},
volume = {135},
pages = {139-147},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304214},
author = {Guangyu Zhu and Tingting Zhao},
keywords = {Deep neural networks, False discovery rate, Group feature selection, Knockoffs},
abstract = {Feature selection is central to contemporary high-dimensional data analysis. Group structure among features arises naturally in various scientific problems. Many methods have been proposed to incorporate the group structure information into feature selection. However, these methods are normally restricted to a linear regression setting. To relax the linear constraint, we design a new Deep Neural Network (DNN) architecture and integrating it with the recently proposed knockoff technique to perform nonlinear group-feature selection with controlled group-wise False Discovery Rate (gFDR). Experimental results on high-dimensional synthetic data demonstrate that our method achieves the highest power and accurate gFDR control compared with state-of-the-art methods. The performance of Deep-gKnock is especially superior in the following five situations: (1) nonlinearity relationship; (2) dimension p greater than sample size n; (3) high between-group correlation; (4) high within-group correlation; (5) large number of associated groups. And Deep-gKnock is also demonstrated to be robust to the misspecification of the feature distribution and the change of network architecture. Moreover, Deep-gKnock achieves scientifically meaningful group-feature selection results for cutting-edge real world datasets.}
}
@article{LI202392,
title = {Corrigendum to “Functional connectivity inference from fMRI data using multivariate information measures” [Neural Networks 146 (2022) 85–97]},
journal = {Neural Networks},
volume = {161},
pages = {92},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000217},
author = {Qiang Li}
}
@article{TOKUDA202172,
title = {Chaos may enhance expressivity in cerebellar granular layer},
journal = {Neural Networks},
volume = {136},
pages = {72-86},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304457},
author = {Keita Tokuda and Naoya Fujiwara and Akihito Sudo and Yuichi Katori},
keywords = {Cerebellar granular layer, Reservoir computing, Gap junction, Chaotic dynamics, Sierpinski gasket, Reaction–diffusion system},
abstract = {Recent evidence suggests that Golgi cells in the cerebellar granular layer are densely connected to each other with massive gap junctions. Here, we propose that the massive gap junctions between the Golgi cells contribute to the representational complexity of the granular layer of the cerebellum by inducing chaotic dynamics. We construct a model of cerebellar granular layer with diffusion coupling through gap junctions between the Golgi cells, and evaluate the representational capability of the network with the reservoir computing framework. First, we show that the chaotic dynamics induced by diffusion coupling results in complex output patterns containing a wide range of frequency components. Second, the long non-recursive time series of the reservoir represents the passage of time from an external input. These properties of the reservoir enable mapping different spatial inputs into different temporal patterns.}
}
@article{2023ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {162},
pages = {ii},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00194-6},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001946}
}
@article{GARCIA2021126,
title = {Small universal spiking neural P systems with dendritic/axonal delays and dendritic trunk/feedback},
journal = {Neural Networks},
volume = {138},
pages = {126-139},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000526},
author = {Luis Garcia and Giovanny Sanchez and Eduardo Vazquez and Gerardo Avalos and Esteban Anides and Mariko Nakano and Gabriel Sanchez and Hector Perez},
keywords = {Dendritic trunk, Dendritic feedback, Dendritic delays, Axonal delays, Spiking neural P systems},
abstract = {In spiking neural P (SN P) systems, neurons are interconnected by means of synapses, and they use spikes to communicate with each other. However, in biology, the complex structure of dendritic tree is also an important part in the communication scheme between neurons since these structures are linked to advanced neural process such as learning and memory formation. In this work, we present a new variant of the SN P systems inspired by diverse dendrite and axon phenomena such as dendritic feedback, dendritic trunk, dendritic delays and axonal delays, respectively. This new variant is referred to as a spiking neural P system with dendritic and axonal computation (DACSN P system). Specifically, we include experimentally proven biological features in the current SN P systems to reduce the computational complexity of the soma by providing it with stable firing patterns through dendritic delays, dendritic feedback and axonal delays. As a consequence, the proposed DACSN P systems use the minimum number of synapses and neurons with simple and homogeneous standard spiking rules. Here, we study the computational capabilities of a DACSN P system. In particular, we prove that DACSN P systems with dendritic and axonal behavior are universal as both number-accepting/generating devices. In addition, we constructed a small universal SN P system using 39 neurons with standard spiking rules to compute any Turing computable function.}
}
@article{ROYEN202143,
title = {MaskLayer: Enabling scalable deep learning solutions by training embedded feature sets},
journal = {Neural Networks},
volume = {137},
pages = {43-53},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100023X},
author = {Remco Royen and Leon Denis and Quentin Bolsee and Pengpeng Hu and Adrian Munteanu},
keywords = {Quality scalable, Scalability, Deep learning, Point clouds, Compression, Semantic hashing},
abstract = {Deep learning-based methods have shown to achieve excellent results in a variety of domains, however, some important assets are absent. Quality scalability is one of them. In this work, we introduce a novel and generic neural network layer, named MaskLayer. It can be integrated in any feedforward network, allowing quality scalability by design by creating embedded feature sets. These are obtained by imposing a specific structure of the feature vector during training. To further improve the performance, a masked optimizer and a balancing gradient rescaling approach are proposed. Our experiments show that the cost of introducing scalability using MaskLayer remains limited. In order to prove its generality and applicability, we integrated the proposed techniques in existing, non-scalable networks for point cloud compression and semantic hashing with excellent results. To the best of our knowledge, this is the first work presenting a generic solution able to achieve quality scalable results within the deep learning framework.}
}
@article{KRISHNA202145,
title = {Biomimetic FPGA-based spatial navigation model with grid cells and place cells},
journal = {Neural Networks},
volume = {139},
pages = {45-63},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000368},
author = {Adithya Krishna and Divyansh Mittal and Siri Garudanagiri Virupaksha and Abhishek Ramdas Nair and Rishikesh Narayanan and Chetan Singh Thakur},
keywords = {Path integration, Autonomous robot navigation, Time-multiplexing, Continuous attractor network, Field programmable gate array, Neuromorphic computing},
abstract = {The mammalian spatial navigation system is characterized by an initial divergence of internal representations, with disparate classes of neurons responding to distinct features including location, speed, borders and head direction; an ensuing convergence finally enables navigation and path integration. Here, we report the algorithmic and hardware implementation of biomimetic neural structures encompassing a feed-forward trimodular, multi-layer architecture representing grid-cell, place-cell and decoding modules for navigation. The grid-cell module comprised of neurons that fired in a grid-like pattern, and was built of distinct layers that constituted the dorsoventral span of the medial entorhinal cortex. Each layer was built as an independent continuous attractor network with distinct grid-field spatial scales. The place-cell module comprised of neurons that fired at one or few spatial locations, organized into different clusters based on convergent modular inputs from different grid-cell layers, replicating the gradient in place-field size along the hippocampal dorso-ventral axis. The decoding module, a two-layer neural network that constitutes the convergence of the divergent representations in preceding modules, received inputs from the place-cell module and provided specific coordinates of the navigating object. After vital design optimizations involving all modules, we implemented the tri-modular structure on Zynq Ultrascale+ field-programmable gate array silicon chip, and demonstrated its capacity in precisely estimating the navigational trajectory with minimal overall resource consumption involving a mere 2.92% Look Up Table utilization. Our implementation of a biomimetic, digital spatial navigation system is stable, reliable, reconfigurable, real-time with execution time of about 32 s for 100k input samples (in contrast to 40 minutes on Intel Core i7-7700 CPU with 8 cores clocking at 3.60 GHz) and thus can be deployed for autonomous-robotic navigation without requiring additional sensors.}
}
@article{WANG2021194,
title = {A neurodynamic optimization approach to supervised feature selection via fractional programming},
journal = {Neural Networks},
volume = {136},
pages = {194-206},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000125},
author = {Yadi Wang and Xiaoping Li and Jun Wang},
keywords = {Feature selection, Information-theoretic measures, Fractional programming, Neurodynamic optimization},
abstract = {Feature selection is an important issue in machine learning and data mining. Most existing feature selection methods are greedy in nature thus are prone to sub-optimality. Though some global feature selection methods based on unsupervised redundancy minimization can potentiate clustering performance improvements, their efficacy for classification may be limited. In this paper, a neurodynamics-based holistic feature selection approach is proposed via feature redundancy minimization and relevance maximization. An information-theoretic similarity coefficient matrix is defined based on multi-information and entropy to measure feature redundancy with respect to class labels. Supervised feature selection is formulated as a fractional programming problem based on the similarity coefficients. A neurodynamic approach based on two one-layer recurrent neural networks is developed for solving the formulated feature selection problem. Experimental results with eight benchmark datasets are discussed to demonstrate the global convergence of the neural networks and superiority of the proposed neurodynamic approach to several existing feature selection methods in terms of classification accuracy, precision, recall, and F-measure.}
}
@article{2023I,
title = {Current Events},
journal = {Neural Networks},
volume = {160},
pages = {I},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00105-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001053}
}
@article{2023II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {158},
pages = {II},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00520-2},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005202}
}
@article{KULKARNI202128,
title = {Quantization Friendly MobileNet (QF-MobileNet) Architecture for Vision Based Applications on Embedded Platforms},
journal = {Neural Networks},
volume = {136},
pages = {28-39},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304470},
author = {Uday Kulkarni and Meena S.M. and Sunil V. Gurlahosur and Gopal Bhogar},
keywords = {Deep Neural Network, Classification, MobileNet, Computer vision, Embedded platform, Quantization},
abstract = {Deep Neural Networks (DNNs) have become popular for various applications in the domain of image and computer vision due to their well-established performance attributes. DNN algorithms involve powerful multilevel feature extractions resulting in an extensive range of parameters and memory footprints. However, memory bandwidth requirements, memory footprint and the associated power consumption of models are issues to be addressed to deploy DNN models on embedded platforms for real time vision-based applications. We present an optimized DNN model for memory and accuracy for vision-based applications on embedded platforms. In this paper we propose Quantization Friendly MobileNet (QF-MobileNet) architecture. The architecture is optimized for inference accuracy and reduced resource utilization. The optimization is obtained by addressing the redundancy and quantization loss of the existing baseline MobileNet architectures. We verify and validate the performance of the QF-MobileNet architecture for image classification task on the ImageNet dataset. The proposed model is tested for inference accuracy and resource utilization and compared to the baseline MobileNet architecture. The inference accuracy of the proposed QF-MobileNetV2 float model attained 73.36% and the quantized model has 69.51%. The MobileNetV3 float model attained an inference accuracy of 68.75% and the quantized model has 67.5% respectively. The proposed model saves 33% of time complexity for QF-MobileNetV2 and QF-MobileNetV3 models against the baseline models. The QF-MobileNet also showed optimized resource utilization with 32% fewer tunable parameters, 30% fewer MAC’s operations per image and reduced inference quantization loss by approximately 5% compared to the baseline models. The model is ported onto the android application using TensorFlow API. The android application performs inference on the native devices viz. smartphones, tablets and handheld devices. Future work is focused on introducing channel-wise and layer-wise quantization schemes to the proposed model. We intend to explore quantization aware training of DNN algorithms to achieve optimized resource utilization and inference accuracy.}
}
@article{CHENG202129,
title = {Resilient asynchronous state estimation of Markov switching neural networks: A hierarchical structure approach},
journal = {Neural Networks},
volume = {135},
pages = {29-37},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304196},
author = {Jun Cheng and Yuyan Wu and Lianglin Xiong and Jinde Cao and Ju H. Park},
keywords = {Markov switching neural networks (MSNNs), Hierarchical structure, Signal quantization (SQ), Asynchronous filter},
abstract = {This paper deals with the issue of resilient asynchronous state estimation of discrete-time Markov switching neural networks. Randomly occurring signal quantization and packet dropout are involved in the imperfect measured output. The asynchronous switching phenomena appear among Markov switching neural networks, quantizer modes and filter modes, which are modeled by a hierarchical structure approach. By resorting to the hierarchical structure approach and Lyapunov functional technique, sufficient conditions are achieved, and asynchronous resilient filters are derived such that filtering error dynamic is stochastically stable. Finally, two examples are included to verify the validity of the proposed method.}
}
@article{2023II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {163},
pages = {II},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00242-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023002423}
}
@article{PARK202176,
title = {A brain-inspired network architecture for cost-efficient object recognition in shallow hierarchical neural networks},
journal = {Neural Networks},
volume = {134},
pages = {76-85},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304111},
author = {Youngjin Park and Seungdae Baek and Se-Bum Paik},
keywords = {Visual cortex, Long-range horizontal connection, Object recognition, Shallow network, Artificial neural network, Cost-efficiency},
abstract = {The brain successfully performs visual object recognition with a limited number of hierarchical networks that are much shallower than artificial deep neural networks (DNNs) that perform similar tasks. Here, we show that long-range horizontal connections (LRCs), often observed in the visual cortex of mammalian species, enable such a cost-efficient visual object recognition in shallow neural networks. Using simulations of a model hierarchical network with convergent feedforward connections and LRCs, we found that the addition of LRCs to the shallow feedforward network significantly enhances the performance of networks for image classification, to a degree that is comparable to much deeper networks. We found that a combination of sparse LRCs and dense local connections dramatically increases performance per wiring cost. From network pruning with gradient-based optimization, we also confirmed that LRCs could emerge spontaneously by minimizing the total connection length while maintaining performance. Ablation of emerged LRCs led to a significant reduction of classification performance, which implies these LRCs are crucial for performing image classification. Taken together, our findings suggest a brain-inspired strategy for constructing a cost-efficient network architecture to implement parsimonious object recognition under physical constraints such as shallow hierarchical depth.}
}
@article{KHODER202111,
title = {An enhanced approach to the robust discriminant analysis and class sparsity based embedding},
journal = {Neural Networks},
volume = {136},
pages = {11-16},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304500},
author = {A. Khoder and F. Dornaika},
keywords = {Supervised learning, Discriminant model, Feature extraction, Linear embedding, Inter-class sparsity, Image categorization},
abstract = {In recent times, feature extraction attracted much attention in machine learning and pattern recognition fields. This paper extends and improves a scheme for linear feature extraction that can be used in supervised multi-class classification problems. Inspired by recent frameworks for robust sparse LDA and Inter-class sparsity, we propose a unifying criterion able to retain the advantages of these two powerful linear discriminant methods. We introduce an iterative alternating minimization scheme in order to estimate the linear transformation and the orthogonal matrix. The linear transformation is efficiently updated via the steepest descent gradient technique. The proposed framework is generic in the sense that it allows the combination and tuning of other linear discriminant embedding methods. We used our proposed method to fine tune the linear solutions delivered by two recent linear methods: RSLDA and RDA_FSIS. Experiments have been conducted on public image datasets of different types including objects, faces, and digits. The proposed framework compared favorably with several competing methods.}
}
@article{RIZZOGLIO2021174,
title = {Building an adaptive interface via unsupervised tracking of latent manifolds},
journal = {Neural Networks},
volume = {137},
pages = {174-187},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000174},
author = {Fabio Rizzoglio and Maura Casadio and Dalia {De Santis} and Ferdinando A. Mussa-Ivaldi},
keywords = {Autoencoder networks, Decoder adaptation, Human–machine interaction, Motor learning, Body–machine interface},
abstract = {In human–machine interfaces, decoder calibration is critical to enable an effective and seamless interaction with the machine. However, recalibration is often necessary as the decoder off-line predictive power does not generally imply ease-of-use, due to closed loop dynamics and user adaptation that cannot be accounted for during the calibration procedure. Here, we propose an adaptive interface that makes use of a non-linear autoencoder trained iteratively to perform online manifold identification and tracking, with the dual goal of reducing the need for interface recalibration and enhancing human–machine joint performance. Importantly, the proposed approach avoids interrupting the operation of the device and it neither relies on information about the state of the task, nor on the existence of a stable neural or movement manifold, allowing it to be applied in the earliest stages of interface operation, when the formation of new neural strategies is still on-going. In order to more directly test the performance of our algorithm, we defined the autoencoder latent space as the control space of a body–machine interface. After an initial offline parameter tuning, we evaluated the performance of the adaptive interface versus that of a static decoder in approximating the evolving low-dimensional manifold of users simultaneously learning to perform reaching movements within the latent space. Results show that the adaptive approach increased the representational efficiency of the interface decoder. Concurrently, it significantly improved users’ task-related performance, indicating that the development of a more accurate internal model is encouraged by the online co-adaptation process.}
}
@article{GOMEZFLORES202140,
title = {Smooth dendrite morphological neurons},
journal = {Neural Networks},
volume = {136},
pages = {40-53},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304469},
author = {Wilfrido Gómez-Flores and Humberto Sossa},
keywords = {Morphological neurons, Dendrite processing, Hyperbox-shaped dendrite, Neural networks, Smooth activation functions},
abstract = {A typical feature of hyperbox-based dendrite morphological neurons (DMN) is the generation of sharp and rough decision boundaries that inaccurately track the distribution shape of classes of patterns. This feature is because the minimum and maximum activation functions force the decision boundaries to match the faces of the hyperboxes. To improve the DMN response, we introduce a dendritic model that uses smooth maximum and minimum functions to soften the decision boundaries. The classification performance assessment is conducted on nine synthetic and 28 real-world datasets. Based on the experimental results, we demonstrate that the smooth activation functions improve the generalization capacity of DMN. The proposed approach is competitive with four machine learning techniques, namely, Multilayer Perceptron, Radial Basis Function Network, Support Vector Machine, and Nearest Neighbor algorithm. Besides, the computational complexity of DMN training is lower than MLP and SVM classifiers.}
}
@article{LU2021148,
title = {Deep multi-kernel auto-encoder network for clustering brain functional connectivity data},
journal = {Neural Networks},
volume = {135},
pages = {148-157},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304226},
author = {Hu Lu and Saixiong Liu and Hui Wei and Chao Chen and Xia Geng},
keywords = {Deep neural network, Brain functional connectivity, Auto-encoder, Multi-kernel, Disease diagnosis},
abstract = {In this study, we propose a deep-learning network model called the deep multi-kernel auto-encoder clustering network (DMACN) for clustering functional connectivity data for brain diseases. This model is an end-to-end clustering algorithm that can learn potentially advanced features and cluster disease categories. Unlike other auto-encoders, DMACN has an added self-expression layer and standard back-propagation is used to learn the features that are beneficial for clustering brain functional connectivity data. In the self-expression layer, the kernel matrix is constructed to extract effective features and a new loss function is proposed to constrain the clustering portion, which enables the training of a deep neural learning network that tends to cluster. To test the performance of the proposed algorithm, we applied the end-to-end deep unsupervised clustering algorithm to brain connectivity data. We then conducted experiments based on four public brain functional connectivity data sets and our own functional connectivity data set. The DMACN algorithm yielded good results in various evaluations compared with the existing clustering algorithm for brain functional connectivity data, the deep auto-encoder clustering algorithm, and several other relevant clustering algorithms. The deep-learning-based clustering algorithm has great potential for use in the unsupervised recognition of brain diseases.}
}
@article{SAEZTRIGUEROS202186,
title = {Generating photo-realistic training data to improve face recognition accuracy},
journal = {Neural Networks},
volume = {134},
pages = {86-94},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303932},
author = {Daniel {Sáez Trigueros} and Li Meng and Margaret Hartnett},
keywords = {Image generation, Generative adversarial learning, Face and gesture recognition, Machine learning},
abstract = {Face recognition has become a widely adopted biometric in forensics, security and law enforcement thanks to the high accuracy achieved by systems based on convolutional neural networks (CNNs). However, to achieve good performance, CNNs need to be trained with very large datasets which are not always available. In this paper we investigate the feasibility of using synthetic data to augment face datasets. In particular, we propose a novel generative adversarial network (GAN) that can disentangle identity-related attributes from non-identity-related attributes. This is done by training an embedding network that maps discrete identity labels to an identity latent space that follows a simple prior distribution, and training a GAN conditioned on samples from that distribution. A main novelty of our approach is the ability to generate both synthetic images of subjects in the training set and synthetic images of new subjects not in the training set, both of which we use to augment face datasets. By using recent advances in GAN training, we show that the synthetic images generated by our model are photo-realistic, and that training with datasets augmented with those images can lead to increased recognition accuracy. Experimental results show that our method is more effective when augmenting small datasets. In particular, an absolute accuracy improvement of 8.42% was achieved when augmenting a dataset of less than 60k facial images.}
}
@article{BIHLO20211,
title = {A generative adversarial network approach to (ensemble) weather prediction},
journal = {Neural Networks},
volume = {139},
pages = {1-16},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000459},
author = {Alex Bihlo},
keywords = {Deep learning, Generative adversarial network, Monte-Carlo dropout, Weather prediction, Ensemble weather prediction},
abstract = {We use a conditional deep convolutional generative adversarial network to predict the geopotential height of the 500 hPa pressure level, the two-meter temperature and the total precipitation for the next 24 h over Europe. The proposed models are trained on 4 years of ERA5 reanalysis data from with the goal to predict the associated meteorological fields in 2019. The forecasts show a good qualitative and quantitative agreement with the true reanalysis data for the geopotential height and two-meter temperature, while failing for total precipitation, thus indicating that weather forecasts based on data alone may be possible for specific meteorological parameters. We further use Monte-Carlo dropout to develop an ensemble weather prediction system based purely on deep learning strategies, which is computationally cheap and further improves the skill of the forecasting model, by allowing to quantify the uncertainty in the current weather forecast as learned by the model.}
}
@article{CHEN202198,
title = {Exponential quasi-synchronization of coupled delayed memristive neural networks via intermittent event-triggered control},
journal = {Neural Networks},
volume = {141},
pages = {98-106},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000216},
author = {Jiejie Chen and Boshan Chen and Zhigang Zeng},
keywords = {Coupled memristive neural networks, Intermittent event-triggered control, Exponential synchronization, Quasi-synchronization},
abstract = {Firstly, an intermittent event-triggered control (IETC), as a combination of intermittent control and event-triggered control, is proposed. Then, the quasi-synchronization problem of coupled memristive neural networks with time-varying delays (CDMNN) is discussed under this IETC. To include more of the existing work, aperiodic intermittent control and event-triggered control with combined measurement errors are adopted in the IETC. Under the IETC, it is shown that Zeno behavior cannot be exhibited for CDMNN. At the same time, two new differential inequalities are established, and some simple and practical criteria for CDMNN quasi-synchronization and synchronization are obtained by using these inequalities. In the obtained results, synchronization is a spatial case of quasi-synchronization, and the activation functions of DMNN do not need to be bounded. Finally, a numerical example and some simulations are provided to test the results in theoretical analysis.}
}
@article{QING202124,
title = {End-to-end novel visual categories learning via auxiliary self-supervision},
journal = {Neural Networks},
volume = {139},
pages = {24-32},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000575},
author = {Yuanyuan Qing and Yijie Zeng and Qi Cao and Guang-Bin Huang},
keywords = {Image classification, Novel visual categories, Self-supervision, Pairwise similarity, Local data structure},
abstract = {Semi-supervised learning has largely alleviated the strong demand for large amount of annotations in deep learning. However, most of the methods have adopted a common assumption that there is always labeled data from the same class of unlabeled data, which is impractical and restricted for real-world applications. In this research work, our focus is on semi-supervised learning when the categories of unlabeled data and labeled data are disjoint from each other. The main challenge is how to effectively leverage knowledge in labeled data to unlabeled data when they are independent from each other, and not belonging to the same categories. Previous state-of-the-art methods have proposed to construct pairwise similarity pseudo labels as supervising signals. However, two issues are commonly inherent in these methods: (1) All of previous methods are comprised of multiple training phases, which makes it difficult to train the model in an end-to-end fashion. (2) Strong dependence on the quality of pairwise similarity pseudo labels limits the performance as pseudo labels are vulnerable to noise and bias. Therefore, we propose to exploit the use of self-supervision as auxiliary task during model training such that labeled data and unlabeled data will share the same set of surrogate labels and overall supervising signals can have strong regularization. By doing so, all modules in the proposed algorithm can be trained simultaneously, which will boost the learning capability as end-to-end learning can be achieved. Moreover, we propose to utilize local structure information in feature space during pairwise pseudo label construction, as local properties are more robust to noise. Extensive experiments have been conducted on three frequently used visual datasets, i.e., CIFAR-10, CIFAR-100 and SVHN, in this paper. Experiment results have indicated the effectiveness of our proposed algorithm as we have achieved new state-of-the-art performance for novel visual categories learning for these three datasets.}
}
@article{GONON202110,
title = {Fading memory echo state networks are universal},
journal = {Neural Networks},
volume = {138},
pages = {10-13},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000332},
author = {Lukas Gonon and Juan-Pablo Ortega},
keywords = {Universality, Reservoir computing, Echo state network, Machine learning, Echo state property, Fading memory property},
abstract = {Echo state networks (ESNs) have been recently proved to be universal approximants for input/output systems with respect to various Lp-type criteria. When 1≤p<∞, only p-integrability hypotheses need to be imposed, while in the case p=∞ a uniform boundedness hypotheses on the inputs is required. This note shows that, in the last case, a universal family of ESNs can be constructed that contains exclusively elements that have the echo state and the fading memory properties. This conclusion could not be drawn with the results and methods available so far in the literature.}
}
@article{2023I,
title = {Editorial Board},
journal = {Neural Networks},
volume = {159},
pages = {I},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00035-7},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000357}
}
@article{KOBAYASHI202163,
title = {t-soft update of target network for deep reinforcement learning},
journal = {Neural Networks},
volume = {136},
pages = {63-71},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304482},
author = {Taisuke Kobayashi and Wendyam Eric Lionel Ilboudo},
keywords = {Deep reinforcement learning, Target network, Student-t distribution},
abstract = {This paper proposes a new robust update rule of target network for deep reinforcement learning (DRL), to replace the conventional update rule, given as an exponential moving average. The target network is for smoothly generating the reference signals for a main network in DRL, thereby reducing learning variance. The problem with its conventional update rule is the fact that all the parameters are smoothly copied with the same speed from the main network, even when some of them are trying to update toward the wrong directions. This behavior increases the risk of generating the wrong reference signals. Although slowing down the overall update speed is a naive way to mitigate wrong updates, it would decrease learning speed. To robustly update the parameters while keeping learning speed, a t-soft update method, which is inspired by Student-t distribution, is derived with reference to the analogy between the exponential moving average and the normal distribution. Through the analysis of the derived t-soft update, we show that it takes over the properties of the Student-t distribution. Specifically, with a heavy-tailed property of the Student-t distribution, the t-soft update automatically excludes extreme updates that differ from past experiences. In addition, when the updates are similar to the past experiences, it can mitigate the learning delay by increasing the amount of updates. In PyBullet robotics simulations for DRL, an online actor–critic algorithm with the t-soft update outperformed the conventional methods in terms of the obtained return and/or its variance. From the training process by the t-soft update, we found that the t-soft update is globally consistent with the standard soft update, and the update rates are locally adjusted for acceleration or suppression.}
}
@article{2023I,
title = {CURRENT EVENTS},
journal = {Neural Networks},
volume = {163},
pages = {I},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00241-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023002411}
}
@article{YU202131,
title = {Extracting and inserting knowledge into stacked denoising auto-encoders},
journal = {Neural Networks},
volume = {137},
pages = {31-42},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000186},
author = {Jianbo Yu and Guoliang Liu},
keywords = {Deep learning, Feature learning, Stacked denoised auto-encoders, Knowledge discovery, Knowledge insertion},
abstract = {Deep neural networks (DNNs) with a complex structure and multiple nonlinear processing units have achieved great successes for feature learning in image and visualization analysis. Due to interpretability of the “black box” problem in DNNs, however, there are still many obstacles to applications of DNNs in various real-world cases. This paper proposes a new DNN model, knowledge-based deep stacked denoising auto-encoders (KBSDAE), which inserts the knowledge (i.e., confidence and classification rules) into the deep network structure. This model not only can offer a good understanding of the representations learned by the deep network but also can produce an improvement in the learning performance of stacked denoising auto-encoder (SDAE). The knowledge discovery algorithm is proposed to extract confidence rules to interpret the layerwise network (i.e., denoising auto-encoder (DAE)). The symbolic language is developed to describe the deep network and shows that it is suitable for the representation of quantitative reasoning in a deep network. The confidence rule insertion to the deep network is able to produce an improvement in feature learning of DAEs. The classification rules extracted from the data offer a novel method for knowledge insertion to the classification layer of SDAE. The testing results of KBSDAE on various benchmark data indicate that the proposed method not only effectively extracts knowledge from the deep network, but also shows better feature learning performance than that of those typical DNNs (e.g., SDAE).}
}
@article{CHEN202178,
title = {Insights on the role of external globus pallidus in controlling absence seizures},
journal = {Neural Networks},
volume = {135},
pages = {78-90},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304238},
author = {Mingming Chen and Yajie Zhu and Renping Yu and Yuxia Hu and Hong Wan and Rui Zhang and Dezhong Yao and Daqing Guo},
keywords = {Absence seizures, Spike and wave discharge, The external globus pallidus, Corticothalamic network, Mean-field model},
abstract = {Absence epilepsy, characterized by transient loss of awareness and bilaterally synchronous 2–4 Hz spike and wave discharges (SWDs) on electroencephalography (EEG) during absence seizures, is generally believed to arise from abnormal interactions between the cerebral cortex (Ctx) and thalamus. Recent animal electrophysiological studies suggested that changing the neural activation level of the external globus pallidus (GPe) neurons can remarkably modify firing rates of the thalamic reticular nucleus (TRN) neurons through the GABAergic GPe–TRN pathway. However, the existing experimental evidence does not provide a clear answer as to whether the GPe–TRN pathway contributes to regulating absence seizures. Here, using a biophysically based mean-field model of the GPe-corticothalamic (GCT) network, we found that both directly decreasing the strength of the GPe–TRN pathway and inactivating GPe neurons can effectively suppress absence seizures. Also, the pallido-cortical pathway and the recurrent connection of GPe neurons facilitate the regulation of absence seizures through the GPe–TRN pathway. Specifically, in the controllable situation, enhancing the coupling strength of either of the two pathways can successfully terminate absence seizures. Moreover, the competition between the GPe–TRN and pallido-cortical pathways may lead to the GPe bidirectionally controlling absence seizures, and this bidirectional control manner can be significantly modulated by the Ctx–TRN pathway. Importantly, when the strength of the Ctx–TRN pathway is relatively strong, the bidirectional control of absence seizures by changing GPe neural activities can be observed at both weak and strong strengths of the pallido-cortical pathway.These findings suggest that the GPe–TRN pathway may have crucial functional roles in regulating absence seizures, which may provide a testable hypothesis for further experimental studies and new perspectives on the treatment of absence epilepsy.}
}
@article{ZHANG202197,
title = {Steganographer detection via a similarity accumulation graph convolutional network},
journal = {Neural Networks},
volume = {136},
pages = {97-111},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304512},
author = {Zhi Zhang and Mingjie Zheng and Sheng-hua Zhong and Yan Liu},
keywords = {Image steganographer detection, Graph convolutional network, Graph-based classification, Multiple-instance learning},
abstract = {Steganographer detection aims to identify guilty users who conceal secret information in a number of images for the purpose of covert communication in social networks. Existing steganographer detection methods focus on designing discriminative features but do not explore relationship between image features or effectively represent users based on features. In these methods, each image is recognized as an equivalent, and each user is regarded as the distribution of all images shared by the corresponding user. However, the nuances of guilty users and innocent users are difficult to recognize with this flattened method. In this paper, the steganographer detection task is formulated as a multiple-instance learning problem in which each user is considered to be a bag, and the shared images are multiple instances in the bag. Specifically, we propose a similarity accumulation graph convolutional network to represent each user as a complete weighted graph, in which each node corresponds to features extracted from an image and the weight of an edge is the similarity between each pair of images. The constructed unit in the network can take advantage of the relationships between instances so that common patterns of positive instances can be enhanced via similarity accumulations. Instead of operating on a fixed original graph, we propose a novel strategy for reconstructing and pooling graphs based on node features to iteratively operate multiple convolutions. This strategy can effectively address oversmoothing problems that render nodes indistinguishable although they share different instance-level labels. Compared with the state-of-the-art method and other representative graph-based models, the proposed framework demonstrates its effectiveness and reliability ability across image domains, even in the context of large-scale social media scenarios. Moreover, the experimental results also indicate that the proposed network can be generalized to other multiple-instance learning problems.}
}
@article{TIWARI20211,
title = {DAPath: Distance-aware knowledge graph reasoning based on deep reinforcement learning},
journal = {Neural Networks},
volume = {135},
pages = {1-12},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030410X},
author = {Prayag Tiwari and Hongyin Zhu and Hari Mohan Pandey},
keywords = {Knowledge graph reasoning, Reinforcement learning, Graph self-attention, GRU},
abstract = {Knowledge graph reasoning aims to find reasoning paths for relations over incomplete knowledge graphs (KG). Prior works may not take into account that the rewards for each position (vertex in the graph) may be different. We propose the distance-aware reward in the reinforcement learning framework to assign different rewards for different positions. We observe that KG embeddings are learned from independent triples and therefore cannot fully cover the information described in the local neighborhood. To this effect, we integrate a graph self-attention (GSA) mechanism to capture more comprehensive entity information from the neighboring entities and relations. To let the model remember the path, we incorporate the GSA mechanism with GRU to consider the memory of relations in the path. Our approach can train the agent in one-pass, thus eliminating the pre-training or fine-tuning process, which significantly reduces the problem complexity. Experimental results demonstrate the effectiveness of our method. We found that our model can mine more balanced paths for each relation.}
}
@article{DONG202175,
title = {A training algorithm with selectable search direction for complex-valued feedforward neural networks},
journal = {Neural Networks},
volume = {137},
pages = {75-84},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000228},
author = {Zhongying Dong and He Huang},
keywords = {Complex-valued feedforward neural networks, Selectable search direction, Direction factors, Efficient training, Tree structure},
abstract = {This paper focuses on presenting an efficient training algorithm for complex-valued feedforward neural networks by utilizing a tree structure. The basic idea of the proposed algorithm is that, by introducing a set of direction factors, distinctive search directions are available to be selected at each iteration such that the objective function is reduced as much as possible. Compared with some well-known training algorithms, one of the advantages of our algorithm is that the determination of search direction is of great flexibility and thus more accurate solution is obtained with faster convergence speed. Experimental simulations on pattern recognition, channel equalization and complex function approximation are provided to verify the effectiveness and applications of the proposed algorithm.}
}
@article{EOM2021131,
title = {Deep-learned spike representations and sorting via an ensemble of auto-encoders},
journal = {Neural Networks},
volume = {134},
pages = {131-142},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303944},
author = {Junsik Eom and In Yong Park and Sewon Kim and Hanbyol Jang and Sanggeon Park and Yeowool Huh and Dosik Hwang},
keywords = {Unsupervised spike sorting, Deep learning-based auto-encoder, Feature extraction, Clustering},
abstract = {Spike sorting refers to the technique of detecting signals generated by single neurons from multi-neuron recordings and is a valuable tool for analyzing the relationships between individual neuronal activity patterns and specific behaviors. Since the precision of spike sorting affects all subsequent analyses, sorting accuracy is critical. Many semi-automatic to fully-automatic spike sorting algorithms have been developed. However, due to unsatisfactory classification accuracy, manual sorting is preferred by investigators despite the intensive time and labor costs. Thus, there still is a strong need for fully automatic spike sorting methods with high accuracy. Various machine learning algorithms have been developed for feature extraction but have yet to show sufficient accuracy for spike sorting. Here we describe a deep learning-based method for extracting features from spike signals using an ensemble of auto-encoders, each with a distinct architecture for distinguishing signals at different levels of resolution. By utilizing ensemble of auto-encoder ensemble, where shallow networks better represent overall signal structure and deep networks better represent signal details, extraction of high-dimensional representative features for improved spike sorting performance is achieved. The model was evaluated on publicly available simulated datasets and single-channel and 4-channel tetrode in vivo datasets. Our model not only classified single-channel spikes with varying degrees of feature similarities and signal to noise levels with higher accuracy, but also more precisely determined the number of source neurons compared to other machine learning methods. The model also demonstrated greater overall accuracy for spike sorting 4-channel tetrode recordings compared to single-channel recordings.}
}
@article{APICELLA202114,
title = {A survey on modern trainable activation functions},
journal = {Neural Networks},
volume = {138},
pages = {14-32},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000344},
author = {Andrea Apicella and Francesco Donnarumma and Francesco Isgrò and Roberto Prevete},
keywords = {Neural networks, Machine learning, Activation functions, Trainable activation functions, Learnable activation functions},
abstract = {In neural networks literature, there is a strong interest in identifying and defining activation functions which can improve neural network performance. In recent years there has been a renovated interest in the scientific community in investigating activation functions which can be trained during the learning process, usually referred to as trainable, learnable or adaptable activation functions. They appear to lead to better network performance. Diverse and heterogeneous models of trainable activation function have been proposed in the literature. In this paper, we present a survey of these models. Starting from a discussion on the use of the term “activation function” in literature, we propose a taxonomy of trainable activation functions, highlight common and distinctive proprieties of recent and past models, and discuss main advantages and limitations of this type of approach. We show that many of the proposed approaches are equivalent to adding neuron layers which use fixed (non-trainable) activation functions and some simple local rule that constrains the corresponding weight layers.}
}
@article{PENG202157,
title = {SAM-GAN: Self-Attention supporting Multi-stage Generative Adversarial Networks for text-to-image synthesis},
journal = {Neural Networks},
volume = {138},
pages = {57-67},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000319},
author = {Dunlu Peng and Wuchen Yang and Cong Liu and Shuairui Lü},
keywords = {Text-to-image synthesis, SAM-GAN, Self-attention mechanism, Machine learning},
abstract = {Synthesizing photo-realistic images based on text descriptions is a challenging task in the field of computer vision. Although generative adversarial networks have made significant breakthroughs in this task, they still face huge challenges in generating high-quality visually realistic images consistent with the semantics of text. Generally, existing text-to-image methods accomplish this task with two steps, that is, first generating an initial image with a rough outline and color, and then gradually yielding the image within high-resolution from the initial image. However, one drawback of these methods is that, if the quality of the initial image generation is not high, it is hard to generate a satisfactory high-resolution image. In this paper, we propose SAM-GAN, Self-Attention supporting Multi-stage Generative Adversarial Networks, for text-to-image synthesis. With the self-attention mechanism, the model can establish the multi-level dependence of the image and fuse the sentence- and word-level visual-semantic vectors, to improve the quality of the generated image. Furthermore, a multi-stage perceptual loss is introduced to enhance the semantic similarity between the synthesized image and the real image, thus enhancing the visual-semantic consistency between text and images. For the diversity of the generated images, a mode seeking regularization term is integrated into the model. The results of extensive experiments and ablation studies, which were conducted in the Caltech-UCSD Birds and Microsoft Common Objects in Context datasets, show that our model is superior to competitive models in text-to-image synthesis.}
}
@article{2023II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {162},
pages = {II},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00199-5},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001995}
}
@article{CHENG2021143,
title = {Bridging multimedia heterogeneity gap via Graph Representation Learning for cross-modal retrieval},
journal = {Neural Networks},
volume = {134},
pages = {143-162},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304093},
author = {Qingrong Cheng and Xiaodong Gu},
keywords = {Cross-modal retrieval, Common space learning, Cross-modal graph, Graph representation learning network, Feature transfer learning network, Graph embedding},
abstract = {Information retrieval among different modalities becomes a significant issue with many promising applications. However, inconsistent feature representation of various multimedia data causes the “heterogeneity gap” among various modalities, which is a challenge in cross-modal retrieval. For bridging the “heterogeneity gap,” the popular methods attempt to project the original data into a common representation space, which needs great fitting ability of the model. To address the above issue, we propose a novel Graph Representation Learning (GRL) method for bridging the heterogeneity gap, which does not project the original feature into an aligned representation space but adopts a cross-modal graph to link different modalities. The GRL approach consists of two subnetworks, Feature Transfer Learning Network (FTLN) and Graph Representation Learning Network (GRLN). Firstly, FTLN model finds a latent space for each modality, where the cosine similarity is suitable to describe their similarity. Then, we build a cross-modal graph to reconstruct the original data and their relationships. Finally, we abandon the features in the latent space and turn into embedding the graph vertexes into a common representation space directly. During the process, the proposed Graph Representation Learning method bypasses the most challenging issue by utilizing a cross-modal graph as a bridge to link the “heterogeneity gap” among different modalities. This attempt utilizes a cross-modal graph as an intermediary agent to bridge the “heterogeneity gap” in cross-modal retrieval, which is simple but effective. Extensive experiment results on six widely-used datasets indicate that the proposed GRL outperforms other state-of-the-art cross-modal retrieval methods.}
}
@article{SRINIVASAN20211,
title = {Robustifying models against adversarial attacks by Langevin dynamics},
journal = {Neural Networks},
volume = {137},
pages = {1-17},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304494},
author = {Vignesh Srinivasan and Csaba Rohrer and Arturo Marban and Klaus-Robert Müller and Wojciech Samek and Shinichi Nakajima},
keywords = {Adversarial examples, Robustness, Langevin dynamics},
abstract = {Adversarial attacks on deep learning models have compromised their performance considerably. As remedies, a number of defense methods were proposed, which however, have been circumvented by newer and more sophisticated attacking strategies. In the midst of this ensuing arms race, the problem of robustness against adversarial attacks still remains a challenging task. This paper proposes a novel, simple yet effective defense strategy where off-manifold adversarial samples are driven towards high density regions of the data generating distribution of the (unknown) target class by the Metropolis-adjusted Langevin algorithm (MALA) with perceptual boundary taken into account. To achieve this task, we introduce a generative model of the conditional distribution of the inputs given labels that can be learned through a supervised Denoising Autoencoder (sDAE) in alignment with a discriminative classifier. Our algorithm, called MALA for DEfense (MALADE), is equipped with significant dispersion—projection is distributed broadly. This prevents white box attacks from accurately aligning the input to create an adversarial sample effectively. MALADE is applicable to any existing classifier, providing robust defense as well as off-manifold sample detection. In our experiments, MALADE exhibited state-of-the-art performance against various elaborate attacking strategies.}
}
@article{WANG2021180,
title = {A bioinspired angular velocity decoding neural network model for visually guided flights},
journal = {Neural Networks},
volume = {136},
pages = {180-193},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304251},
author = {Huatian Wang and Qinbing Fu and Hongxin Wang and Paul Baxter and Jigen Peng and Shigang Yue},
keywords = {Insect vision, Motion perception, Angular velocity, Flight control, Tunnel centering, Terrain following},
abstract = {Efficient and robust motion perception systems are important pre-requisites for achieving visually guided flights in future micro air vehicles. As a source of inspiration, the visual neural networks of flying insects such as honeybee and Drosophila provide ideal examples on which to base artificial motion perception models. In this paper, we have used this approach to develop a novel method that solves the fundamental problem of estimating angular velocity for visually guided flights. Compared with previous models, our elementary motion detector (EMD) based model uses a separate texture estimation pathway to effectively decode angular velocity, and demonstrates considerable independence from the spatial frequency and contrast of the gratings. Using the Unity development platform the model is further tested for tunnel centering and terrain following paradigms in order to reproduce the visually guided flight behaviors of honeybees. In a series of controlled trials, the virtual bee utilizes the proposed angular velocity control schemes to accurately navigate through a patterned tunnel, maintaining a suitable distance from the undulating textured terrain. The results are consistent with both neuron spike recordings and behavioral path recordings of real honeybees, thereby demonstrating the model’s potential for implementation in micro air vehicles which have only visual sensors.}
}
@article{KRISNANDA2021141,
title = {Creating and concentrating quantum resource states in noisy environments using a quantum neural network},
journal = {Neural Networks},
volume = {136},
pages = {141-151},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000034},
author = {Tanjung Krisnanda and Sanjib Ghosh and Tomasz Paterek and Timothy C.H. Liew},
keywords = {Neural network applications, Quantum neural network, Optimization, Quantum state preparation, Quantum information, Quantum entanglement, Quantum machine learning},
abstract = {Quantum information processing tasks require exotic quantum states as a prerequisite. They are usually prepared with many different methods tailored to the specific resource state. Here we provide a versatile unified state preparation scheme based on a driven quantum network composed of randomly-coupled fermionic nodes. The output of such a system is then superposed with the help of linear mixing where weights and phases are trained in order to obtain desired output quantum states. We explicitly show that our method is robust and can be utilized to create almost perfect maximally entangled, NOON, W, cluster, and discorded states. Furthermore, the treatment includes energy decay in the system as well as dephasing and depolarization. Under these noisy conditions we show that the target states are achieved with high fidelity by tuning controllable parameters and providing sufficient strength to the driving of the quantum network. Finally, in very noisy systems, where noise is comparable to the driving strength, we show how to concentrate entanglement by mixing more states in a larger network.}
}
@article{KIM2021173,
title = {Effect of diverse recoding of granule cells on optokinetic response in a cerebellar ring network with synaptic plasticity},
journal = {Neural Networks},
volume = {134},
pages = {173-204},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304123},
author = {Sang-Yoon Kim and Woochang Lim},
keywords = {Optokinetic response, Cerebellar ring network, Diverse recoding, Effective long-term depression, Effective motor learning},
abstract = {We consider a cerebellar ring network for the optokinetic response (OKR), and investigate the effect of diverse recoding of granule (GR) cells on OKR by varying the connection probability pc from Golgi to GR cells. For an optimal value of pc∗(=0.06), individual GR cells exhibit diverse spiking patterns which are in-phase, anti-phase, or complex out-of-phase with respect to their population-averaged firing activity. Then, these diversely-recoded signals via parallel fibers (PFs) from GR cells are effectively depressed by the error-teaching signals via climbing fibers from the inferior olive which are also in-phase ones. Synaptic weights at in-phase PF-Purkinje cell (PC) synapses of active GR cells are strongly depressed via strong long-term depression (LTD), while those at anti-phase and complex out-of-phase PF-PC synapses are weakly depressed through weak LTD. This kind of “effective” depression (i.e., strong/weak LTD) at the PF-PC synapses causes a big modulation in firings of PCs, which then exert effective inhibitory coordination on the vestibular nucleus (VN) neuron (which evokes OKR). For the firing of the VN neuron, the learning gain degree Lg, corresponding to the modulation gain ratio, increases with increasing the learning cycle, and it saturates at about the 300th cycle. By varying pc from pc∗, we find that a plot of saturated learning gain degree Lg∗ versus pc forms a bell-shaped curve with a peak at pc∗ (where the diversity degree in spiking patterns of GR cells is also maximum). Consequently, the more diverse in recoding of GR cells, the more effective in motor learning for the OKR adaptation.}
}
@article{DAVIS202178,
title = {Compositional memory in attractor neural networks with one-step learning},
journal = {Neural Networks},
volume = {138},
pages = {78-97},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000393},
author = {Gregory P. Davis and Garrett E. Katz and Rodolphe J. Gentili and James A. Reggia},
keywords = {Compositionality, Working memory, Itinerant attractor dynamics, Multiplicative gating, One-step learning, Programmable neural networks},
abstract = {Compositionality refers to the ability of an intelligent system to construct models out of reusable parts. This is critical for the productivity and generalization of human reasoning, and is considered a necessary ingredient for human-level artificial intelligence. While traditional symbolic methods have proven effective for modeling compositionality, artificial neural networks struggle to learn systematic rules for encoding generalizable structured models. We suggest that this is due in part to short-term memory that is based on persistent maintenance of activity patterns without fast weight changes. We present a recurrent neural network that encodes structured representations as systems of contextually-gated dynamical attractors called attractor graphs. This network implements a functionally compositional working memory that is manipulated using top-down gating and fast local learning. We evaluate this approach with empirical experiments on storage and retrieval of graph-based data structures, as well as an automated hierarchical planning task. Our results demonstrate that compositional structures can be stored in and retrieved from neural working memory without persistent maintenance of multiple activity patterns. Further, memory capacity is improved by the use of a fast store-erase learning rule that permits controlled erasure and mutation of previously learned associations. We conclude that the combination of top-down gating and fast associative learning provides recurrent neural networks with a robust functional mechanism for compositional working memory.}
}
@article{PENG202168,
title = {Unsupervised cross-domain named entity recognition using entity-aware adversarial training},
journal = {Neural Networks},
volume = {138},
pages = {68-77},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304524},
author = {Qi Peng and Changmeng Zheng and Yi Cai and Tao Wang and Haoran Xie and Qing Li},
keywords = {Named entity recognition, Unsupervised cross-domain, Adversarial training, Entity-aware attention},
abstract = {The success of neural network based methods in named entity recognition (NER) is heavily relied on abundant manual labeled data. However, these NER methods are unavailable when the data is fully-unlabeled in a new domain. To address the problem, we propose an unsupervised cross-domain model which leverages labeled data from source domain to predict entities in unlabeled target domain. To relieve the distribution divergence when transferring knowledge from source to target domain, we apply adversarial training. Furthermore, we design an entity-aware attention module to guide the adversarial training to reduce the discrepancy of entity features between different domains. Experimental results demonstrate that our model outperforms other methods and achieves state-of-the-art performance.}
}
@article{MAHAN202185,
title = {Nonclosedness of sets of neural networks in Sobolev spaces},
journal = {Neural Networks},
volume = {137},
pages = {85-96},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000150},
author = {Scott Mahan and Emily J. King and Alex Cloninger},
keywords = {Fixed-architecture neural networks, Neural network expressivity, Closedness, Sobolev space},
abstract = {We examine the closedness of sets of realized neural networks of a fixed architecture in Sobolev spaces. For an exactly m-times differentiable activation function ρ, we construct a sequence of neural networks (Φn)n∈N whose realizations converge in order-(m−1) Sobolev norm to a function that cannot be realized exactly by a neural network. Thus, sets of realized neural networks are not closed in order-(m−1) Sobolev spaces Wm−1,p for p∈[1,∞). We further show that these sets are not closed in Wm,p under slightly stronger conditions on the mth derivative of ρ. For a real analytic activation function, we show that sets of realized neural networks are not closed in Wk,p for any k∈N. The nonclosedness allows for approximation of non-network target functions with unbounded parameter growth. We partially characterize the rate of parameter growth for most activation functions by showing that a specific sequence of realized neural networks can approximate the activation function’s derivative with weights increasing inversely proportional to the Lp approximation error. Finally, we present experimental results showing that networks are capable of closely approximating non-network target functions with increasing parameters via training.}
}
@article{KIM2021179,
title = {Fast convergence rates of deep neural networks for classification},
journal = {Neural Networks},
volume = {138},
pages = {179-197},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100054X},
author = {Yongdai Kim and Ilsang Ohn and Dongha Kim},
keywords = {Classification, Deep neural network, Excess risk, Fast convergence rate},
abstract = {We derive the fast convergence rates of a deep neural network (DNN) classifier with the rectified linear unit (ReLU) activation function learned using the hinge loss. We consider three cases for a true model: (1) a smooth decision boundary, (2) smooth conditional class probability, and (3) the margin condition (i.e., the probability of inputs near the decision boundary is small). We show that the DNN classifier learned using the hinge loss achieves fast rate convergences for all three cases provided that the architecture (i.e., the number of layers, number of nodes and sparsity) is carefully selected. An important implication is that DNN architectures are very flexible for use in various cases without much modification. In addition, we consider a DNN classifier learned by minimizing the cross-entropy, and show that the DNN classifier achieves a fast convergence rate under the conditions that the noise exponent and margin exponent are large. Even though they are strong, we explain that these two conditions are not too absurd for image classification problems. To confirm our theoretical explanation, we present the results of a small numerical study conducted to compare the hinge loss and cross-entropy.}
}
@article{GUHRING2021107,
title = {Approximation rates for neural networks with encodable weights in smoothness spaces},
journal = {Neural Networks},
volume = {134},
pages = {107-130},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303956},
author = {Ingo Gühring and Mones Raslan},
keywords = {Neural networks, Expressivity, Approximation rates, Smoothness spaces, Encodable weights},
abstract = {We examine the necessary and sufficient complexity of neural networks to approximate functions from different smoothness spaces under the restriction of encodable network weights. Based on an entropy argument, we start by proving lower bounds for the number of nonzero encodable weights for neural network approximation in Besov spaces, Sobolev spaces and more. These results are valid for all sufficiently smooth activation functions. Afterwards, we provide a unifying framework for the construction of approximate partitions of unity by neural networks with fairly general activation functions. This allows us to approximate localized Taylor polynomials by neural networks and make use of the Bramble–Hilbert Lemma. Based on our framework, we derive almost optimal upper bounds in higher-order Sobolev norms. This work advances the theory of approximating solutions of partial differential equations by neural networks.}
}
@article{YANG2021212,
title = {Finite-time cluster synchronization in complex-variable networks with fractional-order and nonlinear coupling},
journal = {Neural Networks},
volume = {135},
pages = {212-224},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304408},
author = {Shuai Yang and Cheng Hu and Juan Yu and Haijun Jiang},
keywords = {Fractional calculus, Complex-variable networks, Nonlinear coupling, Finite-time cluster synchronization, Non-decomposition method},
abstract = {This paper is primarily concentrated on finite-time cluster synchronization of fractional-order complex-variable networks with nonlinear coupling by utilizing the non-decomposition method. Firstly, two control strategies are designed which are relevant to complex-valued sign functions. Thereafter, by employing fractional-order stability theory and complex function theory, several criteria are deduced to ensure finite-time cluster synchronization under the framework within a new norm consisting of absolute values for real and imaginary components. Furthermore, the setting time is effectively estimated based on some significant properties of fractional-order Caputo derivation and Mittag-Leffler functions. Lastly, two numerical examples are given to verify the effectiveness of theoretical results.}
}
@article{BOARETTO202197,
title = {The role of individual neuron ion conductances in the synchronization processes of neuron networks},
journal = {Neural Networks},
volume = {137},
pages = {97-105},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000277},
author = {B.R.R. Boaretto and C. Manchein and T.L. Prado and S.R. Lopes},
keywords = {Neural networks, Phase synchronization, Hodgkin–Huxley},
abstract = {The partial phase synchronization (sometimes called cooperation) of neurons is fundamental for the understanding of the complex behavior of the brain. The lack or the excess of synchronization can generate brain disorders like Parkinson’s disease and epilepsy. The phase synchronization phenomenon is strongly related to the regular or chaotic dynamics of individual neurons. The individual dynamics themselves are a function of the ion channel conductances, turning the conductances into important players in the process of neuron synchronized health depolarization/repolarization processes. It is well known that many diseases are related to alterations of the ion-channel conductance properties. To normalize their functioning, drugs are used to block or activate specific channels, changing their conductances. We investigate the synchronization process of a Hodgkin–Huxley-type neural network as a function of the values of the individual neuron conductances, showing the dynamics of the neurons must be taken into account in the synchronization process. Particular sets of conductances lead to non-chaotic individual neuron dynamics allowing synchronization states for very weak coupling and resulting in a non-monotonic transition to synchronized states, as the coupling strength among neurons is varied. On the other hand, a monotonic transition to synchronized states is observed for individual chaotic dynamics of the neurons. We conclude the analysis of the individual dynamics of isolated neurons allows the prediction of the synchronization process of the network. We provide alternative ways to achieve the desired network state (phase synchronized or desynchronized) without any changes in the synaptic current of neurons but making just small changes in the neuron ion-channel conductances. The mechanism behind the control is the close relation between ion-channel conductance and the regular or chaotic dynamics of neurons. Finally, we show that by changing at least two conductances simultaneously the control may be much more efficient since the second conductance makes the synchronization possible just by performing a small change in the first. The study presented here may have an impact on new drug development research.}
}
@article{2023II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {160},
pages = {II},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00106-5},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001065}
}
@article{PENG2021188,
title = {Bilateral attention decoder: A lightweight decoder for real-time semantic segmentation},
journal = {Neural Networks},
volume = {137},
pages = {188-199},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000290},
author = {Chengli Peng and Tian Tian and Chen Chen and Xiaojie Guo and Jiayi Ma},
keywords = {Semantic segmentation, Real time, Deep learning, Attention mechanism},
abstract = {The encoder–decoder structure has been introduced into semantic segmentation to improve the spatial accuracy of the network by fusing high- and low-level feature maps. However, recent state-of-the-art encoder–decoder-based methods can hardly attain the real-time requirement due to their complex and inefficient decoders. To address this issue, in this paper, we propose a lightweight bilateral attention decoder for real-time semantic segmentation. It consists of two blocks and can fuse different level feature maps via two steps, i.e., information refinement and information fusion. In the first step, we propose a channel attention branch to refine the high-level feature maps and a spatial attention branch for the low-level ones. The refined high-level feature maps can capture more exact semantic information and the refined low-level ones can capture more accurate spatial information, which significantly improves the information capturing ability of these feature maps. In the second step, we develop a new fusion module named pooling fusing block to fuse the refined high- and low-level feature maps. This fusion block can take full advantages of the high- and low-level feature maps, leading to high-quality fusion results. To verify the efficiency of the proposed bilateral attention decoder, we adopt a lightweight network as the backbone and compare our proposed method with other state-of-the-art real-time semantic segmentation methods on the Cityscapes and Camvid datasets. Experimental results demonstrate that our proposed method can achieve better performance with a higher inference speed. Moreover, we compare our proposed network with several state-of-the-art non-real-time semantic segmentation methods and find that our proposed network can also attain better segmentation performance.}
}
@article{LANGE202364,
title = {Corrigendum to “Interfering with a memory without erasing its trace” [Neural Networks 121 (2020) 339–355]},
journal = {Neural Networks},
volume = {163},
pages = {64},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.03.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001624},
author = {Gesa Lange and Mario Senden and Alexandra Radermacher and Peter {De Weerd}}
}
@article{DHARMARETNAM202163,
title = {Words as a window: Using word embeddings to explore the learned representations of Convolutional Neural Networks},
journal = {Neural Networks},
volume = {137},
pages = {63-74},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304263},
author = {Dhanush Dharmaretnam and Chris Foster and Alona Fyshe},
keywords = {Deep learning, Interpretation, Convolutional Neural Nets, CNNs, Word vectors, Distributional Semantics},
abstract = {As deep neural net architectures minimize loss, they accumulate information in a hierarchy of learned representations that ultimately serve the network’s final goal. Different architectures tackle this problem in slightly different ways, but all create intermediate representational spaces built to inform their final prediction. Here we show that very different neural networks trained on two very different tasks build knowledge representations that display similar underlying patterns. Namely, we show that the representational spaces of several distributional semantic models bear a remarkable resemblance to several Convolutional Neural Network (CNN) architectures (trained for image classification). We use this information to explore the network behavior of CNNs (1) in pretrained models, (2) during training, and (3) during adversarial attacks. We use these findings to motivate several applications aimed at improving future research on CNNs. Our work illustrates the power of using one model to explore another, gives new insights into the function of CNN models, and provides a framework for others to perform similar analyses when developing new architectures. We show that one neural network model can provide a window into understanding another.}
}
@article{2023I,
title = {Current Events},
journal = {Neural Networks},
volume = {162},
pages = {I},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00198-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023001983}
}
@article{HAYASHI2021127,
title = {The exact asymptotic form of Bayesian generalization error in latent Dirichlet allocation},
journal = {Neural Networks},
volume = {137},
pages = {127-137},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000320},
author = {Naoki Hayashi},
keywords = {Latent Dirichlet allocation (LDA), Real log canonical threshold (RLCT), Learning coefficient, Bayesian inference, Generalization error, Singular learning theory},
abstract = {Latent Dirichlet allocation (LDA) obtains essential information from data by using Bayesian inference. It is applied to knowledge discovery via dimension reducing and clustering in many fields. However, its generalization error had not been yet clarified since it is a singular statistical model where there is no one-to-one mapping from parameters to probability distributions. In this paper, we give the exact asymptotic form of its generalization error and marginal likelihood, by theoretical analysis of its learning coefficient using algebraic geometry. The theoretical result shows that the Bayesian generalization error in LDA is expressed in terms of that in matrix factorization and a penalty from the simplex restriction of LDA’s parameter region. A numerical experiment is consistent with the theoretical result.}
}
@article{NAGHIZADEH202168,
title = {Greedy auto-augmentation for n-shot learning using deep neural networks},
journal = {Neural Networks},
volume = {135},
pages = {68-77},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304135},
author = {Alireza Naghizadeh and Dimitris N. Metaxas and Dongfang Liu},
keywords = {Augmentation, AutoAugment, n-shot, Few-shot, ANN, Greedy},
abstract = {The goal of n-shot learning is the classification of input data from small datasets. This type of learning is challenging in neural networks, which typically need a high number of data during the training process. Recent advancements in data augmentation allow us to produce an infinite number of target conditions from the primary condition. This process includes two main steps for finding the best augmentations and training the data with the new augmentation techniques. Optimizing these two steps for n-shot learning is still an open problem. In this paper, we propose a new method for auto-augmentation to address both of these problems. The proposed method can potentially extract many possible types of information from a small number of available data points in n-shot learning. The results of our experiments on five prominent n-shot learning datasets show the effectiveness of the proposed method.}
}
@article{SONG202118,
title = {Passive filter design for fractional-order quaternion-valued neural networks with neutral delays and external disturbance},
journal = {Neural Networks},
volume = {137},
pages = {18-30},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000162},
author = {Qiankun Song and Sihan Chen and Zhenjiang Zhao and Yurong Liu and Fuad E. Alsaadi},
keywords = {Fractional-order, Quaternion-valued neural networks, Neutral delay, Passive filtering, Linear matrix inequality},
abstract = {The problem on passive filter design for fractional-order quaternion-valued neural networks (FOQVNNs) with neutral delays and external disturbance is considered in this paper. Without separating the FOQVNNs into two complex-valued neural networks (CVNNs) or the FOQVNNs into four real-valued neural networks (RVNNs), by constructing Lyapunov–Krasovskii functional and using inequality technique, the delay-independent and delay-dependent sufficient conditions presented as linear matrix inequality (LMI) to confirm the augmented filtering dynamic system to be stable and passive with an expected dissipation are derived. One numerical example with simulations is furnished to pledge the feasibility for the obtained theory results.}
}
@article{QIAO202191,
title = {Sparse deep dictionary learning identifies differences of time-varying functional connectivity in brain neuro-developmental study},
journal = {Neural Networks},
volume = {135},
pages = {91-104},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030424X},
author = {Chen Qiao and Lan Yang and Vince D. Calhoun and Zong-Ben Xu and Yu-Ping Wang},
keywords = {Deep dictionary learning, Deep autoencoder, Sparsity, Dynamic functional connectivity, Reoccurring pattern, Brain development},
abstract = {Recently, the focus of functional connectivity analysis of human brain has shifted from merely revealing the inter-regional functional correlation over the entire scan duration to capturing the time-varying information of brain networks and characterizing time-resolved reoccurring patterns of connectivity. Much effort has been invested into developing approaches that can track changes in re-occurring patterns of functional connectivity over time. In this paper, we propose a sparse deep dictionary learning method to characterize the essential differences of reoccurring patterns of time-varying functional connectivity between different age groups. The proposed method combines both the interpretability of sparse dictionary learning and the capability of extracting sparse nonlinear higher-level features in the latent space of sparse deep autoencoder. In other words, it learns a sparse dictionary of the original data by considering the nonlinear representation of the data in the encoder layer based on a sparse deep autoencoder. In this way, the nonlinear structure and higher-level features of the data can be captured by deep dictionary learning. The proposed method is applied to the analysis of the Philadelphia Neurodevelopmental Cohort. It shows that there exist essential differences in the reoccurrence patterns of function connectivity between child and young adult groups. Specially, children have more diffusive functional connectivity patterns while young adults possess more focused functional connectivity patterns, and the brain function transits from undifferentiated systems to specialized neural networks with the growth.}
}
@article{LIU2021112,
title = {A Dual-Dimer method for training physics-constrained neural networks with minimax architecture},
journal = {Neural Networks},
volume = {136},
pages = {112-125},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.12.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020304536},
author = {Dehao Liu and Yan Wang},
keywords = {Machine learning, Physics-constrained neural networks, Partial differential equation, Minimax problem, Saddle point search},
abstract = {Data sparsity is a common issue to train machine learning tools such as neural networks for engineering and scientific applications, where experiments and simulations are expensive. Recently physics-constrained neural networks (PCNNs) were developed to reduce the required amount of training data. However, the weights of different losses from data and physical constraints are adjusted empirically in PCNNs. In this paper, a new physics-constrained neural network with the minimax architecture (PCNN-MM) is proposed so that the weights of different losses can be adjusted systematically. The training of the PCNN-MM is searching the high-order saddle points of the objective function. A novel saddle point search algorithm called Dual-Dimer method is developed. It is demonstrated that the Dual-Dimer method is computationally more efficient than the gradient descent ascent method for nonconvex–nonconcave functions and provides additional eigenvalue information to verify search results. A heat transfer example also shows that the convergence of PCNN-MMs is faster than that of traditional PCNNs.}
}
@article{LIU2021164,
title = {Recurrent neural network with noise rejection for cyclic motion generation of robotic manipulators},
journal = {Neural Networks},
volume = {138},
pages = {164-178},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000447},
author = {Mei Liu and Li He and Bin Hu and Shuai Li},
keywords = {Recurrent neural network, Cyclic motion generation, Joint-angle drift, Noise rejection},
abstract = {Recurrent neural network (RNN), as a kind of neural network with outstanding computing capability, improvability, and hardware realizability, has been widely used in various fields, especially in robotics. In this paper, an RNN with noise rejection is deliberately constructed to remedy the issue of joint-angle drift frequently occurring during the cyclic motion generation (CMG) of a manipulator in a noisy environment. Different from general RNNs, the proposed RNN possesses inherent noise immunity, especially for time-varying polynomial noises. Besides, proofs on the convergence of the proposed RNN in the absence and presence of noises are given. Furthermore, we carry out simulations on manipulators PUMA 560 and UR5 to demonstrate the reliability of the proposed RNN in remedying joint-angle drift, and comparison simulations under different noisy conditions further verify its superiority. In addition, experiments are conducted on manipulator FRANKA Panda to elucidate the realizability of the proposed RNN.}
}
@article{JU20211,
title = {A proximal neurodynamic model for solving inverse mixed variational inequalities},
journal = {Neural Networks},
volume = {138},
pages = {1-9},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000204},
author = {Xingxing Ju and Chuandong Li and Xing He and Gang Feng},
keywords = {Proximal neurodynamic model, Inverse mixed variational inequalities, Lipschitz continuous, Strong monotonicity, Exponential stability},
abstract = {This paper proposes a proximal neurodynamic model (PNDM) for solving inverse mixed variational inequalities (IMVIs) based on the proximal operator. It is shown that the PNDM has a unique continuous solution under the condition of Lipschitz continuity (L-continuity). It is also shown that the equilibrium point of the proposed PNDM is asymptotically stable or exponentially stable under some mild conditions. Finally, three numerical examples are presented to illustrate effectiveness of the proposed PNDM.}
}
@article{SCHMIDTHIEBER2021119,
title = {The Kolmogorov–Arnold representation theorem revisited},
journal = {Neural Networks},
volume = {137},
pages = {119-126},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000289},
author = {Johannes Schmidt-Hieber},
keywords = {Kolmogorov–Arnold representation theorem, Function approximation, Deep ReLU networks, Space-filling curves},
abstract = {There is a longstanding debate whether the Kolmogorov–Arnold representation theorem can explain the use of more than one hidden layer in neural networks. The Kolmogorov–Arnold representation decomposes a multivariate function into an interior and an outer function and therefore has indeed a similar structure as a neural network with two hidden layers. But there are distinctive differences. One of the main obstacles is that the outer function depends on the represented function and can be wildly varying even if the represented function is smooth. We derive modifications of the Kolmogorov–Arnold representation that transfer smoothness properties of the represented function to the outer function and can be well approximated by ReLU networks. It appears that instead of two hidden layers, a more natural interpretation of the Kolmogorov–Arnold representation is that of a deep neural network where most of the layers are required to approximate the interior function.}
}