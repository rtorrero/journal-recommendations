@article{CAI2023227,
title = {Robust exponential stability of discrete-time uncertain impulsive stochastic neural networks with delayed impulses},
journal = {Neural Networks},
volume = {160},
pages = {227-237},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000163},
author = {Ting Cai and Pei Cheng and Fengqi Yao and Mingang Hua},
keywords = {Discrete-time stochastic systems, Neural networks, Delayed impulses, Robust exponential stability, Razumikhin technique},
abstract = {This paper is devoted to the study of the robust exponential stability (RES) of discrete-time uncertain impulsive stochastic neural networks (DTUISNNs) with delayed impulses. Using Lyapunov function methods and Razumikhin techniques, a number of sufficient conditions for mean square (RES-ms) robust exponential stability are derived. The obtained results show that the hybrid dynamic is RES-ms with regard to lower boundary of impulse interval if the discrete-time stochastic neural networks (DTSNNs) is RES-ms and that the impulsive effects are instable. Conversely, if DTSNNs is not RES-ms, impulsive effects can induce unstable neural networks (NNs) to stabilize again concerning an upper bound of the impulsive interval. The results obtained in this study have a broader scope of application than some previously existing findings. Two numerical examples were presented to verify the availability and advantages of the results.}
}
@article{PAN202322,
title = {Multi-granularity graph pooling for video-based person re-identification},
journal = {Neural Networks},
volume = {160},
pages = {22-33},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200507X},
author = {Honghu Pan and Yongyong Chen and Zhenyu He},
keywords = {Person re-identification, Graph neural networks, Graph pooling},
abstract = {The video-based person re-identification (ReID) aims to identify the given pedestrian video sequence across multiple non-overlapping cameras. To aggregate the temporal and spatial features of the video samples, the graph neural networks (GNNs) are introduced. However, existing graph-based models, like STGCN, perform the mean/max pooling on node features to obtain the graph representation, which neglect the graph topology and node importance. In this paper, we propose the graph pooling network (GPNet) to learn the multi-granularity graph representation for the video retrieval, where the graph pooling layer is implemented to downsample the graph. We construct a multi-granular graph by using node features learned from backbone, then implement multiple graph convolutional layers to perform the spatial and temporal aggregation on nodes. To downsample the graph, we propose a multi-head full attention graph pooling (MHFAPool) layer, which integrates the advantages of existing node clustering and node selection pooling methods. Specifically, MHFAPool first learns a full attention matrix for each pooled node, then obtains the principal eigenvector of the attention matrix via the power iteration algorithm, finally takes the softmax of the principal eigenvector as the aggregation coefficients. Extensive experiments demonstrate that our GPNet achieves the competitive results on four widely-used datasets, i.e., MARS, DukeMTMC-VideoReID, iLIDS-VID and PRID-2011.}
}
@article{WATANABE2023148,
title = {Deep learning in random neural fields: Numerical experiments via neural tangent kernel},
journal = {Neural Networks},
volume = {160},
pages = {148-163},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005123},
author = {Kaito Watanabe and Kotaro Sakamoto and Ryo Karakida and Sho Sonoda and Shun-ichi Amari},
keywords = {Random neural field, Neural tangent kernel, Supervised learning, Reproducing kernel Hilbert space},
abstract = {A biological neural network in the cortex forms a neural field. Neurons in the field have their own receptive fields, and connection weights between two neurons are random but highly correlated when they are in close proximity in receptive fields. In this paper, we investigate such neural fields in a multilayer architecture to investigate the supervised learning of the fields. We empirically compare the performances of our field model with those of randomly connected deep networks. The behavior of a randomly connected network is investigated on the basis of the key idea of the neural tangent kernel regime, a recent development in the machine learning theory of over-parameterized networks; for most randomly connected neural networks, it is shown that global minima always exist in their small neighborhoods. We numerically show that this claim also holds for our neural fields. In more detail, our model has two structures: (i) each neuron in a field has a continuously distributed receptive field, and (ii) the initial connection weights are random but not independent, having correlations when the positions of neurons are close in each layer. We show that such a multilayer neural field is more robust than conventional models when input patterns are deformed by noise disturbances. Moreover, its generalization ability can be slightly superior to that of conventional models.}
}
@article{SUETAKE2023208,
title = {S3NN: Time step reduction of spiking surrogate gradients for training energy efficient single-step spiking neural networks},
journal = {Neural Networks},
volume = {159},
pages = {208-219},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005007},
author = {Kazuma Suetake and Shin-ichi Ikegawa and Ryuji Saiin and Yoshihide Sawada},
keywords = {Spiking neural network, Binary neural network, Surrogate gradient, Energy efficiency, Single-time step},
abstract = {As the scales of neural networks increase, techniques that enable them to run with low computational cost and energy efficiency are required. From such demands, various efficient neural network paradigms, such as spiking neural networks (SNNs) or binary neural networks (BNNs), have been proposed. However, they have sticky drawbacks, such as degraded inference accuracy and latency. To solve these problems, we propose a single-step spiking neural network (S3NN), an energy-efficient neural network with low computational cost and high precision. The proposed S3NN processes the information between hidden layers by spikes as SNNs. Nevertheless, it has no temporal dimension so that there is no latency within training and inference phases as BNNs. Thus, the proposed S3NN has a lower computational cost than SNNs that require time-series processing. However, S3NN cannot adopt naïve backpropagation algorithms due to the non-differentiability nature of spikes. We deduce a suitable neuron model by reducing the surrogate gradient for multi-time step SNNs to a single-time step. We experimentally demonstrated that the obtained surrogate gradient allows S3NN to be trained appropriately. We also showed that the proposed S3NN could achieve comparable accuracy to full-precision networks while being highly energy-efficient.}
}
@article{ZHENG20231,
title = {Quasi-synchronization of drive–response systems with parameter mismatch via event-triggered impulsive control},
journal = {Neural Networks},
volume = {161},
pages = {1-8},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000205},
author = {Huannan Zheng and Nanxiang Yu and Wei Zhu},
keywords = {Quasi-synchronization, Drive–response systems, Parameter mismatch, Event-triggered impulsive control, Zeno-behavior},
abstract = {In this paper, an event-triggered impulsive control method is proposed to investigate the quasi-synchronization of drive–response systems with parameter mismatch, which integrates the event-triggered control and impulsive control together. The impulsive instants are event-triggered and determined by a certain state-dependent triggering law. Sufficient conditions for achieving quasi-synchronization are achieved. The synchronization error is shown to be no more than a nonzero bound. Furthermore, Zeno-behavior of impulsive instants is excluded. Finally, a numerical example is presented to verify the validity of the theoretical results.}
}
@article{KUMAR2023541,
title = {Toward a cerebello-thalamo-cortical computational model of spinocerebellar ataxia},
journal = {Neural Networks},
volume = {162},
pages = {541-556},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.045},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000564},
author = {Gajendra Kumar and Chi Him Eddie Ma},
keywords = {Computational model, Cerebello-thalamo-cortical circuit, Ataxia, Purkinje cell, Cerebellum, Deep brain stimulation},
abstract = {Computational neural network modelling is an emerging approach for optimization of drug treatment of neurological disorders and fine-tuning of rehabilitation strategies. In the current study, we constructed a cerebello-thalamo-cortical computational neural network model to simulate a mouse model of cerebellar ataxia (pcd5J mice) by manipulating cerebellar bursts through reduction of GABAergic inhibitory input. Cerebellar output neurons were projected to the thalamus and bidirectionally connected with the cortical network. Our results showed that reduction of inhibitory input in the cerebellum orchestrated the cortical local field potential (LFP) dynamics to generate specific motor outputs of oscillations of the theta, alpha, and beta bands in the computational model as well as in mouse motor cortical neurons. The therapeutic potential of deep brain stimulation (DBS) was tested in the computational model by increasing the sensory input to restore cortical output. Ataxia mice showed normalization of the motor cortex LFP after cerebellum DBS. We provide a novel approach to computational modelling to investigate the effect of DBS by mimicking cerebellar ataxia involving degeneration of Purkinje cells. Simulated neural activity coincides with findings from neural recordings of ataxia mice. Our computational model could thus represent cerebellar pathologies and provide insight into how to improve disease symptoms by restoring neuronal electrophysiological properties using DBS.}
}
@article{SHAO2023192,
title = {Adaptive pseudo-Siamese policy network for temporal knowledge prediction},
journal = {Neural Networks},
volume = {160},
pages = {192-201},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000047},
author = {Pengpeng Shao and Tong Liu and Feihu Che and Dawei Zhang and Jianhua Tao},
keywords = {Temporal knowledge graphs, Prediction, Reinforcement learning},
abstract = {Temporal knowledge prediction is a crucial task for early event warning, which has gained increasing attention recently. It aims to predict future facts based on relevant historical facts using temporal knowledge graphs. There are two main difficulties associated with the prediction task: from the perspective of historical facts, modeling the evolutionary patterns of facts to accurately predict the query and from the query perspective, handling the two cases where the query contains seen and unseen entities in a unified framework. Driven by these two problems, we propose a novel adaptive pseudo-Siamese policy network for temporal knowledge prediction based on reinforcement learning. Specifically, we design the policy network in our model as a pseudo-Siamese network consisting of two sub-policy networks. In the sub-policy network I, the agent searches for the answer to the query along the entity-relation paths to capture static evolutionary patterns. In sub-policy network II, the agent searches for the answer to the query along relation-time paths to deal with unseen entities. Moreover, we develop a temporal relation encoder to capture the temporal evolutionary patterns. Finally, we design a gating mechanism to adaptively integrate the results of the two sub-policy networks to help the agent focus on the destination answer. To assess the performance of our model, we conduct link prediction on four benchmark datasets, and extensive experimental results demonstrate that our method achieves considerable performance compared with existing methods.}
}
@article{RENDONSEGADOR2023318,
title = {CrimeNet: Neural Structured Learning using Vision Transformer for violence detection},
journal = {Neural Networks},
volume = {161},
pages = {318-329},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.048},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000606},
author = {Fernando J. Rendón-Segador and Juan A. Álvarez-García and Jose L. Salazar-González and Tatiana Tommasi},
keywords = {Deep learning, Neural Structured Learning, Vision Transformer, Violence detection, Adversarial Learning},
abstract = {The state of the art in violence detection in videos has improved in recent years thanks to deep learning models, but it is still below 90% of average precision in the most complex datasets, which may pose a problem of frequent false alarms in video surveillance environments and may cause security guards to disable the artificial intelligence system. In this study, we propose a new neural network based on Vision Transformer (ViT) and Neural Structured Learning (NSL) with adversarial training. This network, called CrimeNet, outperforms previous works by a large margin and reduces practically to zero the false positives. Our tests on the four most challenging violence-related datasets (binary and multi-class) show the effectiveness of CrimeNet, improving the state of the art from 9.4 to 22.17 percentage points in ROC AUC depending on the dataset. In addition, we present a generalisation study on our model by training and testing it on different datasets. The obtained results show that CrimeNet improves over competing methods with a gain of between 12.39 and 25.22 percentage points, showing remarkable robustness.}
}
@article{SOUNDARARAJAN202370,
title = {Non-fragile output-feedback synchronization for delayed discrete-time complex-valued neural networks with randomly occurring uncertainties},
journal = {Neural Networks},
volume = {159},
pages = {70-83},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004944},
author = {G. Soundararajan and G. Nagamani},
keywords = {Complex-valued discrete-time neural networks, Synchronization, Output-feedback control, Linear matrix inequality, Lyapunov–Krasovskii functional},
abstract = {This paper is step forward to establish an exponential synchronization criterion for discrete-time complex-valued neural networks (CVNNs) having time-varying delays subject to randomly occurring uncertain weighting parameters, in order to overcome the fluctuation when the output-feedback controller imposes on its dynamics. To achieve this, Jensen’s weighted summation inequalities (WSIs) and an extended reciprocal convex matrix inequality (ERCMI) are extended into the domain of complex field. By introducing some augmented vectors, a Lyapunov–Krasovskii functional (LKF) is constructed to attain an improved delay-dependent linear matrix inequalities (LMIs) constraint for the exponential synchronization phenomenon of the desired master–slave neuronal system model. For instance, the upper bound of the quadratic summation terms occurred in the finite difference of the LKF have been obtained from its linearization that has been made by the developed complex-valued WSIs and complex-valued ERCMI. The proposed results are less restrictive with the minimum number of decision variables than those obtained using existing inequalities. The designed output-feedback control gain has been determined by solving a set of complex-valued LMIs and it has been enforced with a prescribed exponential decay rate. Finally, in sight of MATLAB software, the established results have been examined via a numerical example supported by the simulation results.}
}
@article{YANG2023249,
title = {Multi-scale multi-reception attention network for bone age assessment in X-ray images},
journal = {Neural Networks},
volume = {158},
pages = {249-257},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004427},
author = {Zhichao Yang and Cong Cong and Maurice Pagnucco and Yang Song},
keywords = {Bone age assessment, Spatial attention, Graph attention},
abstract = {Bone age assessment plays a significant role in estimating bone maturity. However, radiograph/X-ray images of hand bones contain a large amount of redundant information. Some detection or segmentation based methods have recently been proposed to solve this issue. These network structures are often of high complexity and might require extra annotations, which make them less applicable in practice. In this paper, we present a Multi-scale Multi-reception Attention Net (MMANet), which combines a novel Multi-scale Multi-reception Complement Attention (MMCA) network and a graph attention module with a ResNet backbone to enhance the feature representation of key regions and suppress the influence of background regions to achieve significant performance improvement. Experimental results show our MMANet is able to accurately detect key regions and achieves 3.88 mean absolute error (MAE) on the RSNA 2017 Paediatric Bone Age Challenge dataset. Our method, without explicit modelling of anatomical information, outperforms the current state-of-the-art method (MAE=3.91) by 0.03 (months) which requires extra annotations. Code is available at https://github.com/yzc1122333/BoneAgeAss.}
}
@article{ZHANG2023318,
title = {Deep MCANC: A deep learning approach to multi-channel active noise control},
journal = {Neural Networks},
volume = {158},
pages = {318-327},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004701},
author = {Hao Zhang and DeLiang Wang},
keywords = {Active noise control, Deep learning, Multi-channel ANC, Quiet zone, Nonlinear distortions},
abstract = {Traditional multi-channel active noise control (MCANC) is based on adaptive filtering and usually uses a separate control unit for each channel. This paper introduces a deep learning based approach for multi-channel active noise control (ANC). The proposed approach, called deep MCANC, encodes optimal control parameters corresponding to different noises and environments, and jointly computes the multiple canceling signals to cancel or attenuate the primary noises captured at error microphones. A convolutional recurrent network (CRN) is employed for complex spectral mapping where the summated power of error signals is used as the loss function for CRN training. Deep MCANC is a fixed-parameter ANC approach and large-scale multi-condition training is employed to achieve robustness against a variety of noises. We explore the performance of deep MCANC with different setups and investigate the impact of factors such as the number of loudspeakers and microphones, and the position of a secondary source, on ANC performance. Experimental results show that deep MCANC is effective for wideband noise reduction and generalizes well to untrained noises. Moreover, the proposed approach is robust against variations in reference signals and works well in the presence of nonlinear distortions.}
}
@article{HAO2023216,
title = {Neural speech enhancement with unsupervised pre-training and mixture training},
journal = {Neural Networks},
volume = {158},
pages = {216-227},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004543},
author = {Xiang Hao and Chenglin Xu and Lei Xie},
keywords = {Speech enhancement, Neural network, Unsupervised pre-training, Mixture training},
abstract = {Supervised neural speech enhancement methods always require a large scale of paired noisy and clean speech data. Since collecting adequate paired data from real-world applications is infeasible, simulated data is always adopted in supervised learning methods. However, the mismatch between the simulated data and in-the-wild data always causes performance inconsistency when the system is deployed in real-world applications. Unsupervised speech enhancement methods are studied to address the mismatch problem by directly using the in-the-wild noisy data without access to the corresponding clean speech. Therefore, the simulated paired data is not necessary. However, the performance of the unsupervised speech enhancement method is not on par with the supervised learning method. To address the aforementioned problems, this work proposes an unsupervised pre-training and mixture training algorithm by leveraging the advantages of supervised and unsupervised learning methods. Specifically, the proposed speech enhancement approach employs large volumes of unpaired noisy and clean speech to conduct unsupervised pre-training. The noisy data and a small amount of simulated paired data are then used for mixture training to optimize the pre-trained model. Experimental results show that the proposed method achieves better performances than other state-of-the-art supervised and unsupervised learning methods.}
}
@article{QIN2023258,
title = {Strictly intermittent quantized control for fixed/predefined-time cluster lag synchronization of stochastic multi-weighted complex networks},
journal = {Neural Networks},
volume = {158},
pages = {258-271},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004300},
author = {Xuejiao Qin and Haijun Jiang and Jianlong Qiu and Cheng Hu and Yue Ren},
keywords = {Fixed-time, Predefined-time, Cluster lag synchronization, Stochastic multi-weighted complex network, Strictly intermittent quantized control},
abstract = {This article addresses the fixed-time (F-T) and predefined-time (P-T) cluster lag synchronization of stochastic multi-weighted complex networks (SMWCNs) via strictly intermittent quantized control (SIQC). Firstly, by exploiting mathematical induction and reduction to absurdity, a novel F-T stability lemma is proved and an accurate estimation of settling time (ST) is obtained. Subsequently, by virtue of the proposed F-T stability, some simple conditions that ensure the F-T cluster lag synchronization of SMWCNs are derived by developing a SIQC strategy. Furthermore, the P-T cluster lag synchronization is also explored based on a SIQC design, where the ST can be predefined by an adjustable constant of the controller. Note that the designed controllers here are simpler and more economical than the traditional design whose the linear part is still activated during the rest interval. Finally, two numerical examples are provided to verify the effectiveness of the theoretical results.}
}
@article{OH202342,
title = {Bayesian Disturbance Injection: Robust imitation learning of flexible policies for robot manipulation},
journal = {Neural Networks},
volume = {158},
pages = {42-58},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200449X},
author = {Hanbit Oh and Hikaru Sasaki and Brendan Michael and Takamitsu Matsubara},
keywords = {Imitation learning, Disturbance injection, Human behavior characteristics, Robotic manipulation},
abstract = {Humans demonstrate a variety of interesting behavioral characteristics when performing tasks, such as selecting between seemingly equivalent optimal actions, performing recovery actions when deviating from the optimal trajectory, or moderating actions in response to sensed risks. However, imitation learning, which attempts to teach robots to perform these same tasks from observations of human demonstrations, often fails to capture such behavior. Specifically, commonly used learning algorithms embody inherent contradictions between the learning assumptions (e.g., single optimal action) and actual human behavior (e.g., multiple optimal actions), thereby limiting robot generalizability, applicability, and demonstration feasibility. To address this, this paper proposes designing imitation learning algorithms with a focus on utilizing human behavioral characteristics, thereby embodying principles for capturing and exploiting actual demonstrator behavioral characteristics. This paper presents the first imitation learning framework, Bayesian Disturbance Injection (BDI), that typifies human behavioral characteristics by incorporating model flexibility, robustification, and risk sensitivity. Bayesian inference is used to learn flexible non-parametric multi-action policies, while simultaneously robustifying policies by injecting risk-sensitive disturbances to induce human recovery action and ensuring demonstration feasibility. Our method is evaluated through risk-sensitive simulations and real-robot experiments (e.g., table-sweep task, shaft-reach task and shaft-insertion task) using the UR5e 6-DOF robotic arm, to demonstrate the improved characterization of behavior. Results show significant improvement in task performance, through improved flexibility, robustness as well as demonstration feasibility.}
}
@article{JIANG202384,
title = {Origin of the efficiency of spike timing-based neural computation for processing temporal information},
journal = {Neural Networks},
volume = {160},
pages = {84-96},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005093},
author = {Zhiwei Jiang and Jiaming Xu and Tielin Zhang and Mu-ming Poo and Bo Xu},
keywords = {Postsynaptic potential, Spiking neural network, Sequence learning, Temporal information processing},
abstract = {Although the advantage of spike timing-based over rate-based network computation has been recognized, the underlying mechanism remains unclear. Using Tempotron and Perceptron as elementary neural models, we examined the intrinsic difference between spike timing-based and rate-based computations. For more direct comparison, we modified Tempotron computation into rate-based computation with the retention of some temporal information. Previous studies have shown that spike timing-based computation are computationally more powerful than rate-based computation in terms of the number of computational units required and the capability in classifying random patterns. Our study showed that spike timing-based and rate-based Tempotron computations provided similar capability in classifying random spike patterns, as well as in text sentiment classification and spam text detection. However, spike timing-based computation is superior in performing a task involving discriminating forward vs. reverse sequence of events, i.e., information mainly temporal in nature. Further studies revealed that this superiority required the asymmetry in the profile of the postsynaptic potential (PSP), and that temporal sequence information was converted to biased spatial distribution of synaptic weight modifications during learning. Thus, the intrinsic PSP asymmetry is a mechanistic basis for the high efficiency of spike timing-based computation for processing temporal information.}
}
@article{S2023178,
title = {VISAL—A novel learning strategy to address class imbalance},
journal = {Neural Networks},
volume = {161},
pages = {178-184},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000151},
author = {Sree Rama Vamsidhar S. and Arun Kumar Sivapuram and Vaishnavi Ravi and Gowtham Senthil and Rama Krishna Gorthi},
keywords = {Data imbalance, Deep neural networks, Image classification, Learning function},
abstract = {In the imbalance data scenarios, Deep Neural Networks (DNNs) fail to generalize well on minority classes. In this letter, we propose a simple and effective learning function i.e, Visually Interpretable Space Adjustment Learning (VISAL) to handle the imbalanced data classification task. VISAL’s objective is to create more room for the generalization of minority class samples by bringing in both the angular and euclidean margins into the cross-entropy learning strategy. When evaluated on the imbalanced versions of CIFAR, Tiny ImageNet, COVIDx and IMDB reviews datasets, our proposed method outperforms the state of the art works by a significant margin.}
}
@article{ZHOU202397,
title = {Predefined-time synchronization of coupled neural networks with switching parameters and disturbed by Brownian motion},
journal = {Neural Networks},
volume = {160},
pages = {97-107},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.024},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200524X},
author = {Xianghui Zhou and Jinde Cao and Xin Wang},
keywords = {Predefined time, Synchronization, Laplace matrix, Disturbed neural networks},
abstract = {This article focuses on predefined time synchronization problem for a class of signal switching neural networks with time-varying delays. In the network models, we not only consider the coupling characteristics in the following networks, but also consider the disturbance with standard Brownian motion. In the design of the controller, the control gain is designed as 1ɛ+Tp−t (t∈[T0,Tp), ɛ is an optional smaller positive number), which avoids the infinite gain (the control gain is designed as 1Tp−t in other reference). In order to get the predefined time control law, a power function is multiplied to the Lyapunov functional, from which it can get an exponential upper bound function via the derivative and mathematical expectation operation. Utilizing the martingale theory and the method of Laplace matrix, some novel predefined time synchronization criteria are obtained for the leader-following neural networks, meanwhile the following networks can maintain the leader network after achieved synchronization. Based on the special network of the main system, five corollaries separately develop the predefined time synchronization results from different perspectives. An example with some simulation figures and computing results fully exhibits the effectiveness of the achieved synchronization scheme. In this case, although the error signal is disturbed by Brownian motion, the trace signal can still stably converge to zero by this control scheme, meanwhile the predefined-time control effect is achieved.}
}
@article{MUNDT2023306,
title = {A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning},
journal = {Neural Networks},
volume = {160},
pages = {306-336},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300014X},
author = {Martin Mundt and Yongwon Hong and Iuliia Pliushch and Visvanathan Ramesh},
keywords = {Continual deep learning, Lifelong machine learning, Active learning, Open set recognition, Open world learning},
abstract = {Current deep learning methods are regarded as favorable if they empirically perform well on dedicated test sets. This mentality is seamlessly reflected in the resurfacing area of continual learning, where consecutively arriving data is investigated. The core challenge is framed as protecting previously acquired representations from being catastrophically forgotten. However, comparison of individual methods is nevertheless performed in isolation from the real world by monitoring accumulated benchmark test set performance. The closed world assumption remains predominant, i.e. models are evaluated on data that is guaranteed to originate from the same distribution as used for training. This poses a massive challenge as neural networks are well known to provide overconfident false predictions on unknown and corrupted instances. In this work we critically survey the literature and argue that notable lessons from open set recognition, identifying unknown examples outside of the observed set, and the adjacent field of active learning, querying data to maximize the expected performance gain, are frequently overlooked in the deep learning era. Hence, we propose a consolidated view to bridge continual learning, active learning and open set recognition in deep neural networks. Finally, the established synergies are supported empirically, showing joint improvement in alleviating catastrophic forgetting, querying data, selecting task orders, while exhibiting robust open world application.}
}
@article{ZHAO2023137,
title = {Representation learning for continuous action spaces is beneficial for efficient policy learning},
journal = {Neural Networks},
volume = {159},
pages = {137-152},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005019},
author = {Tingting Zhao and Ying Wang and Wei Sun and Yarui Chen and Gang Niu and Masashi Sugiyama},
keywords = {Policy model, Model-free reinforcement learning, Continuous action spaces, State representations, Action representations},
abstract = {Deep reinforcement learning (DRL) breaks through the bottlenecks of traditional reinforcement learning (RL) with the help of the perception capability of deep learning and has been widely applied in real-world problems. While model-free RL, as a class of efficient DRL methods, performs the learning of state representations simultaneously with policy learning in an end-to-end manner when facing large-scale continuous state and action spaces. However, training such a large policy model requires a large number of trajectory samples and training time. On the other hand, the learned policy often fails to generalize to large-scale action spaces, especially for the continuous action spaces. To address this issue, in this paper we propose an efficient policy learning method in latent state and action spaces. More specifically, we extend the idea of state representations to action representations for better policy generalization capability. Meanwhile, we divide the whole learning task into learning with the large-scale representation models in an unsupervised manner and learning with the small-scale policy model in the RL manner. The small policy model facilitates policy learning, while not sacrificing generalization and expressiveness via the large representation model. Finally, the effectiveness of the proposed method is demonstrated by MountainCar, CarRacing and Cheetah experiments.}
}
@article{ARORA2023142,
title = {Fractional derivative based weighted skip connections for satellite image road segmentation},
journal = {Neural Networks},
volume = {161},
pages = {142-153},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000436},
author = {Sugandha Arora and Harsh Kumar Suman and Trilok Mathur and Hari Mohan Pandey and Kamlesh Tiwari},
keywords = {Remote sensing, Road network extraction, Image segmentation, Fractional-order derivative},
abstract = {Segmentation of a road portion from a satellite image is challenging due to its complex background, occlusion, shadows, clouds, and other optical artifacts. One must combine both local and global cues for an accurate and continuous/connected road network extraction. This paper proposes a model using fractional derivative-based weighted skip connections on a densely connected convolutional neural network for road segmentation. Weights corresponding to the skip connections are determined using Grunwald–Letnikov fractional derivative. Fractional derivatives being non-local in nature incorporates memory into the system and thereby combine both local and global features. Experiments have been performed on two open source widely used benchmark databases viz. Massachusetts Road database (MRD) and Ottawa Road database (ORD). Both these datasets represent different road topography and network structure including varying road widths and complexities. Result reveals that the proposed system demonstrated better performance than the other state-of-the-art methods by achieving an F1-score of 0.748 and the mIoU of 0.787 at fractional order 0.4 on the MRD and a mIoU of 0.9062 at fractional order 0.5 on the ORD.}
}
@article{ZHANG2023371,
title = {Few-shot link prediction for temporal knowledge graphs based on time-aware translation and attention mechanism},
journal = {Neural Networks},
volume = {161},
pages = {371-381},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.043},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000552},
author = {Han Zhang and Luyi Bai},
keywords = {Attention mechanism, Few-shot link prediction, Temporal knowledge graph},
abstract = {Few-shot knowledge graph completion (KGC) is an important and common task in real applications, which aims to predict unseen facts when only few samples are available for each relation in the knowledge graph (KG). Previous methods on few-shot KGC mainly focus on static KG, however, many KG in real-world applications are dynamic and develop over time. In this work, we consider few-shot KGC in temporal knowledge graphs (TKGs), where the fact may only hold for a specific timestamp. We propose a Few-Shot Completion model in TKG (TFSC), which compare the input query to the given few-shot references to make predictions. Specifically, in order to enhance the representation of entities in the case of few samples, we use the attention mechanism to model the neighbor entities of the task entity with timestamp information, and generate expressive time-aware entity pair representations through the Transformer encoder. A comprehensive set of experiments is finally carried out to demonstrate the effectiveness a of our proposed model TFSC.}
}
@article{WEN202339,
title = {Enhanced robust spatial feature selection and correlation filter learning for UAV tracking},
journal = {Neural Networks},
volume = {161},
pages = {39-54},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000035},
author = {Jiajun Wen and Honglin Chu and Zhihui Lai and Tianyang Xu and Linlin Shen},
keywords = {UAV, Spatial feature selection, Correlation filter, Object tracking},
abstract = {Spatial boundary effect can significantly reduce the performance of a learned discriminative correlation filter (DCF) model. A commonly used method to relieve this effect is to extract appearance features from a wider region of a target. However, this way would introduce unexpected features from background pixels and noises, which will lead to a decrease of the filter’s discrimination power. To address this shortcoming, this paper proposes an innovative method called enhanced robust spatial feature selection and correlation filter Learning (EFSCF), which performs jointly sparse feature learning to handle boundary effects effectively while suppressing the influence of background pixels and noises. Unlike the ℓ2-norm-based tracking approaches that are prone to non-Gaussian noises, the proposed method imposes the ℓ2,1-norm on the loss term to enhance the robustness against the training outliers. To enhance the discrimination further, a jointly sparse feature selection scheme based on the ℓ2,1 -norm is designed to regularize the filter in rows and columns simultaneously. To the best of the authors’ knowledge, this has been the first work exploring the structural sparsity in rows and columns of a learned filter simultaneously. The proposed model can be efficiently solved by an alternating direction multiplier method. The proposed EFSCF is verified by experiments on four challenging unmanned aerial vehicle datasets under severe noise and appearance changes, and the results show that the proposed method can achieve better tracking performance than the state-of-the-art trackers.}
}
@article{AHISHALI202315,
title = {Representation based regression for object distance estimation},
journal = {Neural Networks},
volume = {158},
pages = {15-29},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200452X},
author = {Mete Ahishali and Mehmet Yamac and Serkan Kiranyaz and Moncef Gabbouj},
keywords = {Representation-based regression, Object distance estimation, Sparse support estimation, Convolutional support estimator network},
abstract = {In this study, we propose a novel approach to predict the distances of the detected objects in an observed scene. The proposed approach modifies the recently proposed Convolutional Support Estimator Networks (CSENs). CSENs are designed to compute a direct mapping for the Support Estimation (SE) task in a representation-based classification problem. We further propose and demonstrate that representation-based methods (sparse or collaborative representation) can be used in well-designed regression problems especially over scarce data. To the best of our knowledge, this is the first representation-based method proposed for performing a regression task by utilizing the modified CSENs; and hence, we name this novel approach as Representation-based Regression (RbR). The initial version of CSENs has a proxy mapping stage (i.e., a coarse estimation for the support set) that is required for the input. In this study, we improve the CSEN model by proposing Compressive Learning CSEN (CL-CSEN) that has the ability to jointly optimize the so-called proxy mapping stage along with convolutional layers. The experimental evaluations using the KITTI 3D Object Detection distance estimation dataset show that the proposed method can achieve a significantly improved distance estimation performance over all competing methods. Finally, the software implementations of the methods are publicly shared at https://github.com/meteahishali/CSENDistance.}
}
@article{KAWASHIMA2023239,
title = {Pavlovian-based neurofeedback enhances meta-awareness of mind-wandering},
journal = {Neural Networks},
volume = {158},
pages = {239-248},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004658},
author = {Issaku Kawashima and Toru Nagahama and Hiroaki Kumano and Keiko Momose and Saori C. Tanaka},
keywords = {Mind-wandering, Meta-awareness, EEG, Pavlovian conditioning, Neurofeedback},
abstract = {Absorption in mind-wandering (MW) may worsen our mood and can cause psychological disorders. Researchers indicate the possibility that meta-awareness of MW prevents these mal-effects and enhances favorable consequences of MW, such as boosting creativity; thus, meta-awareness has attracted psychological and clinical attention. However, few studies have investigated the nature of meta-awareness of MW, because there has been no method to isolate and operate this ability. Therefore, we propose a new approach to manipulate the ability of meta-awareness. We used Pavlovian conditioning, tying to it an occurrence of MW and a neutral tone sound inducing the meta-awareness of MW. To perform paired presentations of the unconditioned stimulus (neutral tone) and the conditioned stimulus (perception accompanying MW), we detected participants’ natural occurrence of MW via electroencephalogram and a machine-learning estimation method. The double-blinded randomized controlled trial with 37 participants found that a single 20-min conditioning session significantly increased the meta-awareness of MW as assessed by behavioral and neuroscientific measures. The core protocol of the proposed method is real-time feedback on participants’ neural information, and in that sense, we can refer to it as neurofeedback. However, there are some differences from typical neurofeedback protocols, and we discuss them in this paper. Our novel classical conditioning is expected to contribute to future research on the modulation effect of meta-awareness on MW.}
}
@article{KIM2023125,
title = {Variable three-term conjugate gradient method for training artificial neural networks},
journal = {Neural Networks},
volume = {159},
pages = {125-136},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004932},
author = {Hansu Kim and Chuxuan Wang and Hyoseok Byun and Weifei Hu and Sanghyuk Kim and Qing Jiao and Tae Hee Lee},
keywords = {Three-term conjugate gradient, Variable step size, Artificial neural networks, Image classification and generation, Intelligent robotic grasping},
abstract = {Artificial neural networks (ANNs) have been widely adopted as general computational tools both in computer science as well as many other engineering fields. Stochastic gradient descent (SGD) and adaptive methods such as Adam are popular as robust optimization algorithms used to train the ANNs. However, the effectiveness of these algorithms is limited because they calculate a search direction based on a first-order gradient. Although higher-order gradient methods such as Newton’s method have been proposed, they require the Hessian matrix to be semi-definite, and its inversion incurs a high computational cost. Therefore, in this paper, we propose a variable three-term conjugate gradient (VTTCG) method that approximates the Hessian matrix to enhance search direction and uses a variable step size to achieve improved convergence stability. To evaluate the performance of the VTTCG method, we train different ANNs on benchmark image classification and generation datasets. We also conduct a similar experiment in which a grasp generation and selection convolutional neural network (GGS-CNN) is trained to perform intelligent robotic grasping. After considering a simulated environment, we also test the GGS-CNN with a physical grasping robot. The experimental results show that the performance of the VTTCG method is superior to that of four conventional methods, including SGD, Adam, AMSGrad, and AdaBelief.}
}
@article{DENG202330,
title = {LSTMED: An uneven dynamic process monitoring method based on LSTM and Autoencoder neural network},
journal = {Neural Networks},
volume = {158},
pages = {30-41},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004415},
author = {Wenfeng Deng and Yuxuan Li and Keke Huang and Dehao Wu and Chunhua Yang and Weihua Gui},
keywords = {Uneven dynamic process, Long and short-term memory neural network, Autoencoder, Process monitoring},
abstract = {Due to the complicated production mechanism in multivariate industrial processes, different dynamic features of variables raise challenges to traditional data-driven process monitoring methods which assume the process data is static or dynamically consistent. To tackle this issue, this paper proposes a novel process monitoring method based on the long short-term memory (LSTM) and Autoencoder neural network (called LSTMED) for multivariate process monitoring with uneven dynamic features. First, the LSTM units are arranged in the encoder–decoder form to construct an end-to-end model. Then, the constructed model is trained in an unsupervised manner to capture long-term time dependency within variables and dominant representation of high dimensional process data. Afterward, the kernel density estimation (KDE) method is performed to determine the control limit only based on the reconstruction error from historical normal data. Finally, effective online monitoring for uneven dynamic process can be achieved. The performance and advantage of the process monitoring method proposed are explained through typical cases, including the numerical simulation and Tennessee Eastman (TE) benchmark process, and comparative experimental analysis with state-of-the-art methods.}
}
@article{YANG2023132,
title = {Reinforcement learning for robust stabilization of nonlinear systems with asymmetric saturating actuators},
journal = {Neural Networks},
volume = {158},
pages = {132-141},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004531},
author = {Xiong Yang and Yingjiang Zhou and Zhongke Gao},
keywords = {Adaptive dynamic programming, Neural network control, Robust stabilization, Reinforcement learning, Saturating actuator},
abstract = {We study the robust stabilization problem of a class of nonlinear systems with asymmetric saturating actuators and mismatched disturbances. Initially, we convert such a robust stabilization problem into a nonlinear-constrained optimal control problem by constructing a discounted cost function for the auxiliary system. Then, for the purpose of solving the nonlinear-constrained optimal control problem, we develop a simultaneous policy iteration (PI) in the reinforcement learning framework. The implementation of the simultaneous PI relies on an actor–critic architecture, which employs actor and critic neural networks (NNs) to separately approximate the control policy and the value function. To determine the actor and critic NNs’ weights, we use the approach of weighted residuals together with the typical Monte-Carlo integration technique. Finally, we perform simulations of two nonlinear plants to validate the established theoretical claims.}
}
@article{WANG2023254,
title = {Learning matrix factorization with scalable distance metric and regularizer},
journal = {Neural Networks},
volume = {161},
pages = {254-266},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000461},
author = {Shiping Wang and Yunhe Zhang and Xincan Lin and Lichao Su and Guobao Xiao and William Zhu and Yiqing Shi},
keywords = {Machine learning, Deep learning, Matrix factorization, Projected gradient, Feature representation, Learnable auto-encoder},
abstract = {Matrix factorization has always been an encouraging field, which attempts to extract discriminative features from high-dimensional data. However, it suffers from negative generalization ability and high computational complexity when handling large-scale data. In this paper, we propose a learnable deep matrix factorization via the projected gradient descent method, which learns multi-layer low-rank factors from scalable metric distances and flexible regularizers. Accordingly, solving a constrained matrix factorization problem is equivalently transformed into training a neural network with an appropriate activation function induced from the projection onto a feasible set. Distinct from other neural networks, the proposed method activates the connected weights not just the hidden layers. As a result, it is proved that the proposed method can learn several existing well-known matrix factorizations, including singular value decomposition, convex, nonnegative and semi-nonnegative matrix factorizations. Finally, comprehensive experiments demonstrate the superiority of the proposed method against other state-of-the-arts.}
}
@article{PENG2023108,
title = {Fixed-time and prescribed-time synchronization of quaternion-valued neural networks: A control strategy involving Lyapunov functions},
journal = {Neural Networks},
volume = {160},
pages = {108-121},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005068},
author = {Tao Peng and Yanqiu Wu and Zhengwen Tu and A.S. Alofi and Jianquan Lu},
keywords = {Finite-time synchronization, Prescribed-time synchronization, Quaternion-valued neural networks},
abstract = {A control strategy containing Lyapunov functions is proposed in this paper. Based on this strategy, the fixed-time synchronization of a time-delay quaternion-valued neural network (QVNN) is analyzed. This strategy is extended to the prescribed-time synchronization of the QVNN. Furthermore, an improved two-step switching control strategy is also proposed based on this flexible control strategy. Compared with some existing methods, the main method of this paper is a non-decomposition one, does not contain a sign function in the controller, and has better synchronization accuracy. Two numerical examples verify the above advantages.}
}
@article{ZENG2023164,
title = {Self-attention learning network for face super-resolution},
journal = {Neural Networks},
volume = {160},
pages = {164-174},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000060},
author = {Kangli Zeng and Zhongyuan Wang and Tao Lu and Jianyu Chen and Jiaming Wang and Zixiang Xiong},
keywords = {Face super-resolution, Feature learning, Information compensation, Supervised learning},
abstract = {Existing face super-resolution methods depend on deep convolutional networks (DCN) to recover high-quality reconstructed images. They either acquire information in a single space by designing complex models for direct reconstruction, or employ additional networks to extract multiple prior information to enhance the representation of features. However, existing methods are still challenging to perform well due to the inability to learn complete and uniform representations. To this end, we propose a self-attention learning network (SLNet) for three-stage face super-resolution, which fully explores the interdependence of low- and high-level spaces to achieve compensation of the information used for reconstruction. Firstly, SLNet uses a hierarchical feature learning framework to obtain shallow information in the low-level space. Then, the shallow information with cumulative errors due to DCN is improved under high-resolution (HR) supervision, while bringing an intermediate reconstruction result and a powerful intermediate benchmark. Finally, the improved feature representation is further enhanced in high-level space by a multi-scale context-aware encoder–decoder for facial reconstruction. The features in both spaces are explored progressively from coarse to fine reconstruction information. The experimental results show that SLNet has a competitive performance compared to the state-of-the-art methods.}
}
@article{FENG2023330,
title = {Approximating Nash equilibrium for anti-UAV jamming Markov game using a novel event-triggered multi-agent reinforcement learning},
journal = {Neural Networks},
volume = {161},
pages = {330-342},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005226},
author = {Zikai Feng and Mengxing Huang and Yuanyuan Wu and Di Wu and Jinde Cao and Iakov Korovin and Sergey Gorbachev and Nadezhda Gorbacheva},
keywords = {Anti-jamming Markov game, Event-triggered multi-agent deep reinforcement learning, Beta strategy, Nash equilibrium},
abstract = {In the downlink communication, it is currently challenging for ground users to cope with the uncertain interference from aerial intelligent jammers. The cooperation and competition between ground users and unmanned aerial vehicle (UAV) jammers leads to a Markov game problem of anti-UAV jamming. Therefore, a model-free method is adopted based on multi-agent reinforcement learning (MARL) to handle the Markov game. However, the benchmark MARL strategies suffer from dimension explosion and local optimal convergence. To solve these issues, a novel event-triggered multi-agent proximal policy optimization algorithm with Beta strategy (ETMAPPO) is proposed in this paper, which aims to reduce the dimension of information transmission and improve the efficiency of policy convergence. In this event-triggering mechanism, agents can learn to obtain appropriate observation in different moment, thereby reducing the transmission of valueless information. Beta operator is used to optimize the action search. It expands the search scope of policy space. Ablation simulations show that the proposed strategy achieves better global benefits with fewer dimension of information than benchmark algorithms. In addition, the convergence performance verifies that the well-trained ETMAPPO has the capability to achieve stable jamming strategies and stable anti-jamming strategies. This approximately constitutes the Nash equilibrium of the anti-jamming Markov game.}
}
@article{MING2023281,
title = {Cooperative modular reinforcement learning for large discrete action space problem},
journal = {Neural Networks},
volume = {161},
pages = {281-296},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.046},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000588},
author = {Fangzhu Ming and Feng Gao and Kun Liu and Chengmei Zhao},
keywords = {Deep reinforcement learning, Modular reinforcement learning, Large discrete action space, Parallel training},
abstract = {Deep reinforcement learning (DRL) has achieved remarkable results on high-dimension state tasks. However, it suffers in hard convergence and low sample efficiency when solving large discrete action space problems. To meet these challenges, we develop a cooperative modular reinforcement learning (CMRL) method to distributedly solve the problems with a large discrete action space. A general yet effective task decomposition method is proposed to decompose the complex decision task in a large action space into multiple decision sub-tasks in small action subsets, using a rule-based action division method. The CMRL method consisting of multiple Critic networks is proposed to settle the multiple sub-tasks, where each Critic network learns a decomposed value function to obtain the local optimal action in a sub-task. The global optimal action is cooperatively chosen by all local optimal actions. Moreover, we propose a new parallel training mechanism, which trains multiple Critic networks with different models and multi-data in parallel. Mathematical properties are proposed to analyze the rationality and superiority of CMRL. Four different simulation experiments are conducted to verify the generality and effectiveness of CMRL for large action space problems. The results show that CMRL has superior performance on training efficiency compared with classical and latest DRL methods while maintaining the accuracy of the solution.}
}
@article{LIU2023105,
title = {Knowledge-Preserving continual person re-identification using Graph Attention Network},
journal = {Neural Networks},
volume = {161},
pages = {105-115},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.033},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300045X},
author = {Zhaoshuo Liu and Chaolu Feng and Shuaizheng Chen and Jun Hu},
keywords = {Continual learning, Person re-identification, Graph Attention Network},
abstract = {Person re-identification (ReID), considered as a sub-problem of image retrieval, is critical for intelligent security. The general practice is to train a deep model on images from a particular scenario (also known as a domain) and perform retrieval tests on images from the same domain. Thus, the model has to be retrained to ensure good performance on unseen domains. Unfortunately, retraining will introduce the so called catastrophic forgetting problem existing in deep learning models. To address this problem, we propose a Continual person re-identification model via a Knowledge-Preserving (CKP) mechanism. The proposed model is able to accumulate knowledge from continuously changing scenarios. The knowledge is updated via a graph attention network from the human cognitive-inspired perspective as the scenario changes. The accumulated knowledge is used to guide the learning process of the proposed model on image samples from new-coming domains. We finally evaluate and compare CKP with fine-tuning, continual learning in image classification and person re-identification, and joint training. Experiments on representative benchmark datasets (Market1501, DukeMTMC, CUHK03, CUHK-SYSU, and MSMT17, which arrive in different orders) demonstrate the advantages of the proposed model in preventing forgetting, and experiments on other benchmark datasets (GRID, SenseReID, CUHK01, CUHK02, VIPER, iLIDS, and PRID, which are not available during training) demonstrate the generalization ability of the proposed model. The CKP outperforms the best comparative model by 0.58% and 0.65% on seen domains (datasets available during training), and by 0.95% and 1.02% on never seen domains (datasets not available during training) in terms of mAP and Rank1, respectively. Arrival order of the training datasets, guidance of accumulated knowledge for learning new knowledge and parameter settings are also discussed.}
}
@article{LIN202383,
title = {DEFAEK: Domain Effective Fast Adaptive Network for Face Anti-Spoofing},
journal = {Neural Networks},
volume = {161},
pages = {83-91},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000187},
author = {Jiun-Da Lin and Yue-Hua Han and Po-Han Huang and Julianne Tan and Jun-Cheng Chen and M. Tanveer and Kai-Lung Hua},
keywords = {Meta-learning, Metric loss, Fast learning, Face anti-spoofing, DeepFake},
abstract = {Existing deep learning based face anti-spoofing (FAS) or deepfake detection approaches usually rely on large-scale datasets and powerful networks with significant amount of parameters to achieve satisfactory performance. However, these make them resource-heavy and unsuitable for handheld devices. Moreover, they are limited by the types of spoof in the dataset they train on and require considerable training time. To produce a robust FAS model, they need large datasets covering the widest variety of predefined presentation attacks possible. Testing on new or unseen attacks or environments generally results in poor performance. Ideally, the FAS model should learn discriminative features that can generalize well even on unseen spoof types. In this paper, we propose a fast learning approach called Domain Effective Fast Adaptive nEt-worK (DEFAEK), a face anti-spoofing approach based on the optimization-based meta-learning paradigm that effectively and quickly adapts to new tasks. DEFAEK treats differences in an environment as domains and simulates multiple domain shifts during training. To further improve the effectiveness and efficiency of meta-learning, we adopt the metric learning in the inner loop update with careful sample selection. With extensive experiments on the challenging CelebA-Spoof and FaceForensics++ datasets, the evaluation results show that DEFAEK can learn cues independent of the environment with good generalization capability. In addition, the resulting model is lightweight following the design principle of modern lightweight network architecture and still generalizes well on unseen classes. In addition, we also demonstrate our model’s capabilities by comparing the numbers of parameters, FLOPS, and model performance with other state-of-the-art methods.}
}
@article{JU2023359,
title = {Unsupervised graph-level representation learning with hierarchical contrasts},
journal = {Neural Networks},
volume = {158},
pages = {359-368},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004609},
author = {Wei Ju and Yiyang Gu and Xiao Luo and Yifan Wang and Haochen Yuan and Huasong Zhong and Ming Zhang},
keywords = {Graph representation learning, Graph contrastive learning, Graph neural networks, Unsupervised learning},
abstract = {Unsupervised graph-level representation learning has recently shown great potential in a variety of domains, ranging from bioinformatics to social networks. Plenty of graph contrastive learning methods have been proposed to generate discriminative graph-level representations recently. They typically design multiple types of graph augmentations and enforce a graph to have consistent representations under different views. However, these techniques mostly neglect the intrinsic hierarchical structure of the graph, resulting in a limited exploration of semantic information for graph representation. Moreover, they often rely on a large number of negative samples to prevent collapsing into trivial solutions, while a great need for negative samples may lead to memory issues during optimization in graph domains. To address the two issues, this paper develops an unsupervised graph-level representation learning framework named Hierarchical Graph Contrastive Learning (HGCL), which investigates the hierarchical structural semantics of a graph at both node and graph levels. Specifically, our HGCL consists of three parts, i.e., node-level contrastive learning, graph-level contrastive learning, and mutual contrastive learning to capture graph semantics hierarchically. Furthermore, the Siamese network and momentum update are further involved to release the demand for excessive negative samples. Finally, the experimental results on both benchmark datasets for graph classification and large-scale OGB datasets for transfer learning demonstrate that our proposed HGCL significantly outperforms a broad range of state-of-the-art baselines.}
}
@article{ALABI2023116,
title = {Rapid learning of spatial representations for goal-directed navigation based on a novel model of hippocampal place fields},
journal = {Neural Networks},
volume = {161},
pages = {116-128},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000102},
author = {Adedapo Alabi and Dieter Vanderelst and Ali A. Minai},
keywords = {Spatial cognition, Robotics, Reinforcement learning, Hippocampus, Computational neuroscience},
abstract = {The discovery of place cells and other spatially modulated neurons in the hippocampal complex of rodents has been crucial to elucidating the neural basis of spatial cognition. More recently, the replay of neural sequences encoding previously experienced trajectories has been observed during consummatory behavior—potentially with implications for rapid learning, quick memory consolidation, and behavioral planning. Several promising models for robotic navigation and reinforcement learning have been proposed based on these and previous findings. Most of these models, however, use carefully engineered neural networks, and sometimes require long learning periods. In this paper, we present a self-organizing model incorporating place cells and replay, and demonstrate its utility for rapid one-shot learning in non-trivial environments with obstacles.}
}
@article{HU2023161,
title = {Observer-based dynamical pattern recognition via deterministic learning},
journal = {Neural Networks},
volume = {159},
pages = {161-174},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004968},
author = {Jingtao Hu and Weiming Wu and Fukai Zhang and Tianrui Chen and Cong Wang},
keywords = {Dynamical pattern recognition, Deterministic learning, Observer, Radial basis function network, Univariate time series},
abstract = {In this paper, based on the sampled-data observer and the deterministic learning theory, a rapid dynamical pattern recognition approach is proposed for univariate time series composed of the output signals of the dynamical systems. Specifically, locally-accurate identification of inherent dynamics of univariate time series is first achieved by using the sampled-data observer and the radial basis function (RBF) networks. The dynamical estimators embedded with the learned knowledge are then designed by resorting to the sampled-data observer. It is proved that generated estimator residuals can reflect the difference between the system dynamics of the training and test univariate time series. Finally, a recognition decision-making scheme is proposed based on the residual norms of the dynamical estimators. Through rigorous analysis, recognition conditions are given to guarantee the accurate recognition of the dynamical pattern of the test univariate time series. The significance of this paper lies in that the difficult problems of dynamical modeling and rapid recognition for univariate time series are solved by incorporating the sampled-data observer design and the deterministic learning theory. The effectiveness of the proposed approach is confirmed by a numerical example and compressor stall warning experiments.}
}
@article{LIANG202334,
title = {Depth map guided triplet network for deepfake face detection},
journal = {Neural Networks},
volume = {159},
pages = {34-42},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004725},
author = {Buyun Liang and Zhongyuan Wang and Baojin Huang and Qin Zou and Qian Wang and Jingjing Liang},
keywords = {Deepfake detection, Triplet network, Depth map},
abstract = {The widespread dissemination of facial forgery technology has brought many ethical issues and aroused widespread concern in society. Most research today treats deepfake detection as a fine grained classification task, which however makes it difficult to enable the feature extractor to express the features related to the real and fake attributes. This paper proposes a depth map guided triplet network, which mainly consists of a depth prediction network and a triplet feature extraction network. The depth map predicted by the depth prediction network can effectively reflect the differences between real and fake faces in discontinuity, inconsistent illumination, and blurring, thus in favor of deepfake detection. Regardless of the facial appearance changes induced by deepfake, we argue that real and fake faces should correspond to their respective latent feature spaces. Particularly, the pair of real faces (original–target) remain close in the latent feature space, while the two pairs of real–fake faces (original–fake, target–fake) instead keep faraway. Following this paradigm, we suggest a triplet loss supervision network to extract the sufficiently discriminative deep features, which minimizes the distance of the original–target pair and maximize the distance of the original–fake (also target–fake) pair. The extensive results on public FaceForensics++ and Celeb-DF datasets validate the superiority of our method over competitors.}
}
@article{YANG2023267,
title = {IASA: An IoU-aware tracker with adaptive sample assignment},
journal = {Neural Networks},
volume = {161},
pages = {267-280},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.038},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000503},
author = {Kai Yang and Haijun Zhang and Dongliang Zhou and Li Dong and Jianghong Ma},
keywords = {Visual tracking, IoU-aware tracker, Training sample assignment},
abstract = {Most of existing trackers develop tracking in a tracking head network, which is composed of classification branch and regression branch. However, they lack a meaningful exploration of how to define positive and negative samples during training, which can significantly affect tracking performance. Furthermore, they cannot provide a reliable ranking by using classification scores or a combination of classification and regression scores to obtain candidate locations. To address these issues, we propose an intersection over union (IoU) aware tracker with adaptive sample assignment (IASA). The IASA introduces an IoU-aware classification score to achieve a more accurate ranking for candidate tracking locations. We also propose a new loss function, IoU-focal loss, to train the anchor-free tracker IASA to predict the classification scores and introduce a star-shaped box feature representation to refine classification features. To explore the actual content of the training samples, we develop an adaptive sample assignment (ASA) strategy to divide the positive and negative samples according to the statistical characteristics of the sample IoUs. By combining these two proposed components, the IASA tracker treats the tracking task as a classification and a regression problem. It directly finds the candidate tracking location in the classification branch and then regresses the four distances from the location to the four sides of the tracking box. Experimental results show that the proposed IASA can achieve state-of-the-art performance on seven public datasets.}
}
@article{MAQSOOD2023238,
title = {Multiclass skin lesion localization and classification using deep learning based features fusion and selection framework for smart healthcare},
journal = {Neural Networks},
volume = {160},
pages = {238-258},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000229},
author = {Sarmad Maqsood and Robertas Damaševičius},
keywords = {Skin cancer, Deep learning, Skin lesion analysis, Dermoscopy imaging, Deep features, Classification},
abstract = {Background:
The idea of smart healthcare has gradually gained attention as a result of the information technology industry’s rapid development. Smart healthcare uses next-generation technologies i.e., artificial intelligence (AI) and Internet of Things (IoT), to intelligently transform current medical methods to make them more efficient, dependable and individualized. One of the most prominent uses of telemedicine and e-health in medical image analysis is teledermatology. Telecommunications technologies are used in this industry to send medical information to professionals. Teledermatology is a useful method for the identification of skin lesions, particularly in rural locations, because the skin is visually perceptible. One of the most recent tools for diagnosing skin cancer is dermoscopy. To classify skin malignancies, numerous computational approaches have been proposed in the literature. However, difficulties still exist i.e., lesions with low contrast, imbalanced datasets, high level of memory complexity, and the extraction of redundant features.
Methods:
In this work, a unified CAD model is proposed based on a deep learning framework for skin lesion segmentation and classification. In the proposed approach, the source dermoscopic images are initially pre-processed using a contrast enhancement based modified bio-inspired multiple exposure fusion approach. In the second stage, a custom 26-layered convolutional neural network (CNN) architecture is designed to segment the skin lesion regions. In the third stage, four pre-trained CNN models (Xception, ResNet-50, ResNet-101 and VGG16) are modified and trained using transfer learning on the segmented lesion images. In the fourth stage, the deep features vectors are extracted from all the CNN models and fused using the convolutional sparse image decomposition fusion approach. In the fifth stage, the univariate measurement and Poisson distribution feature selection approach is used for the best features selection for classification. Finally, the selected features are fed to the multi-class support vector machine (MC-SVM) for the final classification.
Results:
The proposed approach employed to the HAM10000, ISIC2018, ISIC2019, and PH2 datasets and achieved an accuracy of 98.57%, 98.62%, 93.47%, and 98.98% respectively which are better than previous works.
Conclusion:
When compared to renowned state-of-the-art methods, experimental results show that the proposed skin lesion detection and classification approach achieved higher performance in terms of both visually and enhanced quantitative evaluation with enhanced accuracy.}
}
@article{JING2023111,
title = {An architecture entropy regularizer for differentiable neural architecture search},
journal = {Neural Networks},
volume = {158},
pages = {111-120},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004567},
author = {Kun Jing and Luoyu Chen and Jungang Xu},
keywords = {Differentiable architecture search, Matthew effect, Discretization discrepancy, Architecture entropy regularizer},
abstract = {Differentiable architecture search (DARTS) is one of the prevailing paradigms of neural architecture search (NAS) due to allowing efficient gradient-based optimization during the search phase. However, its poor stability and generalizability are intolerable. We argue that the crux is the locally optimal architecture parameter caused by a dilemma, which is that the solutions to the Matthew effect and discretization discrepancy are inconsistent. To escape from the dilemma, we propose an architecture entropy to measure the discrepancy of the architecture parameters of different candidate operations and use it as a regularizer to control the learning of architecture parameters. Extensive experiments show that an architecture entropy regularizer with a negative or positive coefficient can effectively solve one side of the contradiction respectively, and the regularizer with a variable coefficient can relieve DARTS from the dilemma. Experimental results demonstrate that our architecture entropy regularizer can significantly improve different differentiable NAS algorithms on different datasets and different search spaces. Furthermore, we also achieve more accurate and more robust results on CIFAR-10 and ImageNet. The code is publicly available at https://github.com/kunjing96/DARTS-AER.}
}
@article{YANG2023305,
title = {Multi-graph Fusion Graph Convolutional Networks with pseudo-label supervision},
journal = {Neural Networks},
volume = {158},
pages = {305-317},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004683},
author = {Yachao Yang and Yanfeng Sun and Fujiao Ju and Shaofan Wang and Junbin Gao and Baocai Yin},
keywords = {Semi-supervised learning, Graph convolutional networks, Node classification, Pseudo-label supervision},
abstract = {Graph convolutional networks (GCNs) have become a popular tool for learning unstructured graph data due to their powerful learning ability. Many researchers have been interested in fusing topological structures and node features to extract the correlation information for classification tasks. However, it is inadequate to integrate the embedding from topology and feature spaces to gain the most correlated information. At the same time, most GCN-based methods assume that the topology graph or feature graph is compatible with the properties of GCNs, but this is usually not satisfied since meaningless, missing, or even unreal edges are very common in actual graphs. To obtain a more robust and accurate graph structure, we intend to construct an adaptive graph with topology and feature graphs. We propose Multi-graph Fusion Graph Convolutional Networks with pseudo-label supervision (MFGCN), which learn a connected embedding by fusing the multi-graphs and node features. We can obtain the final node embedding for semi-supervised node classification by propagating node features over multi-graphs. Furthermore, to alleviate the problem of labels missing in semi-supervised classification, a pseudo-label generation mechanism is proposed to generate more reliable pseudo-labels based on the similarity of node features. Extensive experiments on six benchmark datasets demonstrate the superiority of MFGCN over state-of-the-art classification methods.}
}
@article{LIU202314,
title = {Monte Carlo Ensemble Neural Network for the diagnosis of Alzheimer’s disease},
journal = {Neural Networks},
volume = {159},
pages = {14-24},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004282},
author = {Chaoqiang Liu and Fei Huang and Anqi Qiu},
keywords = {Monte Carlo sampling, Convolutional neural network, ResNet, DenseNet, Structural magnetic resonance imaging, Alzheimer’s disease},
abstract = {Convolutional neural networks (CNNs) have been increasingly used in the computer-aided diagnosis of Alzheimer’s Disease (AD). This study takes the advantage of the 2D-slice CNN fast computation and ensemble approaches to develop a Monte Carlo Ensemble Neural Network (MCENN) by introducing Monte Carlo sampling and an ensemble neural network in the integration with ResNet50. Our goals are to improve the 2D-slice CNN performance and to design the MCENN model insensitive to image resolution. Unlike traditional ensemble approaches with multiple base learners, our MCENN model incorporates one neural network learner and generates a large number of possible classification decisions via Monte Carlo sampling of feature importance within the combined slices. This can overcome the main weakness of the lack of 3D brain anatomical information in 2D-slice CNNs and develop a neural network to learn the 3D relevance of the features across multiple slices. Brain images from Alzheimer’s Disease Neuroimaging Initiative (ADNI, 7199 scans), the Open Access Series of Imaging Studies-3 (OASIS-3, 1992 scans), and a clinical sample (239 scans) are used to evaluate the performance of the MCENN model for the classification of cognitively normal (CN), patients with mild cognitive impairment (MCI) and AD. Our MCENN with a small number of slices and minimal image processing (rigid transformation, intensity normalization, skull stripping) achieves the AD classification accuracy of 90%, better than existing 2D-slice CNNs (accuracy: 63%∼84%) and 3D CNNs (accuracy: 74%∼88%). Furthermore, the MCENN is robust to be trained in the ADNI dataset and applied to the OASIS-3 dataset and the clinical sample. Our experiments show that the AD classification accuracy of the MCENN model is comparable when using high- and low-resolution brain images, suggesting the insensitivity of the MCENN to image resolution. Hence, the MCENN does not require high-resolution 3D brain structural images and comprehensive image processing, which supports its potential use in a clinical setting.}
}
@article{MAZUMDER2023202,
title = {Leveraging joint incremental learning objective with data ensemble for class incremental learning},
journal = {Neural Networks},
volume = {161},
pages = {202-212},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000175},
author = {Pratik Mazumder and Mohammed Asad Karim and Indu Joshi and Pravendra Singh},
keywords = {Incremental learning, Image classification, Deep learning},
abstract = {A class-incremental learning problem is characterized by training data becoming available in a phase-by-phase manner. Deep learning models suffer from catastrophic forgetting of the classes in the older phases as they get trained on the classes introduced in the new phase. In this work, we show that the change in orientation of an image has a considerable effect on the model prediction accuracy, which in turn demonstrates the different rates of catastrophic forgetting for the different orientations of the same image, which is a novel finding. Based on this, we propose a data-ensemble approach that combines the predictions for the different orientations of the image to help the model retain information regarding the previously seen classes and thereby reduce the rate of forgetting in the model predictions. However, we cannot directly use the data-ensemble approach if the model is trained using traditional techniques. Therefore, we also propose a novel training approach using a joint-incremental learning objective (JILO) that involves jointly training the network with two incremental learning objectives, i.e., the class-incremental learning objective and our proposed data-incremental learning objective. We empirically demonstrate that JILO is vital to the data-ensemble approach. We apply our proposed approach to state-of-the-art class-incremental learning methods and empirically show that our approach significantly improves the performance of these methods. Our proposed approach significantly improves the performance of the state-of-the-art method (AANets) on the CIFAR-100 dataset by absolute margins of 3.30%, 4.28%, 3.55%, 4.03%, for the number of phases P=50, 25, 10, and 5, respectively, which establishes the efficacy of the proposed work.}
}
@article{ATTO202312,
title = {On joint parameterizations of linear and nonlinear functionals in neural networks},
journal = {Neural Networks},
volume = {160},
pages = {12-21},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005111},
author = {Abdourrahmane Mahamane Atto and Sylvie Galichet and Dominique Pastor and Nicolas Méger},
keywords = {Deep learning, Ensemble learning, Sigmoid shrinkage, Rectified sigmoid, Parametric activation, Convolutional neural network},
abstract = {The paper proposes a new class of nonlinear operators and a dual learning paradigm where optimization jointly concerns both linear convolutional weights and the parameters of these nonlinear operators. The nonlinear class proposed to perform a rich functional representation is composed by functions called rectified parametric sigmoid units. This class is constructed to benefit from the advantages of both sigmoid and rectified linear unit functions, while rejecting their respective drawbacks. Moreover, the analytic form of this new neural class involves scale, shift and shape parameters to obtain a wide range of activation shapes, including the standard rectified linear unit as a limit case. Parameters of this neural transfer class are considered as learnable for the sake of discovering the complex shapes that can contribute to solving machine learning issues. Performance achieved by the joint learning of convolutional and rectified parametric sigmoid learnable parameters are shown to be outstanding in both shallow and deep learning frameworks. This class opens new prospects with respect to machine learning in the sense that main learnable parameters are attached not only to linear transformations, but also to a wide range of nonlinear operators.}
}
@article{LI2023343,
title = {Multi-relational graph convolutional networks: Generalization guarantees and experiments},
journal = {Neural Networks},
volume = {161},
pages = {343-358},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.044},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000576},
author = {Xutao Li and Michael K. Ng and Guangning Xu and Andy Yip},
keywords = {Multi-relational data, Graph convolutional networks, Algorithmic stability, Generalization guarantees},
abstract = {The class of multi-relational graph convolutional networks (MRGCNs) is a recent extension of standard graph convolutional networks (GCNs) to handle heterogenous graphs with multiple types of relationships. MRGCNs have been shown to yield results superior than traditional GCNs in various machine learning tasks. The key idea is to introduce a new kind of convolution operated on tensors that can effectively exploit correlations exhibited in multiple relationships. The main objective of this paper is to analyze the algorithmic stability and generalization guarantees of MRGCNs to confirm the usefulness of MRGCNs. Our contributions are of three folds. First, we develop a matrix representation of various tensor operations underneath MRGCNs to simplify the analysis significantly. Next, we prove the uniform stability of MRGCNs and deduce the convergence of the generalization gap to support the usefulness of MRGCNs. The analysis sheds lights on the design of MRGCNs, for instance, how the data should be scaled to achieve the uniform stability of the learning process. Finally, we provide experimental results to demonstrate the stability results.}
}
@article{FEI2023175,
title = {Deterministic learning-based neural network control with adaptive phase compensation},
journal = {Neural Networks},
volume = {160},
pages = {175-191},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000059},
author = {Yiming Fei and Dongyu Li and Yanan Li and Jiangang Li},
keywords = {Deterministic learning, Radial basis function neural network (RBFNN), Adaptive phase compensation, Neural network learning control},
abstract = {Under the persistent excitation (PE) condition, the real dynamics of the nonlinear system can be obtained through the deterministic learning-based radial basis function neural network (RBFNN) control. However, in this scheme, the learning speed and accuracy are limited by the tradeoff between the PE levels and the approximation capabilities of the neural network (NN). Inspired by the frequency domain phase compensation of linear time-invariant (LTI) systems, this paper presents an adaptive phase compensator employing the pure time delay to improve the performance of the deterministic learning-based adaptive feedforward control with the reference input known a priori. When the adaptive phase compensation is applied to the hidden layer of the RBFNN, the nonlinear approximation capability of the RBFNN is effectively improved such that both the learning performance (learning speed and accuracy) and the control performance of the deterministic learning-based control scheme are improved. Theoretical analysis is conducted to prove the stability of the proposed learning control scheme for a class of systems which are affine in the control. Simulation studies demonstrate the effectiveness of the proposed phase compensation method.}
}
@article{JALALI2023122,
title = {Adversarial Lagrangian integrated contrastive embedding for limited size datasets},
journal = {Neural Networks},
volume = {160},
pages = {122-131},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005238},
author = {Amin Jalali and Minho Lee},
keywords = {Deep learning, Adversarial transfer contrastive embedding, Small and limited datasets, Sparsity and low-rank constraints, Augmented Lagrangian multipliers},
abstract = {Certain datasets contain a limited number of samples with highly various styles and complex structures. This study presents a novel adversarial Lagrangian integrated contrastive embedding (ALICE) method for small-sized datasets. First, the accuracy improvement and training convergence of the proposed pre-trained adversarial transfer are shown on various subsets of datasets with few samples. Second, a novel adversarial integrated contrastive model using various augmentation techniques is investigated. The proposed structure considers the input samples with different appearances and generates a superior representation with adversarial transfer contrastive training. Finally, multi-objective augmented Lagrangian multipliers encourage the low-rank and sparsity of the presented adversarial contrastive embedding to adaptively estimate the coefficients of the regularizers automatically to the optimum weights. The sparsity constraint suppresses less representative elements in the feature space. The low-rank constraint eliminates trivial and redundant components and enables superior generalization. The performance of the proposed model is verified by conducting ablation studies by using benchmark datasets for scenarios with small data samples.}
}
@article{LEE20231,
title = {STACoRe: Spatio-temporal and action-based contrastive representations for reinforcement learning in Atari},
journal = {Neural Networks},
volume = {160},
pages = {1-11},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200510X},
author = {Young Jae Lee and Jaehoon Kim and Mingu Kwak and Young Joon Park and Seoung Bum Kim},
keywords = {Atari, Automatic data augmentation, End-to-end learning, Reinforcement learning, Supervised contrastive learning, Spatio-temporal contrastive learning},
abstract = {With the development of deep learning technology, deep reinforcement learning (DRL) has successfully built intelligent agents in sequential decision-making problems through interaction with image-based environments. However, learning from unlimited interaction is impractical and sample inefficient because training an agent requires many trial and error and numerous samples. One response to this problem is sample-efficient DRL, a research area that encourages learning effective state representations in limited interactions with image-based environments. Previous methods could effectively surpass human performance by training an RL agent using self-supervised learning and data augmentation to learn good state representations from a given interaction. However, most of the existing methods only consider similarity of image observations so that they are hard to capture semantic representations. To address these challenges, we propose spatio-temporal and action-based contrastive representation (STACoRe) learning for sample-efficient DRL. STACoRe performs two contrastive learning to learn proper state representations. One uses the agent’s actions as pseudo labels, and the other uses spatio-temporal information. In particular, when performing the action-based contrastive learning, we propose a method that automatically selects data augmentation techniques suitable for each environment for stable model training. We train the model by simultaneously optimizing an action-based contrastive loss function and spatio-temporal contrastive loss functions in an end-to-end manner. This leads to improving sample efficiency for DRL. We use 26 benchmark games in Atari 2600 whose environment interaction is limited to only 100k steps. The experimental results confirm that our method is more sample efficient than existing methods. The code is available at https://github.com/dudwojae/STACoRe.}
}
@article{ZHANG202343,
title = {Graph Spring Network and Informative Anchor Selection for session-based recommendation},
journal = {Neural Networks},
volume = {159},
pages = {43-56},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004956},
author = {Zizhuo Zhang and Bang Wang},
keywords = {Graph spring network, Informative anchor selection, Item entropy, Session-based recommendation, Graph neural network},
abstract = {Session-based recommendation (SBR) aims at predicting the next item for an ongoing anonymous session. The major challenge of SBR is how to capture richer relations in between items and learn ID-based item embeddings to capture such relations. Recent studies propose to first construct an item graph from sessions and employ a Graph Neural Network (GNN) to encode item embedding from the graph. Although such graph-based approaches have achieved performance improvements, their GNNs are not suitable for ID-based embedding learning for the SBR task. In this paper, we argue that the objective of such ID-based embedding learning is to capture a kind of neighborhood affinity in that the embedding of a node is similar to that of its neighbors’ in the embedding space. We propose a new graph neural network, called Graph Spring Network (GSN), for learning ID-based item embedding on an item graph to optimize neighborhood affinity in the embedding space. Furthermore, we argue that even stacking multiple GNN layers may not be enough to encode potential relations for two item nodes far-apart in a graph. In this paper, we propose a strategy that first selects some informative item anchors and then encode items’ potential relations to such anchors. In summary, we propose a GSN-IAS model (Graph Spring Network and Informative Anchor Selection) for the SBR task. We first construct an item graph to describe items’ co-occurrences in all sessions. We design the GSN for ID-based item embedding learning and propose an item entropy measure to select informative anchors. We then design an unsupervised learning mechanism to encode items’ relations to anchors. We next employ a shared gated recurrent unit (GRU) network to learn two session representations and make two next item predictions. Finally, we design an adaptive decision fusion strategy to fuse two predictions to make the final recommendation. Extensive experiments on three public datasets demonstrate the superiority of our GSN-IAS model over the state-of-the-art models.}
}
@article{MIAO2023444,
title = {Revisiting graph neural networks from hybrid regularized graph signal reconstruction},
journal = {Neural Networks},
volume = {157},
pages = {444-459},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004439},
author = {Jiaxing Miao and Feilong Cao and Hailiang Ye and Ming Li and Bing Yang},
keywords = {Graph neural network, Unfolding network, Regularization, Graph signal reconstruction},
abstract = {Graph neural networks (GNNs) have shown strong graph-structured data processing capabilities. However, most of them are generated based on the message-passing mechanism and lack of the systematic approach to guide their developments. Meanwhile, a unified point of view is hard to explain the design concepts of different GNN models. This paper presents a unified optimization framework from hybrid regularized graph signal reconstruction to establish the connection between the aggregation operations of different GNNs, showing that exploring the optimal solution is the process of GNN information aggregation. We use this new framework to mathematically explain several classic GNN models and summarizes their commonalities and differences from a macro perspective. The proposed framework not only provides convenience to understand GNNs, but also has a guiding significance for the proposal of new GNNs. Moreover, we design a model-driven fixed-point iteration method and a data-driven dictionary learning network according to the corresponding optimization objective and sparse representation. Then the new model, GNN based on model-driven and data-driven (GNN-MD), is established by using alternating iteration methods. We also theoretically analyze its convergence. Numerous node classification experiments on multiple datasets illustrate that the proposed GNN-MD has excellent performance and outperforms all baselines on high-feature-dimension datasets.}
}
@article{WANG2023382,
title = {U-SPDNet: An SPD manifold learning-based neural network for visual classification},
journal = {Neural Networks},
volume = {161},
pages = {382-396},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004713},
author = {Rui Wang and Xiao-Jun Wu and Tianyang Xu and Cong Hu and Josef Kittler},
keywords = {SPD manifold, Neural network, Visual classification, Skip connection, Riemannian barycenter, Riemannian optimization},
abstract = {With the development of neural networking techniques, several architectures for symmetric positive definite (SPD) matrix learning have recently been put forward in the computer vision and pattern recognition (CV&PR) community for mining fine-grained geometric features. However, the degradation of structural information during multi-stage feature transformation limits their capacity. To cope with this issue, this paper develops a U-shaped neural network on the SPD manifolds (U-SPDNet) for visual classification. The designed U-SPDNet contains two subsystems, one of which is a shrinking path (encoder) making up of a prevailing SPD manifold neural network (SPDNet (Huang and Van Gool, 2017)) for capturing compact representations from the input data. Another is a constructed symmetric expanding path (decoder) to upsample the encoded features, trained by a reconstruction error term. With this design, the degradation problem will be gradually alleviated during training. To enhance the representational capacity of U-SPDNet, we also append skip connections from encoder to decoder, realized by manifold-valued geometric operations, namely Riemannian barycenter and Riemannian optimization. On the MDSD, Virus, FPHA, and UAV-Human datasets, the accuracy achieved by our method is respectively 6.92%, 8.67%, 1.57%, and 1.08% higher than SPDNet, certifying its effectiveness.}
}
@article{GAO2023228,
title = {SSA-ICL: Multi-domain adaptive attention with intra-dataset continual learning for Facial expression recognition},
journal = {Neural Networks},
volume = {158},
pages = {228-238},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.025},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200466X},
author = {Hongxiang Gao and Min Wu and Zhenghua Chen and Yuwen Li and Xingyao Wang and Shan An and Jianqing Li and Chengyu Liu},
keywords = {Facial expression recognition, Spectral, Spatial, Attention, Long-tail and continual learning},
abstract = {Facial expression recognition (FER) is a kind of affective computing that identifies the emotional state represented in facial photographs. Various methods have been developed for completing this critical task. In spite of this progress, three significant obstacles, the interaction between spatial action units, the inadequacy of semantic information about spectral expressions and the unbalanced data distribution, are not well addressed. In this work, we propose SSA-ICL, a novel approach for FER, and solve these three difficulties inside a coherent framework. To address the first two challenges, we develop a Spectral and Spatial Attention (SSA) module that integrates spectral semantics with spatial locations to improve the performance of the model. We provide an Intra-dataset Continual Learning (ICL) module to combat the issue of long-tail distribution in FER datasets. By subdividing a single long-tail dataset into multiple sub-datasets, ICL repeatedly trains well-balanced representations from each subset and finally develop a independent classifier. We performed extensive experiments on two publicly available datasets, AffectNet and RAFDB. In comparison to existing attention modules, our SSA achieves an accuracy improvement of 3.8%∼6.7%, as evidenced by testing results. In the meanwhile, our proposed SSA-ICL can achieve superior or comparable performance to state-of-the-art FER methods (65.78% on AffectNet and 89.44% on RAFDB).}
}
@article{KIM2023369,
title = {CT-Loc: Cross-domain visual localization with a channel-wise transformer},
journal = {Neural Networks},
volume = {158},
pages = {369-383},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004555},
author = {Daeho Kim and Jaeil Kim},
keywords = {Visual localization, Cross-domain, 3D model, Transformer, Deep learning},
abstract = {We tackle the cross-domain visual localization problem of estimating camera position and orientation from real images without three-dimensional (3D) spatial mapping or modeling. Recent studies have shown suboptimal performance in this task owing to the photometric and geometric differences between synthetic and real images. In this study, we present a deep learning approach that uses a channel-wise transformer localization (CT-Loc) framework. Inspired by the human behavior of looking for structural landmarks to estimate one’s location, CT-Loc encodes the most salient features of task-relevant objects in target scenes. To evaluate the efficacy of the proposed method in a real-world application, we built a complex and large-scale dataset of the interior of the mechanical room during operations and conducted extensive performance comparisons with the publicly available state-of-the-art University of Melbourne Corridor and Virtual KITTI 2 datasets. Compared with the otherwise best-performing BIM-PoseNet indoor camera localization model, our method significantly reduces position and orientation errors through the application of attention weights and saliency maps while also learning only the visual structural patterns (e.g., floors and doors) that are most relevant to localization tasks. Our model successfully ignores uninformative objects. This approach yields higher-level robust camera-pose regression localization results without requiring prebuilt maps. The code is available at https://github.com/kdaeho27/CT-Loc.}
}
@article{SCALZO202383,
title = {A class of doubly stochastic shift operators for random graph signals and their boundedness},
journal = {Neural Networks},
volume = {158},
pages = {83-88},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004312},
author = {Bruno Scalzo and Ljubiša Stanković and Miloš Daković and Anthony G. Constantinides and Danilo P. Mandic},
keywords = {Graph signal processing, Doubly stochastic matrix, Shift operator, Statistical consistency, Boundedness analysis, Graph neural networks},
abstract = {A class of doubly stochastic graph shift operators (GSO) is proposed, which is shown to exhibit: (i) lower and upper L2-boundedness for locally stationary random graph signals, (ii) L2-isometry for i.i.d. random graph signals with the asymptotic increase in the incoming neighbourhood size of vertices, and (iii) preservation of the mean of any graph signal – all prerequisites for reliable graph neural networks. These properties are obtained through a statistical consistency analysis of the proposed graph shift operator, and by exploiting the dual role of the doubly stochastic GSO as a Markov (diffusion) matrix and as an unbiased expectation operator. For generality, we consider directed graphs which exhibit asymmetric connectivity matrices. The proposed approach is validated through an example on the estimation of a vector field.}
}
@article{LIU202363,
title = {Tucker network: Expressive power and comparison},
journal = {Neural Networks},
volume = {160},
pages = {63-83},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005081},
author = {Ye Liu and Junjun Pan and Michael K. Ng},
keywords = {Expressive power, Deep neural network, Tensor decomposition},
abstract = {Deep neural networks have achieved great success in solving many machine learning and computer vision problems. In this paper, we propose a deep neural network called the Tucker network derived from the Tucker format and analyze its expressive power. The results demonstrate that the Tucker network has exponentially higher expressive power than the shallow network. In other words, a shallow network with an exponential width is required to realize the same score function as that computed by the Tucker network. Moreover, we discuss the expressive power between the hierarchical Tucker tensor network (HT network) and the proposed Tucker network. To generalize the Tucker network into a deep version, we combine the hierarchical Tucker format and Tucker format to propose a deep Tucker tensor decomposition. Its corresponding deep Tucker network is presented. Experiments are conducted on three datasets: MNIST, CIFAR-10 and CIFAR-100. The results experimentally validate the theoretical results and show that the Tucker network and deep Tucker network have better performance than the shallow network and HT network.}
}
@article{BENFENATI2023344,
title = {A singular Riemannian geometry approach to deep neural networks II. Reconstruction of 1-D equivalence classes},
journal = {Neural Networks},
volume = {158},
pages = {344-358},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004671},
author = {Alessandro Benfenati and Alessio Marta},
keywords = {Deep learning, Neural network, Classification problem, Riemannian geometry},
abstract = {We proposed in a previous work a geometric framework to study a deep neural network, seen as sequence of maps between manifolds, employing singular Riemannian geometry. In this paper, we present an application of this framework, proposing a way to build the class of equivalence of an input point: such class is defined as the set of the points on the input manifold mapped to the same output by the neural network. In other words, we build the preimage of a point in the output manifold in the input space. In particular. We focus for simplicity on the case of neural networks maps from n–dimensional real spaces to (n−1)–dimensional real spaces, we propose an algorithm allowing to build the set of points lying on the same class of equivalence. This approach leads to two main applications: the generation of new synthetic data and it may provides some insights on how a classifier can be confused by small perturbation on the input data (e.g. a penguin image classified as an image containing a chihuahua). In addition, for neural networks from 2D to 1D real spaces, we also discuss how to find the preimages of closed intervals of the real line. We also present some numerical experiments with several neural networks trained to perform non-linear regression tasks, including the case of a binary classifier.}
}
@article{DONG2023202,
title = {Performance estimation for the memristor-based computing-in-memory implementation of extremely factorized network for real-time and low-power semantic segmentation},
journal = {Neural Networks},
volume = {160},
pages = {202-215},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000084},
author = {Shuai Dong and Zhen Fan and Yihong Chen and Kaihui Chen and Minghui Qin and Min Zeng and Xubing Lu and Guofu Zhou and Xingsen Gao and Jun-Ming Liu},
keywords = {Semantic segmentation, Lightweight network, Memristor-based CIM accelerator, Real-time, Low-power},
abstract = {Nowadays many semantic segmentation algorithms have achieved satisfactory accuracy on von Neumann platforms (e.g., GPU), but the speed and energy consumption have not meet the high requirements of certain edge applications like autonomous driving. To tackle this issue, it is of necessity to design an efficient lightweight semantic segmentation algorithm and then implement it on emerging hardware platforms with high speed and energy efficiency. Here, we first propose an extremely factorized network (EFNet) which can learn multi-scale context information while preserving rich spatial information with reduced model complexity. Experimental results on the Cityscapes dataset show that EFNet achieves an accuracy of 68.0% mean intersection over union (mIoU) with only 0.18M parameters, at a speed of 99 frames per second (FPS) on a single RTX 3090 GPU. Then, to further improve the speed and energy efficiency, we design a memristor-based computing-in-memory (CIM) accelerator for the hardware implementation of EFNet. It is shown by the simulation in DNN+NeuroSim V2.0 that the memristor-based CIM accelerator is ∼63× (∼4.6×) smaller in area, at most ∼9.2× (∼1000×) faster, and ∼470× (∼2400×) more energy-efficient than the RTX 3090 GPU (the Jetson Nano embedded development board), although its accuracy slightly decreases by 1.7% mIoU. Therefore, the memristor-based CIM accelerator has great potential to be deployed at the edge to implement lightweight semantic segmentation models like EFNet. This study showcases an algorithm-hardware co-design to realize real-time and low-power semantic segmentation at the edge.}
}
@article{PAN2023198,
title = {Improving fine-tuning of self-supervised models with Contrastive Initialization},
journal = {Neural Networks},
volume = {159},
pages = {198-207},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005044},
author = {Haolin Pan and Yong Guo and Qinyi Deng and Haomin Yang and Jian Chen and Yiqun Chen},
keywords = {Self-supervised model, Model fine-tuning, Model initialization, Semantic information, Supervised contrastive loss},
abstract = {Self-supervised learning (SSL) has achieved remarkable performance in pre-training the models that can be further used in downstream tasks via fine-tuning. However, these self-supervised models may not capture meaningful semantic information since the images belonging to the same class are often regarded as negative pairs in the contrastive loss. Consequently, the images of the same class are often located far away from each other in the learned feature space, which would inevitably hamper the fine-tuning process. To address this issue, we seek to explicitly enhance the semantic relation among instances on the targeted downstream task and provide a better initialization for the subsequent fine-tuning. To this end, we propose a Contrastive Initialization (COIN) method that breaks the standard fine-tuning pipeline by introducing an extra class-aware initialization stage before fine-tuning. Specifically, we exploit a supervised contrastive loss to increase inter-class discrepancy and intra-class compactness of features on the target dataset. In this way, self-supervised models can be easily trained to discriminate instances of different classes during the final fine-tuning stage. Extensive experiments show that, with the enriched semantics, our COIN significantly outperforms existing methods without introducing extra training cost and sets new state-of-the-arts on multiple downstream tasks. For example, compared with the baseline method, our COIN improves the accuracy by 5% on ImageNet-20 and 2.57% on CIFAR100, respectively.}
}
@article{LI2023359,
title = {Video summarization for event-centric videos},
journal = {Neural Networks},
volume = {161},
pages = {359-370},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.047},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300059X},
author = {Qingwen Li and Jianni Chen and Qiqin Xie and Xiao Han},
keywords = {Event-centric videos, Video summarization, Deep learning, Boundary-aware},
abstract = {Video summarization has long been used to ease video browsing and plays a more crucial role with the explosion of online videos. In the context of event-centric videos, we aim to extract the corresponding clips of more important events in the video. To tackle the dilemma between the detection precision and the clip completeness faced by previous methods, we present an efficient Boundary-Aware framework for Summary clip Extraction (BASE) to extract summary clips with more precise boundaries while maintaining their completeness. Specifically, we propose a new distance-based importance signal to reflect the progress information in each video. The signal can not only help us to detect boundaries with higher precision, but also make it possible to preserve the clip completeness. For the feature presentation part, we also explore new information types to facilitate video summarization. Our approach outperforms current state-of-the-art video summarization models in terms of more precise clip boundaries and more complete summary clips. Note that we even yield comparable results to manual annotations.}
}
@article{TIAN2023213,
title = {Domain adaptive object detection with model-agnostic knowledge transferring},
journal = {Neural Networks},
volume = {161},
pages = {213-227},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000400},
author = {Kun Tian and Chenghao Zhang and Ying Wang and Shiming Xiang},
keywords = {Domain adaptation, Knowledge transferring, Object detection},
abstract = {The development of deep learning techniques has greatly benefited CNN-based object detectors, leading to unprecedented progress in recent years. However, the distribution variance between training and testing domains causes significant performance degradation. Labeling data for new scenarios is costly and time-consuming, so most existing domain adaptation methods perform feature alignment through adversarial training. While this can improve the accuracy of detectors in unlabeled target domains, the unconstrained domain alignment also negatively transfers the feature distribution, which compromises the recognition ability of the model. To address this problem, we propose the Knowledge Transfer Network (KTNet), which consists of object intrinsic knowledge mining and category relational knowledge constraint modules. Specifically, a binary classifier shared by the source and target domains is designed to extract common attribute knowledge of objects, which can align foreground and background features from different data domains adaptively. Then, we construct relational knowledge graphs to explicitly constrain the category correlations in the source, target, and cross-domain settings. These two modules guide the detector to learn object-related and domain-invariant representations, enabling the proposed KTNet to perform well in four commonly-used cross-domain scenarios. Furthermore, the ablation experiments show that our method is scalable to more complex backbone networks and different detection architectures.}
}
@article{LIU2023259,
title = {A subgradient-based neurodynamic algorithm to constrained nonsmooth nonconvex interval-valued optimization},
journal = {Neural Networks},
volume = {160},
pages = {259-273},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000126},
author = {Jingxin Liu and Xiaofeng Liao and Jin-song Dong and Amin Mansoori},
keywords = {Subgradient, Neurodynamic algorithm, Nonsmooth nonconvex, Interval-valued optimization, Asymptotic convergence},
abstract = {In this paper, a subgradient-based neurodynamic algorithm is presented to solve the nonsmooth nonconvex interval-valued optimization problem with both partial order and linear equality constraints, where the interval-valued objective function is nonconvex, and interval-valued partial order constraint functions are convex. The designed neurodynamic system is constructed by a differential inclusion with upper semicontinuous right-hand side, whose calculation load is reduced by relieving penalty parameters estimation and complex matrix inversion. Based on nonsmooth analysis and the extension theorem of the solution of differential inclusion, it is obtained that the global existence and boundedness of state solution of neurodynamic system, as well as the asymptotic convergence of state solution to the feasible region and the set of LU-critical points of interval-valued nonconvex optimization problem. Several numerical experiments and the applications to emergency supplies distribution and nondeterministic fractional continuous static games are solved to illustrate the applicability of the proposed neurodynamic algorithm.}
}
@article{EO2023165,
title = {An effective low-rank compression with a joint rank selection followed by a compression-friendly training},
journal = {Neural Networks},
volume = {161},
pages = {165-177},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000242},
author = {Moonjung Eo and Suhyun Kang and Wonjong Rhee},
keywords = {Low-rank compression, Penalty regularizer, Stable rank, Beam search algorithm},
abstract = {Low-rank compression of a neural network is one of the popular compression techniques, where it has been known to have two main challenges. The first challenge is determining the optimal rank of all the layers and the second is training the neural network into a compression-friendly form. To overcome the two challenges, we propose BSR (Beam-search and Stable Rank), a low-rank compression algorithm that embodies an efficient rank-selection method and a unique compression-friendly training method. For the rank selection, BSR employs a modified beam search that can perform a joint optimization of the rank allocations over all the layers in contrast to the previously used heuristic methods. For the compression-friendly training, BSR adopts a regularization loss derived from a modified stable rank, which can control the rank while incurring almost no harm in performance. Experiment results confirm that BSR is effective and superior when compared to the existing low-rank compression methods. For CIFAR10 on ResNet56, BSR not only achieves compression but also provides a performance improvement over the baseline model’s performance for the compression ratio of up to 0.82. For CIFAR100 on ResNet56 and ImageNet on AlexNet, BSR outperforms the previous SOTA method, LC, by 4.7% and by 6.7% on the average, respectively. BSR is also effective for EfficientNet-B0 and MobileNetV2 that are known for their efficient design in terms of parameters and computational cost. We also show that BSR provides a competitive performance when compared with the recent pruning compression algorithms. As with pruning, BSR can be easily combined with quantization for an additional compression.}
}
@article{LI2023297,
title = {BalanceHRNet: An effective network for bottom-up human pose estimation},
journal = {Neural Networks},
volume = {161},
pages = {297-305},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000485},
author = {Yaoping Li and Shuangcheng Jia and Qian Li},
keywords = {Multi-branch structure, Fusion, Balance structure, Branch attention},
abstract = {In the study of human pose estimation, which is widely used in safety and sports scenes, the performance of deep learning methods is greatly reduced in high overlap rate and crowded scenes. Therefore, we propose a bottom-up model, called BalanceHRNet, which is based on balanced high-resolution module and a new branch attention module. BalanceHRNet draws on the multi-branch structure and fusion method of a popular model HigherHRNet. And our model overcomes the shortcoming of HigherHRNet that cannot obtain a large enough receptive field. Specifically, through the connecting structure in balanced high-resolution module, we can connect almost all convolutional layers and obtain a sufficiently large receptive field. At the same time, the multi-resolution representation can be maintained due to the use of balanced high-resolution module, which enable our model to recognize objects with richer scales and obtain more complex semantics information. And for branch fusion method, we design branch attention to obtain the importance of different branches at different stages. Finally, our model improves the accuracy while ensuring a smaller amount of computation than HigherHRNet. The CrowdPose dataset is used as test dataset, and HigherHRNet, AlphaPose, OpenPose and so on are taken as comparison models. The AP measured by BalanceHRNet is 63.0%, increased by 3.1% compared to best model — HigherHRNet. We also demonstrate the effectiveness of our network through the COCO(2017) keypoint detection dataset. Compared with HigherHRNet-w32, the AP of our model is improved by 1.6%.}
}
@article{GAO2023121,
title = {DANet: Semi-supervised differentiated auxiliaries guided network for video action recognition},
journal = {Neural Networks},
volume = {158},
pages = {121-131},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004506},
author = {Guangyu Gao and Ziming Liu and Guangjun Zhang and Jinyang Li and A.K. Qin},
keywords = {Action recognition, Semi-supervised learning, Contrastive loss, Unannotated video},
abstract = {Video Action Recognition (ViAR) aims to identify the category of the human action observed in a given video. With the advent of Deep Learning (DL) techniques, noticeable performance breakthroughs have been achieved in this study. However, the success of most existing DL-based ViAR methods heavily relies on the existence of a large amount of annotated data, i.e., videos with corresponding action categories. In practice, obtaining such a desired number of annotations is often difficult due to expensive labeling costs, which may lead to significant performance degradation for these methods. To address this issue, we propose an end-to-end semi-supervised Differentiated Auxiliary guided Network (DANet) to best use a few annotated videos. Except for the common supervised learning on a few annotated videos, the DANet also involves the knowledge of multiple pre-trained auxiliary networks to optimize the ViAR network in a self-supervised way on the unannotated data by removing the annotations. Considering the tight connection between video action recognition and classical static image-based visual tasks, the abundant knowledge from the pre-trained static image-based models can be used for training the ViAR model. Specifically, the DANet is a two-branch architecture, which includes a target branch of the ViAR network, and an auxiliary branch of multiple auxiliary networks (i.e., referring to diverse off-the-shelf models of relevant image tasks). Given a limited number of annotated videos, we train the target ViAR network end-to-end in a semi-supervised way, namely, with both the supervised cross-entropy loss on annotated videos, and the per-auxiliary weighted self-supervised contrastive losses on the same videos but without using annotations. Besides, we further explore different weighted guidance of the auxiliary networks to the ViAR network to better reflect different relationships between the image-based models and the ViAR model. Finally, we conduct extensive experiments on several popular action recognition benchmarks in comparison with existing state-of-the-art methods, and the experimental results demonstrate the superiority of DANet over most of the compared methods. In particular, the DANet obviously suppresses state-of-the-art ViAR methods even with very fewer annotated videos.}
}
@article{YADAV202357,
title = {DroneAttention: Sparse weighted temporal attention for drone-camera based activity recognition},
journal = {Neural Networks},
volume = {159},
pages = {57-69},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200497X},
author = {Santosh Kumar Yadav and Achleshwar Luthra and Esha Pahwa and Kamlesh Tiwari and Heena Rathore and Hari Mohan Pandey and Peter Corcoran},
keywords = {Action recognition, Sparse weighted temporal attention, Drone vision},
abstract = {Human activity recognition (HAR) using drone-mounted cameras has attracted considerable interest from the computer vision research community in recent years. A robust and efficient HAR system has a pivotal role in fields like video surveillance, crowd behavior analysis, sports analysis, and human–computer interaction. What makes it challenging are the complex poses, understanding different viewpoints, and the environmental scenarios where the action is taking place. To address such complexities, in this paper, we propose a novel Sparse Weighted Temporal Attention (SWTA) module to utilize sparsely sampled video frames for obtaining global weighted temporal attention. The proposed SWTA is comprised of two parts. First, temporal segment network that sparsely samples a given set of frames. Second, weighted temporal attention, which incorporates a fusion of attention maps derived from optical flow, with raw RGB images. This is followed by a basenet network, which comprises a convolutional neural network (CNN) module along with fully connected layers that provide us with activity recognition. The SWTA network can be used as a plug-in module to the existing deep CNN architectures, for optimizing them to learn temporal information by eliminating the need for a separate temporal stream. It has been evaluated on three publicly available benchmark datasets, namely Okutama, MOD20, and Drone-Action. The proposed model has received an accuracy of 72.76%, 92.56%, and 78.86% on the respective datasets thereby surpassing the previous state-of-the-art performances by a margin of 25.26%, 18.56%, and 2.94%, respectively.}
}
@article{LI2023153,
title = {Path reliability-based graph attention networks},
journal = {Neural Networks},
volume = {159},
pages = {153-160},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004622},
author = {Yayang Li and Shuqing Liang and Yuncheng Jiang},
keywords = {Path reliability, Graph attention network, Graph transformer, Graph Neural Networks, Deep learning},
abstract = {Self-attention mechanism has been successfully introduced in Graph Neural Networks (GNNs) for graph representation learning and achieved state-of-the-art performances in tasks such as node classification and node attacks. In most existing attention-based GNNs, attention score is only computed between two directly connected nodes with their representation at a single layer. However, this attention score computation method cannot account for its multi-hop neighbors, which supply graph structure information and have influence on many tasks such as link prediction, knowledge graph completion, and adversarial attack as well. In order to address this problem, in this paper, we propose Path Reliability-based Graph Attention Networks (PRGATs), a novel method to incorporate multi-hop neighboring context into attention score computation, enabling to capture longer-range dependencies and large-scale structural information within a single layer. Moreover, path reliability-based attention layer, a core layer of PRGATs, uses a resource-constrain allocation algorithm to compute the reliable path and its attention scores from neighboring nodes to non-neighboring nodes, increasing the receptive field for every message-passing layer. Experimental results on real-world datasets show that, as compared with baselines, our model outperforms existing methods up to 3% on standard node classification and 12% on graph universal adversarial attack.}
}
@article{DORNAIKA2023188,
title = {A unified deep semi-supervised graph learning scheme based on nodes re-weighting and manifold regularization},
journal = {Neural Networks},
volume = {158},
pages = {188-196},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004580},
author = {Fadi Dornaika and Jingjun Bi and Chongsheng Zhang},
keywords = {Semi-supervised learning, Deep Graph Neural Networks, Graph Convolutional Networks, Graph construction, Graph regularization},
abstract = {In recent years, semi-supervised learning on graphs has gained importance in many fields and applications. The goal is to use both partially labeled data (labeled examples) and a large amount of unlabeled data to build more effective predictive models. Deep Graph Neural Networks (GNNs) are very useful in both unsupervised and semi-supervised learning problems. As a special class of GNNs, Graph Convolutional Networks (GCNs) aim to obtain data representation through graph-based node smoothing and layer-wise neural network transformations. However, GCNs have some weaknesses when applied to semi-supervised graph learning: (1) it ignores the manifold structure implicitly encoded by the graph; (2) it uses a fixed neighborhood graph and focuses only on the convolution of a graph, but pays little attention to graph construction; (3) it rarely considers the problem of topological imbalance. To overcome the above shortcomings, in this paper, we propose a novel semi-supervised learning method called Re-weight Nodes and Graph Learning Convolutional Network with Manifold Regularization (ReNode-GLCNMR). Our proposed method simultaneously integrates graph learning and graph convolution into a unified network architecture, which also enforces label smoothing through an unsupervised loss term. At the same time, it addresses the problem of imbalance in graph topology by adaptively reweighting the influence of labeled nodes based on their distances to the class boundaries. Experiments on 8 benchmark datasets show that ReNode-GLCNMR significantly outperforms the state-of-the-art semi-supervised GNN methods.11The code is available at https://github.com/BiJingjun/ReNode-GLCNMR.}
}
@article{HUANG202325,
title = {Interpretable local flow attention for multi-step traffic flow prediction},
journal = {Neural Networks},
volume = {161},
pages = {25-38},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000230},
author = {Xu Huang and Bowen Zhang and Shanshan Feng and Yunming Ye and Xutao Li},
keywords = {Traffic flow prediction, Attention mechanism, Neural networks, Explainable artificial intelligence},
abstract = {Traffic flow prediction (TFP) has attracted increasing attention with the development of smart city. In the past few years, neural network-based methods have shown impressive performance for TFP. However, most of previous studies fail to explicitly and effectively model the relationship between inflows and outflows. Consequently, these methods are usually uninterpretable and inaccurate. In this paper, we propose an interpretable local flow attention (LFA) mechanism for TFP, which yields three advantages. (1) LFA is flow-aware. Different from existing works, which blend inflows and outflows in the channel dimension, we explicitly exploit the correlations between flows with a novel attention mechanism. (2) LFA is interpretable. It is formulated by the truisms of traffic flow, and the learned attention weights can well explain the flow correlations. (3) LFA is efficient. Instead of using global spatial attention as in previous studies, LFA leverages the local mode. The attention query is only performed on the local related regions. This not only reduces computational cost but also avoids false attention. Based on LFA, we further develop a novel spatiotemporal cell, named LFA-ConvLSTM (LFA-based convolutional long short-term memory), to capture the complex dynamics in traffic data. Specifically, LFA-ConvLSTM consists of three parts. (1) A ConvLSTM module is utilized to learn flow-specific features. (2) An LFA module accounts for modeling the correlations between flows. (3) A feature aggregation module fuses the above two to obtain a comprehensive feature. Extensive experiments on two real-world datasets show that our method achieves a better prediction performance. We improve the RMSE metric by 3.2%–4.6%, and the MAPE metric by 6.2%–6.7%. Our LFA-ConvLSTM is also almost 32% faster than global self-attention ConvLSTM in terms of prediction time. Furthermore, we also present some visual results to analyze the learned flow correlations.}
}
@article{WU2023132,
title = {Coexistence and local stability of multiple equilibrium points for fractional-order state-dependent switched competitive neural networks with time-varying delays},
journal = {Neural Networks},
volume = {160},
pages = {132-147},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005056},
author = {Zhongwen Wu and Xiaobing Nie and Boqiang Cao},
keywords = {Fractional-order competitive neural networks, Multistability, State-dependent switching, Sigmoidal activation functions, Time-varying delays},
abstract = {This paper investigates the coexistence and local stability of multiple equilibrium points for a class of competitive neural networks with sigmoidal activation functions and time-varying delays, in which fractional-order derivative and state-dependent switching are involved at the same time. Some novel criteria are established to ensure that such n-neuron neural networks can have 5m1⋅3m2 total equilibrium points and 3m1⋅2m2 locally stable equilibrium points with m1+m2=n, based on the fixed-point theorem, the definition of equilibrium point in the sense of Filippov, the theory of fractional-order differential equation and Lyapunov function method. The investigation implies that the competitive neural networks with switching can possess greater storage capacity than the ones without switching. Moreover, the obtained results include the multistability results of both fractional-order switched Hopfield neural networks and integer-order switched Hopfield neural networks as special cases, thus generalizing and improving some existing works. Finally, four numerical examples are presented to substantiate the effectiveness of the theoretical analysis.}
}
@article{BAKER2023274,
title = {A domain-agnostic approach for characterization of lifelong learning systems},
journal = {Neural Networks},
volume = {160},
pages = {274-296},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000072},
author = {Megan M. Baker and Alexander New and Mario Aguilar-Simon and Ziad Al-Halah and Sébastien M.R. Arnold and Ese Ben-Iwhiwhu and Andrew P. Brna and Ethan Brooks and Ryan C. Brown and Zachary Daniels and Anurag Daram and Fabien Delattre and Ryan Dellana and Eric Eaton and Haotian Fu and Kristen Grauman and Jesse Hostetler and Shariq Iqbal and Cassandra Kent and Nicholas Ketz and Soheil Kolouri and George Konidaris and Dhireesha Kudithipudi and Erik Learned-Miller and Seungwon Lee and Michael L. Littman and Sandeep Madireddy and Jorge A. Mendez and Eric Q. Nguyen and Christine Piatko and Praveen K. Pilly and Aswin Raghavan and Abrar Rahman and Santhosh Kumar Ramakrishnan and Neale Ratzlaff and Andrea Soltoggio and Peter Stone and Indranil Sur and Zhipeng Tang and Saket Tiwari and Kyle Vedder and Felix Wang and Zifan Xu and Angel Yanguas-Gil and Harel Yedidsion and Shangqun Yu and Gautam K. Vallabha},
keywords = {Lifelong learning, Reinforcement learning, Continual learning, System evaluation, Catastrophic forgetting},
abstract = {Despite the advancement of machine learning techniques in recent years, state-of-the-art systems lack robustness to “real world” events, where the input distributions and tasks encountered by the deployed systems will not be limited to the original training context, and systems will instead need to adapt to novel distributions and tasks while deployed. This critical gap may be addressed through the development of “Lifelong Learning” systems that are capable of (1) Continuous Learning, (2) Transfer and Adaptation, and (3) Scalability. Unfortunately, efforts to improve these capabilities are typically treated as distinct areas of research that are assessed independently, without regard to the impact of each separate capability on other aspects of the system. We instead propose a holistic approach, using a suite of metrics and an evaluation framework to assess Lifelong Learning in a principled way that is agnostic to specific domains or system techniques. Through five case studies, we show that this suite of metrics can inform the development of varied and complex Lifelong Learning systems. We highlight how the proposed suite of metrics quantifies performance trade-offs present during Lifelong Learning system development — both the widely discussed Stability-Plasticity dilemma and the newly proposed relationship between Sample Efficient and Robust Learning. Further, we make recommendations for the formulation and use of metrics to guide the continuing development of Lifelong Learning systems and assess their progress in the future.}
}
@article{WANG202350,
title = {2DHeadPose: A simple and effective annotation method for the head pose in RGB images and its dataset},
journal = {Neural Networks},
volume = {160},
pages = {50-62},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005214},
author = {Yang Wang and Wanlin Zhou and Jiakai Zhou},
keywords = {Head pose estimation, Landmark-free, Landmark-based, Label smoothing, 2DHeadPose},
abstract = {Head pose estimation is one of the essential tasks in computer vision, which predicts the Euler angles of the head in an image. In recent years, CNN-based methods for head pose estimation have achieved excellent performance. Their training relies on RGB images providing facial landmarks or depth images from RGBD cameras. However, labeling facial landmarks is complex for large angular head poses in RGB images, and RGBD cameras are unsuitable for outdoor scenes. We propose a simple and effective annotation method for the head pose in RGB images. The novelty method uses a 3D virtual human head to simulate the head pose in the RGB image. The Euler angle can be calculated from the change in coordinates of the 3D virtual head. We then create a dataset using our annotation method: 2DHeadPose dataset, which contains a rich set of attributes, dimensions, and angles. Finally, we propose Gaussian label smoothing to suppress annotation noises and reflect inter-class relationships. A baseline approach is established using Gaussian label smoothing. Experiments demonstrate that our annotation method, datasets, and Gaussian label smoothing are very effective. Our baseline approach surpasses most current state-of-the-art methods. The annotation tool, dataset, and source code are publicly available at https://github.com/youngnuaa/2DHeadPose.}
}
@article{TSVETKOV2023515,
title = {The role of capacity constraints in Convolutional Neural Networks for learning random versus natural data},
journal = {Neural Networks},
volume = {161},
pages = {515-524},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000114},
author = {Christian Tsvetkov and Gaurav Malhotra and Benjamin D. Evans and Jeffrey S. Bowers},
keywords = {Deep Neural Networks, Capacity, Biological constraints, Internal noise, Bottleneck},
abstract = {Convolutional neural networks (CNNs) are often described as promising models of human vision, yet they show many differences from human abilities. We focus on a superhuman capacity of top-performing CNNs, namely, their ability to learn very large datasets of random patterns. We verify that human learning on such tasks is extremely limited, even with few stimuli. We argue that the performance difference is due to CNNs’ overcapacity and introduce biologically inspired mechanisms to constrain it, while retaining the good test set generalisation to structured images as characteristic of CNNs. We investigate the efficacy of adding noise to hidden units’ activations, restricting early convolutional layers with a bottleneck, and using a bounded activation function. Internal noise was the most potent intervention and the only one which, by itself, could reduce random data performance in the tested models to chance levels. We also investigated whether networks with biologically inspired capacity constraints show improved generalisation to out-of-distribution stimuli, however little benefit was observed. Our results suggest that constraining networks with biologically motivated mechanisms paves the way for closer correspondence between network and human performance, but the few manipulations we have tested are only a small step towards that goal.}
}
@article{CHEN2023505,
title = {SP-GNN: Learning structure and position information from graphs},
journal = {Neural Networks},
volume = {161},
pages = {505-514},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.051},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000631},
author = {Yangrui Chen and Jiaxuan You and Jun He and Yuan Lin and Yanghua Peng and Chuan Wu and Yibo Zhu},
keywords = {Graph neural networks, Positional embedding, Structural embedding, Node classification, Graph classification},
abstract = {Graph neural network (GNN) is a powerful model for learning from graph data. However, existing GNNs may have limited expressive power, especially in terms of capturing adequate structural and positional information of input graphs. Structure properties and node position information are unique to graph-structured data, but few GNNs are capable of capturing them. This paper proposes Structure- and Position-aware Graph Neural Networks (SP-GNN), a new class of GNNs offering generic and expressive power of graph data. SP-GNN enhances the expressive power of GNN architectures by incorporating a near-isometric proximity-aware position encoder and a scalable structure encoder. Further, given a GNN learning task, SP-GNN can be used to analyze positional and structural awareness of GNN tasks using the corresponding embeddings computed by the encoders. The awareness scores can guide fusion strategies of the extracted positional and structural information with raw features for better performance of GNNs on downstream tasks. We conduct extensive experiments using SP-GNN on various graph datasets and observe significant improvement in classification over existing GNN models.}
}
@article{BELOMESTNY2023242,
title = {Simultaneous approximation of a smooth function and its derivatives by deep neural networks with piecewise-polynomial activations},
journal = {Neural Networks},
volume = {161},
pages = {242-253},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000473},
author = {Denis Belomestny and Alexey Naumov and Nikita Puchkin and Sergey Samsonov},
keywords = {Deep neural networks, Approximation complexity, ReQU activations, ReLU activations, Hölder class},
abstract = {This paper investigates the approximation properties of deep neural networks with piecewise-polynomial activation functions. We derive the required depth, width, and sparsity of a deep neural network to approximate any Hölder smooth function up to a given approximation error in Hölder norms in such a way that all weights of this neural network are bounded by 1. The latter feature is essential to control generalization errors in many statistical and machine learning applications.}
}
@article{WEN202384,
title = {Factorizing time-heterogeneous Markov transition for temporal recommendation},
journal = {Neural Networks},
volume = {159},
pages = {84-96},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004737},
author = {Wen Wen and Wencui Wang and Zhifeng Hao and Ruichu Cai},
keywords = {Temporal recommendation, Tensor factorization, Time-heterogeneous, Neural network},
abstract = {Temporal recommendation which recommends items to users with consideration of time information has been of wide interest in recent years. But huge event space, highly sparse user activities and time-heterogeneous dependency of temporal behaviors make it really challenging to learn the temporal patterns for high-quality recommendation. In this paper, aiming to handle these challenges, especially the time-heterogeneous characteristic of user’s temporal behaviors, we proposed the Neural-based Time-heterogenous Markov Transition (NeuralTMT) model. Firstly, users’ temporal behaviors are mathematically simplified as the third-order Markov transition tensors. And then a linear co-factorization model which learns the time-evolving user/item factors from these tensors is proposed. Furthermore, the model is extended to the neural-based learning framework (NeuralTMT), which is more flexible and able to capture time-heterogeneous temporal patterns via nonlinear neural network mappings and attention techniques. Extensive experiments on four datasets demonstrate that NeuralTMT performs significantly better than the state-of-the-art baselines. And the proposed method is fundamentally inspired by factorization techniques, which may also provide some interesting ideas on the connection of tensor factorization and neural-based sequential recommendation methods.}
}
@article{TAI202355,
title = {Asynchronous dissipative stabilization for stochastic Markov-switching neural networks with completely- and incompletely-known transition rates},
journal = {Neural Networks},
volume = {161},
pages = {55-64},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.039},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000515},
author = {Weipeng Tai and Xinling Li and Jianping Zhou and Sabri Arik},
keywords = {Stochastic neural networks, Markov switching, Asynchronous control, Transition rates, Extended dissipativity},
abstract = {The asynchronous dissipative stabilization for stochastic Markov-switching neural networks (SMSNNs) is investigated. The aim is to design an output-feedback controller with inconsistent mode switching to ensure that the SMSNN is stochastically stable with extended dissipativity. Two situations, which involve completely- and incompletely-known transition rates (TRs), are taken into account. The situation that all TRs are exactly known is considered first. By applying a mode-dependent Lyapunov–Krasovskii functional, Dynkin’s formula, and several matrix inequalities, a criterion for the desired performance of the closed-loop SMSNN is derived and a design method for determining the asynchronous controller is developed. Then, the study is generalized to the situation where some TRs are allowed to be uncertain or even fully unknown. An inequality is established for judging the upper bound of the product of the TRs with the Lyapunov matrix by making full use of accessible information on the incompletely-known TRs. Based on the inequality, performance analysis and control synthesis are presented without imposing the zero-sum hypothesis of the uncertainties in the TR matrix. Finally, an example with numerical calculation and simulation is provided to verify the validity of the stabilizing approaches.}
}
@article{HUANG2023272,
title = {IA-FaceS: A bidirectional method for semantic face editing},
journal = {Neural Networks},
volume = {158},
pages = {272-292},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004579},
author = {Wenjing Huang and Shikui Tu and Lei Xu},
keywords = {Deep bidirectional method, Disentangled attribute manipulation, Facial component editing},
abstract = {Semantic face editing has achieved substantial progress in recent years. However, existing face editing methods, which often encode the entire image into a single code, still have difficulty in enabling flexible editing while keeping high-fidelity reconstruction. The one-code scheme also brings entangled face manipulations and limited flexibility in editing face components. In this paper, we present IA-FaceS, a bidirectional method for disentangled face attribute manipulation as well as flexible, controllable component editing. We propose to embed images onto two branches: one branch computes high-dimensional component-invariant content embedding for capturing face details, and the other provides low-dimensional component-specific embeddings for component manipulations. The two-branch scheme naturally enables high-quality facial component-level editing while keeping faithful reconstruction with details. Moreover, we devise a component adaptive modulation (CAM) module, which integrates component-specific guidance into the decoder and successfully disentangles highly-correlated face components. The single-eye editing is developed for the first time without editing face masks or sketches. According to the experimental results, IA-FaceS establishes a good balance between maintaining image details and performing flexible face manipulation. Both quantitative and qualitative results indicate that the proposed method outperforms the existing methods in reconstruction, face attribute manipulation, and component transfer. We release the code and weights at: https://github.com/CMACH508/IA-FaceS.}
}
@article{TAYLORMELANSON202325,
title = {SGORNN: Combining scalar gates and orthogonal constraints in recurrent networks},
journal = {Neural Networks},
volume = {159},
pages = {25-33},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004695},
author = {Will Taylor-Melanson and Martha Dais Ferreira and Stan Matwin},
keywords = {Recurrent Neural Networks, Deep learning, Unitary matrices, Exploding gradient problem},
abstract = {Recurrent Neural Network (RNN) models have been applied in different domains, producing high accuracies on time-dependent data. However, RNNs have long suffered from exploding gradients during training, mainly due to their recurrent process. In this context, we propose a variant of the scalar gated FastRNN architecture, called Scalar Gated Orthogonal Recurrent Neural Networks (SGORNN). SGORNN utilizes orthogonal matrices at the recurrent step. Our experiments evaluate SGORNN using two recently proposed orthogonal parametrizations for the recurrent weights of an RNN. We present a constraint on the scalar gates of SGORNN, which is easily enforced at training time to provide a probabilistic generalization gap which grows linearly with the length of sequences processed. Next, we provide bounds on the gradients of SGORNN to show the impossibility of exponentially exploding gradients through time. Our experimental results on the addition problem confirm that our combination of orthogonal and scalar gated RNNs are able to outperform other orthogonal RNNs and LSTM on long sequences. We further evaluate SGORNN on the HAR-2 classification task, where it improves upon the accuracy of several models using far fewer parameters than standard RNNs. Finally, we evaluate SGORNN on the Penn Treebank word-level language modeling task, where it again outperforms its related architectures and shows comparable performance to LSTM using far less parameters. Overall, SGORNN shows higher representation capacity than the other orthogonal RNNs tested, suffers from less overfitting than other models in our experiments, benefits from a decrease in parameter count, and alleviates exploding gradients during backpropagation through time.}
}
@article{YELUGAM202334,
title = {Topological biclustering ARTMAP for identifying within bicluster relationships},
journal = {Neural Networks},
volume = {160},
pages = {34-49},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005020},
author = {Raghu Yelugam and Leonardo Enzo {Brito da Silva} and Donald C. {Wunsch II}},
keywords = {Biclustering, Topological data analysis, Adaptive resonance theory (ART), Gene expression, Gene Co-expression},
abstract = {Biclustering is a powerful tool for exploratory data analysis in domains such as social networking, data reduction, and differential gene expression studies. Topological learning identifies connected regions that are difficult to find using other traditional clustering methods and produces a graphical representation. Therefore, to improve the quality of biclustering and module extraction, this work combines the adaptive resonance theory (ART)-based methods of biclustering ARTMAP (BARTMAP) and topological ART (TopoART), to produce TopoBARTMAP. The latter inherits the ability to detect topological associations while performing data reduction. The capabilities of TopoBARTMAP were benchmarked using 35 real world cancer datasets and contrasted with other (bi)clustering methods, where it showed a statistically significant improvement over the other assessed methods on ordered and shuffled data experiments. In experiments with 12 synthetic datasets, the method was observed to perform better at identifying constant, scale, shift, and shift scale type biclusters. The produced graphical representation was refined to represent gene bicluster associations and was assessed on the NCBI GSE89116 dataset containing expression levels of 39,326 probes sampled over 38 observations.}
}
@article{SONG2023397,
title = {MPGE and RootRank: A sufficient root cause characterization and quantification framework for industrial process faults},
journal = {Neural Networks},
volume = {161},
pages = {397-417},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000424},
author = {Pengyu Song and Chunhui Zhao and Biao Huang},
keywords = {Root cause diagnosis, Multi-level predictive graph extraction, RootRank scoring, Hierarchical adjacency pruning, Multi-level Granger causality},
abstract = {Root cause diagnosis can locate abnormalities of industrial processes, ensuring production safety and manufacturing efficiency. However, existing root cause diagnosis models only consider pairwise direct causality and ignore the multi-level fault propagation, which may lead to incomplete root cause descriptions and ambiguous root cause candidates. To address the above issue, a novel framework, named multi-level predictive graph extraction (MPGE) and RootRank scoring, is proposed and applied to the root cause diagnosis for industrial processes. In this framework, both direct and indirect Granger causalities are characterized by multi-level predictive relationships to provide a sufficient characterization of root cause variables. First, a predictive graph structure with a sparse constrained adjacency matrix is constructed to describe the information transmission between variables. The information of variables is deeply fused according to the adjacency matrix to consider multi-level fault propagation. Then, a hierarchical adjacency pruning (HAP) mechanism is designed to automatically capture vital predictive relationships through adjacency redistribution. In this way, the multi-level causalities between variables are extracted to fully describe both direct and indirect fault propagation and highlight the root cause. Further, a RootRank scoring algorithm is proposed to analyze the predictive graph and quantify the fault propagation contribution of each variable, thereby giving definite root cause identification results. Three examples are adopted to verify the diagnostic performance of the proposed framework, including a numerical example, the Tennessee Eastman benchmark process, and a real cut-made process of cigarette. Both theoretical analysis and experimental verification show the high interpretability and reliability of the proposed framework.}
}
@article{MA2023154,
title = {A feedforward unitary equivariant neural network},
journal = {Neural Networks},
volume = {161},
pages = {154-164},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.042},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000540},
author = {Pui-Wai Ma and T.-H. Hubert Chan},
keywords = {Equivariant neural network, Feedforward neural network, Unitary equivariant, Rotational equivariant},
abstract = {We devise a new type of feedforward neural network. It is equivariant with respect to the unitary group U(n). The input and output can be vectors in ℂn with arbitrary dimension n. No convolution layer is required in our implementation. We avoid errors due to truncated higher order terms in Fourier-like transformation. The implementation of each layer can be done efficiently using simple calculations. As a proof of concept, we have given empirical results on the prediction of the dynamics of atomic motion to demonstrate the practicality of our approach.}
}
@article{SHIN2023185,
title = {Accelerating gradient descent and Adam via fractional gradients},
journal = {Neural Networks},
volume = {161},
pages = {185-201},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000023},
author = {Yeonjong Shin and Jérôme Darbon and George Em Karniadakis},
keywords = {Caputo fractional derivative, Non-local calculus, Optimization, Adam, Neural networks},
abstract = {We propose a class of novel fractional-order optimization algorithms. We define a fractional-order gradient via the Caputo fractional derivatives that generalizes integer-order gradient. We refer it to as the Caputo fractional-based gradient, and develop an efficient implementation to compute it. A general class of fractional-order optimization methods is then obtained by replacing integer-order gradients with the Caputo fractional-based gradients. To give concrete algorithms, we consider gradient descent (GD) and Adam, and extend them to the Caputo fractional GD (CfGD) and the Caputo fractional Adam (CfAdam). We demonstrate the superiority of CfGD and CfAdam on several large scale optimization problems that arise from scientific machine learning applications, such as ill-conditioned least squares problem on real-world data and the training of neural networks involving non-convex objective functions. Numerical examples show that both CfGD and CfAdam result in acceleration over GD and Adam, respectively. We also derive error bounds of CfGD for quadratic functions, which further indicate that CfGD could mitigate the dependence on the condition number in the rate of convergence and results in significant acceleration over GD.}
}
@article{XIAO20239,
title = {SPIDE: A purely spike-based method for training feedback spiking neural networks},
journal = {Neural Networks},
volume = {161},
pages = {9-24},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000266},
author = {Mingqing Xiao and Qingyan Meng and Zongpeng Zhang and Yisen Wang and Zhouchen Lin},
keywords = {Spiking neural networks, Equilibrium state, Spike-based training method, Neuromorphic computing},
abstract = {Spiking neural networks (SNNs) with event-based computation are promising brain-inspired models for energy-efficient applications on neuromorphic hardware. However, most supervised SNN training methods, such as conversion from artificial neural networks or direct training with surrogate gradients, require complex computation rather than spike-based operations of spiking neurons during training. In this paper, we study spike-based implicit differentiation on the equilibrium state (SPIDE) that extends the recently proposed training method, implicit differentiation on the equilibrium state (IDE), for supervised learning with purely spike-based computation, which demonstrates the potential for energy-efficient training of SNNs. Specifically, we introduce ternary spiking neuron couples and prove that implicit differentiation can be solved by spikes based on this design, so the whole training procedure, including both forward and backward passes, is made as event-driven spike computation, and weights are updated locally with two-stage average firing rates. Then we propose to modify the reset membrane potential to reduce the approximation error of spikes. With these key components, we can train SNNs with flexible structures in a small number of time steps and with firing sparsity during training, and the theoretical estimation of energy costs demonstrates the potential for high efficiency. Meanwhile, experiments show that even with these constraints, our trained models can still achieve competitive results on MNIST, CIFAR-10, CIFAR-100, and CIFAR10-DVS.}
}
@article{ZHOU2023293,
title = {Forgetting memristor based STDP learning circuit for neural networks},
journal = {Neural Networks},
volume = {158},
pages = {293-304},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004646},
author = {Wenhao Zhou and Shiping Wen and Yi Liu and Lu Liu and Xin Liu and Ling Chen},
keywords = {Forgetting memristor, Spike timing dependent plasticity (STDP), Learning rule, Circuit, Neural networks},
abstract = {The circuit implementation of STDP based on memristor is of great significance for the application of neural network. However, recent research shows that the research on the pure circuit implementation of forgetting memristor and STDP is still rare. This paper proposes a new STDP learning rule implementation circuit based on the forgetting memristor. This kind of forgetting memory resistance synapse makes the neural network have the function of time-division multiplexing, but the instability of short-term memory will affect the learning ability of the neural network. This paper analyzes and discusses the influence of synapses with long-term and short-term memory on the learning characteristics of neural network STDP, which lays a foundation for the construction of time-division multiplexing neural network with long-term and short-term memory synapses. Through this circuit, it is found that the volatile memristor has different behaviors to the stimulus signal in different initial states, and the resulting LTP phenomenon is more in line with the forgetting effect in biology. This circuit has multiple adjustable parameters, which can fit the STDP learning rules under different conditions. The application of neural network proves the availability of this circuit.}
}
@article{VILARESFERRO2023109,
title = {Early stopping by correlating online indicators in neural networks},
journal = {Neural Networks},
volume = {159},
pages = {109-124},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004920},
author = {Manuel {Vilares Ferro} and Yerai {Doval Mosquera} and Francisco J. {Ribadas Pena} and Víctor M. {Darriba Bilbao}},
keywords = {Canary functions, Early stopping, Natural language processing, Neural networks, Overfitting},
abstract = {In order to minimize the generalization error in neural networks, a novel technique to identify overfitting phenomena when training the learner is formally introduced. This enables support of a reliable and trustworthy early stopping condition, thus improving the predictive power of that type of modeling. Our proposal exploits the correlation over time in a collection of online indicators, namely characteristic functions for indicating if a set of hypotheses are met, associated with a range of independent stopping conditions built from a canary judgment to evaluate the presence of overfitting. That way, we provide a formal basis for decision making in terms of interrupting the learning process. As opposed to previous approaches focused on a single criterion, we take advantage of subsidiarities between independent assessments, thus seeking both a wider operating range and greater diagnostic reliability. With a view to illustrating the effectiveness of the halting condition described, we choose to work in the sphere of natural language processing, an operational continuum increasingly based on machine learning. As a case study, we focus on parser generation, one of the most demanding and complex tasks in the domain. The selection of cross-validation as a canary function enables an actual comparison with the most representative early stopping conditions based on overfitting identification, pointing to a promising start toward an optimal bias and variance control.}
}
@article{LEE20231,
title = {Achieving small-batch accuracy with large-batch scalability via Hessian-aware learning rate adjustment},
journal = {Neural Networks},
volume = {158},
pages = {1-14},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004488},
author = {Sunwoo Lee and Chaoyang He and Salman Avestimehr},
keywords = {Deep learning, Large-batch training, Hessian information, Learning rate adjustment},
abstract = {We consider synchronous data-parallel neural network training with a fixed large batch size. While the large batch size provides a high degree of parallelism, it degrades the generalization performance due to the low gradient noise scale. We propose a general learning rate adjustment framework and three critical heuristics that tackle the poor generalization issue. The key idea is to adjust the learning rate based on geometric information of loss landscape and encourage the model to converge into a flat minimum that is known to better generalize to the unknown data. Our empirical study demonstrates that the Hessian-aware learning rate schedule remarkably improves the generalization performance in large-batch training. For CIFAR-10 classification with ResNet20, our method achieves 92.31% accuracy using 16,384 batch size, which is close to 92.83% achieved using 128 batch size, at a negligible extra computational cost.}
}
@article{MAO202365,
title = {Cross-modal guiding and reweighting network for multi-modal RSVP-based target detection},
journal = {Neural Networks},
volume = {161},
pages = {65-82},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000096},
author = {Jiayu Mao and Shuang Qiu and Wei Wei and Huiguang He},
keywords = {Brain–computer interface (BCI), Convolutional neural network (CNN), Electroencephalogram (EEG), Rapid serial visual presentation (RSVP), Multi-modal learning},
abstract = {Rapid Serial Visual Presentation (RSVP) based Brain–Computer Interface (BCI) facilities the high-throughput detection of rare target images by detecting evoked event-related potentials (ERPs). At present, the decoding accuracy of the RSVP-based BCI system limits its practical applications. This study introduces eye movements (gaze and pupil information), referred to as EYE modality, as another useful source of information to combine with EEG-based BCI and forms a novel target detection system to detect target images in RSVP tasks. We performed an RSVP experiment, recorded the EEG signals and eye movements simultaneously during a target detection task, and constructed a multi-modal dataset including 20 subjects. Also, we proposed a cross-modal guiding and fusion network to fully utilize EEG and EYE modalities and fuse them for better RSVP decoding performance. In this network, a two-branch backbone was built to extract features from these two modalities. A Cross-Modal Feature Guiding (CMFG) module was proposed to guide EYE modality features to complement the EEG modality for better feature extraction. A Multi-scale Multi-modal Reweighting (MMR) module was proposed to enhance the multi-modal features by exploring intra- and inter-modal interactions. And, a Dual Activation Fusion (DAF) was proposed to modulate the enhanced multi-modal features for effective fusion. Our proposed network achieved a balanced accuracy of 88.00% (±2.29) on the collected dataset. The ablation studies and visualizations revealed the effectiveness of the proposed modules. This work implies the effectiveness of introducing the EYE modality in RSVP tasks. And, our proposed network is a promising method for RSVP decoding and further improves the performance of RSVP-based target detection systems.}
}
@article{DIABA2023175,
title = {Proposed algorithm for smart grid DDoS detection based on deep learning},
journal = {Neural Networks},
volume = {159},
pages = {175-184},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005032},
author = {Sayawu Yakubu Diaba and Mohammed Elmusrati},
keywords = {State estimation, Smart grid, Distributed denial of service, Intrusion detection, Gated recurrent unit, Convolutional neural network},
abstract = {The Smart Grid’s objective is to increase the electric grid’s dependability, security, and efficiency through extensive digital information and control technology deployment. As a result, it is necessary to apply real-time analysis and state estimation-based techniques to ensure efficient controls are implemented correctly. These systems are vulnerable to cyber-attacks, posing significant risks to the Smart Grid’s overall availability due to their reliance on communication technology. Therefore, effective intrusion detection algorithms are required to mitigate such attacks. In dealing with these uncertainties, we propose a hybrid deep learning algorithm that focuses on Distributed Denial of Service attacks on the communication infrastructure of the Smart Grid. The proposed algorithm is hybridized by the Convolutional Neural Network and the Gated Recurrent Unit algorithms. Simulations are done using a benchmark cyber security dataset of the Canadian Institute of Cybersecurity Intrusion Detection System. According to the simulation results, the proposed algorithm outperforms the current intrusion detection algorithms, with an overall accuracy rate of 99.7%.}
}
@article{FRANCO2023129,
title = {Approximation bounds for convolutional neural networks in operator learning},
journal = {Neural Networks},
volume = {161},
pages = {129-141},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000412},
author = {Nicola Rares Franco and Stefania Fresca and Andrea Manzoni and Paolo Zunino},
keywords = {Operator learning, Convolutional neural networks, Approximation theory},
abstract = {Recently, deep Convolutional Neural Networks (CNNs) have proven to be successful when employed in areas such as reduced order modeling of parametrized PDEs. Despite their accuracy and efficiency, the approaches available in the literature still lack a rigorous justification on their mathematical foundations. Motivated by this fact, in this paper we derive rigorous error bounds for the approximation of nonlinear operators by means of CNN models. More precisely, we address the case in which an operator maps a finite dimensional input μ∈Rp onto a functional output uμ:[0,1]d→R, and a neural network model is used to approximate a discretized version of the input-to-output map. The resulting error estimates provide a clear interpretation of the hyperparameters defining the neural network architecture. All the proofs are constructive, and they ultimately reveal a deep connection between CNNs and the Fourier transform. Finally, we complement the derived error bounds by numerical experiments that illustrate their application.}
}
@article{GUPTA2023297,
title = {Model-free forecasting of partially observable spatiotemporally chaotic systems},
journal = {Neural Networks},
volume = {160},
pages = {297-305},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000138},
author = {Vikrant Gupta and Larry K.B. Li and Shiyi Chen and Minping Wan},
keywords = {Time-series forecasting, Machine learning, Chaos, Turbulence, Reservoir computing, Echo-state networks},
abstract = {Reservoir computing is a powerful tool for forecasting turbulence because its simple architecture has the computational efficiency to handle high-dimensional systems. Its implementation, however, often requires full state-vector measurements and knowledge of the system nonlinearities. We use nonlinear projector functions to expand the system measurements to a high dimensional space and then feed them to a reservoir to obtain forecasts. We demonstrate the application of such reservoir computing networks on spatiotemporally chaotic systems, which model several features of turbulence. We show that using radial basis functions as nonlinear projectors enables complex system nonlinearities to be captured robustly even with only partial observations and without knowing the governing equations. Finally, we show that when measurements are sparse or incomplete and noisy, such that even the governing equations become inaccurate, our networks can still produce reasonably accurate forecasts, thus paving the way towards model-free forecasting of practical turbulent systems.}
}
@article{ZHOU20231,
title = {Synchronization of hybrid switching diffusions delayed networks via stochastic event-triggered control},
journal = {Neural Networks},
volume = {159},
pages = {1-13},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004919},
author = {Hui Zhou and Shufan Li and Chunmei Zhang},
keywords = {Event-triggered control, Synchronization, Hybrid switching diffusions, Time delays, Stochastic sequence},
abstract = {In this paper, the synchronization problem of stochastic complex networks with time delays and hybrid switching diffusions (SCNTH) is concerned based on event-triggered control. Therein, a new class of event-triggered function is proposed for the control design. Particularly, different from the existing work, the triggered instant generated by event-triggered control in this paper is a stochastic sequence instead of a number sequence to be more realistic for stochastic systems, which is a breakthrough. Furthermore, some sufficient conditions are derived to guarantee asymptotical synchronization in mean square, exponential synchronization in mean square and almost surely exponential synchronization of SCNTH based on sampled-data control, event-driven control theory and stability analysis. Meanwhile, the Zeno phenomenon can be avoided. Then, the synchronization of single-link robot arms is investigated in detail as a practical application of the obtained results. Ultimately, a numerical example is given for demonstration.}
}
@article{KE2023216,
title = {DF-UDetector: An effective method towards robust deepfake detection via feature restoration},
journal = {Neural Networks},
volume = {160},
pages = {216-226},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000011},
author = {Jianpeng Ke and Lina Wang},
keywords = {Degradation deepfake detection, Feature space manipulation, Deep neural networks, Face manipulation, Deep learning, Deepfakes},
abstract = {The abuse of deepfakes, a rising face swap technique, causes severe concerns about the authenticity of visual content and the dissemination of misinformation. To alleviate the threats imposed by deepfakes, a vast body of data-centric detectors has been deployed. However, the performance of these methods can be easily defected by degradations on deepfakes. To improve the performance of degradation deepfake detection, we creatively explore the recovery method in the feature space to preserve the artifacts for detection instead of directly in the image domain. In this paper, we propose a method, namely DF-UDetector, against degradation deepfakes by modeling the degraded images and transforming the extracted features to a high-quality level. To be specific, the whole model consists of three key components: an image feature extractor to capture image features, a feature transforming module to map the degradation features into a higher quality, and a discriminator to determine whether the feature map is of high quality enough. Extensive experiments on multiple video datasets show that our proposed model performs comparably or even better than state-of-the-art counterparts. Moreover, DF-UDetector outperforms by a small margin when detecting deepfakes in the wild.}
}
@article{XING2023228,
title = {Achieving efficient interpretability of reinforcement learning via policy distillation and selective input gradient regularization},
journal = {Neural Networks},
volume = {161},
pages = {228-241},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000254},
author = {Jinwei Xing and Takashi Nagata and Xinyun Zou and Emre Neftci and Jeffrey L. Krichmar},
keywords = {Efficient interpretability, Interpretable reinforcement learning, Saliency map},
abstract = {Although deep Reinforcement Learning (RL) has proven successful in a wide range of tasks, one challenge it faces is interpretability when applied to real-world problems. Saliency maps are frequently used to provide interpretability for deep neural networks. However, in the RL domain, existing saliency map approaches are either computationally expensive and thus cannot satisfy the real-time requirement of real-world scenarios or cannot produce interpretable saliency maps for RL policies. In this work, we propose an approach of Distillation with selective Input Gradient Regularization (DIGR) which uses policy distillation and input gradient regularization to produce new policies that achieve both high interpretability and computation efficiency in generating saliency maps. Our approach is also found to improve the robustness of RL policies to multiple adversarial attacks. We conduct experiments on three tasks, MiniGrid (Fetch Object), Atari (Breakout) and CARLA Autonomous Driving, to demonstrate the importance and effectiveness of our approach.}
}
@article{XIE202393,
title = {Enhanced tensor low-rank representation learning for multi-view clustering},
journal = {Neural Networks},
volume = {161},
pages = {93-104},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000497},
author = {Deyan Xie and Quanxue Gao and Ming Yang},
keywords = {Multi-view clustering, Subspace clustering, t-SVD, Weighted tensor nuclear norm},
abstract = {Multi-view subspace clustering (MSC), assuming the multi-view data are generated from a latent subspace, has attracted considerable attention in multi-view clustering. To recover the underlying subspace structure, a successful approach adopted recently is subspace clustering based on tensor nuclear norm (TNN). But there are some limitations to this approach that the existing TNN-based methods usually fail to exploit the intrinsic cluster structure and high-order correlations well, which leads to limited clustering performance. To address this problem, the main purpose of this paper is to propose a novel tensor low-rank representation (TLRR) learning method to perform multi-view clustering. First, we construct a 3rd-order tensor by organizing the features from all views, and then use the t-product in the tensor space to obtain the self-representation tensor of the tensorial data. Second, we use the ℓ1,2 norm to constrain the self-representation tensor to make it capture the class-specificity distribution, that is important for depicting the intrinsic cluster structure. And simultaneously, we rotate the self-representation tensor, and use the tensor singular value decomposition-based weighted TNN as a tighter tensor rank approximation to constrain the rotated tensor. For the challenged mathematical optimization problem, we present an effective optimization algorithm with a theoretical convergence guarantee and relatively low computation complexity. The constructed convergent sequence to the Karush–Kuhn–Tucker (KKT) critical point solution is mathematically validated in detail. We perform extensive experiments on four datasets and demonstrate that TLRR outperforms state-of-the-art multi-view subspace clustering methods.}
}
@article{SHEN2023142,
title = {UniSKGRep: A unified representation learning framework of social network and knowledge graph},
journal = {Neural Networks},
volume = {158},
pages = {142-153},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004518},
author = {Yinghan Shen and Xuhui Jiang and Zijian Li and Yuanzhuo Wang and Chengjin Xu and Huawei Shen and Xueqi Cheng},
keywords = {Social knowledge graph, Graph representation learning, Knowledge graph, Social network},
abstract = {The human-oriented applications aim to exploit behaviors of people, which impose challenges on user modeling of integrating social network (SN) with knowledge graph (KG), and jointly analyzing two types of graph data. However, existing graph representation learning methods merely represent one of two graphs alone, and hence are unable to comprehensively consider features of both SN and KG with profiling the correlation between them, resulting in unsatisfied performance in downstream tasks. Considering the diverse gap of features and the difficulty of associating of the two graph data, we introduce a Unified Social Knowledge Graph Representation learning framework (UniSKGRep), with the goal to leverage the multi-view information inherent in the SN and KG for improving the downstream tasks of user modeling. To the best of our knowledge, we are the first to present a unified representation learning framework for SN and KG. Concretely, the SN and KG are organized as the Social Knowledge Graph (SKG), a unified representation of SN and KG. For the representation learning of SKG, first, two separate encoders in the Intra-graph model capture both the social-view and knowledge-view in two embedding spaces, respectively. Then the Inter-graph model is learned to associate the two separate spaces via bridging the semantics of overlapping node pairs. In addition, the overlapping node enhancement module is designed to effectively align two spaces with the consideration of a relatively small number of overlapping nodes. The two spaces are gradually unified by continuously iterating the joint training procedure. Extensive experiments on two real-world SKG datasets have proved the effectiveness of UniSKGRep in yielding general and substantial performance improvement compared with the strong baselines in various downstream tasks.}
}
@article{BENFENATI2023331,
title = {A singular Riemannian geometry approach to Deep Neural Networks I. Theoretical foundations},
journal = {Neural Networks},
volume = {158},
pages = {331-343},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004634},
author = {Alessandro Benfenati and Alessio Marta},
keywords = {Deep learning, Riemann geometry, Classification, Degenerate metrics, Neural networks},
abstract = {Deep Neural Networks are widely used for solving complex problems in several scientific areas, such as speech recognition, machine translation, image analysis. The strategies employed to investigate their theoretical properties mainly rely on Euclidean geometry, but in the last years new approaches based on Riemannian geometry have been developed. Motivated by some open problems, we study a particular sequence of maps between manifolds, with the last manifold of the sequence equipped with a Riemannian metric. We investigate the structures induced through pullbacks on the other manifolds of the sequence and on some related quotients. In particular, we show that the pullbacks of the final Riemannian metric to any manifolds of the sequence is a degenerate Riemannian metric inducing a structure of pseudometric space. We prove that the Kolmogorov quotient of this pseudometric space yields a smooth manifold, which is the base space of a particular vertical bundle. We investigate the theoretical properties of the maps of such sequence, eventually we focus on the case of maps between manifolds implementing neural networks of practical interest and we present some applications of the geometric framework we introduced in the first part of the paper.}
}
@article{MENEZES2023476,
title = {Continual Object Detection: A review of definitions, strategies, and challenges},
journal = {Neural Networks},
volume = {161},
pages = {476-493},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.041},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000539},
author = {Angelo G. Menezes and Gustavo {de Moura} and Cézanne Alves and André C.P.L.F. {de Carvalho}},
keywords = {Continual Learning, Object detection, Systematic review, Benchmarks},
abstract = {The field of Continual Learning investigates the ability to learn consecutive tasks without losing performance on those previously learned. The efforts of researchers have been mainly focused on incremental classification tasks. Yet, we believe that continual object detection deserves even more attention due to its vast range of applications in robotics and autonomous vehicles. This scenario is also more complex than conventional classification, given the occurrence of instances of classes that are unknown at the time but can appear in subsequent tasks as a new class to be learned, resulting in missing annotations and conflicts with the background label. In this review, we analyze the current strategies proposed to tackle the problem of class-incremental object detection. Our main contributions are: (1) a short and systematic review of the methods that propose solutions to traditional incremental object detection scenarios; (2) A comprehensive evaluation of the existing approaches using a new metric to quantify the stability and plasticity of each technique in a standard way; (3) an overview of the current trends within continual object detection and a discussion of possible future research directions.}
}
@article{XU2023185,
title = {An explainable autoencoder with multi-paradigm fMRI fusion for identifying differences in dynamic functional connectivity during brain development},
journal = {Neural Networks},
volume = {159},
pages = {185-197},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004993},
author = {Faming Xu and Chen Qiao and Huiyu Zhou and Vince D. Calhoun and Julia M. Stephen and Tony W. Wilson and Yuping Wang},
keywords = {Explainability, Dynamic functional connectivity, Multi-paradigm learning, Hypergraph regularization, Feature fusion, Brain development},
abstract = {Multi-paradigm deep learning models show great potential for dynamic functional connectivity (dFC) analysis by integrating complementary information. However, many of them cannot use information from different paradigms effectively and have poor explainability, that is, the ability to identify significant features that contribute to decision making. In this paper, we propose a multi-paradigm fusion-based explainable deep sparse autoencoder (MF-EDSAE) to address these issues. Considering explainability, the MF-EDSAE is constructed based on a deep sparse autoencoder (DSAE). For integrating information effectively, the MF-EDASE contains the nonlinear fusion layer and multi-paradigm hypergraph regularization. We apply the model to the Philadelphia Neurodevelopmental Cohort and demonstrate it achieves better performance in detecting dynamic FC (dFC) that differ significantly during brain development than the single-paradigm DSAE. The experimental results show that children have more dispersive dFC patterns than adults. The function of the brain transits from undifferentiated systems to specialized networks during brain development. Meanwhile, adults have stronger connectivities between task-related functional networks for a given task than children. As the brain develops, the patterns of the global dFC change more quickly when stimulated by a task.}
}
@article{XIE2023154,
title = {A fractional gradient descent algorithm robust to the initial weights of multilayer perceptron},
journal = {Neural Networks},
volume = {158},
pages = {154-170},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004592},
author = {Xuetao Xie and Yi-Fei Pu and Jian Wang},
keywords = {Initial weights, Multilayer perceptron (MLP), Robust, First derivative, Fractional calculus, Convergence},
abstract = {For multilayer perceptron (MLP), the initial weights will significantly influence its performance. Based on the enhanced fractional derivative extend from convex optimization, this paper proposes a fractional gradient descent (RFGD) algorithm robust to the initial weights of MLP. We analyze the effectiveness of the RFGD algorithm. The convergence of the RFGD algorithm is also analyzed. The computational complexity of the RFGD algorithm is generally larger than that of the gradient descent (GD) algorithm but smaller than that of the Adam, Padam, AdaBelief, and AdaDiff algorithms. Numerical experiments show that the RFGD algorithm has strong robustness to the order of fractional calculus which is the only added parameter compared to the GD algorithm. More importantly, compared to the GD, Adam, Padam, AdaBelief, and AdaDiff algorithms, the experimental results show that the RFGD algorithm has the best robust performance for the initial weights of MLP. Meanwhile, the correctness of the theoretical analysis is verified.}
}