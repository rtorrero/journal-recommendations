@article{WANG202294,
title = {Learning a discriminative SPD manifold neural network for image set classification},
journal = {Neural Networks},
volume = {151},
pages = {94-110},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000909},
author = {Rui Wang and Xiao-Jun Wu and Ziheng Chen and Tianyang Xu and Josef Kittler},
keywords = {SPD manifold neural network, Image set classification, Metric learning, Riemannian barycenter, Riemannian optimization},
abstract = {Performing pattern analysis over the symmetric positive definite (SPD) manifold requires specific mathematical computations, characterizing the non-Euclidian property of the involved data points and learning tasks, such as the image set classification problem. Accompanied with the advanced neural networking techniques, several architectures for processing the SPD matrices have recently been studied to obtain fine-grained structured representations. However, existing approaches are challenged by the diversely changing appearance of the data points, begging the question of how to learn invariant representations for improved performance with supportive theories. Therefore, this paper designs two Riemannian operation modules for SPD manifold neural network. Specifically, a Riemannian batch regularization (RBR) layer is firstly proposed for the purpose of training a discriminative manifold-to-manifold transforming network with a novelly-designed metric learning regularization term. The second module realizes the Riemannian pooling operation with geometric computations on the Riemannian manifolds, notably the Riemannian barycenter, metric learning, and Riemannian optimization. Extensive experiments on five benchmarking datasets show the efficacy of the proposed approach.}
}
@article{JAHANBAKHT2022311,
title = {Sediment Prediction in the Great Barrier Reef using Vision Transformer with finite element analysis},
journal = {Neural Networks},
volume = {152},
pages = {311-321},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200154X},
author = {Mohammad Jahanbakht and Wei Xiang and Mostafa Rahimi Azghadi},
keywords = {Deep neural networks, Vision Transformer, Finite element analysis, Partial differential equation, Total sediment forecasting, Great Barrier Reef},
abstract = {Suspended sediment is a significant threat to the Great Barrier Reef (GBR) ecosystem. This catchment pollutant stems primarily from terrestrial soil erosion. Bulk masses of sediments have potential to propagate from river plumes into the mid-shelf and outer-shelf regions. Existing sediment forecasting methods suffer from the problem of low-resolution predictions, making them unsuitable for wide area coverage. In this paper, a novel sediment distribution prediction model is proposed to augment existing water quality management programs for the GBR. This model is based on the state-of-the-art Transformer network in conjunction with the well-known finite element analysis. For model training, the emerging physics-informed neural network is employed to incorporate both simulated and measured sediment data. Our proposed Finite Element Transformer (FE-Transformer) model offers accurate predictions of sediment across the entire GBR. It provides unblurred outputs, which cannot be achieved with previous next-frame prediction models. This paves a way for accurate forecasting of sediment, which in turn may lead to improved water quality management for the GBR.}
}
@article{HEIBERG202217,
title = {Risk-based implementation of COLREGs for autonomous surface vehicles using deep reinforcement learning},
journal = {Neural Networks},
volume = {152},
pages = {17-33},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001435},
author = {Amalie Heiberg and Thomas Nakken Larsen and Eivind Meyer and Adil Rasheed and Omer San and Damiano Varagnolo},
keywords = {Deep reinforcement learning, Collision avoidance, Path following, Collision risk indices, Machine learning controller, Autonomous surface vehicle},
abstract = {Autonomous systems are becoming ubiquitous and gaining momentum within the marine sector. Since the electrification of transport is happening simultaneously, autonomous marine vessels can reduce environmental impact, lower costs, and increase efficiency. Although close monitoring is still required to ensure safety, the ultimate goal is full autonomy. One major milestone is to develop a control system that is versatile enough to handle any weather and encounter that is also robust and reliable. Additionally, the control system must adhere to the International Regulations for Preventing Collisions at Sea (COLREGs) for successful interaction with human sailors. Since the COLREGs were written for the human mind to interpret, they are written in ambiguous prose and therefore not machine-readable or verifiable. Due to these challenges and the wide variety of situations to be tackled, classical model-based approaches prove complicated to implement and computationally heavy. Within machine learning (ML), deep reinforcement learning (DRL) has shown great potential for a wide range of applications. The model-free and self-learning properties of DRL make it a promising candidate for autonomous vessels. In this work, a subset of the COLREGs is incorporated into a DRL-based path following and obstacle avoidance system using collision risk theory. The resulting autonomous agent dynamically interpolates between path following and COLREG-compliant collision avoidance in the training scenario, isolated encounter situations, and AIS-based simulations of real-world scenarios.}
}
@article{GOU202212,
title = {A class-specific mean vector-based weighted competitive and collaborative representation method for classification},
journal = {Neural Networks},
volume = {150},
pages = {12-27},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000624},
author = {Jianping Gou and Xin He and Junyu Lu and Hongxing Ma and Weihua Ou and Yunhao Yuan},
keywords = {Representation-based classification, Collaborative representation, Collaborative representation-based classification, Pattern classification},
abstract = {Collaborative representation-based classification (CRC), as a typical kind of linear representation-based classification, has attracted more attention due to the effective and efficient pattern classification performance. However, the existing class-specific representations are not competitively learned from collaborative representation for achieving more informative pattern discrimination among all the classes. With the purpose of enhancing the power of competitive and discriminant representations among all the classes for favorable classification, we propose a novel CRC method called the class-specific mean vector-based weighted competitive and collaborative representation (CMWCCR). The CMWCCR mainly contains three discriminative constraints including the competitive, mean vector and weighted constraints that fully employ the discrimination information in different ways. In the competitive constraint, the representations from any one class and the other classes are adapted for learning competitive representations among all the classes. In the newly designed mean vector constraint, the mean vectors of all the class-specific training samples with the corresponding class-specific representations are taken into account to further enhance the competitive representations. In the devised weighted constraint, the class-specific weights are constrained on the representation coefficients to make the similar classes have more representation contributions to strengthening the discrimination among all the class-specific representations. Thus, these three constraints in the unified CMWCCR model can complement each other for competitively learning the discriminative class-specific representations. To verify the CMWCCR classification performance, the extensive experiments are conducted on twenty-eight data sets in comparisons with the state-of-the-art representation-based classification methods. The experimental results show that the proposed CMWCCR is an effective and robust CRC method with satisfactory performance.}
}
@article{SERRAOUI2022222,
title = {Knowledge-based tensor subspace analysis system for kinship verification},
journal = {Neural Networks},
volume = {151},
pages = {222-237},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000983},
author = {I. Serraoui and O. Laiadi and A. Ouamane and F. Dornaika and A. Taleb-Ahmed},
keywords = {Kinship verification, Knowledge-based tensor subspace analysis, Convolutional neural networks, Multi-view deep features, Metric learning, Facial images analysis},
abstract = {Most existing automatic kinship verification methods focus on learning the optimal distance metrics between family members. However, learning facial features and kinship features simultaneously may cause the proposed models to be too weak. In this work, we explore the possibility of bridging this gap by developing knowledge-based tensor models based on pre-trained multi-view models. We propose an effective knowledge-based tensor similarity extraction framework for automatic facial kinship verification using four pre-trained networks (i.e., VGG-Face, VGG-F, VGG-M, and VGG-S). Therefore, knowledge-based deep face and general features (such as identity, age, gender, ethnicity, expression, lighting, pose, contour, edges, corners, shape, etc.) were successfully fused by our tensor design to understand the kinship cue. Multiple effective representations are learned for kinship verification statements (children and parents) using a margin maximization learning scheme based on Tensor Cross-view Quadratic Exponential Discriminant Analysis. Through the exponential learning process, the large gap between distributions of the same family can be reduced to the maximum, while the small gap between distributions of different families is simultaneously increased. The WCCN metric successfully reduces the intra-class variability problem caused by deep features. The explanation of black-box models and the problems of ubiquitous face recognition are considered in our system. The extensive experiments on four challenging datasets show that our system performs very well compared to state-of-the-art approaches.}
}
@article{KIM2022510,
title = {Human-guided auto-labeling for network traffic data: The GELM approach},
journal = {Neural Networks},
volume = {152},
pages = {510-526},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001794},
author = {Meejoung Kim and Inkyu Lee},
keywords = {Human-guided labeling, Auto-labeling process, Generalized extreme learning machine, Moore–Penrose generalized inverse, Network traffic, Attack prediction},
abstract = {Data labeling is crucial in various areas, including network security, and a prerequisite for applying statistical-based classification and supervised learning techniques. Therefore, developing labeling methods that ensure good performance is important. We propose a human-guided auto-labeling algorithm involving the self-supervised learning concept, with the purpose of labeling data quickly, accurately, and consistently. It consists of three processes: auto-labeling, validation, and update. A labeling scheme is proposed by considering weighted features in the auto-labeling, while the generalized extreme learning machine (GELM) enabling fast training is applied to validate assigned labels. Two different approaches are considered in the update to label new data to investigate labeling speed and accuracy. We experiment to verify the suitability and accuracy of the algorithm for network traffic, applying the algorithm to five traffic datasets, some including distributed denial of service (DDoS), DoS, BruteForce, and PortScan attacks. Numerical results show the algorithm labels unlabeled datasets quickly, accurately, and consistently and the GELM’s learning speed enables labeling data in real-time. It also shows that the performances between auto- and conventional labels are nearly identical on datasets containing only DDoS attacks, which implies the algorithm is quite suitable for such datasets. However, the performance differences between the two labels are not negligible on datasets, including various attacks. Several reasons that require further investigation can be considered, including the selected features and the reliability of conventional labels. Even with this limitation of the current study, the algorithm will provide a criterion for labeling data in real-time occurring in many areas.}
}
@article{GONG202287,
title = {Unsupervised feature selection via adaptive autoencoder with redundancy control},
journal = {Neural Networks},
volume = {150},
pages = {87-101},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000740},
author = {Xiaoling Gong and Ling Yu and Jian Wang and Kai Zhang and Xiao Bai and Nikhil R. Pal},
keywords = {Unsupervised feature selection, Autoencoder, Group lasso, Redundancy control},
abstract = {Unsupervised feature selection is one of the efficient approaches to reduce the dimension of unlabeled high-dimensional data. We present a novel adaptive autoencoder with redundancy control (AARC) as an unsupervised feature selector. By adding two Group Lasso penalties to the objective function, AARC integrates unsupervised feature selection and determination of a compact network structure into a single framework. Besides, a penalty based on a measure of dependency between features (such as Pearson correlation, mutual information) is added to the objective function for controlling the level of redundancy in the selected features. To realize the desired effects of different regularizers in different phases of the training, we introduce adaptive parameters which change with iterations. In addition, a smoothing function is utilized to approximate the three penalties since they are not differentiable at the origin. An ablation study is carried out to validate the capabilities of redundancy control and structure optimization of AARC. Subsequently, comparisons with nine state-of-the-art methods illustrate the efficiency of AARC for unsupervised feature selection.}
}
@article{NERI2022244,
title = {Deep networks may capture biological behavior for shallow, but not deep, empirical characterizations},
journal = {Neural Networks},
volume = {152},
pages = {244-266},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001551},
author = {Peter Neri},
keywords = {Volterra/Wiener kernels, Psychophysics, Ideal observer, Signal detection theory, Intrinsic noise, Divisive gain control},
abstract = {We assess whether deep convolutional networks (DCN) can account for a most fundamental property of human vision: detection/discrimination of elementary image elements (bars) at different contrast levels. The human visual process can be characterized to varying degrees of “depth,” ranging from percentage of correct detection to detailed tuning and operating characteristics of the underlying perceptual mechanism. We challenge deep networks with the same stimuli/tasks used with human observers and apply equivalent characterization of the stimulus–response coupling. In general, we find that popular DCN architectures do not account for signature properties of the human process. For shallow depth of characterization, some variants of network-architecture/training-protocol produce human-like trends; however, more articulate empirical descriptors expose glaring discrepancies. Networks can be coaxed into learning those richer descriptors by shadowing a human surrogate in the form of a tailored circuit perturbed by unstructured input, thus ruling out the possibility that human–model misalignment in standard protocols may be attributable to insufficient representational power. These results urge caution in assessing whether neural networks do or do not capture human behavior: ultimately, our ability to assess “success” in this area can only be as good as afforded by the depth of behavioral characterization against which the network is evaluated. We propose a novel set of metrics/protocols that impose stringent constraints on the evaluation of DCN behavior as an adequate approximation to biological processes.}
}
@article{SUN2022111,
title = {Golden subject is everyone: A subject transfer neural network for motor imagery-based brain computer interfaces},
journal = {Neural Networks},
volume = {151},
pages = {111-120},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001034},
author = {Biao Sun and Zexu Wu and Yong Hu and Ting Li},
keywords = {Brain computer interfaces (BCIs), Motor imagery (MI), Golden subject, BCI-illiterate, Convolutional neural network (CNN)},
abstract = {Electroencephalographic measurement of cortical activity subserving motor behavior varies among different individuals, restricting the potential of brain computer interfaces (BCIs) based on motor imagery (MI). How to deal with this variability and thereby improve the accuracy of BCI classification remains a key issue. This paper proposes a deep learning-based approach to transfer the data distribution from BCI-friendly — “golden subjects” to the data from more typical BCI-illiterate users. In this work, we use the perceptual loss to align the dimensionality-reduced BCI-illiterate data with the data of golden subjects in low dimensions, by which a subject transfer neural network (STNN) is proposed. The network consists of two parts: 1) a generator, which generates the transferred BCI-illiterate features, and 2) a CNN classifier, which is used for the classification of the transferred features, thus outperforming traditional classification methods both in terms of accuracy and robustness. Electroencephalography (EEG) signals from 25 healthy subjects performing MI of the right hand and foot were classified with an average accuracy of 88.2%±5.1%. The proposed model was further validated on the BCI Competition IV dataset 2b, and was demonstrated to be robust to inter-subject variations. The advantages of STNN allow it to bridge the gap between the golden subjects and the BCI-illiterate ones, paving the way to real-time BCI applications.}
}
@article{BISCIONE2022222,
title = {Learning online visual invariances for novel objects via supervised and self-supervised training},
journal = {Neural Networks},
volume = {150},
pages = {222-236},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000582},
author = {Valerio Biscione and Jeffrey S. Bowers},
keywords = {Invariant representation, Internal representation, Convolutional neural networks, Unsupervised learning, Online invariance},
abstract = {Humans can identify objects following various spatial transformations such as scale and viewpoint. This extends to novel objects, after a single presentation at a single pose, sometimes referred to as online invariance. CNNs have been proposed as a compelling model of human vision, but their ability to identify objects across transformations is typically tested on held-out samples of trained categories after extensive data augmentation. This paper assesses whether standard CNNs can support human-like online invariance by training models to recognize images of synthetic 3D objects that undergo several transformations: rotation, scaling, translation, brightness, contrast, and viewpoint. Through the analysis of models’ internal representations, we show that standard supervised CNNs trained on transformed objects can acquire strong invariances on novel classes even when trained with as few as 50 objects taken from 10 classes. This extended to a different dataset of photographs of real objects. We also show that these invariances can be acquired in a self-supervised way, through solving the same/different task. We suggest that this latter approach may be similar to how humans acquire invariances.}
}
@article{MATSUO2022267,
title = {Deep learning, reinforcement learning, and world models},
journal = {Neural Networks},
volume = {152},
pages = {267-275},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001150},
author = {Yutaka Matsuo and Yann LeCun and Maneesh Sahani and Doina Precup and David Silver and Masashi Sugiyama and Eiji Uchibe and Jun Morimoto},
keywords = {Deep learning, Reinforcement learning, World models, Machine learning, Artificial intelligence},
abstract = {Deep learning (DL) and reinforcement learning (RL) methods seem to be a part of indispensable factors to achieve human-level or super-human AI systems. On the other hand, both DL and RL have strong connections with our brain functions and with neuroscientific findings. In this review, we summarize talks and discussions in the “Deep Learning and Reinforcement Learning” session of the symposium, International Symposium on Artificial Intelligence and Brain Science. In this session, we discussed whether we can achieve comprehensive understanding of human intelligence based on the recent advances of deep learning and reinforcement learning algorithms. Speakers contributed to provide talks about their recent studies that can be key technologies to achieve human-level intelligence.}
}
@article{OSA202290,
title = {Discovering diverse solutions in deep reinforcement learning by maximizing state–action-based mutual information},
journal = {Neural Networks},
volume = {152},
pages = {90-104},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001393},
author = {Takayuki Osa and Voot Tangkaratt and Masashi Sugiyama},
keywords = {Reinforcement learning, Robot learning, Representation learning},
abstract = {Reinforcement learning algorithms are typically limited to learning a single solution for a specified task, even though diverse solutions often exist. Recent studies showed that learning a set of diverse solutions is beneficial because diversity enables robust few-shot adaptation. Although existing methods learn diverse solutions by using the mutual information as unsupervised rewards, such an approach often suffers from the bias of the gradient estimator induced by value function approximation. In this study, we propose a novel method that can learn diverse solutions without suffering the bias problem. In our method, a policy conditioned on a continuous or discrete latent variable is trained by directly maximizing the variational lower bound of the mutual information, instead of using the mutual information as unsupervised rewards as in previous studies. Through extensive experiments on robot locomotion tasks, we demonstrate that the proposed method successfully learns an infinite set of diverse solutions by learning continuous latent variables, which is more challenging than learning a finite number of solutions. Subsequently, we show that our method enables more effective few-shot adaptation compared with existing methods.}
}
@article{HOU202228,
title = {Two-stage streaming keyword detection and localization with multi-scale depthwise temporal convolution},
journal = {Neural Networks},
volume = {150},
pages = {28-42},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000739},
author = {Jingyong Hou and Lei Xie and Shilei Zhang},
keywords = {Keyword spotting, Wake-up word detection and localization, Temporal convolution, Multi-scale, Two-stage},
abstract = {A keyword spotting (KWS) system running on smart devices should accurately detect the appearances and predict the locations of predefined keywords from audio streams, with small footprint and high efficiency. To this end, this paper proposes a new two-stage KWS method which combines a novel multi-scale depthwise temporal convolution (MDTC) feature extractor and a two-stage keyword detection and localization module. The MDTC feature extractor learns multi-scale feature representation efficiently with dilated depthwise temporal convolution, modeling both the temporal context and the speech rate variation. We use a region proposal network (RPN) as the first-stage KWS. At each frame, we design multiple time regions, which all take the current frame as the end position but have different start positions. These time regions (or formally anchors) are used to indicate rough location candidates of keyword. With frame level features from the MDTC feature extractor as inputs, RPN learns to propose keyword region proposals based on the designed anchors. To alleviate the keyword/non-keyword class imbalance problem, we specifically introduce a hard example mining algorithm to select effective negative anchors in RPN training. The keyword region proposals from the first-stage RPN contain keyword location information which is subsequently used to explicitly extract keyword related sequential features to train the second-stage KWS. The second-stage system learns to classify and transform region proposal to keyword IDs and ground-truth keyword region respectively. Experiments on the Google Speech Command dataset show that the proposed MDTC feature extractor surpasses several competitive feature extractors with a new state-of-the-art command classification error rate of 1.74%. With the MDTC feature extractor, we further conduct wake-up word (WuW) detection and localization experiments on a commercial WuW dataset. Compared to a strong baseline, our proposed two-stage method achieves relatively 27–32% better false rejection rate at one false alarm per hour, while for keyword localization, the two-stage approach achieves more than 0.95 mean intersection-over-union ratio, which is clearly better than the one-stage RPN method.}
}
@article{LONG2022300,
title = {Multivariate time series forecasting method based on nonlinear spiking neural P systems and non-subsampled shearlet transform},
journal = {Neural Networks},
volume = {152},
pages = {300-310},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001708},
author = {Lifan Long and Qian Liu and Hong Peng and Jun Wang and Qian Yang},
keywords = {Nonlinear spiking neural P systems, Multivariate time series, Time series forecasting, Non-subsampled shearlet transform},
abstract = {Multivariate time series forecasting remains a challenging task because of its nonlinear, non-stationary, high-dimensional, and spatial–temporal characteristics, along with the dependence between variables. To address this limitation, we propose a novel method for multivariate time series forecasting based on nonlinear spiking neural P (NSNP) systems and non-subsampled shearlet transform (NSST). A multivariate time series is first converted into the NSST domain, and then NSNP systems are automatically constructed, trained, and predicted in the NSST domain. Because NSNP systems are used as nonlinear prediction models and work in the NSST domain, the proposed prediction method is essentially a multiscale transform (MST)–based prediction method. Therefore, the proposed prediction method can process nonlinear and non-stationary time series, and the dependence between variables can be characterized by the multiresolution features of the NSST transform. Five real-life multivariate time series were used to compare the proposed prediction method with five state-of-the-art and 28 baseline prediction methods. The comparison results demonstrate the effectiveness of the proposed method for multivariate time-series forecasting.}
}
@article{JU202270,
title = {GHNN: Graph Harmonic Neural Networks for semi-supervised graph-level classification},
journal = {Neural Networks},
volume = {151},
pages = {70-79},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200096X},
author = {Wei Ju and Xiao Luo and Zeyu Ma and Junwei Yang and Minghua Deng and Ming Zhang},
keywords = {Graph classification, Graph neural networks, Graph kernels, Semi-supervised learning},
abstract = {Graph classification aims to predict the property of the whole graph, which has attracted growing attention in the graph learning community. This problem has been extensively studied in the literature of both graph convolutional networks and graph kernels. Graph convolutional networks can learn effective node representations via message passing to mine graph topology in an implicit way, whereas graph kernels can explicitly utilize graph structural knowledge for classification. Due to the scarcity of labeled data in real-world applications, semi-supervised algorithms are anticipated for this problem. In this paper, we propose Graph Harmonic Neural Network (GHNN) which combines the advantages of both worlds to sufficiently leverage the unlabeled data, and thus overcomes label scarcity in semi-supervised scenarios. Specifically, our GHNN consists of a graph convolutional network (GCN) module and a graph kernel network (GKN) module that explore graph topology information from complementary perspectives. To fully leverage the unlabeled data, we develop a novel harmonic contrastive loss and a harmonic consistency loss to harmonize the training of two modules by giving priority to high-quality unlabeled data, thereby reconciling prediction consistency between both of them. In this manner, the two modules mutually enhance each other to sufficiently explore the graph topology of both labeled and unlabeled data. Extensive experiments on a variety of benchmarks demonstrate the effectiveness of our approach over competitive baselines.}
}
@article{CHAMPION2022295,
title = {Branching Time Active Inference: The theory and its generality},
journal = {Neural Networks},
volume = {151},
pages = {295-316},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001149},
author = {Théophile Champion and Lancelot {Da Costa} and Howard Bowman and Marek Grześ},
keywords = {Active inference, Variational message passing, Tree search, Planning, Free energy principle},
abstract = {Over the last 10 to 15 years, active inference has helped to explain various brain mechanisms from habit formation to dopaminergic discharge and even modelling curiosity. However, the current implementations suffer from an exponential (space and time) complexity class when computing the prior over all the possible policies up to the time-horizon. Fountas et al. (2020) used Monte Carlo tree search to address this problem, leading to impressive results in two different tasks. In this paper, we present an alternative framework that aims to unify tree search and active inference by casting planning as a structure learning problem. Two tree search algorithms are then presented. The first propagates the expected free energy forward in time (i.e., towards the leaves), while the second propagates it backward (i.e., towards the root). Then, we demonstrate that forward and backward propagations are related to active inference and sophisticated inference, respectively, thereby clarifying the differences between those two planning strategies.}
}
@article{ILYAS20221,
title = {TSFD-Net: Tissue specific feature distillation network for nuclei segmentation and classification},
journal = {Neural Networks},
volume = {151},
pages = {1-15},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000612},
author = {Talha Ilyas and Zubaer Ibna Mannan and Abbas Khan and Sami Azam and Hyongsuk Kim and Friso {De Boer}},
keywords = {Bidirectional feature pyramid, Computational pathology, Deep learning, Medical imaging, Nuclei classification, Nuclei segmentation},
abstract = {Nuclei segmentation and classification of hematoxylin and eosin-stained histology images is a challenging task due to a variety of issues, such as color inconsistency that results from the non-uniform manual staining operations, clustering of nuclei, and blurry and overlapping nuclei boundaries. Existing approaches involve segmenting nuclei by drawing their polygon representations or by measuring the distances between nuclei centroids. In contrast, we leverage the fact that morphological features (appearance, shape, and texture) of nuclei in a tissue vary greatly depending upon the tissue type. We exploit this information by extracting tissue specific (TS) features from raw histopathology images using the proposed tissue specific feature distillation (TSFD) backbone. The bi-directional feature pyramid network (BiFPN) within TSFD-Net generates a robust hierarchical feature pyramid utilizing TS features where the interlinked decoders jointly optimize and fuse these features to generate final predictions. We also propose a novel combinational loss function for joint optimization and faster convergence of our proposed network. Extensive ablation studies are performed to validate the effectiveness of each component of TSFD-Net. The proposed network outperforms state-of-the-art networks such as StarDist, Micro-Net, Mask-RCNN, Hover-Net, and CPP-Net on the PanNuke dataset, which contains 19 different tissue types and 5 clinically important tumor classes, achieving 50.4% and 63.77% mean and binary panoptic quality, respectively. The code is available at: https://github.com/Mr-TalhaIlyas/TSFD.}
}
@article{WANG2022385,
title = {Distributed k-winners-take-all via multiple neural networks with inertia},
journal = {Neural Networks},
volume = {151},
pages = {385-397},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200137X},
author = {Xiaoxuan Wang and Shaofu Yang and Zhenyuan Guo and Tingwen Huang},
keywords = {Multiple neural networks, -winners-take-all, Distributed optimization, Inertial term, Cocoercive operator},
abstract = {This paper is dedicated to solving the k-winners-take-all problem with large-scale input signals in a distributed manner. According to the decomposition of global input signals, a novel dynamical system consisting of multiple coordinated neural networks is proposed for finding the k largest inputs. In the system, each neural network is designed to tackle its available partial inputs only for a local objective ki (ki≤k). Simultaneously, a consensus-based approach is adopted to coordinate multiple neural networks for achieving the global objective k. In addition, an inertial term is introduced in each neural network for regulating its transient behavior, which has the potential of accelerating the convergence. By developing a cocoercive operator, we theoretically prove that the multiple neural networks with inertial terms converge asymptotically/exponentially to the k-winners-take-all solution exactly from arbitrary initial states for whatever decomposition of inputs and objective. Furthermore, some extensions to distributed constrained k-winners-take-all are also investigated. Finally, simulation results are presented to substantiate the effectiveness of the proposed system as well as its superior performance over existing distributed networks.}
}
@article{LYU202248,
title = {Improving generalization of deep neural networks by leveraging margin distribution},
journal = {Neural Networks},
volume = {151},
pages = {48-60},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000971},
author = {Shen-Huan Lyu and Lu Wang and Zhi-Hua Zhou},
keywords = {Deep neural network, Margin theory, Generalization},
abstract = {Recent research has used margin theory to analyze the generalization performance for deep neural networks (DNNs). The existed results are almost based on the spectrally-normalized minimum margin. However, optimizing the minimum margin ignores a mass of information about the entire margin distribution, which is crucial to generalization performance. In this paper, we prove a generalization upper bound dominated by the statistics of the entire margin distribution. Compared with the minimum margin bounds, our bound highlights an important measure for controlling the complexity, which is the ratio of the margin standard deviation to the expected margin. We utilize a convex margin distribution loss function on the deep neural networks to validate our theoretical results by optimizing the margin ratio. Experiments and visualizations confirm the effectiveness of our approach and the correlation between generalization gap and margin ratio.}
}
@article{BEKHOUCHE2022150,
title = {Spatiotemporal CNN with Pyramid Bottleneck Blocks: Application to eye blinking detection},
journal = {Neural Networks},
volume = {152},
pages = {150-159},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001423},
author = {S.E. Bekhouche and I. Kajo and Y. Ruichek and F. Dornaika},
keywords = {Eye blinking, Pyramid Bottleneck Blocks, Spatiotemporal CNN, Incremental SVD, Facial landmarks},
abstract = {Eye blink detection is a challenging problem that many researchers are working on because it has the potential to solve many facial analysis tasks, such as face anti-spoofing, driver drowsiness detection, and some health disorders. There have been few attempts to detect blinking in the wild scenario, while most of the work has been done under controlled conditions. Moreover, current learning approaches are designed to process sequences that contain only a single blink ignoring the case of the presence of multiple eye blinks. In this work, we propose a fast framework for eye blink detection and eye blink verification that can effectively extract multiple blinks from image sequences considering several challenges such as lighting changes, variety of poses, and change in appearance. The proposed framework employs fast landmarks detector to extract multiple facial key points including the ones that identify the eye regions. Then, an SVD-based method is proposed to extract the potential eye blinks in a moving time window that is updated with new images every second. Finally, the detected blink candidates are verified using a 2D Pyramidal Bottleneck Block Network (PBBN). We also propose an alternative approach that uses a sequence of frames instead of an image as input and employs a continuous 3D PBBN that follows most of the state-of-the-art approaches schemes. Experimental results show the better performance of the proposed approach compared to the state-of-the-art approaches.}
}
@article{LIU2022181,
title = {Synchronization and state estimation for discrete-time coupled delayed complex-valued neural networks with random system parameters},
journal = {Neural Networks},
volume = {150},
pages = {181-193},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000697},
author = {Yufei Liu and Bo Shen and Ping Zhang},
keywords = {Coupled complex-valued neural networks, Discrete-time, Random system parameters, Synchronization, State estimation},
abstract = {In this paper, an array of discrete-time coupled complex-valued neural networks (CVNNs) with random system parameters and time-varying delays are introduced. The stochastic fluctuations of system parameters, which are characterized by a set of random variables, are considered in the individual CVNNs. Firstly, the synchronization issue is solved for the considered coupled CVNNs. By the use of the Lyapunov stability theory and the Kronecker product, a synchronization criterion is proposed to guarantee that the coupled CVNNs are asymptotically synchronized in the mean square. Subsequently, the state estimation issue is studied for the identical coupled CVNNs via available measurement output. By establishing a suitable Lyapunov functional, sufficient conditions are derived under which the mean square asymptotic stability of the estimation error system is ensured and the design scheme of desired state estimator is explicitly provided. Finally, two numerical simulation examples are shown for the purpose of illustrating the effectiveness of the proposed theory.}
}
@article{ZHANG202280,
title = {Towards understanding theoretical advantages of complex-reaction networks},
journal = {Neural Networks},
volume = {151},
pages = {80-93},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001022},
author = {Shao-Qun Zhang and Wei Gao and Zhi-Hua Zhou},
keywords = {Complex-valued neural network, Complex-reaction network, Approximation, Convergence, Critical point set},
abstract = {Complex-valued neural networks have attracted increasing attention in recent years, while it remains open on the advantages of complex-valued neural networks in comparison with real-valued networks. This work takes one step on this direction by introducing the complex-reaction network with fully-connected feed-forward architecture. We prove the universal approximation property for complex-reaction networks, and show that a class of radial functions can be approximated by a complex-reaction network using the polynomial number of parameters, whereas real-valued networks need at least exponential parameters to reach the same approximation level. For empirical risk minimization, we study the landscape and convergence of complex gradient descents. Our theoretical result shows that the critical point set of complex-reaction networks is a proper subset of that of real-valued networks, which may show some insights on finding the optimal solutions more easily for complex-reaction networks.}
}
@article{WELPER2022259,
title = {Universality of gradient descent neural network training},
journal = {Neural Networks},
volume = {150},
pages = {259-273},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000570},
author = {G. Welper},
keywords = {Deep neural networks, Universality, Global minima, Turing machines, Meta-learning, Biologically plausible learning},
abstract = {It has been observed that design choices of neural networks are often crucial for their successful optimization. In this article, we therefore discuss the question if it is always possible to redesign a neural network so that it trains well with gradient descent. This yields the following universality result: If, for a given network, there is any algorithm that can find good network weights for a classification task, then there exists an extension of this network that reproduces the same forward model by mere gradient descent training. The construction is not intended for practical computations, but it provides some orientation on the possibilities of pre-trained networks in meta-learning and related approaches.}
}
@article{PARK2022370,
title = {Generative convolution layer for image generation},
journal = {Neural Networks},
volume = {152},
pages = {370-379},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001782},
author = {Seung Park and Yong-Goo Shin},
keywords = {Generative adversarial networks, Image generation, Generative convolution, Convolution operation},
abstract = {This paper introduces a novel convolution method, called generative convolution (GConv), which is simple yet effective for improving the generative adversarial network (GAN) performance. Unlike the standard convolution, GConv first selects useful kernels compatible with the given latent vector, and then linearly combines the selected kernels to make latent-specific kernels. Using the latent-specific kernels, the proposed method produces the latent-specific features which encourage the generator to produce high-quality images. This approach is simple but surprisingly effective. First, the GAN performance is significantly improved with a little additional hardware cost. Second, GConv can be employed to the existing state-of-the-art generators without modifying the network architecture. To reveal the superiority of GConv, this paper provides extensive experiments using various standard datasets including CIFAR-10, CIFAR-100, LSUN-Church, CelebA, and tiny-ImageNet. Quantitative evaluations prove that GConv significantly boosts the performances of the unconditional and conditional GANs in terms of Frechet inception distance (FID) and Inception score (IS). For example, the proposed method improves both FID and IS scores on the tiny-ImageNet dataset from 35.13 to 29.76 and 20.23 to 22.64, respectively.}
}
@article{WU2022140,
title = {A dynamical neural network approach for solving stochastic two-player zero-sum games},
journal = {Neural Networks},
volume = {152},
pages = {140-149},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001381},
author = {Dawen Wu and Abdel Lisser},
keywords = {Stochastic two-player zero-sum game, Saddle point, Dynamical neural network},
abstract = {This paper aims at solving a stochastic two-player zero-sum Nash game problem studied in Singh and Lisser (2019). The main contribution of our paper is that we model this game problem as a dynamical neural network (DNN for short). In this paper, we show that the saddle point of this game problem is the equilibrium point of the DNN model, and we study the globally asymptotically stable of the DNN model. In our numerical experiments, we present the time-continuous feature of the DNN model and compare it with the state-of-the-art convex solvers, i.e., Splitting conic solver (SCS for short) and Cvxopt. Our numerical results show that our DNN method has two advantages in dealing with this game problem. Firstly, the DNN model can converge to a better optimal point. Secondly, the DNN method can solve all problems, even when the problem size is large.}
}
@article{LIAO2022440,
title = {A zeroing neural dynamics based acceleration optimization approach for optimizers in deep neural networks},
journal = {Neural Networks},
volume = {150},
pages = {440-461},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000806},
author = {Shan Liao and Shubin Li and Jiayong Liu and Haoen Huang and Xiuchun Xiao},
keywords = {Zeroing neural dynamics (ZND), Optimizer, Deep neural networks (DNN), Optimization},
abstract = {The first-order optimizers in deep neural networks (DNN) are of pivotal essence for a concrete loss function to reach the local minimum or global one on the loss surface within convergence time. However, each optimizer possesses its own superiority and virtue when encountering a specific application scene and environment. In addition, the existing modified optimizers mostly emphasize a given optimizer without any transfer property. In this paper, a zeroing neural dynamics (ZND) based optimization approach for the first-order optimizers is proposed, which can assist ZND via the activation function to expedite the process of solving gradient information, with lower loss and higher accuracy. To the best of our knowledge, it is the first work to integrate the ZND in control domain with the first-order optimizers in DNN. This generic work is an optimization method for the most commonly-used first-order optimizers to handle different application scenes, rather than developing a brand-new algorithm besides the existing optimizers or their modifications. Furthermore, mathematic derivations concerning the gradient information transformation of the ZND are systematically provided. Finally, comparison experiments are implemented, which demonstrates the effectiveness of the proposed approach with different loss functions and network frameworks on the Reuters, CIFAR, and MNIST data sets.}
}
@article{FAKHOURY2022332,
title = {ExSpliNet: An interpretable and expressive spline-based neural network},
journal = {Neural Networks},
volume = {152},
pages = {332-346},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001617},
author = {Daniele Fakhoury and Emanuele Fakhoury and Hendrik Speleers},
keywords = {Kolmogorov neural networks, Probabilistic trees, Tensor-product B-splines},
abstract = {In this paper we present ExSpliNet, an interpretable and expressive neural network model. The model combines ideas of Kolmogorov neural networks, ensembles of probabilistic trees, and multivariate B-spline representations. We give a probabilistic interpretation of the model and show its universal approximation properties. We also discuss how it can be efficiently encoded by exploiting B-spline properties. Finally, we test the effectiveness of the proposed model on synthetic approximation problems and classical machine learning benchmark datasets.}
}
@article{XU202243,
title = {Quasi-synchronization of fractional-order multi-layer networks with mismatched parameters via delay-dependent impulsive feedback control},
journal = {Neural Networks},
volume = {150},
pages = {43-57},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000648},
author = {Yao Xu and Jingjing Liu and Wenxue Li},
keywords = {Delay-dependent impulsive feedback control, Quasi-synchronization, Fractional-order multi-layer networks, Mismatched parameters},
abstract = {The paper is devoted to investigating the quasi-synchronization issue of fractional-order multi-layer networks with mismatched parameters under delay-dependent impulsive feedback control. It is worth highlighting that fractional-order multi-layer networks with mismatched parameters, as the extension model for single-layer or two-layer ones, are constructed in this paper. Simultaneously, the intra-layer and inter-layer couplings are taken into consideration, which is more general and rarely considered in discussions of network synchronization. An extended fractional differential inequality with impulsive effects is given to establish the grounded framework and theory on the quasi-synchronization problem under delay-dependent impulsive feedback control. Moreover, in the light of the Lyapunov method and graph theory, two criteria for achieving the quasi-synchronization of fractional-order multi-layer networks with mismatched parameters are derived. Furthermore, exponential convergence rates as well as the bounds of quasi-synchronization errors are successfully deduced. Ultimately, the theoretical results are applied in a practical power system, and some illustrative examples are proposed to show the effectiveness of theoretical analysis.}
}
@article{CUI2022313,
title = {Deep feature fusion based childhood epilepsy syndrome classification from electroencephalogram},
journal = {Neural Networks},
volume = {150},
pages = {313-325},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000922},
author = {Xiaonan Cui and Dinghan Hu and Peng Lin and Jiuwen Cao and Xiaoping Lai and Tianlei Wang and Tiejia Jiang and Feng Gao},
keywords = {Children epileptic syndrome, Mel frequency cepstral coefficients, Linear predictive cepstral coefficient, Wavelet packet features, Statistical features, Transfer learning},
abstract = {Accurate classification of the children’s epilepsy syndrome is vital to the diagnosis and treatment of epilepsy. But existing literature mainly focuses on seizure detection and few attention has been paid to the children’s epilepsy syndrome classification. In this paper, we present a study on the classification of two most common epilepsy syndromes: the benign childhood epilepsy with centro-temporal spikes (BECT) and the infantile spasms (also known as the WEST syndrome), recorded from the Children’s Hospital, Zhejiang University School of Medicine (CHZU). A novel feature fusion model based on the deep transfer learning and the conventional time–frequency representation of the scalp electroencephalogram (EEG) is developed for the epilepsy syndrome characterization. A fully connected network is constructed for the feature learning and syndrome classification. Experiments on the CHZU database show that the proposed algorithm can offer an average of 92.35% classification accuracy on the BECT and WEST syndromes and their corresponding normal cases.}
}
@article{XUE2022212,
title = {Event-triggered integral reinforcement learning for nonzero-sum games with asymmetric input saturation},
journal = {Neural Networks},
volume = {152},
pages = {212-223},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001459},
author = {Shan Xue and Biao Luo and Derong Liu and Ying Gao},
keywords = {Adaptive dynamic programming, Reinforcement learning, Event-triggered mechanism, Asymmetric input saturation, Experience replay},
abstract = {In this paper, an event-triggered integral reinforcement learning (IRL) algorithm is developed for the nonzero-sum game problem with asymmetric input saturation. First, for each player, a novel non-quadratic value function with a discount factor is designed, and the coupled Hamilton–Jacobi equation that does not require a complete knowledge of the game is derived by using the idea of IRL. Second, the execution of each player is based on the event-triggered mechanism. In the implementation, an adaptive dynamic programming based learning scheme using a single critic neural network (NN) is developed. Experience replay technique is introduced into the classical gradient descent method to tune the weights of the critic NN. The stability of the system and the elimination of Zeno behavior are proved. Finally, simulation experiments verify the effectiveness of the event-triggered IRL algorithm.}
}
@article{PANG2022194,
title = {A novel ramp loss-based multi-task twin support vector machine with multi-parameter safe acceleration},
journal = {Neural Networks},
volume = {150},
pages = {194-212},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000764},
author = {Xinying Pang and Jiang Zhao and Yitian Xu},
keywords = {Multi-task learning, Support vector machine, Ramp loss, Safe screening rule, Speed up},
abstract = {Direct multi-task twin support vector machine (DMTSVM) is an effective algorithm to deal with multi-task classification problems. However, the generated hyperplane may shift to outliers since the hinge loss is used in DMTSVM. Therefore, we propose an improved multi-task model RaMTTSVM based on ramp loss to handle noisy points more effectively. It could limit the maximal loss value distinctly and put definite restrictions on the influences of noises. But RaMTTSVM is non-convex which should be solved by CCCP, then a series of approximate convex problems need to be solved. So, it may be time-consuming. Motivated by the sparse solution of our RaMTTSVM, we further propose a safe acceleration rule MSA to accelerate the solving speed. Based on optimality conditions and convex optimization theory, MSA could delete a lot of inactive samples corresponding to 0 elements in dual solutions before solving the model. Then the computation speed can be accelerated by just solving reduced problems. The rule contains three different parts that correspond to different parameters and different iteration phases of CCCP. It can be used not only for the first approximate convex problem of CCCP but also for the successive problems during the iteration process. More importantly, our MSA is safe in the sense that the reduced problem can derive an identical optimal solution as the original problem, so the prediction accuracy will not be disturbed. Experimental results on one artificial dataset, ten Benchmark datasets, ten Image datasets and one real wine dataset confirm the generalization and acceleration ability of our proposed algorithm.}
}
@article{ZHOU2022322,
title = {Embedding graphs on Grassmann manifold},
journal = {Neural Networks},
volume = {152},
pages = {322-331},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001733},
author = {Bingxin Zhou and Xuebin Zheng and Yu Guang Wang and Ming Li and Junbin Gao},
keywords = {Grassmann manifold, Graph neural network, Projection embedding, Subspace clustering},
abstract = {Learning efficient graph representation is the key to favorably addressing downstream tasks on graphs, such as node or graph property prediction. Given the non-Euclidean structural property of graphs, preserving the original graph data’s similarity relationship in the embedded space needs specific tools and a similarity metric. This paper develops a new graph representation learning scheme, namely Egg, which embeds approximated second-order graph characteristics into a Grassmann manifold. The proposed strategy leverages graph convolutions to learn hidden representations of the corresponding subspace of the graph, which is then mapped to a Grassmann point of a low dimensional manifold through truncated singular value decomposition (SVD). The established graph embedding approximates denoised correlationship of node attributes, as implemented in the form of a symmetric matrix space for Euclidean calculation. The effectiveness of Egg is demonstrated using both clustering and classification tasks at the node level and graph level. It outperforms baseline models on various benchmarks.}
}
@article{ZHANG2022376,
title = {Quantum support vector machine based on regularized Newton method},
journal = {Neural Networks},
volume = {151},
pages = {376-384},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.043},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001216},
author = {Rui Zhang and Jian Wang and Nan Jiang and Hong Li and Zichen Wang},
keywords = {Quantum support vector machine, Regularized quantum Newton method, Quantum machine learning, Quantum computing},
abstract = {An elegant quantum version of least-square support vector machine, which is exponentially faster than the classical counterpart, was given by Rebentrost et al. using the matrix inversion algorithm (HHL). However, the application of the HHL algorithm is restricted when the structure of the input matrix is not well. The iteration algorithms such as the Newton method are widespread in training the classical support vector machine. This paper demonstrates a quantum support vector machine based on the regularized Newton method (RN-QSVM), which achieves an exponential speed-up over classical algorithm. At first, the regularized quantum Newton algorithm is proposed to get rid of the constraint of input matrix. Then we train the RN-QSVM by using the regularized quantum Newton algorithm and classify a query sample by constructing the quantum state. Experiments demonstrate that RN-QSVM respectively provides advantages in terms of accuracy, robustness, and complexity compared to QSLS-SVM, LS-QSVM, and the classical method.}
}
@article{TANIGUCHI2022317,
title = {Hippocampal formation-inspired probabilistic generative model},
journal = {Neural Networks},
volume = {151},
pages = {317-335},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001332},
author = {Akira Taniguchi and Ayako Fukawa and Hiroshi Yamakawa},
keywords = {Brain-inspired artificial intelligence, Brain reference architecture, Hippocampal formation, Simultaneous localization and mapping, Probabilistic generative model, Phase precession queue assumption},
abstract = {In building artificial intelligence (AI) agents, referring to how brains function in real environments can accelerate development by reducing the design space. In this study, we propose a probabilistic generative model (PGM) for navigation in uncertain environments by integrating the neuroscientific knowledge of hippocampal formation (HF) and the engineering knowledge in robotics and AI, namely, simultaneous localization and mapping (SLAM). We follow the approach of brain reference architecture (BRA) (Yamakawa, 2021) to compose the PGM and outline how to verify the model. To this end, we survey and discuss the relationship between the HF findings and SLAM models. The proposed hippocampal formation-inspired probabilistic generative model (HF-PGM) is designed to be highly consistent with the anatomical structure and functions of the HF. By referencing the brain, we elaborate on the importance of integration of egocentric/allocentric information from the entorhinal cortex to the hippocampus and the use of discrete-event queues.}
}
@article{GUO2022287,
title = {Context-aware dynamic neural computational models for accurate Poly(A) signal prediction},
journal = {Neural Networks},
volume = {152},
pages = {287-299},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001575},
author = {Yanbu Guo and Chaoyang Li and Dongming Zhou and Jinde Cao and Hui Liang},
keywords = {Co-occurrence embedding, Poly(A) signals, Deep neural networks, Attention mechanism},
abstract = {Accurately predicting Polyadenylation (Poly(A)) signals isthe key to understand the mechanism of translation regulation and mRNA metabolism. However, existing computational algorithms fail to work well for predicting Poly(A) signals due to the vanishing gradient problem when simply increasing the number of layers. In this work, we devise a spatiotemporal context-aware neural model called ACNet for Poly(A) signal prediction based on co-occurrence embedding. Specifically, genomic sequences of Poly(A) signals are first split into k-mer sequences, and k-mer embeddings are pre-trained based on the co-occurrence matrix information; Then, gated residual networks are devised to fully extract spatial information, which has an excellent ability to control the information flow and ease the problem of vanishing gradients. The gated mechanism generates channel weights by a dilated convolution and aggregates local features by identity connections which are obtained by multi-scale dilated convolutions. Experimental results indicate that our ACNet model outperforms the state-of-the-art prediction methods on various Poly(A) signal data, and an ablation study shows the effectiveness of the design strategy.}
}
@article{WANG2022132,
title = {Dynamic Auxiliary Soft Labels for decoupled learning},
journal = {Neural Networks},
volume = {151},
pages = {132-142},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001058},
author = {Yan Wang and Yongshun Zhang and Furao Shen and Jian Zhao},
keywords = {Neural network, Decoupled learning, Long-tailed},
abstract = {The long-tailed distribution in the dataset is one of the major challenges of deep learning. Convolutional Neural Networks have poor performance in identifying classes with only a few samples. For this problem, it has been proved that separating the feature learning stage and the classifier learning stage improves the performance of models effectively, which is called decoupled learning. We use soft labels to improve the performance of the decoupled learning framework by proposing a Dynamic Auxiliary Soft Labels (DaSL) method. Specifically, we design a dedicated auxiliary network to generate auxiliary soft labels for the two different training stages. In the feature learning stage, it helps to learn features with smaller variance within the class, and in the classifier learning stage it helps to alleviate the overconfidence of the model prediction. We also introduce a feature-level distillation method for the feature learning, and improve the learning of general features through multi-scale feature fusion. We conduct extensive experiments on three long-tailed recognition benchmark datasets to demonstrate the effectiveness of our DaSL.}
}
@article{YAO2022168,
title = {Double structure scaled simplex representation for multi-view subspace clustering},
journal = {Neural Networks},
volume = {151},
pages = {168-177},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.039},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001174},
author = {Liang Yao and Gui-Fu Lu},
keywords = {Multi-view subspace clustering, Affinity matrix, Clustering performance, Objective function},
abstract = {In the era of big data, there are an increasing number of multisource information data, and multi-view clustering (MVC) algorithms have developed rapidly. However, the affinity matrix learned by most MVC methods is not clean and precise enough and cannot describe the latent structure of multi-view data accurately, which results in poor clustering performance. In this paper, we propose a novel Double Structure Scaled Simplex Representation (DSSSR) method for MVC. Initially, we concatenate the multi-view data into a joint representation. Then, we use the scaled simplex representation (SSR) method on the concatenated data to obtain the affinity matrix. However, the affinity matrix is not clean and precise. Therefore, we use the SSR method again on the obtained affinity matrix to obtain a more accurate and clean affinity matrix. Furthermore, the two-step SSR is integrated into a unified optimization framework, a clean and accurate affinity matrix can be obtained, and the sum of each column vector of the affinity matrix is constrained to be nonnegative and equal to s (0<s<1), which can be adjusted to obtain the best clustering performance. Finally, an efficient optimization algorithm based on the augmented Lagrangian method (ALM) for solving the objective function is also designed. The experimental results on some datasets show that this algorithm has better clustering performance than some state-of-the-art algorithms.}
}
@article{2023ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {168},
pages = {ii},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00598-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005981}
}
@article{MILANO2022137,
title = {Connectome of memristive nanowire networks through graph theory},
journal = {Neural Networks},
volume = {150},
pages = {137-148},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000636},
author = {Gianluca Milano and Enrique Miranda and Carlo Ricciardi},
keywords = {Neuromorphic hardware, Neuromorphic nanowire networks, Self-organizing networks, Emergent dynamics, Memristive networks, Unconventional computing},
abstract = {Hardware implementation of neural networks represents a milestone for exploiting the advantages of neuromorphic-type data processing and for making use of the inherent parallelism associated with such structures. In this context, memristive devices with their analogue functionalities are called to be promising building blocks for the hardware realization of artificial neural networks. As an alternative to conventional crossbar architectures where memristive devices are organized with a top-down approach in a grid-like fashion, neuromorphic-type data processing and computing capabilities have been explored in networks realized according to the principle of self-organization similarity found in biological neural networks. Here, we explore structural and functional connectivity of self-organized memristive nanowire (NW) networks within the theoretical framework of graph theory. While graph metrics reveal the link of the graph theoretical approach with geometrical considerations, results show that the interplay between network structure and its capacity to transmit information is related to a phase transition process consistent with percolation theory. Also the concept of memristive distance is introduced to investigate activation patterns and the dynamic evolution of the information flow across the network represented as a memristive graph. In agreement with experimental results, the emergent short-term dynamics reveals the formation of self-selected pathways with enhanced transport characteristics connecting stimulated areas and regulating the trafficking of the information flow. The network capability to process spatio-temporal input signals can be exploited for the implementation of unconventional computing paradigms in memristive graphs that take into advantage the inherent relationship between structure and functionality as in biological systems.}
}
@article{RODRIGUEZMARTINEZ2022380,
title = {Replacing pooling functions in Convolutional Neural Networks by linear combinations of increasing functions},
journal = {Neural Networks},
volume = {152},
pages = {380-393},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001605},
author = {Iosu Rodriguez-Martinez and Julio Lafuente and Regivan H.N. Santiago and Graçaliz Pereira Dimuro and Francisco Herrera and Humberto Bustince},
keywords = {Convolutional Neural Networks, Pooling function, Order statistic, Generalized Sugeno integral},
abstract = {Traditionally, Convolutional Neural Networks make use of the maximum or arithmetic mean in order to reduce the features extracted by convolutional layers in a downsampling process known as pooling. However, there is no strong argument to settle upon one of the two functions and, in practice, this selection turns to be problem dependent. Further, both of these options ignore possible dependencies among the data. We believe that a combination of both of these functions, as well as of additional ones which may retain different information, can benefit the feature extraction process. In this work, we replace traditional pooling by several alternative functions. In particular, we consider linear combinations of order statistics and generalizations of the Sugeno integral, extending the latter’s domain to the whole real line and setting the theoretical base for their application. We present an alternative pooling layer based on this strategy which we name “CombPool” layer. We replace the pooling layers of three different architectures of increasing complexity by CombPool layers, and empirically prove over multiple datasets that linear combinations outperform traditional pooling functions in most cases. Further, combinations with either the Sugeno integral or one of its generalizations usually yield the best results, proving a strong candidate to apply in most architectures.}
}
@article{BARROS2022364,
title = {All by Myself: Learning individualized competitive behavior with a contrastive reinforcement learning optimization},
journal = {Neural Networks},
volume = {150},
pages = {364-376},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000910},
author = {Pablo Barros and Alessandra Sciutti},
keywords = {Reinforcement learning, Contrastive learning, Competitive learning},
abstract = {In a competitive game scenario, a set of agents have to learn decisions that maximize their goals and minimize their adversaries’ goals at the same time. Besides dealing with the increased dynamics of the scenarios due to the opponents’ actions, they usually have to understand how to overcome the opponent’s strategies. Most of the common solutions, usually based on continual learning or centralized multi-agent experiences, however, do not allow the development of personalized strategies to face individual opponents. In this paper, we propose a novel model composed of three neural layers that learn a representation of a competitive game, learn how to map the strategy of specific opponents, and how to disrupt them. The entire model is trained online, using a composed loss based on a contrastive optimization, to learn competitive and multiplayer games. We evaluate our model on a pokemon duel scenario and the four-player competitive Chef’s Hat card game. Our experiments demonstrate that our model achieves better performance when playing against offline, online, and competitive-specific models, in particular when playing against the same opponent multiple times. We also present a discussion on the impact of our model, in particular on how well it deals with on specific strategy learning for each of the two scenarios.}
}
@article{NA2022326,
title = {Efficient learning rate adaptation based on hierarchical optimization approach},
journal = {Neural Networks},
volume = {150},
pages = {326-335},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000478},
author = {Gyoung S. Na},
keywords = {Deep learning, Mathematical optimization, Computer vision},
abstract = {This paper proposes a new hierarchical approach to learning rate adaptation in gradient methods, called learning rate optimization (LRO). LRO formulates the learning rate adaption problem as a hierarchical optimization problem that minimizes the loss function with respect to the learning rate for current model parameters and gradients. Then, LRO optimizes the learning rate based on the alternating direction method of multipliers (ADMM). In the process of this learning rate optimization, LRO does not require any second-order information and probabilistic model, so it is highly efficient. Furthermore, LRO does not require any additional hyperparameters when compared to the vanilla gradient method with the simple exponential learning rate decay. In the experiments, we integrated LRO with vanilla SGD and Adam. Then, we compared their optimization performance with the state-of-the-art learning rate adaptation methods and also the most commonly-used adaptive gradient methods. The SGD and Adam with LRO outperformed all the competitors on the benchmark datasets in image classification tasks.}
}
@article{LIU2022349,
title = {Neural feedback facilitates rough-to-fine information retrieval},
journal = {Neural Networks},
volume = {151},
pages = {349-364},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.042},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001204},
author = {Xiao Liu and Xiaolong Zou and Zilong Ji and Gengshuo Tian and Yuanyuan Mi and Tiejun Huang and K.Y. Michael Wong and Si Wu},
keywords = {Feedback modulation, Memory retrieval, Correlation interference},
abstract = {Categorical relationships between objects are encoded as overlapped neural representations in the brain, where the more similar the objects are, the larger the correlations between their evoked neuronal responses. These representation correlations, however, inevitably incur interference when memories are retrieved. Here, we propose that neural feedback, which is widely observed in the brain but whose function remains largely unknown, contributes to disentangle neural correlations to improve information retrieval. We study a hierarchical neural network storing the hierarchical categorical information of objects, and information retrieval goes from rough-to-fine, aided by the push–pull neural feedback. We elucidate that the push and the pull components of the feedback suppress the interferences due to the representation correlations between objects from different and the same categories, respectively. Our model reproduces the push–pull phenomenon observed in neural data and sheds light on our understanding of the role of feedback in neural information processing.}
}
@article{TRICHE202216,
title = {Exploration in neo-Hebbian reinforcement learning: Computational approaches to the exploration–exploitation balance with bio-inspired neural networks},
journal = {Neural Networks},
volume = {151},
pages = {16-33},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000995},
author = {Anthony Triche and Anthony S. Maida and Ashok Kumar},
keywords = {Reinforcement learning, Hebbian plasticity, STDP, Spiking neural networks, Exploration–exploitation balance},
abstract = {Recent theoretical and experimental works have connected Hebbian plasticity with the reinforcement learning (RL) paradigm, producing a class of trial-and-error learning in artificial neural networks known as neo-Hebbian plasticity. Inspired by the role of the neuromodulator dopamine in synaptic modification, neo-Hebbian RL methods extend unsupervised Hebbian learning rules with value-based modulation to selectively reinforce associations. This reinforcement allows for learning exploitative behaviors and produces RL models with strong biological plausibility. The review begins with coverage of fundamental concepts in rate- and spike-coded models. We introduce Hebbian correlation detection as a basis for modification of synaptic weighting and progress to neo-Hebbian RL models guided solely by extrinsic rewards. We then analyze state-of-the-art neo-Hebbian approaches to the exploration–exploitation balance under the RL paradigm, emphasizing works that employ additional mechanics to modulate that dynamic. Our review of neo-Hebbian RL methods in this context indicates substantial potential for novel improvements in exploratory learning, primarily through stronger incorporation of intrinsic motivators. We provide a number of research suggestions for this pursuit by drawing from modern theories and results in neuroscience and psychology. The exploration–exploitation balance is a central issue in RL research, and this review is the first to focus on it under the neo-Hebbian RL framework.}
}
@article{KOJIMA2022234,
title = {Organization of a Latent Space structure in VAE/GAN trained by navigation data},
journal = {Neural Networks},
volume = {152},
pages = {234-243},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001447},
author = {Hiroki Kojima and Takashi Ikegami},
keywords = {Cognitive map, GAN, Place cell, Prediction, Latent space, Chaos},
abstract = {We present a novel artificial cognitive mapping system using generative deep neural networks, called variational autoencoder/generative adversarial network (VAE/GAN), which can map input images to latent vectors and generate temporal sequences internally. The results show that the distance of the predicted image is reflected in the distance of the corresponding latent vector after training. This indicates that the latent space is self-organized to reflect the proximity structure of the dataset and may provide a mechanism through which many aspects of cognition are spatially represented. The present study allows the network to internally generate temporal sequences that are analogous to the hippocampal replay/pre-play ability, where VAE produces only near-accurate replays of past experiences, but by introducing GANs, the generated sequences are coupled with instability and novelty.}
}
@article{MASON2022353,
title = {A manifold learning approach for gesture recognition from micro-Doppler radar measurements},
journal = {Neural Networks},
volume = {152},
pages = {353-369},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001563},
author = {E.S. Mason and H.N. Mhaskar and Adam Guo},
keywords = {Machine learning, Kernel methods, Micro-Doppler radar gesture recognition},
abstract = {A recent paper (Mhaskar (2020)) introduces a straightforward and simple kernel based approximation for manifold learning that does not require the knowledge of anything about the manifold, except for its dimension. In this paper, we examine how the pointwise error in approximation using least squares optimization based on similarly localized kernels depends upon the data characteristics and deteriorates as one goes away from the training data. The theory is presented with an abstract localized kernel, which can utilize any prior knowledge about the data being located on an unknown sub-manifold of a known manifold. We demonstrate the performance of our approach using a publicly available micro-Doppler data set, and investigate the use of different preprocessing measures, kernels, and manifold dimensions. Specifically, it is shown that the localized kernel introduced in the above mentioned paper when used with PCA components leads to a near-competitive performance to deep neural networks, and offers significant improvements in training speed and memory requirements. To demonstrate the fact that our methods are agnostic to the domain knowledge, we examine the classification problem in a simple video data set.}
}
@article{KAMKAR2022121,
title = {Brain-inspired multiple-target tracking using Dynamic Neural Fields},
journal = {Neural Networks},
volume = {151},
pages = {121-131},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001046},
author = {Shiva Kamkar and Hamid {Abrishami Moghaddam} and Reza Lashgari and Wolfram Erlhagen},
keywords = {Multiple-object tracking, Dynamic field theory, Brain-inspired algorithms},
abstract = {Despite considerable progress in the field of automatic multi-target tracking, several problems such as data association remained challenging. On the other hand, cognitive studies have reported that humans can robustly track several objects simultaneously. Such circumstances happen regularly in daily life, and humans have evolved to handle the associated problems. Accordingly, using brain-inspired processing principles may contribute to significantly increase the performance of automatic systems able to follow the trajectories of multiple objects. In this paper, we propose a multiple-object tracking algorithm based on dynamic neural field theory which has been proven to provide neuro-plausible processing mechanisms for cognitive functions of the brain. We define several input neural fields responsible for representing previous location and orientation information as well as instantaneous linear and angular speed of the objects in successive video frames. Image processing techniques are applied to extract the critical object features including target location and orientation. Two prediction fields anticipate the objects’ locations and orientations in the upcoming frame after receiving excitatory and inhibitory inputs from the input fields in a feed-forward architecture. This information is used in the data association and labeling process. We tested the proposed algorithm on a zebrafish larvae segmentation and tracking dataset and an ant-tracking dataset containing non-rigid objects with spiky movements and frequently occurring occlusions. The results showed a significant improvement in tracking metrics compared to state-of-the-art algorithms.}
}
@article{ALMALIOGLU2022119,
title = {SelfVIO: Self-supervised deep monocular Visual–Inertial Odometry and depth estimation},
journal = {Neural Networks},
volume = {150},
pages = {119-136},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000752},
author = {Yasin Almalioglu and Mehmet Turan and Muhamad Risqi U. Saputra and Pedro P.B. {de Gusmão} and Andrew Markham and Niki Trigoni},
keywords = {Self-supervised learning, Geometry reconstruction, Machine perception, Generative adversarial networks, Deep sensor fusion, visual–inertial odometry},
abstract = {In the last decade, numerous supervised deep learning approaches have been proposed for visual–inertial odometry (VIO) and depth map estimation, which require large amounts of labelled data. To overcome the data limitation, self-supervised learning has emerged as a promising alternative that exploits constraints such as geometric and photometric consistency in the scene. In this study, we present a novel self-supervised deep learning-based VIO and depth map recovery approach (SelfVIO) using adversarial training and self-adaptive visual–inertial sensor fusion. SelfVIO learns the joint estimation of 6 degrees-of-freedom (6-DoF) ego-motion and a depth map of the scene from unlabelled monocular RGB image sequences and inertial measurement unit (IMU) readings. The proposed approach is able to perform VIO without requiring IMU intrinsic parameters and/or extrinsic calibration between IMU and the camera. We provide comprehensive quantitative and qualitative evaluations of the proposed framework and compare its performance with state-of-the-art VIO, VO, and visual simultaneous localization and mapping (VSLAM) approaches on the KITTI, EuRoC and Cityscapes datasets. Detailed comparisons prove that SelfVIO outperforms state-of-the-art VIO approaches in terms of pose estimation and depth recovery, making it a promising approach among existing methods in the literature.}
}
@article{YUN2022112,
title = {Attributes learning network for generalized zero-shot learning},
journal = {Neural Networks},
volume = {150},
pages = {112-118},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000594},
author = {Yu Yun and Sen Wang and Mingzhen Hou and Quanxue Gao},
keywords = {Generalized zero-shot learning, Attributes learning, Classification},
abstract = {In the absence of unseen training data, zero-shot learning algorithms utilize the semantic knowledge shared by the seen and unseen classes to establish the connection between the visual space and the semantic space, so as to realize the recognition of the unseen classes. However, in real applications, the original semantic representation cannot well characterize both the class-specificity structure and discriminative information in dimension space, which leads to unseen classes being easily misclassified into seen classes. To tackle this problem, we propose a Salient Attributes Learning Network (SALN) to generate discriminative and expressive semantic representation under the supervision of the visual features. Meanwhile, ℓ1,2-norm constraint is employed to make the learned semantic representation well characterize the class-specificity structure and discriminative information in dimension space. Then feature alignment network projects the learned semantic representation into visual space and a relation network is adopted for classification. The performance of the proposed approach has made progress on the five benchmark datasets in generalized zero-shot learning task, and in-depth experiments indicate the effectiveness and excellence of our method.}
}
@article{AN2022336,
title = {DGInet: Dynamic graph and interaction-aware convolutional network for vehicle trajectory prediction},
journal = {Neural Networks},
volume = {151},
pages = {336-348},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.038},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001162},
author = {Jiyao An and Wei Liu and Qingqin Liu and Liang Guo and Ping Ren and Tao Li},
keywords = {Vehicle trajectory prediction, Graph convolutional network, Dynamic graph, Interaction-aware network, M-product},
abstract = {This paper investigates vehicle trajectory prediction problems in real traffic scenarios by fully harnessing the spatio-temporal dependencies between multiple vehicles. The existing GCN-based trajectory predictions are often considered in a single traffic scene without time attributes, complete interaction information, dynamic graph-based model, etc. Time and interaction aware models are more challenging than the existing ones. Despite very well does the graph-based model describe the relationship between driving vehicles, the critical problem in the traffic scene is how to deeply explore the spatio-temporal characteristics of dynamic graphs. Therefore, a novel dynamic graph and interaction-aware neural network model called as DGInet is proposed by combining a semi-global graph mechanism and an M-product based graph convolutional network, which are built into novel dual-network architecture in the entire model. The DGInet is built by exploiting the dynamic interaction in depth between driving vehicles in urban traffic scenarios, and then realized by utilizing semi-global graph convolution operations on the input data cell to capture the basic spatial interaction features of the driving scene. Meanwhile, the dynamic graph is further extracted by a novel M-product approach, in which the embedding of the model is then established along with the embedding of the semi-global network to perform the final embedding. Extensive experiments have been conducted on the two public datasets, named NGSIM and Apollo respectively, to show that our approach outperforms the existing ones with better performance and less computing time. Besides the real-world Shenzhen traffic dataset, China, is also developed to verify the effectiveness of our approach.}
}
@article{HO2022422,
title = {Predicting progression of Alzheimer’s disease using forward-to-backward bi-directional network with integrative imputation},
journal = {Neural Networks},
volume = {150},
pages = {422-439},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000946},
author = {Ngoc-Huynh Ho and Hyung-Jeong Yang and Jahae Kim and Duy-Phuong Dao and Hyuk-Ro Park and Sudarshan Pant},
keywords = {Alzheimer’s progression, MRI biomarker forecasting, Missing value imputation, Clinical status prediction, Progressive recurrent networks},
abstract = {If left untreated, Alzheimer’s disease (AD) is a leading cause of slowly progressive dementia. Therefore, it is critical to detect AD to prevent its progression. In this study, we propose a bidirectional progressive recurrent network with imputation (BiPro) that uses longitudinal data, including patient demographics and biomarkers of magnetic resonance imaging (MRI), to forecast clinical diagnoses and phenotypic measurements at multiple timepoints. To compensate for missing observations in the longitudinal data, we use an imputation module to inspect both temporal and multivariate relations associated with the mean and forward relations inherent in the time series data. To encode the imputed information, we define a modification of the long short-term memory (LSTM) cell by using a progressive module to compute the progression score of each biomarker between the given timepoint and the baseline through a negative exponential function. These features are used for the prediction task. The proposed system is an end-to-end deep recurrent network that can accomplish multiple tasks at the same time, including (1) imputing missing values, (2) forecasting phenotypic measurements, and (3) predicting the clinical status of a patient based on longitudinal data. We experimented on 1,335 participants from The Alzheimer’s Disease Prediction of Longitudinal Evolution (TADPOLE) challenge cohort. The proposed method achieved a mean area under the receiver-operating characteristic curve (mAUC) of 78% for predicting the clinical status of patients, a mean absolute error (MAE) of 3.5ml for forecasting MRI biomarkers, and an MAE of 6.9ml for missing value imputation. The results confirm that our proposed model outperforms prevalent approaches, and can be used to minimize the progression of Alzheimer’s disease.}
}
@article{LI2022274,
title = {A self-learning cognitive architecture exploiting causality from rewards},
journal = {Neural Networks},
volume = {150},
pages = {274-292},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000703},
author = {Hongming Li and Ran Dou and Andreas Keil and Jose C. Principe},
keywords = {Cognitive architecture, Foveal vision, Wiener–Granger causality, Deep reinforcement learning},
abstract = {Inspired by the human vision system and learning, we propose a novel cognitive architecture that understands the content of raw videos in terms of objects without using labels. The architecture achieves four objectives: (1) Decomposing raw frames in objects by exploiting foveal vision and memory. (2) Describing the world by projecting objects on an internal canvas. (3) Extracting relevant objects from the canvas by analyzing the causal relation between objects and rewards. (4) Exploiting the information of relevant objects to facilitate the reinforcement learning (RL) process. In order to speed up learning, and better identify objects that produce rewards, the architecture implements learning by causality from the perspective of Wiener and Granger using object trajectories stored in working memory and the time series of external rewards. A novel non-parametric estimator of directed information using Renyi’s entropy is designed and tested. Experiments on three environments show that our architecture extracts most of relevant objects. It can be thought of as ‘understanding’ the world in an object-oriented way. As a consequence, our architecture outperforms state-of-the-art deep reinforcement learning in terms of training speed and transfer learning.}
}
@article{2023I,
title = {CURRENT EVENTS},
journal = {Neural Networks},
volume = {168},
pages = {I},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00593-2},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005932}
}
@article{NEKOOEI2022350,
title = {Compression of Deep Neural Networks based on quantized tensor decomposition to implement on reconfigurable hardware platforms},
journal = {Neural Networks},
volume = {150},
pages = {350-363},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.024},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200065X},
author = {Amirreza Nekooei and Saeed Safari},
keywords = {Deep Neural Network, Tensor decomposition, Principal vectors, Network weights, External memory},
abstract = {Deep Neural Networks (DNNs) have been vastly and successfully employed in various artificial intelligence and machine learning applications (e.g., image processing and natural language processing). As DNNs become deeper and enclose more filters per layer, they incur high computational costs and large memory consumption to preserve their large number of parameters. Moreover, present processing platforms (e.g., CPU, GPU, and FPGA) have not enough internal memory, and hence external memory storage is needed. Hence deploying DNNs on mobile applications is difficult, considering the limited storage space, computation power, energy supply, and real-time processing requirements. In this work, using a method based on tensor decomposition, network parameters were compressed, thereby reducing access to external memory. This compression method decomposes the network layers’ weight tensor into a limited number of principal vectors such that (i) almost all the initial parameters can be retrieved, (ii) the network structure did not change, and (iii) the network quality after reproducing the parameters was almost similar to the original network in terms of detection accuracy. To optimize the realization of this method on FPGA, the tensor decomposition algorithm was modified while its convergence was not affected, and the reproduction of network parameters on FPGA was straightforward. The proposed algorithm reduced the parameters of ResNet50, VGG16, and VGG19 networks trained with Cifar10 and Cifar100 by almost 10 times.}
}
@article{YANG2022201,
title = {Non-linear perceptual multi-scale network for single image super-resolution},
journal = {Neural Networks},
volume = {152},
pages = {201-211},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001514},
author = {Aiping Yang and Leilei Li and Jinbin Wang and Zhong Ji and Yanwei Pang and Jiale Cao and Zihao Wei},
keywords = {Image super-resolution, Multi-scale, Global multi-cascade, Local residual nesting},
abstract = {Recently, deep convolutional neural networks (CNNs) have been widely explored in single image super-resolution (SISR) and achieved remarkable progress. However, most of the existing CNN-based SISR networks with a single-stream structure fail to make full use of the multi-scale features of low-resolution (LR) image. While those multi-scale SR models often integrate the information with different receptive fields by means of linear fusion, which leads to the redundant feature extraction and hinders the reconstruction performance of the network. To address both issues, in this paper, we propose a non-linear perceptual multi-scale network (NLPMSNet) to fuse the multi-scale image information in a non-linear manner. Specifically, a novel non-linear perceptual multi-scale module (NLPMSM) is developed to learn more discriminative multi-scale feature correlation by using high-order channel attention mechanism, so as to adaptively extract image features at different scales. Besides, we present a multi-cascade residual nested group (MC-RNG) structure, which uses a global multi-cascade mechanism to organize multiple local residual nested groups (LRNG) to capture sufficient non-local hierarchical context information for reconstructing high-frequency details. LRNG uses a local residual nesting mechanism to stack NLPMSMs, which aims to form a more effective residual learning mechanism and obtain more representative local features. Experimental results show that, compared with the state-of-the-art SISR methods, the proposed NLPMSNet performs well in both quantitative metrics and visual quality with a small number of parameters.}
}
@article{FAGHIHI2022555,
title = {A neuroscience-inspired spiking neural network for EEG-based auditory spatial attention detection},
journal = {Neural Networks},
volume = {152},
pages = {555-565},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001757},
author = {Faramarz Faghihi and Siqi Cai and Ahmed A. Moustafa},
keywords = {EEG, Spiking neurons, Auditory attention, Connectivity, Sparse coding},
abstract = {Recent studies have shown that alpha oscillations (8–13 Hz) enable the decoding of auditory spatial attention. Inspired by sparse coding in cortical neurons, we propose a spiking neural network model for auditory spatial attention detection. The proposed model can extract the patterns of recorded EEG of leftward and rightward attention, independently, and uses them to train the network to detect auditory spatial attention. Specifically, our model is composed of three layers, two of which are Integrate and Fire spiking neurons. We formulate a new learning rule that is based on the firing rate of pre- and post-synaptic neurons in the first and second layers of spiking neurons. The third layer has 10 spiking neurons and the pattern of their firing rate is used in the test phase to decode the auditory spatial attention of a given test sample. Moreover, the effects of using low connectivity rates of the layers and specific range of learning parameters of the learning rule are investigated. The proposed model achieves an average accuracy of 90% with only 10% of EEG signals as training data. This study also provides new insights into the role of sparse coding in both cortical networks subserving cognitive tasks and brain-inspired machine learning.}
}
@article{RASSIL2022149,
title = {Augmented Graph Neural Network with hierarchical global-based residual connections},
journal = {Neural Networks},
volume = {150},
pages = {149-166},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000788},
author = {Asmaa Rassil and Hiba Chougrad and Hamid Zouaki},
keywords = {Graph representation learning, Graph Neural Networks, Residual connections, Reversible networks},
abstract = {Graph Neural Networks (GNNs) are powerful architectures for learning on graphs. They are efficient for predicting nodes, links and graphs properties. Standard GNN variants follow a message passing schema to update nodes representations using information from higher-order neighborhoods iteratively. Consequently, deeper GNNs make it possible to define high-level nodes representations generated based on local as well as distant neighborhoods. However, deeper networks are prone to suffer from over-smoothing. To build deeper GNN architectures and avoid losing the dependency between lower (the layers closer to the input) and higher (the layers closer to the output) layers, networks can integrate residual connections to connect intermediate layers. We propose the Augmented Graph Neural Network (AGNN) model with hierarchical global-based residual connections. Using the proposed residual connections, the model generates high-level nodes representations without the need for a deeper architecture. We disclose that the nodes representations generated through our proposed AGNN model are able to define an expressive all-encompassing representation of the entire graph. As such, the graph predictions generated through the AGNN model surpass considerably state-of-the-art results. Moreover, we carry out extensive experiments to identify the best global pooling strategy and attention weights to define the adequate hierarchical and global-based residual connections for different graph property prediction tasks. Furthermore, we propose a reversible variant of the AGNN model to address the extensive memory consumption problem that typically arises from training networks on large and dense graph datasets. The proposed Reversible Augmented Graph Neural Network (R-AGNN) only stores the nodes representations acquired from the output layer as opposed to saving all representations from intermediate layers as it is conventionally done when optimizing the parameters of other GNNs. We further refine the definition of the backpropagation algorithm to fit the R-AGNN model. We evaluate the proposed models AGNN and R-AGNN on benchmark Molecular, Bioinformatics and Social Networks datasets for graph classification and achieve state-of-the-art results. For instance the AGNN model realizes improvements of +39% on IMDB-MULTI reaching 91.7% accuracy and +16% on COLLAB reaching 96.8% accuracy compared to other GNN variants.}
}
@article{YE2022118,
title = {DynamicNet: A time-variant ODE network for multi-step wind speed prediction},
journal = {Neural Networks},
volume = {152},
pages = {118-139},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001356},
author = {Rui Ye and Xutao Li and Yunming Ye and Baoquan Zhang},
keywords = {Deep learning, Wind speed prediction, Neural ordinary differential equations, Time variance},
abstract = {Wind power is a new type of green energy. Though it is economical to access and gather such energy, effectively matching the energy with consumers’ demand is difficult, because of the fluctuate, intermittent and chaotic nature of wind speed. Hence, multi-step wind speed prediction becomes an important research topic. In this paper, we propose a novel deep learning method, DyanmicNet, for the problem. DynamicNet follows an encoder–decoder framework. To capture the fluctuate, intermittent and chaotic nature of wind speed, it leverages a time-variant structure to build the decoder, which is different from conventional encoder–decoder methods. In addition, a new neural block (ST-GRU-ODE) is developed, which can model the wind speed in a continuous manner by using the neural ordinary differential equation (ODE). To enhance the prediction performance, a multi-step training procedure is also put forward. Comprehensive experiments have been conducted on two real-world datasets, where wind speed is recorded in the form of two orthogonal components namely U-Wind and V-Wind. Each component can be illustrated as wind speed images. Experimental results demonstrate the effectiveness and superiority of the proposed method over state-of-the-art techniques.}
}
@article{ZHANG2022394,
title = {Knowledge-guided multi-task attention network for survival risk prediction using multi-center computed tomography images},
journal = {Neural Networks},
volume = {152},
pages = {394-406},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001599},
author = {Liwen Zhang and Lianzhen Zhong and Cong Li and Wenjuan Zhang and Chaoen Hu and Di Dong and Zaiyi Liu and Junlin Zhou and Jie Tian},
keywords = {Overall survival, Deep learning, Computed tomography (CT), Neural network},
abstract = {Accurate preoperative prediction of overall survival (OS) risk of human cancers based on CT images is greatly significant for personalized treatment. Deep learning methods have been widely explored to improve automated prediction of OS risk. However, the accuracy of OS risk prediction has been limited by prior existing methods. To facilitate capturing survival-related information, we proposed a novel knowledge-guided multi-task network with tailored attention modules for OS risk prediction and prediction of clinical stages simultaneously. The network exploits useful information contained in multiple learning tasks to improve prediction of OS risk. Three multi-center datasets, including two gastric cancer datasets with 459 patients, and a public American lung cancer dataset with 422 patients, are used to evaluate our proposed network. The results show that our proposed network can boost its performance by capturing and sharing information from other predictions of clinical stages. Our method outperforms the state-of-the-art methods with the highest geometrical metric. Furthermore, our method shows better prognostic value with the highest hazard ratio for stratifying patients into high- and low-risk groups. Therefore, our proposed method may be exploited as a potential tool for the improvement of personalized treatment.}
}
@article{HAO202258,
title = {Boosting the transferability of adversarial examples via stochastic serial attack},
journal = {Neural Networks},
volume = {150},
pages = {58-67},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000661},
author = {Lingguang Hao and Kuangrong Hao and Bing Wei and Xue-song Tang},
keywords = {Deep neural networks, Image classification, Adversarial example, Serial attack},
abstract = {Deep neural networks (DNNs) are vulnerable to adversarial examples, which are crafted by imposing mild perturbation on clean ones. An intriguing property of adversarial examples is that they are efficient among different DNNs. Thus transfer-based attacks against DNNs become an increasing concern. In this scenario, attackers devise adversarial instances based on the local model without feedback information from the target one. Unfortunately, most existing transfer-based attack methods only employ a single local model to generate adversarial examples. It results in poor transferability because of overfitting to the local model. Although several ensemble attacks have been proposed, the transferability of adversarial examples merely have a slight increase. Meanwhile, these methods need high memory cost during the training process. To this end, we propose a novel attack strategy called stochastic serial attack (SSA). It adopts a serial strategy to attack local models, which reduces memory consumption compared to parallel attacks. Moreover, since local models are stochastically selected from a large model set, SSA can ensure that the adversarial examples do not overfit specific weaknesses of local source models. Extensive experiments on the ImageNet dataset and NeurIPS 2017 adversarial competition dataset show the effectiveness of SSA in improving the transferability of adversarial examples and reducing the memory consumption of the training process.}
}
@article{CHAIREZ2022156,
title = {Adaptive modeling of nonnegative environmental systems based on projectional Differential Neural Networks observer},
journal = {Neural Networks},
volume = {151},
pages = {156-167},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.028},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200106X},
author = {Isaac Chairez and Olga Andrianova and Tatyana Poznyak and Alexander Poznyak},
keywords = {Positive systems, Projection operator, Differential neural networks, Learning laws design, Control Lyapunov functions},
abstract = {A new design of a non-parametric adaptive approximate model based on Differential Neural Networks (DNNs) applied for a class of non-negative environmental systems with an uncertain mathematical model is the primary outcome of this study. The approximate model uses an extended state formulation that gathers the dynamics of the DNN and a state projector (pDNN). Implementing a non-differentiable projection operator ensures the positiveness of the identifier states. The extended form allows producing continuous dynamics for the projected model. The design of the learning laws for the weight adjustment of the continuous projected DNN considered the application of a controlled Lyapunov-like function. The stability analysis based on the proposed Lyapunov-like function leads to the characterization of the ultimate boundedness property for the identification error. Applying the Attractive Ellipsoid Method (AEM) yields to analyze the convergence quality of the designed approximate model. The solution to the specific optimization problem using the AEM with matrix inequalities constraints allows us to find the parameters of the considered DNN that minimizes the ultimate bound. The evaluation of two numerical examples confirmed the ability of the proposed pDNN to approximate the positive model in the presence of bounded noises and perturbations in the measured data. The first example corresponds to a catalytic ozonation system that can be used to decompose toxic and recalcitrant contaminants. The second one describes the bacteria growth in aerobic batch regime biodegrading simple organic matter mixture.}
}
@article{WEI2022211,
title = {Neural network for a class of sparse optimization with L0-regularization},
journal = {Neural Networks},
volume = {151},
pages = {211-221},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001113},
author = {Zhe Wei and Qingfa Li and Jiazhen Wei and Wei Bian},
keywords = {-regularization, Projected neural network, Sparse optimization, Nonconvex optimization, Critical point},
abstract = {Sparse optimization involving the L0-norm function as the regularization in objective function has a wide application in many fields. In this paper, we propose a projected neural network modeled by a differential equation to solve a class of these optimization problems, in which the objective function is the sum of a nonsmooth convex loss function and the regularization defined by the L0-norm function. This optimization problem is not only nonconvex, but also discontinuous. To simplify the structure of the proposed network and let it own better convergence properties, we use the smoothing method, where the new constructed smoothing function for the regularization term plays a key role. We prove that the solution to the proposed network is globally existent and unique, and any accumulation point of it is a critical point of the continuous relaxation model. Except for a special case, which can be easily justified, any critical point is a local minimizer of the considered sparse optimization problem. It is an interesting thing that all critical points own a promising lower bound property, which is satisfied by all global minimizers of the considered problem, but is not by all local minimizers. Finally, we use some numerical experiments to illustrate the efficiency and good performance of the proposed method for solving this class of sparse optimization problems, which include the most widely used models in feature selection of classification learning.}
}
@article{ASAKAWA2022365,
title = {Evaluation of text-to-gesture generation model using convolutional neural network},
journal = {Neural Networks},
volume = {151},
pages = {365-375},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.041},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001198},
author = {Eiichi Asakawa and Naoshi Kaneko and Dai Hasegawa and Shinichi Shirakawa},
keywords = {Gesture generation, Spoken text, Convolutional neural network, Transformer architecture, Deep learning},
abstract = {Conversational gestures have a crucial role in realizing natural interactions with virtual agents and robots. Data-driven approaches, such as deep learning and machine learning, are promising in constructing the gesture generation model, which automatically provides the gesture motion for speech or spoken texts. This study experimentally analyzes a deep learning-based gesture generation model from spoken text using a convolutional neural network. The proposed model takes a sequence of spoken words as the input and outputs a sequence of 2D joint coordinates representing the conversational gesture motion. We prepare a dataset consisting of gesture motions and spoken texts by adding text information to an existing dataset and train the models using specific speaker’s data. The quality of the generated gestures is compared with those from an existing speech-to-gesture generation model through a user perceptual study. The subjective evaluation shows that the model performance is comparable or superior to those by the existing speech-to-gesture generation model. In addition, we investigate the importance of data cleansing and loss function selection in the text-to-gesture generation model. We further examine the model transferability between speakers. The experimental results demonstrate successful model transferability of the proposed model. Finally, we show that the text-to-gesture generation model can produce good quality gestures even when using a transformer architecture.}
}
@article{LIU202280,
title = {Multistability analysis of delayed recurrent neural networks with a class of piecewise nonlinear activation functions},
journal = {Neural Networks},
volume = {152},
pages = {80-89},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001472},
author = {Yang Liu and Zhen Wang and Qian Ma and Hao Shen},
keywords = {Multistability, Recurrent neural networks, Time-varying delay, Piecewise nonlinear activation functions, Equilibrium points},
abstract = {This paper studies the multistability of delayed recurrent neural networks (DRNNs) with a class of piecewise nonlinear activation functions. The coexistence as well as the stability of multiple equilibrium points (EPs) of DRNNs are proved. With the Brouwer’s fixed point theorem as well as the Lagrange mean value theorem, it is obtained that under some conditions, the n-neuron DRNNs with the proposed activation function can have at least 5n EPs and 3n of them are locally stable. Compared with the DRNNs with sigmoidal activation functions, DRNNs with this kind of activation function can have more total EPs and more locally stable EPs. It implies that when designing DRNNs with the proposed activation function to apply in associative memory, it can have an even larger storage capacity. Furthermore, it is obtained that there exists a relationship between the number of the total EPs/stable EPs and the frequency of the sinusoidal function in the proposed activation function. Last, the above obtained results are extended to a more general case. It is shown that, DRNNs with the extended activation function can have (2k+1)n EPs, (k+1)n of which are locally stable, therein k is closely related to the frequency of the sinusoidal function in the extended activation function. Two simulation examples are given to verify the correctness of the theoretical results.}
}
@article{KON2022190,
title = {Cortical circuits for top-down control of perceptual grouping},
journal = {Neural Networks},
volume = {151},
pages = {190-210},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001071},
author = {Maria Kon and Gregory Francis},
keywords = {Grouping, Gestalt, Segmentation, Strategy, Emergent segmentation},
abstract = {A fundamental characteristic of human visual perception is the ability to group together disparate elements in a scene and treat them as a single unit. The mechanisms by which humans create such groupings remain unknown, but grouping seems to play an important role in a wide variety of visual phenomena, and a good understanding of these mechanisms might provide guidance for how to improve machine vision algorithms. Here, we build on a proposal that some groupings are the result of connections in cortical area V2 that join disparate elements, thereby allowing them to be selected and segmented together. In previous instantiations of this proposal, connection formation was based on the anatomy (e.g., extent) of receptive fields, which made connection formation obligatory when the stimulus conditions stimulate the corresponding receptive fields. We now propose dynamic circuits that provide greater flexibility in the formation of connections and that allow for top-down control of perceptual grouping. With computer simulations we explain how the circuits work and show how they can account for a wide variety of Gestalt principles of perceptual grouping, texture segmentation tasks, amodal illusory contours, and ratings of perceived groupings. We propose that human observers use such top-down control to implement task-dependent connection strategies that encourage particular groupings of stimulus elements in order to promote performance on various visual tasks.}
}
@article{BLAKEMAN2022408,
title = {Selective particle attention: Rapidly and flexibly selecting features for deep reinforcement learning},
journal = {Neural Networks},
volume = {150},
pages = {408-421},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000934},
author = {Sam Blakeman and Denis Mareschal},
keywords = {Selective attention, Visual features, Reinforcement learning, Particle filter, Neural networks},
abstract = {Deep Reinforcement Learning (RL) is often criticised for being data inefficient and inflexible to changes in task structure. Part of the reason for these issues is that Deep RL typically learns end-to-end using backpropagation, which results in task-specific representations. One approach for circumventing these problems is to apply Deep RL to existing representations that have been learned in a more task-agnostic fashion. However, this only partially solves the problem as the Deep RL algorithm learns a function of all pre-existing representations and is therefore still susceptible to data inefficiency and a lack of flexibility. Biological agents appear to solve this problem by forming internal representations over many tasks and only selecting a subset of these features for decision-making based on the task at hand; a process commonly referred to as selective attention. We take inspiration from selective attention in biological agents and propose a novel algorithm called Selective Particle Attention (SPA), which selects subsets of existing representations for Deep RL. Crucially, these subsets are not learned through backpropagation, which is slow and prone to overfitting, but instead via a particle filter that rapidly and flexibly identifies key subsets of features using only reward feedback. We evaluate SPA on two tasks that involve raw pixel input and dynamic changes to the task structure, and show that it greatly increases the efficiency and flexibility of downstream Deep RL algorithms.}
}
@article{CHEN2022407,
title = {LAP: Latency-aware automated pruning with dynamic-based filter selection},
journal = {Neural Networks},
volume = {152},
pages = {407-418},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001745},
author = {Zailong Chen and Chubo Liu and Wangdong Yang and Kenli Li and Keqin Li},
keywords = {AutoML, Channel pruning, Model compression and acceleration, Reinforcement learning},
abstract = {Model pruning is widely used to compress and accelerate convolutional neural networks (CNNs). Conventional pruning techniques only focus on how to remove more parameters while ensuring model accuracy. This work not only covers the optimization of model accuracy, but also optimizes the model latency during pruning. When there are multiple optimization objectives, the difficulty of algorithm design increases exponentially. So latency sensitivity is proposed to effectively guide the determination of layer sparsity in this paper. We present the latency-aware automated pruning (LAP) framework which leverages the reinforcement learning to automatically determine the layer sparsity. Latency sensitivity is used as a prior knowledge and involved into the exploration loop. Rather than relying on a single reward signal such as validation accuracy or floating-point operations (FLOPs), our agent receives the feedback on the accuracy error and latency sensitivity. We also provide a novel filter selection algorithm to accurately distinguish important filters within a layer based on their dynamic changes. Compared to the state-of-the-art compression policies, our framework demonstrated superior performances for VGGNet, ResNet, and MobileNet on CIFAR-10, ImageNet, and Food-101. Our LAP allowed the inference latency of MobileNet-V1 to achieve approximately 1.64 times speedup on the Titan RTX GPU, with no loss of ImageNet Top-1 accuracy. It significantly improved the pareto optimal curve on the accuracy and latency trade-off.}
}
@article{FILIPPINI2022276,
title = {Decoding sensorimotor information from superior parietal lobule of macaque via Convolutional Neural Networks},
journal = {Neural Networks},
volume = {151},
pages = {276-294},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.044},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001228},
author = {Matteo Filippini and Davide Borra and Mauro Ursino and Elisa Magosso and Patrizia Fattori},
keywords = {Neural decoding, Posterior parietal cortex, Convolutional neural network, Sensorymotor transformation, Brain–computer interfaces, Monkey},
abstract = {Despite the well-recognized role of the posterior parietal cortex (PPC) in processing sensory information to guide action, the differential encoding properties of this dynamic processing, as operated by different PPC brain areas, are scarcely known. Within the monkey’s PPC, the superior parietal lobule hosts areas V6A, PEc, and PE included in the dorso-medial visual stream that is specialized in planning and guiding reaching movements. Here, a Convolutional Neural Network (CNN) approach is used to investigate how the information is processed in these areas. We trained two macaque monkeys to perform a delayed reaching task towards 9 positions (distributed on 3 different depth and direction levels) in the 3D peripersonal space. The activity of single cells was recorded from V6A, PEc, PE and fed to convolutional neural networks that were designed and trained to exploit the temporal structure of neuronal activation patterns, to decode the target positions reached by the monkey. Bayesian Optimization was used to define the main CNN hyper-parameters. In addition to discrete positions in space, we used the same network architecture to decode plausible reaching trajectories. We found that data from the most caudal V6A and PEc areas outperformed PE area in the spatial position decoding. In all areas, decoding accuracies started to increase at the time the target to reach was instructed to the monkey, and reached a plateau at movement onset. The results support a dynamic encoding of the different phases and properties of the reaching movement differentially distributed over a network of interconnected areas. This study highlights the usefulness of neurons’ firing rate decoding via CNNs to improve our understanding of how sensorimotor information is encoded in PPC to perform reaching movements. The obtained results may have implications in the perspective of novel neuroprosthetic devices based on the decoding of these rich signals for faithfully carrying out patient’s intentions.}
}
@article{WANG2022213,
title = {Event-triggered delayed impulsive control for nonlinear systems with application to complex neural networks},
journal = {Neural Networks},
volume = {150},
pages = {213-221},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000776},
author = {Mingzhu Wang and Xiaodi Li and Peiyong Duan},
keywords = {Event-triggered delayed impulsive control, Nonlinear system, Stability, Synchronization, Complex neural networks},
abstract = {This paper studies the Lyapunov stability of nonlinear systems and the synchronization of complex neural networks in the framework of event-triggered delayed impulsive control (ETDIC), where the effect of time delays in impulses is fully considered. Based on the Lyapunov-based event-triggered mechanism (ETM), some sufficient conditions are presented to avoid Zeno behavior and achieve globally asymptotical stability of the addressed system. In the framework of event-triggered impulse control (ETIC), control input is only generated at state-dependent triggered instants and there is no any control input during two consecutive triggered impulse instants, which can greatly reduce resource consumption and control waste. The contributions of this paper can be summarized as follows: Firstly, compared with the classical ETIC, our results not only provide the well-designed ETM to determine the impulse time sequence, but also fully extract the information of time delays in impulses and integrate it into the dynamic analysis of the system. Secondly, it is shown that the time delays in impulses in our results exhibit positive effects, that is, it may contribute to stabilizing a system and achieve better performance. Thirdly, as an application of ETDIC strategies, we apply the proposed theoretical results to synchronization problem of complex neural networks. Some sufficient conditions to ensure the synchronization of complex neural networks are presented, where the information of time delays in impulses is fully fetched in these conditions. Finally, two numerical examples are provided to show the effectiveness and validity of the theoretical results.}
}
@article{ZHANG2022224,
title = {Attributed graph clustering with multi-task embedding learning},
journal = {Neural Networks},
volume = {152},
pages = {224-233},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001502},
author = {Xiaotong Zhang and Han Liu and Xianchao Zhang and Xinyue Liu},
keywords = {Attributed graph clustering, Multi-task learning, Network embedding},
abstract = {Attributed graph clustering is challenging as it needs to effectively combine both graph structure and node feature information to accomplish node clustering. Recent studies mostly adopt graph neural networks to learn node embeddings, then apply traditional clustering methods to obtain clusters. However, their node embeddings are not specifically designed for clustering. Moreover, most of their loss functions only rely on either structure or feature information, making both kinds of information not fully retained in node embeddings. In this paper, we propose a multi-task embedding learning method (MTEL) for attributed graph clustering, which constructs two prediction tasks in terms of structure and feature based adjacency matrices respectively. To make the node embeddings helpful for the downstream clustering, in each task, we predict the minimum hop number between each pair of nodes in the adjacency matrix, so that the correlation degrees among nodes can be encoded into node embeddings. To improve the performance of the prediction task, we regularize the model parameters in these two tasks via ℓ2,1 norm, through which the model parameters can be jointly learned. Experiments on real attributed graphs show that MTEL is superior for attributed graph clustering over state-of-the-art methods.}
}
@article{ZHUANG2022276,
title = {Multi-level landmark-guided deep network for face super-resolution},
journal = {Neural Networks},
volume = {152},
pages = {276-286},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001587},
author = {Cheng Zhuang and Minqi Li and Kaibing Zhang and Zheng Li and Jian Lu},
keywords = {Facial component, Facial landmarks, Super-resolution reconstruction, Recursive feedback deep network},
abstract = {Recent years deep learning-based methods incorporating facial prior knowledge for face super-resolution (FSR) are advancing and have gained impressive performance. However, some important priors such as facial landmarks are not fully exploited in existing methods, leading to noticeable artifacts in the resultant SR face images especially under large magnification. In this paper, we propose a novel multi-level landmark-guided deep network (MLGDN) for FSR. More specifically, to fully exploit the dependencies between low and high resolution images and to reduce network parameters as well as capture more reliable feature representation, we introduce a recursive back-projection network with a particular feedback mechanism for coarse-to-fine FSR. Furthermore, we incorporate an attention fusion module in the front of backbone network to strengthen face components and a feature modulation module to refine features in the middle of backbone network. By this way, the facial landmarks extracted from face images can be fully shared by the modules in different levels, which benefit to produce more faithful facial details. Both quantitative and qualitative performance evaluations on two benchmark databases demonstrate that the proposed MLGDN can achieve more impressive SR results than other state-of-the-art competitors. Code will be available at https://github.com/zhuangcheng31/MLG_Face.git/}
}
@article{ZHAO2022336,
title = {Novel projection neurodynamic approaches for constrained convex optimization},
journal = {Neural Networks},
volume = {150},
pages = {336-349},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000892},
author = {You Zhao and Xiaofeng Liao and Xing He},
keywords = {Accelerated neurodynamic approaches, Constrained optimization, Variational method, Arithmetical and exponential convergence rate},
abstract = {Consider that the constrained convex optimization problems have emerged in a variety of scientific and engineering applications that often require efficient and fast solutions. Inspired by the Nesterov’s accelerated method for solving unconstrained convex and strongly convex optimization problems, in this paper we propose two novel accelerated projection neurodynamic approaches for constrained smooth convex and strongly convex optimization based on the variational approach. First, for smooth, and convex optimization problems, a non-autonomous accelerated projection neurodynamic approach (NAAPNA) is presented and the existence, uniqueness and feasibility of the solution to it are analyzed rigorously. We provide that the NAAPNA has a convergence rate which is inversely proportional to the square of the running time. In addition, we present a novel autonomous accelerated projection neurodynamic approach (AAPNA) for addressing the constrained, smooth, strongly convex optimization problems and prove the existence, uniqueness to the strong global solution of AAPNA based on the Cauchy–Lipschitz–Picard theorem. Furthermore, we also prove the global convergence of AAPNA with different exponential convergence rates for different parameters. Compared with existing projection neurodynamic approaches based on the Brouwer’s fixed point theorem, both NAAPNA and AAPNA use the projection operators of the auxiliary variable to map the primal variables to the constrained feasible region, thus our proposed neurodynamic approaches are easier to realize algorithm’s acceleration. Finally, the effectiveness of NAAPNA and AAPNA is illustrated with several numerical examples.}
}
@article{CAO2022143,
title = {Lag H∞ synchronization of coupled neural networks with multiple state couplings and multiple delayed state couplings},
journal = {Neural Networks},
volume = {151},
pages = {143-155},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001101},
author = {Yuting Cao and Linhao Zhao and Shiping Wen and Tingwen Huang},
keywords = {Adaptive control, Coupled neural networks, Lag  synchronization, Multiple delayed state couplings, Multiple state couplings},
abstract = {This paper mainly focuses on the lag H∞ synchronization problem of coupled neural networks with multiple state or delayed state couplings. On one hand, by exploiting state feedback controller and Lyapunov functional, a criterion of lag H∞ synchronization for coupled neural networks with multiple state couplings (CNNMSCs) is insured, and lag H∞ synchronization problem in CNNMSCs is also coped with based on the adaptive state feedback controller. On the other hand, we explore the lag H∞ synchronization for coupled neural networks with multiple delayed state couplings (CNNMDSCs) by utilizing similar control strategies. At last, two numerical examples are presented to verify the effectiveness and correctness of lag H∞ synchronization for CNNMSCs and CNNMDSCs.}
}
@article{SHAHAM202234,
title = {Deep unsupervised feature selection by discarding nuisance and correlated features},
journal = {Neural Networks},
volume = {152},
pages = {34-43},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001344},
author = {Uri Shaham and Ofir Lindenbaum and Jonathan Svirsky and Yuval Kluger},
keywords = {Unsupervised feature selection, Laplacian score, Concrete layer},
abstract = {Modern datasets often contain large subsets of correlated features and nuisance features, which are not or loosely related to the main underlying structures of the data. Nuisance features can be identified using the Laplacian score criterion, which evaluates the importance of a given feature via its consistency with the Graph Laplacians’ leading eigenvectors. We demonstrate that in the presence of large numbers of nuisance features, the Laplacian must be computed on the subset of selected features rather than on the complete feature set. To do this, we propose a fully differentiable approach for unsupervised feature selection, utilizing the Laplacian score criterion to avoid the selection of nuisance features. We employ an autoencoder architecture to cope with correlated features, trained to reconstruct the data from the subset of selected features. Building on the recently proposed concrete layer that allows controlling for the number of selected features via architectural design, simplifying the optimization process. Experimenting on several real-world datasets, we demonstrate that our proposed approach outperforms similar approaches designed to avoid only correlated or nuisance features, but not both. Several state-of-the-art clustering results are reported. Our code is publically available at https://github.com/jsvir/lscae.}
}
@article{KHALITOV2022160,
title = {Sparse factorization of square matrices with application to neural attention modeling},
journal = {Neural Networks},
volume = {152},
pages = {160-168},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001460},
author = {Ruslan Khalitov and Tong Yu and Lei Cheng and Zhirong Yang},
keywords = {Matrix factorization, Sparse, Neural networks, Attention modeling},
abstract = {Square matrices appear in many machine learning problems and models. Optimization over a large square matrix is expensive in memory and in time. Therefore an economic approximation is needed. Conventional approximation approaches factorize the square matrix into a number matrices of much lower ranks. However, the low-rank constraint is a performance bottleneck if the approximated matrix is intrinsically high-rank or close to full rank. In this paper, we propose to approximate a large square matrix with a product of sparse full-rank matrices. In the approximation, our method needs only N(logN)2 non-zero numbers for an N×N full matrix. Our new method is especially useful for scalable neural attention modeling. Different from the conventional scaled dot-product attention methods, we train neural networks to map input data to the non-zero entries of the factorizing matrices. The sparse factorization method is tested for various square matrices, and the experimental results demonstrate that our method gives a better approximation when the approximated matrix is sparse and high-rank. As an attention module, our new method defeats Transformer and its several variants for long sequences in synthetic data sets and in the Long Range Arena benchmarks. Our code is publicly available22https://github.com/RuslanKhalitov/SparseFactorization..}
}
@article{KARMAKAR2022264,
title = {Provable training of a ReLU gate with an iterative non-gradient algorithm},
journal = {Neural Networks},
volume = {151},
pages = {264-275},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.040},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001186},
author = {Sayar Karmakar and Anirbit Mukherjee},
keywords = {Neural nets, Non-gradient iterative algorithms, Stochastic algorithms, Non-smooth non-convex optimization},
abstract = {In this work, we demonstrate provable guarantees on the training of a single ReLU gate in hitherto unexplored regimes. We give a simple iterative stochastic algorithm that can train a ReLU gate in the realizable setting in linear time while using significantly milder conditions on the data distribution than previous such results. Leveraging certain additional moment assumptions, we also show a first-of-its-kind approximate recovery of the true label generating parameters under an (online) data-poisoning attack on the true labels, while training a ReLU gate by the same algorithm. Our guarantee is shown to be nearly optimal in the worst case and its accuracy of recovering the true weight degrades gracefully with increasing probability of attack and its magnitude. For both the realizable and the non-realizable cases as outlined above, our analysis allows for mini-batching and computes how the convergence time scales with the mini-batch size. We corroborate our theorems with simulation results which also bring to light a striking similarity in trajectories between our algorithm and the popular S.G.D. algorithm — for which similar guarantees as here are still unknown.}
}
@article{WANG2022105,
title = {Quantum pulse coupled neural network},
journal = {Neural Networks},
volume = {152},
pages = {105-117},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200140X},
author = {Zhaobin Wang and Minzhe Xu and Yaonan Zhang},
keywords = {Quantum neural network, Image processing, Quantum image processing, Pulse coupled neural network},
abstract = {Artificial neural network has been fully developed in recent years, but as the size of the network grows, the required computing power also grows rapidly. In order to take advantage of the parallel computing of quantum computing to solve the difficulties of large computation in neural network, quantum neural network was proposed. In this paper, based on the pulse coupled neural network (PCNN), quantum pulse coupled neural network (QPCNN) is proposed. In this model, the basic quantum logic gates are utilized to form quantum operation modules, such as quantum full adder, quantum multiplier, and quantum comparator. A quantum image convolution operation applicable to QPCNN is designed employing quantum full adders and neighborhood preparation module. And these modules are employed to complete the operations required for QPCNN. And based on QPCNN, an quantum image segmentation is designed. Meanwhile, the effectiveness of QPCNN is proved by simulation experiments, and the complexity analysis shows that QPCNN has exponential speedup compared with classical PCNN.}
}
@article{KOBAYASHI2022169,
title = {Optimistic reinforcement learning by forward Kullback–Leibler divergence optimization},
journal = {Neural Networks},
volume = {152},
pages = {169-180},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001538},
author = {Taisuke Kobayashi},
keywords = {Reinforcement learning, Control as probabilistic inference, Kullback–Leibler divergence, Optimistic learning},
abstract = {This paper addresses a new interpretation of the traditional optimization method in reinforcement learning (RL) as optimization problems using reverse Kullback–Leibler (KL) divergence, and derives a new optimization method using forward KL divergence, instead of reverse KL divergence in the optimization problems. Although RL originally aims to maximize return indirectly through optimization of policy, the recent work by Levine has proposed a different derivation process with explicit consideration of optimality as stochastic variable. This paper follows this concept and formulates the traditional learning laws for both value function and policy as the optimization problems with reverse KL divergence including optimality. Focusing on the asymmetry of KL divergence, the new optimization problems with forward KL divergence are derived. Remarkably, such new optimization problems can be regarded as optimistic RL. That optimism is intuitively specified by a hyperparameter converted from an uncertainty parameter. In addition, it can be enhanced when it is integrated with prioritized experience replay and eligibility traces, both of which accelerate learning. The effects of this expected optimism was investigated through learning tendencies on numerical simulations using Pybullet. As a result, moderate optimism accelerated learning and yielded higher rewards. In a realistic robotic simulation, the proposed method with the moderate optimism outperformed one of the state-of-the-art RL method.}
}
@article{VERDUZCOFLORES2022237,
title = {A differential Hebbian framework for biologically-plausible motor control},
journal = {Neural Networks},
volume = {150},
pages = {237-258},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000727},
author = {Sergio Verduzco-Flores and William Dorrell and Erik {De Schutter}},
keywords = {Synaptic plasticity, Motor control, Reinforcement learning, Feedback control},
abstract = {In this paper we explore a neural control architecture that is both biologically plausible, and capable of fully autonomous learning. It consists of feedback controllers that learn to achieve a desired state by selecting the errors that should drive them. This selection happens through a family of differential Hebbian learning rules that, through interaction with the environment, can learn to control systems where the error responds monotonically to the control signal. We next show that in a more general case, neural reinforcement learning can be coupled with a feedback controller to reduce errors that arise non-monotonically from the control signal. The use of feedback control can reduce the complexity of the reinforcement learning problem, because only a desired value must be learned, with the controller handling the details of how it is reached. This makes the function to be learned simpler, potentially allowing learning of more complex actions. We use simple examples to illustrate our approach, and discuss how it could be extended to hierarchical architectures.}
}
@article{ZHAO2022102,
title = {Robust multi-view subspace clustering based on consensus representation and orthogonal diversity},
journal = {Neural Networks},
volume = {150},
pages = {102-111},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200079X},
author = {Nan Zhao and Jie Bu},
keywords = {Multi-view subspace clustering, Consensus representation, Orthogonal diversity, Grouping-enhanced representation},
abstract = {The main purpose of multi-view subspace clustering is to reveal the intrinsic low-dimensional architecture of data points according to their multi-view characteristics. Exploring the potential relationship from views is one of the most essential research focuses of the multi-view task. To better utilize the complementary and consistency information from distinct views, we propose a novel robust subspace clustering approach based on consensus representation and orthogonal diversity (RMSCCO). A novel defined orthogonality term is adopted to improve the diversity and decrease the redundance of learning subspace representation. The consensus representation and subspace learning are integrated into one unified framework to characterize the consistency from views. The grouping-enhanced representation is utilized to maintain the local geometric architecture in the original data space. The ℓ2,1-norm regularizer constraint to the noise is applied to improve the robustness. Finally, an optimization algorithm is exploited to solve RMSCCO with the Alternating Direction Method of Multipliers (ADMM). Extensive experimental results on six challenging datasets demonstrate that our approach has accomplished highly qualified performance.}
}
@article{LEE202268,
title = {Uncertainty-aware hierarchical segment-channel attention mechanism for reliable and interpretable multichannel signal classification},
journal = {Neural Networks},
volume = {150},
pages = {68-86},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000600},
author = {Jiyoon Lee and Seoung Bum Kim},
keywords = {Explainable neural network, Attention mechanism, Bayesian neural network, Multichannel signal, Multivariate time series},
abstract = {Multichannel signal data analysis has been crucial in various industrial applications, such as human activity recognition, vehicle failure predictions, and manufacturing equipment monitoring. Recently, deep neural networks have come into use for multichannel signal data because of their ability to automatically extract useful features from complex multichannel signals. However, deep neural networks are black-box models whose internal working mechanisms cannot be put in a form readily understood by humans. To address this issue, we have proposed an uncertainty-aware hierarchical segment-channel attention model that consists of a time segment and channel level attentions. The hierarchical attention mechanism enables a neural network to identify important time segments and channels critical for prediction, making the model explainable. In addition, the model uses variational inferences to provide uncertainty information that yields a confidence interval that can be easily explained. We conducted experiments on simulated and real-world datasets to demonstrate the usefulness and applicability of our method. The results confirm that our method can attend to important time segments and sensors while achieving better classification performance.}
}
@article{LEE202257,
title = {Tri-view two-photon microscopic image registration and deblurring with convolutional neural networks},
journal = {Neural Networks},
volume = {152},
pages = {57-69},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001411},
author = {Sehyung Lee and Hideaki Kume and Hidetoshi Urakubo and Haruo Kasai and Shin Ishii},
keywords = {Microscopy image, Deep learning, Convolutional neural network, Deblurring, Registration},
abstract = {Two-photon fluorescence microscopy has enabled the three-dimensional (3D) neural imaging of deep cortical regions. While it can capture the detailed neural structures in the x–y image space, the image quality along the depth direction is lower because of lens blur, which often makes it difficult to identify the neural connectivity. To address this problem, we propose a novel approach for restoring the isotropic image volume by estimating and fusing the intersection regions of the images captured from three orthogonal viewpoints using convolutional neural networks (CNNs). Because convolution on 3D images is computationally complex, the proposed method takes the form of cascaded CNN models consisting of rigid transformation, dense registration, and deblurring networks for more efficient processing. In addition, to enable self-supervised learning, we trained the CNN models with simulated synthetic images by considering the distortions of the microscopic imaging process. Through extensive experiments, the proposed method achieved substantial image quality improvements.}
}
@article{CHAARI2022250,
title = {Multigraph classification using learnable integration network with application to gender fingerprinting},
journal = {Neural Networks},
volume = {151},
pages = {250-263},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001137},
author = {Nada Chaari and Mohammed Amine Gharsallaoui and Hatice Camgöz Akdağ and Islem Rekik},
keywords = {Multigraph integration, Multigraph classification, Geometric deep learning (GDL), Graph neural network (GNN), Gender differences},
abstract = {Multigraphs with heterogeneous views present one of the most challenging obstacles to classification tasks due to their complexity. Several works based on feature selection have been recently proposed to disentangle the problem of multigraph heterogeneity. However, such techniques have major drawbacks. First, the bulk of such works lies in the vectorization and the flattening operations, failing to preserve and exploit the rich topological properties of the multigraph. Second, they learn the classification process in a dichotomized manner where the cascaded learning steps are pieced in together independently. Hence, such architectures are inherently agnostic to the cumulative estimation error from step to step. To overcome these drawbacks, we introduce MICNet (multigraph integration and classifier network), the first end-to-end graph neural network based model for multigraph classification. First, we learn a single-view graph representation of a heterogeneous multigraph using a GNN based integration model. The integration process in our model helps tease apart the heterogeneity across the different views of the multigraph by generating a subject-specific graph template while preserving its geometrical and topological properties conserving the node-wise information while reducing the size of the graph (i.e., number of views). Second, we classify each integrated template using a geometric deep learning block which enables us to grasp the salient graph features. We train, in end-to-end fashion, these two blocks using a single objective function to optimize the classification performance. We evaluate our MICNet in gender classification using brain multigraphs derived from different cortical measures. We demonstrate that our MICNet significantly outperformed its variants thereby showing its great potential in multigraph classification.}
}
@article{SANTHAKUMAR2022167,
title = {Lifelong 3D object recognition and grasp synthesis using dual memory recurrent self-organization networks},
journal = {Neural Networks},
volume = {150},
pages = {167-180},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000685},
author = {Krishnakumar Santhakumar and Hamidreza Kasaei},
keywords = {Lifelong learning, Continual learning, Dual memory recurrent self-organization, Object recognition, Grasp synthesis, Memory replay},
abstract = {Humans learn to recognize and manipulate new objects in lifelong settings without forgetting the previously gained knowledge under non-stationary and sequential conditions. In autonomous systems, the agents also need to mitigate similar behaviour to continually learn the new object categories and adapt to new environments. In most conventional deep neural networks, this is not possible due to the problem of catastrophic forgetting, where the newly gained knowledge overwrites existing representations. Furthermore, most state-of-the-art models excel either in recognizing the objects or in grasp prediction, while both tasks use visual input. The combined architecture to tackle both tasks is very limited. In this paper, we proposed a hybrid model architecture consists of a dynamically growing dual-memory recurrent neural network (GDM) and an autoencoder to tackle object recognition and grasping simultaneously. The autoencoder network is responsible to extract a compact representation for a given object, which serves as input for the GDM learning, and is responsible to predict pixel-wise antipodal grasp configurations. The GDM part is designed to recognize the object in both instances and categories levels. We address the problem of catastrophic forgetting using the intrinsic memory replay, where the episodic memory periodically replays the neural activation trajectories in the absence of external sensory information. To extensively evaluate the proposed model in a lifelong setting, we generate a synthetic dataset due to lack of sequential 3D objects dataset. Experiment results demonstrated that the proposed model can learn both object representation and grasping simultaneously in continual learning scenarios.}
}
@article{LI2022347,
title = {Robust kernel principal component analysis with optimal mean},
journal = {Neural Networks},
volume = {152},
pages = {347-352},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001770},
author = {Pei Li and Wenlin Zhang and Chengjun Lu and Rui Zhang and Xuelong Li},
keywords = {Kernel principal component analysis, Robust principal component analysis, Optimal mean},
abstract = {The kernel principal component analysis (KPCA) serves as an efficient approach for dimensionality reduction. However, the KPCA method is sensitive to the outliers since the large square errors tend to dominate the loss of KPCA. To strengthen the robustness of KPCA method, we propose a novel robust kernel principal component analysis with optimal mean (RKPCA-OM) method. RKPCA-OM not only possesses stronger robustness for outliers than the conventional KPCA method, but also can eliminate the optimal mean automatically. What is more, the theoretical proof proves the convergence of the algorithm to guarantee that the optimal subspaces and means are obtained. Lastly, exhaustive experimental results verify the superiority of our method.}
}
@article{CHEN2022181,
title = {A new deep learning framework based on blood pressure range constraint for continuous cuffless BP estimation},
journal = {Neural Networks},
volume = {152},
pages = {181-190},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001496},
author = {Yongyi Chen and Dan Zhang and Hamid Reza Karimi and Chao Deng and Wutao Yin},
keywords = {Photoplethysmography (PPG), Blood pressure (BP), Parallel mixed domain attention mechanism, Receptive field, Soft threshold, BP range constraint},
abstract = {Blood pressure (BP) is known as an indicator of human health status, and regular measurement is helpful for early detection of cardiovascular diseases. Traditional techniques for measuring BP are either invasive or cuff-based and thus are not suitable for continuous measurement. Aiming at the deficiencies in existing studies, a novel cuffless BP estimation framework of Receptive Field Parallel Attention Shrinkage Network (RFPASN) and BP range constraint is proposed. Firstly, RFPASN uses the multi-scale large receptive field convolution module to capture the long-term dynamics in the photoplethysmography (PPG) signal without using long short-term memory (LSTM). On this basis, the features acquired by the parallel mixed domain attention module are used as thresholds, and the soft threshold function is used to screen the input features to enhance the discriminability and robustness of features, which can significantly improve the prediction accuracy of diastolic blood pressure (DBP) and systolic blood pressure (SBP). Finally, in order to prevent large fluctuations in the prediction results of RFPASN, RFPASN based on BP range constraint is proposed to make the prediction results of RFPASN more accurate and reasonable. The performance of the proposed method is demonstrated on a publically available MIMIC-II database. The database contains normal, hypertensive and hypotensive people. We have achieved MAE of 1.63/1.59 (DBP) and 2.26/2.15 (SBP) mmHg for BP on total population of 1562 subjects. A comparative study shows that the proposed algorithm is more promising than the state-of-the-art.}
}
@article{YANG202261,
title = {Guaranteed approximation error estimation of neural networks and model modification},
journal = {Neural Networks},
volume = {151},
pages = {61-69},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001010},
author = {Yejiang Yang and Tao Wang and Jefferson P. Woolard and Weiming Xiang},
keywords = {Feedforward neural network, Approximation error estimation, Lipschitz constant, Reachability, Neural network compression},
abstract = {Approximation error is a key measure in the process of model validation and verification for neural networks. In this paper, the problems of guaranteed error estimation of neural networks and applications to assured system modeling and assured neural network compression are addressed. First, a concept called guaranteed error estimation of feedforward neural networks is proposed, which intends to provide the worst-case approximation error of a trained neural network with respect to a compact input set essentially containing an infinite number of values. Given different prior information about the original system, two approaches including Lipschitz constant analysis and set-valued reachability analysis methods are developed to efficiently compute upper-bounds of approximation errors. Based on the guaranteed approximation error estimation framework, an optimization for obtaining parameter values from data set is proposed. A robotic arm and neural network compression examples are presented to illustrate the effectiveness of our approach.}
}
@article{WANG2022238,
title = {Informative pairs mining based adaptive metric learning for adversarial domain adaptation},
journal = {Neural Networks},
volume = {151},
pages = {238-249},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001095},
author = {Mengzhu Wang and Paul Li and Li Shen and Ye Wang and Shanshan Wang and Wei Wang and Xiang Zhang and Junyang Chen and Zhigang Luo},
keywords = {Domain adaptation, Informative pairs mining, Adaptive metric learning, Adversarial domain adaptation},
abstract = {Adversarial domain adaptation has made remarkable in promoting feature transferability, while recent work reveals that there exists an unexpected degradation of feature discrimination during the procedure of learning transferable features. This paper proposes an informative pairs mining based adaptive metric learning (IPM-AML), where a novel two-triplet-sampling strategy is advanced to select informative positive pairs from the same classes and informative negative pairs from different classes, and a metric loss imposed with special weights is further utilized to adaptively pay more attention to those more informative pairs which can adaptively improve discrimination. Then, we incorporate IPM-AML into popular conditional domain adversarial network (CDAN) to learn feature representation that is transferable and discriminative desirably (IPM-AML-CDAN). To ensure the reliability of pseudo target labels in the whole training process, we select more confident target ones whose predicted scores are higher than a given threshold T, and also provide theoretical validation for this simple threshold strategy. Extensive experiment results on four cross-domain benchmarks validate that IPM-AML-CDAN can achieve competitive results compared with state-of-the-art approaches.}
}
@article{2023II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {168},
pages = {II},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00594-4},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023005944}
}
@article{KUMAR2022392,
title = {A BERT based dual-channel explainable text emotion recognition system},
journal = {Neural Networks},
volume = {150},
pages = {392-407},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000958},
author = {Puneet Kumar and Balasubramanian Raman},
keywords = {Emotion recognition, Natural language processing, Explainable AI, Deep neural network explainability},
abstract = {In this paper, a novel dual-channel system for multi-class text emotion recognition has been proposed, and a novel technique to explain its training & predictions has been developed. The architecture of the proposed system contains the embedding module, dual-channel module, emotion classification module, and explainability module. The embedding module extracts the textual features from the input sentences in the form of embedding vectors using the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model. Then the embedding vectors are fed as the inputs to the dual-channel network containing two network channels made up of convolutional neural network (CNN) and bidirectional long short term memory (BiLSTM) network. The intuition behind using CNN and BiLSTM in both the channels was to harness the goodness of the convolutional layer for feature extraction and the BiLSTM layer to extract text’s order and sequence-related information. The outputs of both channels are in the form of embedding vectors which are concatenated and fed to the emotion classification module. The proposed system’s architecture has been determined by thorough ablation studies, and a framework has been developed to discuss its computational cost. The emotion classification module learns and projects the emotion embeddings on a hyperplane in the form of clusters. The proposed explainability technique explains the training and predictions of the proposed system by analyzing the inter & intra-cluster distances and the intersection of these clusters. The proposed approach’s consistent accuracy, precision, recall, and F1 score results for ISEAR, Aman, AffectiveText, and EmotionLines datasets, ensure its applicability to diverse texts.}
}
@article{ZHOU2022419,
title = {Sampled-data synchronization of complex network based on periodic self-triggered intermittent control and its application to image encryption},
journal = {Neural Networks},
volume = {152},
pages = {419-433},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001769},
author = {Hui Zhou and Zijiang Liu and Dianhui Chu and Wenxue Li},
keywords = {Complex networks, Periodic self-triggered control, Intermittent control, Sampled-data control, Image encryption},
abstract = {The aim of this paper is to investigate exponential synchronization issue of time-varying multi-weights network with time delays (TMNTD) via periodic self-triggered intermittent sampled-data control. In particular, it is the first time to combine periodic self-triggered control and intermittent control with sampled-data, which has broader application prospects. Therein, self-triggered scheme is periodic judgment and aimed at intermittent control. And during control intervals in intermittent control, there is periodic sampled-data control. In addition, by applying tools of sampled-data control, intermittent control, event-driven control theory and stability analysis, some sufficient conditions are derived to guarantee exponential synchronization of TMNTD. After that, the theoretical results are utilized to research exponential synchronization issue of time-varying multi-weights Chua’s circuits with time delays. Meantime, numerical simulations are provided to demonstrate the validity of the theoretical results. Finally, an image encryption algorithm is designed as a practical application of the developed results.}
}
@article{GAO2022377,
title = {The passive properties of dendrites modulate the propagation of slowly-varying firing rate in feedforward networks},
journal = {Neural Networks},
volume = {150},
pages = {377-391},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000715},
author = {Tianshi Gao and Bin Deng and Jixuan Wang and Jiang Wang and Guosheng Yi},
keywords = {Dendrite, Two-compartment model, Time-varying spiking activity, Information propagation, Feedforward neural network},
abstract = {The propagation of slowly-varying firing rates has been proved significant for the development of the central nervous system. Recent reports have shown that the membrane passive properties of dendrites play a key role in the computation of the single neuron, which is of great importance to the function of neural networks. However, it is still unclear how dendritic passive properties affect the ability of cortical networks to propagate slowly-varying spiking activity. Here, we use two-compartment biophysical models to construct multilayered feedforward neural networks (FFNs) to investigate how dendritic passive properties affect the propagation of the slow-varying inputs. In the two-compartment biophysical models, one compartment represents apical dendrites, and the other compartment describes the soma plus the axon initial segment. Area proportion occupied by somatic compartment and coupling conductance between dendritic and somatic compartments are abstracted to capture the dendritic passive properties. A time-varying signal is injected into the first layer of the FFNs and the fidelity of the signal during propagation is used to qualify the ability of the FFN to transmit wave-like signals. Numerical results reveal an optimal value of coupling conductance between dendritic and somatic compartments to maximize the fidelity of the initial spiking activity. An increase of the dendritic area enhances the initial firing rate of neurons in the first layer by increasing the response of neurons to slow-varying wave-like input, resulting in a delay of attenuation of the firing rate, thus promoting the transmission of signals in FFN. Using a mean-field approach, we examine that changes in area proportion occupied by somatic compartment and coupling conductance between dendritic and somatic compartment affect the signal propagation ability of the FFN by adjusting the input–output transform of a single neuron. With the participation of external noise, a wide range of initial firing rates maintains a unique representation during propagation, which ensures the reliable transmission of slow-varying signals in FFNs. These findings are helpful to understand how passive properties of dendrites participate in the propagation of slowly varying signals in the cerebellum.}
}
@article{QIN2022434,
title = {Visual context learning based on textual knowledge for image–text retrieval},
journal = {Neural Networks},
volume = {152},
pages = {434-449},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001800},
author = {Yuzhuo Qin and Xiaodong Gu and Zhenshan Tan},
keywords = {Image–text retrieval, Knowledge transfer, Visual context learning, Modal alignment},
abstract = {Image–text bidirectional retrieval is a significant task within cross-modal learning field. The main issue lies on the jointly embedding learning and accurately measuring image–text matching score. Most prior works make use of either intra-modality methods performing within two separate modalities or inter-modality ones combining two modalities tightly. However, intra-modality methods remain ambiguous when learning visual context due to the existence of redundant messages. And inter-modality methods increase the complexity of retrieval because of unifying two modalities closely when learning modal features. In this research, we propose an eclectic Visual Context Learning based on Textual knowledge Network (VCLTN), which transfers textual knowledge to visual modality for context learning and decreases the discrepancy of information capacity between two modalities. Specifically, VCLTN merges label semantics into corresponding regional features and employs those labels as intermediaries between images and texts for better modal alignment. Contextual knowledge of those labels learned within textual modality is utilized to guide the visual context learning. Besides, considering the homogeneity within each modality, global features are merged into regional features for assisting in the context learning. In order to alleviate the imbalance of information capacity between images and texts, entities together with relations inside the given caption are extracted and an auxiliary caption is sampled for attaching supplementary messages to textual modality. Experiments performed on Flickr30K and MS-COCO reveal that our model VCLTN achieves best results compared with the state-of-the-art methods.}
}
@article{HAN2022191,
title = {Distantly Supervised Relation Extraction via Recursive Hierarchy-Interactive Attention and Entity-Order Perception},
journal = {Neural Networks},
volume = {152},
pages = {191-200},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001526},
author = {Ridong Han and Tao Peng and Jiayu Han and Hai Cui and Lu Liu},
keywords = {Distant Supervision, Relation Extraction, Relation Hierarchies, Entity Order, Long-tail Relations, Attention},
abstract = {Wrong-labeling problem and long-tail relations severely affect the performance of distantly supervised relation extraction task. Many studies mitigate the effect of wrong-labeling through selective attention mechanism and handle long-tail relations by introducing relation hierarchies to share knowledge. However, almost all existing studies ignore the fact that, in a sentence, the appearance order of two entities contributes to the understanding of its semantics. Furthermore, they only utilize each relation level of relation hierarchies separately, but do not exploit the heuristic effect between relation levels, i.e., higher-level relations can give useful information to the lower ones. Based on the above, in this paper, we design a novel Recursive Hierarchy-Interactive Attention network (RHIA) to further handle long-tail relations, which models the heuristic effect between relation levels. From the top down, it passes relation-related information layer by layer, which is the most significant difference from existing models, and generates relation-augmented sentence representations for each relation level in a recursive structure. Besides, we introduce a newfangled training objective, called Entity-Order Perception (EOP), to make the sentence encoder retain more entity appearance information. Substantial experiments on the popular New York Times (NYT) dataset are conducted. Compared to prior baselines, our RHIA-EOP achieves state-of-the-art performance in terms of precision–recall (P–R) curves, AUC, Top-N precision and other evaluation metrics. Insightful analysis also demonstrates the necessity and effectiveness of each component of RHIA-EOP.}
}
@article{VASIC202234,
title = {MoËT: Mixture of Expert Trees and its application to verifiable reinforcement learning},
journal = {Neural Networks},
volume = {151},
pages = {34-47},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001009},
author = {Marko Vasić and Andrija Petrović and Kaiyuan Wang and Mladen Nikolić and Rishabh Singh and Sarfraz Khurshid},
keywords = {Verification, Deep learning, Reinforcement learning, Mixture of Experts, Explainability},
abstract = {Rapid advancements in deep learning have led to many recent breakthroughs. While deep learning models achieve superior performance, often statistically better than humans, their adoption into safety-critical settings, such as healthcare or self-driving cars is hindered by their inability to provide safety guarantees or to expose the inner workings of the model in a human understandable form. We present MoËT, a novel model based on Mixture of Experts, consisting of decision tree experts and a generalized linear model gating function. Thanks to such gating function the model is more expressive than the standard decision tree. To support non-differentiable decision trees as experts, we formulate a novel training procedure. In addition, we introduce a hard thresholding version, MoËT h, in which predictions are made solely by a single expert chosen via the gating function. Thanks to that property, MoËT h allows each prediction to be easily decomposed into a set of logical rules in a form which can be easily verified. While MoËT is a general use model, we illustrate its power in the reinforcement learning setting. By training MoËT models using an imitation learning procedure on deep RL agents we outperform the previous state-of-the-art technique based on decision trees while preserving the verifiability of the models. Moreover, we show that MoËT can also be used in real-world supervised problems on which it outperforms other verifiable machine learning models.}
}
@article{SINGH2022178,
title = {Think positive: An interpretable neural network for image recognition},
journal = {Neural Networks},
volume = {151},
pages = {178-189},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001125},
author = {Gurmail Singh},
keywords = {CT-scan, Prototypes, COVID-19, Pneumonia, Interpretable},
abstract = {The COVID-19 pandemic is an ongoing pandemic and is placing additional burden on healthcare systems around the world. Timely and effectively detecting the virus can help to reduce the spread of the disease. Although, RT-PCR is still a gold standard for COVID-19 testing, deep learning models to identify the virus from medical images can also be helpful in certain circumstances. In particular, in situations when patients undergo routine X-rays and/or CT-scans tests but within a few days of such tests they develop respiratory complications. Deep learning models can also be used for pre-screening prior to RT-PCR testing. However, the transparency/interpretability of the reasoning process of predictions made by such deep learning models is essential. In this paper, we propose an interpretable deep learning model that uses positive reasoning process to make predictions. We trained and tested our model over the dataset of chest CT-scan images of COVID-19 patients, normal people and pneumonia patients. Our model gives the accuracy, precision, recall and F-score equal to 99.48%, 0.99, 0.99 and 0.99, respectively.}
}
@article{TANIGUCHI2022293,
title = {A whole brain probabilistic generative model: Toward realizing cognitive architectures for developmental robots},
journal = {Neural Networks},
volume = {150},
pages = {293-312},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000673},
author = {Tadahiro Taniguchi and Hiroshi Yamakawa and Takayuki Nagai and Kenji Doya and Masamichi Sakagami and Masahiro Suzuki and Tomoaki Nakamura and Akira Taniguchi},
keywords = {Cognitive architecture, Probabilistic generative model, Brain-inspired artificial intelligence, Artificial general intelligence, Developmental robotics},
abstract = {Building a human-like integrative artificial cognitive system, that is, an artificial general intelligence (AGI), is the holy grail of the artificial intelligence (AI) field. Furthermore, a computational model that enables an artificial system to achieve cognitive development will be an excellent reference for brain and cognitive science. This paper describes an approach to develop a cognitive architecture by integrating elemental cognitive modules to enable the training of the modules as a whole. This approach is based on two ideas: (1) brain-inspired AI, learning human brain architecture to build human-level intelligence, and (2) a probabilistic generative model (PGM)-based cognitive architecture to develop a cognitive system for developmental robots by integrating PGMs. The proposed development framework is called a whole brain PGM (WB-PGM), which differs fundamentally from existing cognitive architectures in that it can learn continuously through a system based on sensory-motor information. In this paper, we describe the rationale for WB-PGM, the current status of PGM-based elemental cognitive modules, their relationship with the human brain, the approach to the integration of the cognitive modules, and future challenges. Our findings can serve as a reference for brain studies. As PGMs describe explicit informational relationships between variables, WB-PGM provides interpretable guidance from computational sciences to brain science. By providing such information, researchers in neuroscience can provide feedback to researchers in AI and robotics on what the current models lack with reference to the brain. Further, it can facilitate collaboration among researchers in neuro-cognitive sciences as well as AI and robotics.}
}
@article{BENIWHIWHU202270,
title = {Context meta-reinforcement learning via neuromodulation},
journal = {Neural Networks},
volume = {152},
pages = {70-79},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001368},
author = {Eseoghene Ben-Iwhiwhu and Jeffery Dick and Nicholas A. Ketz and Praveen K. Pilly and Andrea Soltoggio},
keywords = {Meta-learning, Lifelong-learning, Deep reinforcement learning, Neuromodulation},
abstract = {Meta-reinforcement learning (meta-RL) algorithms enable agents to adapt quickly to tasks from few samples in dynamic environments. Such a feat is achieved through dynamic representations in an agent’s policy network (obtained via reasoning about task context, model parameter updates, or both). However, obtaining rich dynamic representations for fast adaptation beyond simple benchmark problems is challenging due to the burden placed on the policy network to accommodate different policies. This paper addresses the challenge by introducing neuromodulation as a modular component to augment a standard policy network that regulates neuronal activities in order to produce efficient dynamic representations for task adaptation. The proposed extension to the policy network is evaluated across multiple discrete and continuous control environments of increasing complexity. To prove the generality and benefits of the extension in meta-RL, the neuromodulated network was applied to two state-of-the-art meta-RL algorithms (CAVIA and PEARL). The result demonstrates that meta-RL augmented with neuromodulation produces significantly better result and richer dynamic representations in comparison to the baselines.}
}
@article{SOLISPEREZ202244,
title = {Artificial neural networks with conformable transfer function for improving the performance in thermal and environmental processes},
journal = {Neural Networks},
volume = {152},
pages = {44-56},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001484},
author = {J.E. Solís-Pérez and J.A. Hernández and A. Parrales and J.F. Gómez-Aguilar and A. Huicochea},
keywords = {Non-integer transfer function, Multilayer feedforward neural network, Conformable calculus, Thermal processes neural network model, Environmental processes neural network model},
abstract = {This research proposes a novel transfer function based on the hyperbolic tangent and the Khalil conformable exponential function. The non-integer order transfer function offers a suitable neural network configuration because of its ability to adapt. Consequently, this function was introduced into neural network models for three experimental cases: estimating the annular Nusselt number correlation to a helical double-pipe evaporator, the volumetric mass transfer coefficient in an electrochemical reaction, and the thermal efficiency of a solar parabolic trough collector. We found the new transfer function parameters during the training step of the neural networks. Therefore, weights and biases depend on them. We assessed the models applied to the three cases using the determination coefficient, adjusted determination coefficient, and the slope-intercept test. In addition, the MSE for the training set and the whole database were computed to show that there is no overfitting problem. The best-assessed models showed a relationship of 99%, 97%, and 95% with the experimental data for the first, second, and third cases. This novel proposal made reducing the number of neurons in the hidden layer feasible. Therefore, we show a neural network with a conformable transfer function (ANN-CTF) that learns well enough with less available information from the experimental database during its training.}
}
@article{CHANG20221,
title = {Dynamic image clustering from projected coordinates of deep similarity learning},
journal = {Neural Networks},
volume = {152},
pages = {1-16},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.03.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001083},
author = {Jui-Hung Chang and Yin-Chung Leung},
keywords = {Clustering, Neural network, Similarity learning, Dimension reduction, Image processing},
abstract = {Commonly used clustering algorithms typically require user parameters such as the number of clusters to be divided. Density-based algorithms do not have such requirements but are not suitable for high dimensional data. Recent studies have merged the cluster assignment task with deep similarity learning. In this paper, we propose a novel framework to perform dynamic image clustering without prior knowledge of the cluster count. A deep learning model first learns data similarity from scratch, followed by the use of a coordinate learning model to project high dimensional data onto a two-dimensional space. A new clustering algorithm, raster clustering, is proposed to evaluate and classify the projected data. This mechanism can be applied in high dimensional data clustering like image data, and it allows the prediction of unseen data in a consistent way without the need for consolidating with training data.}
}