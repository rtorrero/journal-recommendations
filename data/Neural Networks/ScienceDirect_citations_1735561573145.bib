@article{HE2022303,
title = {Finite-time stability of state-dependent delayed systems and application to coupled neural networks},
journal = {Neural Networks},
volume = {154},
pages = {303-309},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002647},
author = {Xinyi He and Xiaodi Li and Shiji Song},
keywords = {Finite-time stability, State-dependent delay, Coupled neural networks, Lyapunov function, Razumikhin inequality},
abstract = {Finite-time stability and stabilization problems of state-dependent delayed systems are studied in this paper. Different from discrete delays and time-dependent delays which can be well estimated over time, the information of state-dependent delays is usually hard to be estimated, especially when states are unknown or unmeasurable. To guarantee the stability of state-dependent delayed systems in the framework of finite time, a Razumikhin-type inequality is used, following which estimations on the settling time and the region of attraction are proposed. Moreover, the relationship between the variation speed of state-dependent delays and the size of the region of attraction is proposed. Then as an application of the theoretical result, finite-time stabilization is studied for a set of nonlinear coupled neural networks involving state-dependent transmission delay, where the design of memoryless finite-time controllers is addressed. Two numerical examples are given to show the effectiveness of the proposed results.}
}
@article{TAN202264,
title = {Recurrent neural networks as kinematics estimator and controller for redundant manipulators subject to physical constraints},
journal = {Neural Networks},
volume = {153},
pages = {64-75},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001952},
author = {Ning Tan and Peng Yu and Shen Liao and Zhenglong Sun},
keywords = {Kinematics estimator, Model-free, Neurodynamics, Joint limits},
abstract = {Redundant manipulators could be efficient tools in industrial production as a result of their dexterity. However, existing kinematic control methods for redundant manipulators have two main disadvantages. On one hand, model uncertainties or unknown kinematic parameters may degrade the performance of existing model-based control methods subject to joint limits. On the other hand, existing model-free control methods ignore the existence of joint limits although they do not need to know kinematic models of redundant manipulators. In this paper, a quadratic programming (QP) scheme is elaborated to achieve the primary tracking control task of redundant manipulators as well as joint limits avoidance task. Besides, a gradient neurodynamics (GND) model is utilized to estimate the kinematics of redundant manipulators. Then, a primal dual neural network, which is employed to solve the QP problem, and the GND model are integrated towards developing a model-free control method constrained by joint angle and velocity limits for redundant manipulators. The visual sensory feedback is fed to the two neural networks. The efficacy of the proposed control method is demonstrated by extensive simulations and experiments, and the merits of the proposed method are also substantiated by comparisons.}
}
@article{PLATT2022530,
title = {A systematic exploration of reservoir computing for forecasting complex spatiotemporal dynamics},
journal = {Neural Networks},
volume = {153},
pages = {530-552},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002404},
author = {Jason A. Platt and Stephen G. Penny and Timothy A. Smith and Tse-Chun Chen and Henry D.I. Abarbanel},
keywords = {Reservoir computing, Chaotic time series forecasting, Echo-state networks, Nonlinear dynamical systems, Machine learning, Recurrent neural network},
abstract = {A reservoir computer (RC) is a type of recurrent neural network architecture with demonstrated success in the prediction of spatiotemporally chaotic dynamical systems. A further advantage of RC is that it reproduces intrinsic dynamical quantities essential for its incorporation into numerical forecasting routines such as the ensemble Kalman filter—used in numerical weather prediction to compensate for sparse and noisy data. We explore here the architecture and design choices for a “best in class” RC for a number of characteristic dynamical systems. Our analysis points to the importance of large scale parameter optimization. We also note in particular the importance of including input bias in the RC design, which has a significant impact on the forecast skill of the trained RC model. In our tests, the use of a nonlinear readout operator does not affect the forecast time or the stability of the forecast. The effects of the reservoir dimension, spinup time, amount of training data, normalization, noise, and the RC time step are also investigated. Finally, we detail how our investigation leads to optimal design choices for a parallel RC scheme applied to the 40 dimensional spatiotemporally chaotic Lorenz 1996 dynamics.}
}
@article{XIA20221,
title = {Distributed optimized dynamic event-triggered control for unknown heterogeneous nonlinear MASs with input-constrained},
journal = {Neural Networks},
volume = {154},
pages = {1-12},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002489},
author = {Lina Xia and Qing Li and Ruizhuo Song and Shuzhi Sam Ge},
keywords = {Dynamic event-triggered controller, Unknown heterogeneous nonlinear MASs, Critic–actor NNs, Zeno behavior, MIET},
abstract = {The distributed optimized dynamic event-triggered controller is investigated for completely unknown heterogeneous nonlinear multi-agent systems (MASs) on a directed graph subject to input-constrained. First, the distributed observer is designed to estimate the information of the leader for each follower, and a network of the augmented system is constructed by employing the dynamics of the followers and the observers. An identifier with a compensator is designed to approximate the unknown augmented system (agent) with an arbitrarily small identifier error. Then, consider that the input-constrained optimal controller, along with Hamilton–Jacobi–Bellman (HJB) equation, is under pressure to execute in certain systems associated with bottlenecks such as communication and computing burdens. A critic–actor-based optimized dynamic event-triggered controller, which tunes the parameters of critic–actor neural networks (NNs) by the dynamic triggering mechanism, is leveraged to determine the rule of aperiodic sampling and maintain the desired synchronization service. In addition, the existence of a positive minimum inter-event time (MIET) between consecutive events is also proved. Finally, the applications in non-identical nonlinear MAS and 2-DOF robots illustrate the availability of the proposed theoretical results.}
}
@article{ZHAO202268,
title = {BackEISNN: A deep spiking neural network with adaptive self-feedback and balanced excitatory–inhibitory neurons},
journal = {Neural Networks},
volume = {154},
pages = {68-77},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002520},
author = {Dongcheng Zhao and Yi Zeng and Yang Li},
keywords = {Spiking neural networks, Adaptive self-feedback connections, Dynamically balanced excitatory–inhibitory neurons},
abstract = {Spiking neural networks (SNNs) transmit information through discrete spikes that perform well in processing spatial–temporal information. Owing to their nondifferentiable characteristic, difficulties persist in designing SNNs that deliver good performance. SNNs trained with backpropagation have recently exhibited impressive performance by using gradient approximation. However, their performance on complex tasks remains significantly inferior to that of deep neural networks. By taking inspiration from autapses in the brain that connect spiking neurons with a self-feedback connection, we apply adaptive time-delayed self-feedback to the membrane potential to regulate the precision of the spikes. We also strike a balance between the excitatory and inhibitory mechanisms of neurons to dynamically control the output of spiking neurons. By combining these two mechanisms, we propose a deep SNN with adaptive self-feedback and balanced excitatory and inhibitory neurons (BackEISNN). The results of experiments on several standard datasets show that the two modules not only accelerate the convergence of the network but also increase its accuracy. Our model achieved state-of-the-art performance on the MNIST, Fashion-MNIST, and N-MNIST datasets. The proposed BackEISNN also achieved remarkably good performance on the CIFAR10 dataset while using a relatively light structure that competes against state-of-the-art SNNs.}
}
@article{YUN2022104,
title = {Graph Transformer Networks: Learning meta-path graphs to improve GNNs},
journal = {Neural Networks},
volume = {153},
pages = {104-119},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002003},
author = {Seongjun Yun and Minbyul Jeong and Sungdong Yoo and Seunghun Lee and Sean S. Yi and Raehyun Kim and Jaewoo Kang and Hyunwoo J. Kim},
keywords = {Graph Neural Networks, Heterogeneous graphs, Machine learning on graphs, Network analysis},
abstract = {Graph Neural Networks (GNNs) have been widely applied to various fields due to their powerful representations of graph-structured data. Despite the success of GNNs, most existing GNNs are designed to learn node representations on the fixed and homogeneous graphs. The limitations especially become problematic when learning representations on a misspecified graph or a heterogeneous graph that consists of various types of nodes and edges. To address these limitations, we propose Graph Transformer Networks (GTNs) that are capable of generating new graph structures, which preclude noisy connections and include useful connections (e.g., meta-paths) for tasks, while learning effective node representations on the new graphs in an end-to-end fashion. We further propose enhanced version of GTNs, Fast Graph Transformer Networks (FastGTNs), that improve scalability of graph transformations. Compared to GTNs, FastGTNs are up to 230× and 150× faster in inference and training, and use up to 100× and 148× less memory while allowing the identical graph transformations as GTNs. In addition, we extend graph transformations to the semantic proximity of nodes allowing non-local operations beyond meta-paths. Extensive experiments on both homogeneous graphs and heterogeneous graphs show that GTNs and FastGTNs with non-local operations achieve the state-of-the-art performance for node classification tasks. The code is available: https://github.com/seongjunyun/Graph_Transformer_Networks}
}
@article{BRANDMAYR2022310,
title = {Relational local electroencephalography representations for sleep scoring},
journal = {Neural Networks},
volume = {154},
pages = {310-322},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002763},
author = {Georg Brandmayr and Manfred Hartmann and Franz Fürbass and Gerald Matz and Matthias Samwald and Tilmann Kluge and Georg Dorffner},
keywords = {EEG, Relative position attention, Transformer, Context encoding, Sequence learning, REM},
abstract = {Computational sleep scoring from multimodal neurophysiological time-series (polysomnography PSG) has achieved impressive clinical success. Models that use only a single electroencephalographic (EEG) channel from PSG have not yet received the same clinical recognition, since they lack Rapid Eye Movement (REM) scoring quality. The question whether this lack can be remedied at all remains an important one. We conjecture that predominant Long Short-Term Memory (LSTM) models do not adequately represent distant REM EEG segments (termed epochs), since LSTMs compress these to a fixed-size vector from separate past and future sequences. To this end, we introduce the EEG representation model ENGELBERT (electroEncephaloGraphic Epoch Local Bidirectional Encoder Representations from Transformer). It jointly attends to multiple EEG epochs from both past and future. Compared to typical token sequences in language, for which attention models have originally been conceived, overnight EEG sequences easily span more than 1000 30 s epochs. Local attention on overlapping windows reduces the critical quadratic computational complexity to linear, enabling versatile sub-one-hour to all-day scoring. ENGELBERT is at least one order of magnitude smaller than established LSTM models and is easy to train from scratch in a single phase. It surpassed state-of-the-art macro F1-scores in 3 single-EEG sleep scoring experiments. REM F1-scores were pushed to at least 86%. ENGELBERT virtually closed the gap to PSG-based methods from 4–5 percentage points (pp) to less than 1 pp F1-score.}
}
@article{DALBELLO2022349,
title = {Computational role of exploration noise in error-based de novo motor learning},
journal = {Neural Networks},
volume = {153},
pages = {349-372},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002246},
author = {Lucas Rebelo Dal’Bello and Jun Izawa},
keywords = {Motor learning, Exploration, Sensitivity derivative, Computational model, Redundancy, Error-based learning},
abstract = {The redundancy inherent to the human body is a central problem that must be solved by the brain when acquiring new motor skills. The problem of redundancy becomes particularly critical when learning a new motor policy from scratch in a novel environment and task (i.e., de novo learning). It has been proposed that motor variability could be leveraged to explore and identify task-potent motor commands, and recent results indicated a possible role of motor exploration in error-based motor learning, including in de novo learning tasks. However, the precise computational mechanisms underlying this role remain poorly understood. A new controller in a de novo motor task can potentially be learned by first using motor exploration to learn a sensitivity derivative, which can transform observed task errors into motor corrections, enabling the error-based learning of the controller. Although this approach has been discussed, the computational properties of exploration and how this mechanism can explain recent reports of motor exploration in error-based de-novo learning have not been thoroughly examined. Here, we used this approach to simulate the tasks used in several recent studies of human motor learning tasks in which motor exploration was observed, and replicating their main results. Analyses of the proposed learning mechanism using equations and simulations suggested that exploring the entire motor command space leads to the training of an efficient sensitivity derivative, enabling rapid learning of the controller, in visuomotor adaptation and de novo tasks. The successful replication of previous experimental results elucidated the role of motor exploration in motor learning.}
}
@article{SALHAGALVAN2022474,
title = {Modularity-aware graph autoencoders for joint community detection and link prediction},
journal = {Neural Networks},
volume = {153},
pages = {474-495},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002362},
author = {Guillaume Salha-Galvan and Johannes F. Lutzeyer and George Dasoulas and Romain Hennequin and Michalis Vazirgiannis},
keywords = {Graph autoencoders, Node embedding, Modularity, Graph neural networks, Link prediction, Community detection},
abstract = {Graph autoencoders (GAE) and variational graph autoencoders (VGAE) emerged as powerful methods for link prediction. Their performances are less impressive on community detection problems where, according to recent and concurring experimental evaluations, they are often outperformed by simpler alternatives such as the Louvain method. It is currently still unclear to which extent one can improve community detection with GAE and VGAE, especially in the absence of node features. It is moreover uncertain whether one could do so while simultaneously preserving good performances on link prediction. In this paper, we show that jointly addressing these two tasks with high accuracy is possible. For this purpose, we introduce and theoretically study a community-preserving message passing scheme, doping our GAE and VGAE encoders by considering both the initial graph structure and modularity-based prior communities when computing embedding spaces. We also propose novel training and optimization strategies, including the introduction of a modularity-inspired regularizer complementing the existing reconstruction losses for joint link prediction and community detection. We demonstrate the empirical effectiveness of our approach, referred to as Modularity-Aware GAE and VGAE, through in-depth experimental validation on various real-world graphs.}
}
@article{LI2022287,
title = {Unsupervised robust discriminative subspace representation based on discriminative approximate isometric embedding},
journal = {Neural Networks},
volume = {155},
pages = {287-307},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002088},
author = {Jianwei Li},
keywords = {Subspace representation, Dimensionality reduction, Discriminative approximate isometric embedding, Johnson–Lindenstrauss theorem, Laplacian rank, Unsupervised learning},
abstract = {Subspace learning has shown a tremendous potential in the fields of machine learning and computer vision due to its effectiveness. Subspace representation is a key subspace learning method that encodes subspace membership information. To effectively encode the subspace memberships of data, some structured prior constraints are imposed on the subspace representation, such as low-rank, sparse, and so on. To handle various noises, existing methods tend to separate a specific type of noise using a specific way to obtain robust subspace representation. When encountering diversified noises, their subspace-preserving property may not be guaranteed. To address this issue, we propose a novel unsupervised robust discriminative subspace representation to mitigate the impacts of diversified noises via discriminative approximate isometric embedding, rather than directly separating noises from the high-dimensional space, as done like the existing methods. To ensure the performance of our approach, we provide a crucial theorem, termed as noisy Johnson–Lindenstrauss theorem. Meanwhile, Laplacian rank constraint is imposed on the discriminative subspace representation to uncover the ground truth subspace memberships of noisy data and improve the graph connectivity of subspaces. Extensive experiments on several benchmark datasets and two large-scale datasets validate the effectiveness and robustness of our approach with respect to diversified noises.}
}
@article{WAN202278,
title = {AdjointBackMap: Reconstructing effective decision hypersurfaces from CNN layers using adjoint operators},
journal = {Neural Networks},
volume = {154},
pages = {78-98},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002519},
author = {Qing Wan and Yoonsuck Choe},
keywords = {Adjoint operator, Theory of Neural Networks, Computer vision},
abstract = {There are several methods in the exploration of Convolutional Neural Networks’ (CNNs’) inner workings. However, in general, finding the inverse of the function performed by CNNs as a whole is an ill-posed problem. In this paper, we propose a method based on adjoint operators to reconstruct, given an arbitrary unit in the CNN (except for the first convolutional layer), its effective hypersurface in the input space. Since the reconstructed hyperplane (each point on the hypersurface) resides in the input space, we can easily visualize it. Our results show that the reconstructed hyperplane, when multiplied by the original input image, would give nearly the exact output value of that unit. We find that the CNN unit’s decision process is largely conditioned on the input, and the corresponding reconstructed hypersurfaces are highly sensitive to adversarial noise, thus providing insights on why CNNs are susceptible to adversarial attack.}
}
@article{CHE2022255,
title = {Sparse signal reconstruction via collaborative neurodynamic optimization},
journal = {Neural Networks},
volume = {154},
pages = {255-269},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200274X},
author = {Hangjun Che and Jun Wang and Andrzej Cichocki},
keywords = {Sparse signal reconstruction, Sparsity maximization, -ratio surrogate function, Collaborative neurodynamic optimization},
abstract = {In this paper, we formulate a mixed-integer problem for sparse signal reconstruction and reformulate it as a global optimization problem with a surrogate objective function subject to underdetermined linear equations. We propose a sparse signal reconstruction method based on collaborative neurodynamic optimization with multiple recurrent neural networks for scattered searches and a particle swarm optimization rule for repeated repositioning. We elaborate on experimental results to demonstrate the outperformance of the proposed approach against ten state-of-the-art algorithms for sparse signal reconstruction.}
}
@article{CHAMPION2022450,
title = {Branching time active inference: Empirical study and complexity class analysis},
journal = {Neural Networks},
volume = {152},
pages = {450-466},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001824},
author = {Théophile Champion and Howard Bowman and Marek Grześ},
keywords = {Active inference, Variational message passing, Tree search, Planning, Free energy principle},
abstract = {Active inference is a state-of-the-art framework for modelling the brain that explains a wide range of mechanisms such as habit formation, dopaminergic discharge and curiosity. However, recent implementations suffer from an exponential (space and time) complexity class when computing the prior over all the possible policies up to the time horizon. Fountas et al. (2020) used Monte Carlo tree search to address this problem, leading to very good results in two different tasks. Additionally, Champion et al. (2021a) proposed a tree search approach based on (temporal) structure learning. This was enabled by the development of a variational message passing approach to active inference (Champion, Bowman, Grześ, 2021), which enables compositional construction of Bayesian networks for active inference. However, this message passing tree search approach, which we call branching-time active inference (BTAI), has never been tested empirically. In this paper, we present an experimental study of the approach (Champion, Grześ, Bowman, 2021) in the context of a maze solving agent. In this context, we show that both improved prior preferences and deeper search help mitigate the vulnerability to local minima. Then, we compare BTAI to standard active inference (AcI) on a graph navigation task. We show that for small graphs, both BTAI and AcI successfully solve the task. For larger graphs, AcI exhibits an exponential (space) complexity class, making the approach intractable. However, BTAI explores the space of policies more efficiently, successfully scaling to larger graphs. Then, BTAI was compared to the POMCP algorithm (Silver and Veness, 2010) on the frozen lake environment. The experiments suggest that BTAI and the POMCP algorithm accumulate a similar amount of reward. Also, we describe when BTAI receives more rewards than the POMCP agent, and when the opposite is true. Finally, we compared BTAI to the approach of Fountas et al. (2020) on the dSprites dataset, and we discussed the pros and cons of each approach.}
}
@article{PEI2022508,
title = {A portable clustering algorithm based on compact neighbors for face tagging},
journal = {Neural Networks},
volume = {154},
pages = {508-520},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002878},
author = {Shenfei Pei and Yuze Zhang and Rong Wang and Feiping Nie},
keywords = {Fast clustering, Unsupervised, Scalability, Compact neighbors},
abstract = {We focus on the following problem: Given a collection of unlabeled facial images, group them into the individual identities where the number of subjects is not known. To this end, a Portable clustering algorithm based on Compact Neighbors called PCN is proposed. (1) Benefiting from the compact neighbor, the local density of each sample can be determined automatically and only one user-specified parameter, the number of nearest neighbors k, is involved in our model. (2) More importantly, the performance of PCN is not sensitive to the number of nearest neighbors. Therefore this parameter is relatively easy to determine in practical applications. (3) The computational overhead of PCN is O(nk(k2+log(nk))) that is nearly linear with respect to the number of samples, which means it is easily scalable to large-scale problems. In order to verify the effectiveness of PCN on the face clustering problem, extensive experiments based on a two-stage framework (extracting features using a deep model and performing clustering in the feature space) have been conducted on 16 middle- and 5 large-scale benchmark datasets. The experimental results have shown the efficiency and effectiveness of the proposed algorithm, compared with state-of-the-art methods. [code]}
}
@article{MAUS2022383,
title = {Estimating heading from optic flow: Comparing deep learning network and human performance},
journal = {Neural Networks},
volume = {154},
pages = {383-396},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002635},
author = {Natalie Maus and Oliver W. Layton},
keywords = {Optic flow, Deep learning, Heading, Vision, Self-motion},
abstract = {Convolutional neural networks (CNNs) have made significant advances over the past decade with visual recognition, matching or exceeding human performance on certain tasks. Visual recognition is subserved by the ventral stream of the visual system, which, remarkably, CNNs also effectively model. Inspired by this connection, we investigated the extent to which CNNs account for human heading perception, an important function of the complementary dorsal stream. Heading refers to the direction of movement during self-motion, which humans judge with high degrees of accuracy from the streaming pattern of motion on the eye known as optic flow. We examined the accuracy with which CNNs estimate heading from optic flow in a range of situations in which human heading perception has been well studied. These scenarios include heading estimation from sparse optic flow, in the presence of moving objects, and in the presence of rotation. We assessed performance under controlled conditions wherein self-motion was simulated through minimal or realistic scenes. We found that the CNN did not capture the accuracy of heading perception. The addition of recurrent processing to the network, however, closed the gap in performance with humans substantially in many situations. Our work highlights important self-motion scenarios in which recurrent processing supports heading estimation that approaches human-like accuracy.}
}
@article{LI2022142,
title = {Boolean matrix factorization based on collaborative neurodynamic optimization with Boltzmann machines},
journal = {Neural Networks},
volume = {153},
pages = {142-151},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002118},
author = {Xinqi Li and Jun Wang and Sam Kwong},
keywords = {Boolean matrix factorization, Collaborative neurodynamic optimization, Boltzmann machines},
abstract = {This paper presents a collaborative neurodynamic approach to Boolean matrix factorization. Based on a binary optimization formulation to minimize the Hamming distance between a given data matrix and its low-rank reconstruction, the proposed approach employs a population of Boltzmann machines operating concurrently for scatter search of factorization solutions. In addition, a particle swarm optimization rule is used to re-initialize the neuronal states of Boltzmann machines upon their local convergence to escape from local minima toward global solutions. Experimental results demonstrate the superior convergence and performance of the proposed approach against six baseline methods on ten benchmark datasets.}
}
@article{GU202249,
title = {Approximation properties of Gaussian-binary restricted Boltzmann machines and Gaussian-binary deep belief networks},
journal = {Neural Networks},
volume = {153},
pages = {49-63},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001940},
author = {Linyan Gu and Lihua Yang and Feng Zhou},
keywords = {Approximation theory, Gaussian-binary restricted Boltzmann machines, Gaussian-binary deep belief networks, Feedforward neural network},
abstract = {Despite the successful use of Gaussian-binary restricted Boltzmann machines (GB-RBMs) and Gaussian-binary deep belief networks (GB-DBNs), little is known about their theoretical approximation capabilities to represent distributions of continuous random variables. In this paper, we address the expressive properties of GB-RBMs and GB-DBNs, contributing theoretical insights to the optimal number of hidden variables. We first treat the GB-RBM’s unnormalized log-likelihood as a sum of a special two-layer feedforward neural network and a negative quadratic term. Then, a series of simulation results are established, which can be used to relate GB-RBMs to general two-layer feedforward neural networks whose expressive properties are much better understood. On this basis, we show that a two-layer ReLU network with all weights in the second layer being 1, along with a negative quadratic term, can approximate all continuous functions. In addition, we provide qualified lower bounds for the number of hidden variables of GB-RBMs required to approximate distributions whose log-likelihood are given by some classes of smooth functions. Moreover, we further study the universal approximation of GB-DBNs with two hidden layers by providing a sufficient number of hidden variables O(ɛ−2) that are guaranteed to approximate any given strictly positive continuous distribution within a given error ɛ. Finally, numerical experiments are carried out to verify some of the proposed theoretical results.}
}
@article{WANG2022131,
title = {Novel optimal trajectory tracking for nonlinear affine systems with an advanced critic learning structure},
journal = {Neural Networks},
volume = {154},
pages = {131-140},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002751},
author = {Ding Wang and Huiling Zhao and Mingming Zhao and Jin Ren},
keywords = {Discount factor, Dual heuristic dynamic programming, Neural networks, Optimal tracking control, Polynomial, Value iteration},
abstract = {In this paper, a critic learning structure based on the novel utility function is developed to solve the optimal tracking control problem with the discount factor of affine nonlinear systems. The utility function is defined as the quadratic form of the error at the next moment, which can not only avoid solving the stable control input, but also effectively eliminate the tracking error. Next, the theoretical derivation of the method under value iteration is given in detail with convergence and stability analysis. Then, the dual heuristic dynamic programming (DHP) algorithm via a single neural network is introduced to reduce the amount of computation. The polynomial is used to approximate the costate function during the DHP implementation. The weighted residual method is used to update the weight matrix. During simulation, the convergence speed of the given strategy is compared with the heuristic dynamic programming (HDP) algorithm. The experiment results display that the convergence speed of the proposed method is faster than the HDP algorithm. Besides, the proposed method is compared with the traditional tracking control approach to verify its tracking performance. The experiment results show that the proposed method can avoid solving the stable control input, and the tracking error is closer to zero than the traditional strategy.}
}
@article{LEE2022455,
title = {Using source data to aid and build variational state–space autoencoders with sparse target data for process monitoring},
journal = {Neural Networks},
volume = {154},
pages = {455-468},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002234},
author = {Yi Shan Lee and Junghui Chen},
keywords = {Gaussian mixture model, Multigrade-process, Process dynamics, Process monitoring, Sparse data, Variational autoencoder},
abstract = {In industrial processes, different operating conditions and ratios of ingredients are used to produce multi-grade products in the same production line. Yet, the production grade changes so quickly as the demand from customers varies from time to time. As a result, the process data collected in certain operating regions are often scarce. Process dynamics, nonlinearity, and process uncertainty increase the hardship in developing a reliable model to monitor the process status. In this paper, the source-aided variational state–space autoencoder (SA-VSSAE) is proposed. It integrates variational state–space autoencoder with the Gaussian mixture. With the additional information from the source grades, SA-VSSAE can be used for monitoring processes with sparse target data by performing information sharing to enhance the reliability of the target model. Unlike the past works which perform information sharing and modeling in a two-step procedure, the proposed model is designed for information sharing and modeling in a one-step procedure without causing information loss. In contrast to the traditional state–space model, which is linear and deterministic, the variational state–space autoencoder (VSSAE) extracts the dynamic and nonlinear features in the process variables using neural networks. Also, by taking process uncertainty into consideration, VSSAE describes the features in a probabilistic form. Probability density estimates of the residual and latent variables are given to design the monitoring indices for fault detection. A numerical example and an industrial polyvinyl chloride drying process are presented to show the advantages of the proposed method over the comparative methods.}
}
@article{THOMPSON2022425,
title = {Predictions on multi-class terminal ballistics datasets using conditional Generative Adversarial Networks},
journal = {Neural Networks},
volume = {154},
pages = {425-440},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002994},
author = {S. Thompson and F. Teixeira-Dias and M. Paulino and A. Hamilton},
keywords = {Machine learning, Multi-Layer Perceptron (MLP), Conditional Generative Adversarial Networks (cGAN), Terminal ballistics, Armour systems, Multi-class dataset},
abstract = {Ballistic impacts are a primary risk in both civil and military defence applications, where successfully predicting the dynamic response of a material or structure to impact crucial to the design of safe and fit-for-purpose protective structures. This study proposes a conditional Generative Adversarial Network (cGAN) architecture that can learn directly from available ballistic data and can be conditioned on additional information, such as class labels, to govern its output. A single Multi-Layer Perceptron (MLP) cGAN architecture is trained on a multi-class ballistic training set consisting of 10 classes labelled 0−9 where each class refers to a ballistic curve with a different ballistic limit velocity, vbl. A total of 5 models are trained on datasets consisting of 5, 10, 15, 20 and 25 samples within each class. For integer class labels 0−9, all cGAN models successfully predict the vbl with a maximum error of 4.12%. Additionally, for non-integer class labels between 0−9 the vbl predictions are similar despite not explicitly appearing in the training set. Moreover, each cGAN model is challenged to generate new samples for class labels that exist beyond the scope of the training set for class labels between 9−20. Four of the models predict the vbl with an error of less than 1.5% in all cases. This study showcases how a cGAN model can learn directly from a multi-class ballistic dataset and generate additional samples representative of that data for classes that do not appear explicitly in the training set.}
}
@article{KEISHAM2022518,
title = {Online action proposal generation using spatio-temporal attention network},
journal = {Neural Networks},
volume = {153},
pages = {518-529},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002477},
author = {Kanchan Keisham and Amin Jalali and Minho Lee},
keywords = {Temporal action proposal, Action detection, Spatial attention, Temporal attention},
abstract = {Temporal action proposal generation aims to generate temporal boundaries containing action instances. In real-time applications such as surveillance cameras, autonomous driving, and traffic monitoring, the online localization and recognition of human activities occurring in short temporal intervals are important areas of research. Existing approaches of temporal action proposal generation consider only the offline and frame-level feature aggregation along the temporal dimension. Those offline methods also generate many redundant irrelevant proposal regions in the frames as temporal boundaries. This leads to higher computational cost along with slow processing speed which is not suitable for online tasks. In this study, we propose a novel spatio-temporal attention network for online action proposal generation as opposed to existing offline proposal generation methods. Our novel proposed approach incorporates the inter-dependency between the spatial and temporal context information of each incoming video clip to generate more relevant online temporal action proposals. First, we propose a windowed spatial attention module to capture the inter-spatial relationship between the features of incoming frames. The windowed spatial network produces more robust clip-level feature representation and efficiently deals with noisy features such as occlusion or background scenes. Second, we introduce a temporal attention module to capture relevant temporal dynamic information mutually to the localized spatial information to model the long inter-frame temporal relationship since most online real life videos are untrimmed in nature. By applying these two attention modules sequentially, the novel proposed spatio-temporal network model is able to generate precise action boundaries at a particular instant of time. In addition, the model generates fewer discriminative temporal action proposals while maintaining a low computational cost and high processing speed suitable for online settings.}
}
@article{LEADHOLM2022258,
title = {Hierarchical binding in convolutional neural networks: Making adversarial attacks geometrically challenging},
journal = {Neural Networks},
volume = {155},
pages = {258-286},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002593},
author = {Niels Leadholm and Simon Stringer},
keywords = {Adversarial examples, Robust representations, Feature binding, Robust vision},
abstract = {We approach the issue of robust machine vision by presenting a novel deep-learning architecture, inspired by work in theoretical neuroscience on how the primate brain performs visual feature binding. Feature binding describes how separately represented features are encoded in a relationally meaningful way, such as an edge composing part of the larger contour of an object. We propose that the absence of such representations from current models might partly explain their vulnerability to small, often humanly-imperceptible distortions known as adversarial examples. It has been proposed that adversarial examples are a result of ‘off-manifold’ perturbations of images. Our novel architecture is designed to approximate hierarchical feature binding, providing explicit representations in these otherwise vulnerable directions. Having introduced these representations into convolutional neural networks, we provide empirical evidence of enhanced robustness against a broad range of L0, L2 and L∞ attacks, particularly in the black-box setting. While we eventually report that the model remains vulnerable to a sufficiently powerful attacker (i.e. the defense can be broken), we demonstrate that our main results cannot be accounted for by trivial, false robustness (gradient masking). Analysis of the representational geometry of our architectures shows a positive relationship between hierarchical binding, expanded manifolds, and robustness. Through hyperparameter manipulation, we find evidence that robustness emerges through the preservation of general low-level information alongside more abstract features, rather than by capturing which specific low-level features drove the abstract representation. Finally, we propose how hierarchical binding relates to the observation that, under appropriate viewing conditions, humans show sensitivity to adversarial examples.}
}
@article{ZHENG2022192,
title = {Fixed-time synchronization of discontinuous competitive neural networks with time-varying delays},
journal = {Neural Networks},
volume = {153},
pages = {192-203},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002076},
author = {Caicai Zheng and Cheng Hu and Juan Yu and Haijun Jiang},
keywords = {Competitive neural network, Fixed-time synchronization, Discontinuous activation, Time-varying delay},
abstract = {In this article, the fixed-time (FXT) synchronization of discontinuous competitive neural networks (CNNs) involving time-varying delays is investigated. Firstly, two kinds of discontinuous FXT control schemes are proposed and two forms of Lyapunov function are constructed based on p-norm and 1-norm to discuss the FXT synchronization of CNNs. By means of nonsmooth analysis and some inequality techniques, some simple criteria are obtained to achieve FXT synchronization and the upper bound of the settling time with less conservativeness is provided. Furthermore, the effect of time scale on FXT synchronization of CNNs is considered. Lastly, some numerical results for an example are provided to demonstrate the derived theoretical results.}
}
@article{ROBERTAZZI2022283,
title = {Brain-inspired meta-reinforcement learning cognitive control in conflictual inhibition decision-making task for artificial agents},
journal = {Neural Networks},
volume = {154},
pages = {283-302},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002350},
author = {Federica Robertazzi and Matteo Vissani and Guido Schillaci and Egidio Falotico},
keywords = {Meta-learning, Brain-inspired modeling, Inhibition cognitive control, Basal ganglia, Prefrontal cortex},
abstract = {Conflictual cues and unexpected changes in human real-case scenarios may be detrimental to the execution of tasks by artificial agents, thus affecting their performance. Meta-learning applied to reinforcement learning may enhance the design of control algorithms, where an outer learning system progressively adjusts the operation of an inner learning system, leading to practical benefits for the learning schema. Here, we developed a brain-inspired meta-learning framework for inhibition cognitive control that i) exploits the meta-learning principles in the neuromodulation theory proposed by Doya, ii) relies on a well-established neural architecture that contains distributed learning systems in the human brain, and iii) proposes optimization rules of meta-learning hyperparameters that mimic the dynamics of the major neurotransmitters in the brain. We tested an artificial agent in inhibiting the action command in two well-known tasks described in the literature: NoGo and Stop-Signal Paradigms. After a short learning phase, the artificial agent learned to react to the hold signal, and hence to successfully inhibit the motor command in both tasks, via the continuous adjustment of the learning hyperparameters. We found a significant increase in global accuracy, right inhibition, and a reduction in the latency time required to cancel the action process, i.e., the Stop-signal reaction time. We also performed a sensitivity analysis to evaluate the behavioral effects of the meta-parameters, focusing on the serotoninergic modulation of the dopamine release. We demonstrated that brain-inspired principles can be integrated into artificial agents to achieve more flexible behavior when conflictual inhibitory signals are present in the environment.}
}
@article{HONG2022397,
title = {Return of the normal distribution: Flexible deep continual learning with variational auto-encoders},
journal = {Neural Networks},
volume = {154},
pages = {397-412},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002702},
author = {Yongwon Hong and Martin Mundt and Sungho Park and Yungjung Uh and Hyeran Byun},
keywords = {Continual learning, Lifelong learning, Variational auto-encoder},
abstract = {Learning continually from sequentially arriving data has been a long standing challenge in machine learning. An emergent body of deep learning literature suggests various solutions, through introduction of significant simplifications to the problem statement. As a consequence of a growing focus on particular tasks and their respective benchmark assumptions, these efforts are thus becoming increasingly tailored to specific settings. Whereas approaches that leverage Variational Bayesian techniques seem to provide a more general perspective of key continual learning mechanisms, they however entail their own caveats. Inspired by prior theoretical work on solving the prevalent mismatch between prior and aggregate posterior in deep generative models, we return to a generic variational auto-encoder based formulation and investigate its utility for continual learning. Specifically, we propose to adapt a two-stage training framework towards a context conditioned variant for continual learning, where we then formulate mechanisms to alleviate catastrophic forgetting through choices of generative rehearsal or well-motivated extraction of data exemplar subsets. Although the proposed generic two-stage variational auto-encoder is not tailored towards a particular task and allows for flexible amounts of supervision, we empirically demonstrate it to surpass task-tailored methods in both supervised classification, as well as unsupervised representation learning.}
}
@article{YU2022314,
title = {Online subspace learning and imputation by Tensor-Ring decomposition},
journal = {Neural Networks},
volume = {153},
pages = {314-324},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001976},
author = {Jinshi Yu and Tao Zou and Guoxu Zhou},
keywords = {Online tensor completion, Streaming data, Tensor ring decomposition, Low rank},
abstract = {This paper considers the completion problem of a partially observed high-order streaming data, which is cast as an online low-rank tensor completion problem. Though the online low-rank tensor completion problem has drawn lots of attention in recent years, most of them are designed based on the traditional decomposition method, such as CP and Tucker. Inspired by the advantages of Tensor Ring decomposition over the traditional decompositions in expressing high-order data and its superiority in missing values estimation, this paper proposes two online subspace learning and imputation methods based on Tensor Ring decomposition. Specifically, we first propose an online Tensor Ring subspace learning and imputation model by formulating an exponentially weighted least squares with Frobenium norm regularization of TR-cores. Then, two commonly used optimization algorithms, i.e. alternating recursive least squares and stochastic-gradient algorithms, are developed to solve the proposed model. Numerical experiments show that the proposed methods are more effective to exploit the time-varying subspace in comparison with the conventional Tensor Ring completion methods. Besides, the proposed methods are demonstrated to be superior to obtain better results than state-of-the-art online methods in streaming data completion under varying missing ratios and noise.}
}
@article{UTKIN2022346,
title = {Attention-based random forest and contamination model},
journal = {Neural Networks},
volume = {154},
pages = {346-359},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002945},
author = {Lev V. Utkin and Andrei V. Konstantinov},
keywords = {Attention mechanism, Random forest, Nadaraya-Watson regression, Quadratic programming, Contamination model},
abstract = {A new approach called ABRF (the attention-based random forest) and its modifications for applying the attention mechanism to the random forest (RF) for regression and classification are proposed. The main idea behind the proposed ABRF models is to assign attention weights with trainable parameters to decision trees in a specific way. The attention weights depend on the distance between an instance, which falls into a corresponding leaf of a tree, and training instances, which fall in the same leaf. This idea stems from representation of the Nadaraya–Watson kernel regression in the form of a RF. Three modifications of the general approach are proposed. The first one is based on applying the Huber’s contamination model and on computing the attention weights by solving quadratic or linear optimization problems. The second and the third modifications use the gradient-based algorithms for computing an extended set of the attention trainable parameters. Numerical experiments with various regression and classification datasets illustrate the proposed method. The code implementing the approach is publicly available.}
}
@article{KODAMA2022444,
title = {Dimensionality of the intermediate-level representation of shape and texture in monkey V4},
journal = {Neural Networks},
volume = {153},
pages = {444-449},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002428},
author = {Atsushi Kodama and Kouji Kimura and Ko Sakai},
keywords = {Visual cortex, V4, Dimensionality, Representation, Natural images},
abstract = {The visual area V4 has been considered to play a crucial role in the intermediate representation of objects, where low-level image features are transformed into object-level representations. We estimated the intrinsic dimensionality in V4 for the representation of local patches generated from natural scenes. The dimensionality was approximately 40, which is approximately half of that reported in IT for the representation of whole natural objects. The analyses of the estimated dimensionality suggest both common and independent representations that code contour shapes and/or surfaces with textures, implying a relatively complex and mixed representation in the intermediate-level area.}
}
@article{TANG202243,
title = {Periodic event-triggered adaptive tracking control design for nonlinear discrete-time systems via reinforcement learning},
journal = {Neural Networks},
volume = {154},
pages = {43-55},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.039},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002544},
author = {Fanghua Tang and Ben Niu and Guangdeng Zong and Xudong Zhao and Ning Xu},
keywords = {Periodic event-triggered mechanism, Reinforcement learning (RL), Neural networks (NNs), Discrete-time systems},
abstract = {In this paper, an event-triggered control scheme with periodic characteristic is developed for nonlinear discrete-time systems under an actor–critic architecture of reinforcement learning (RL). The periodic event-triggered mechanism (ETM) is constructed to decide whether the sampling data are delivered to controllers or not. Meanwhile, the controller is updated only when the event-triggered condition deviates from a prescribed threshold. Compared with traditional continuous ETMs, the proposed periodic ETM can guarantee a minimal lower bound of the inter-event intervals and avoid sampling calculation point-to-point, which means that the partial communication resources can be efficiently economized. The critic and actor neural networks (NNs), consisting of radial basis function neural networks (RBFNNs), aim to approximate the unknown long-term performance index function and the ideal event-triggered controller, respectively. A rigorous stability analysis based on the Lyapunov difference method is provided to substantiate that the closed-loop system can be stabilized. All error signals of the closed-loop system are uniformly ultimately bounded (UUB) under the guidance of the proposed control scheme. Finally, two simulation examples are given to validate the effectiveness of the control design.}
}
@article{MARCIANO2022164,
title = {Quantum Neural Networks and Topological Quantum Field Theories},
journal = {Neural Networks},
volume = {153},
pages = {164-178},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002027},
author = {Antonino Marcianò and Deen Chen and Filippo Fabrocini and Chris Fields and Enrico Greco and Niels Gresnigt and Krid Jinklub and Matteo Lulli and Kostas Terzidis and Emanuele Zappala},
keywords = {Topological quantum field theory, Topological quantum neural networks, Graph neural networks, Quantum amplitude classifiers, Quantum perceptron},
abstract = {Our work intends to show that: (1) Quantum Neural Networks (QNNs) can be mapped onto spin-networks, with the consequence that the level of analysis of their operation can be carried out on the side of Topological Quantum Field Theory (TQFT); (2) A number of Machine Learning (ML) key-concepts can be rephrased by using the terminology of TQFT. Our framework provides as well a working hypothesis for understanding the generalization behavior of DNNs, relating it to the topological features of the graph structures involved.}
}
@article{XU2022242,
title = {LS-NTP: Unifying long- and short-range spatial correlations for near-surface temperature prediction},
journal = {Neural Networks},
volume = {155},
pages = {242-257},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002787},
author = {Guangning Xu and Xutao Li and Shanshan Feng and Yunming Ye and Zhihua Tu and Kenghong Lin and Zhichao Huang},
keywords = {temperature prediction, Near-surface temperature, Long-range, Short-range, Spatial–temporal, CNN, GCN},
abstract = {The near-surface temperature prediction (NTP) is an important spatial–temporal forecast problem, which can be used to prevent temperature crises. Most of the previous approaches fail to explicitly model the long- and short-range spatial correlations simultaneously, which is critical to making an accurate temperature prediction. In this study, both long- and short-range spatial correlations are captured to fill this gap by a novel convolution operator named Long- and Short-range Convolution (LS-Conv). The proposed LS-Conv operator includes three key components, namely, Node-based Spatial Attention (NSA), Long-range Adaptive Graph Constructor (LAGC), and Long- and Short-range Integrator (LSI). To capture long-range spatial correlations, NSA and LAGC are proposed to evaluate node importance aiming at auto-constructing long-range spatial correlations, which is named as Long-range aware Graph Convolution Network (LR-GCN). After that, the Short-range aware Convolution Neural Network (SR-CNN) accounts for the short-range spatial correlations. Finally, LSI is proposed to capture both long- and short-range spatial correlations by intra-unifying LR-GCN and SR-CNN. Upon the proposed LS-Conv operator, a new model called Long- and Short-range for NPT (LS-NTP) is developed. Extensive experiments are conducted on two real-world datasets and the results demonstrate that the proposed method outperforms state-of-the-art techniques. The source code is available on GitHub:https://github.com/xuguangning1218/LS_NTP.}
}
@article{ALFALOUJI2022303,
title = {Reframing control methods for parameters optimization in adversarial image generation},
journal = {Neural Networks},
volume = {153},
pages = {303-313},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002301},
author = {Qamar Alfalouji and Piergiorgio Sartor and Pietro Zanuttigh},
keywords = {Hyper-parameters optimization, GAN, Control methods},
abstract = {Training procedures for deep networks require the setting of several hyper-parameters that strongly affect the obtained results. The problem is even worse in adversarial learning strategies used for image generation where a proper balancing of the discriminative and generative networks is fundamental for an effective training. In this work we propose a novel hyper-parameters optimization strategy based on the use of Proportional–Integral (PI) and Proportional–Integral–Derivative (PID) controllers. Both open loop and closed loop schemes for the tuning of a single parameter or of multiple parameters together are proposed allowing an efficient parameter tuning without resorting to computationally demanding trial-and-error schemes. We applied the proposed strategies to the widely used BEGAN and CycleGAN models: They allowed to achieve a more stable training that converges faster. The obtained images are also sharper with a slightly better quality both visually and according to the FID and FCN metrics. Image translation results also showed better background preservation and less color artifacts with respect to CycleGAN.}
}
@article{LEUNG2022399,
title = {Cardinality-constrained portfolio selection via two-timescale duplex neurodynamic optimization},
journal = {Neural Networks},
volume = {153},
pages = {399-410},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002386},
author = {Man-Fai Leung and Jun Wang and Hangjun Che},
keywords = {Neurodynamic optimization, Portfolio selection, Cardinality constraints},
abstract = {This paper addresses portfolio selection based on neurodynamic optimization. The portfolio selection problem is formulated as a biconvex optimization problem with a variable weight in the Markowitz risk–return framework. In addition, the cardinality-constrained portfolio selection problem is formulated as a mixed-integer optimization problem and reformulated as a biconvex optimization problem. A two-timescale duplex neurodynamic approach is customized and applied for solving the reformulated portfolio optimization problem. In the two-timescale duplex neurodynamic approach, two recurrent neural networks operating at two timescales are employed for local searches, and their neuronal states are reinitialized upon local convergence using a particle swarm optimization rule to escape from local optima toward global ones. Experimental results on four datasets of world stock markets are elaborated to demonstrate the superior performance of the neurodynamic optimization approach to three baselines in terms of two major risk-adjusted performance criteria and portfolio returns.}
}
@article{HUANG2022224,
title = {Riemannian gradient methods for stochastic composition problems},
journal = {Neural Networks},
volume = {153},
pages = {224-234},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200209X},
author = {Feihu Huang and Shangqian Gao},
keywords = {Riemannian manifold, Composition optimization, Deep neural networks, Stiefel manifold, Principal component analysis, Grassmann manifold},
abstract = {In the paper, we study a class of novel stochastic composition optimization problems over Riemannian manifold, which have been raised by multiple emerging machine learning applications such as distributionally robust learning in Riemannian manifold setting. To solve these composition problems, we propose an effective Riemannian compositional gradient (RCG) algorithm, which has a sample complexity of O(ϵ−4) for finding an ϵ-stationary point. To further reduce sample complexity, we propose an accelerated momentum-based Riemannian compositional gradient (M-RCG) algorithm. Moreover, we prove that the M-RCG obtains a lower sample complexity of Õ(ϵ−3) without large batches, which achieves the best known sample complexity for its Euclidean counterparts. Extensive numerical experiments on training deep neural networks (DNNs) over Stiefel manifold and learning principal component analysis (PCA) over Grassmann manifold demonstrate effectiveness of our proposed algorithms. To the best of our knowledge, this is the first study of the composition optimization problems over Riemannian manifold.}
}
@article{STEPHANY2022360,
title = {PDE-READ: Human-readable partial differential equation discovery using deep learning},
journal = {Neural Networks},
volume = {154},
pages = {360-382},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002660},
author = {Robert Stephany and Christopher Earls},
keywords = {Deep learning, Sparse regression, Partial differential equation discovery, Physics informed machine learning},
abstract = {PDE discovery shows promise for uncovering predictive models of complex physical systems but has difficulty when measurements are noisy and limited. We introduce a new approach for PDE discovery that uses two Rational Neural Networks and a principled sparse regression algorithm to identify the hidden dynamics that govern a system’s response. The first network learns the system response function, while the second learns a hidden PDE describing the system’s evolution. We then use a parameter-free sparse regression algorithm to extract a human-readable form of the hidden PDE from the second network. We implement our approach in an open-source library called PDE-READ. Our approach successfully identifies the governing PDE in six benchmark examples. We demonstrate that our approach is robust to both sparsity and noise and it, therefore, holds promise for application to real-world observational data.}
}
@article{TIAN2022373,
title = {Image super-resolution with an enhanced group convolutional neural network},
journal = {Neural Networks},
volume = {153},
pages = {373-385},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002143},
author = {Chunwei Tian and Yixuan Yuan and Shichao Zhang and Chia-Wen Lin and Wangmeng Zuo and David Zhang},
keywords = {Group convolution, CNN, Signal processing, Image super-resolution},
abstract = {CNNs with strong learning abilities are widely chosen to resolve super-resolution problem. However, CNNs depend on deeper network architectures to improve performance of image super-resolution, which may increase computational cost in general. In this paper, we present an enhanced super-resolution group CNN (ESRGCNN) with a shallow architecture by fully fusing deep and wide channel features to extract more accurate low-frequency information in terms of correlations of different channels in single image super-resolution (SISR). Also, a signal enhancement operation in the ESRGCNN is useful to inherit more long-distance contextual information for resolving long-term dependency. An adaptive up-sampling operation is gathered into a CNN to obtain an image super-resolution model with low-resolution images of different sizes. Extensive experiments report that our ESRGCNN surpasses the state-of-the-arts in terms of SISR performance, complexity, execution speed, image quality evaluation and visual effect in SISR. Code is found at https://github.com/hellloxiaotian/ESRGCNN.}
}
@article{XIAO2022413,
title = {Latent neighborhood-based heterogeneous graph representation},
journal = {Neural Networks},
volume = {154},
pages = {413-424},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002933},
author = {Yang Xiao and Pei Quan and MingLong Lei and Lingfeng Niu},
keywords = {Heterogeneous graph, Graph neural networks, Graph representation learning, Meta-path generation, HodgeRank},
abstract = {Graph, as a powerful data structure, has shown superior capability on modeling complex systems. Since real-world objects and their interactions are often multi-modal and multi-typed, compared with traditional homogeneous graphs, heterogeneous graphs can represent real-world objects more effectively. Meanwhile, rich semantic information brings great challenges for learning heterogeneous graph representation (HGR). Most existing HGR methods are based on the concept of meta-path, which is constructed based on direct neighbors and define composite semantic relations in heterogeneous graph. However, when the direct neighbor information is inadequate, which always happens due to insufficient observation, the quality of meta-paths cannot be guaranteed. Therefore, we propose a novel HGR framework based on latent direct neighbors. Specifically, random walks are first utilized to discover the potential candidates from indirect neighbors. Then HodgeRank is introduced to determine the latent direct neighbors according to their importance to the target. After that, neighborhood relationships are augmented with the selected latent direct neighbors, and the adjacency tensor of the heterogeneous graph is refactored correspondingly. Finally, Graph Transformer Network is adopted to construct semantic meta-paths automatically and generate HGR. Numerical experiments on different real-world heterogeneous networks show that our new approach can produce more meta-path instances and introduce more complex and diverse semantic information, and consequently achieves more accurate predictions compared with several state-of-the-art baselines.}
}
@article{HUANG202213,
title = {Compressing speaker extraction model with ultra-low precision quantization and knowledge distillation},
journal = {Neural Networks},
volume = {154},
pages = {13-21},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002416},
author = {Yating Huang and Yunzhe Hao and Jiaming Xu and Bo Xu},
keywords = {Speaker extraction, Quantization-aware training, Knowledge distillation, Parameter sharing},
abstract = {Recently, our proposed speaker extraction model, WASE (learning When to Attend for Speaker Extraction) yielded superior performance over the prior state-of-the-art methods by explicitly modeling onset clue and regarding it as important guidance in speaker extraction tasks. However, it still remains challenging when it comes to the deployments on the resource-constrained devices, where the model must be tiny and fast to perform inference with minimal budget in CPU and memory while keeping the speaker extraction performance. In this work, we utilize model compression techniques to alleviate the problem and propose a lightweight speaker extraction model, TinyWASE, which aims to run on resource-constrained devices. Specifically, we mainly investigate the grouping effects of quantization-aware training and knowledge distillation techniques in the speaker extraction task and propose Distillation-aware Quantization. Experiments on WSJ0-2mix dataset show that our proposed model can achieve comparable performance as the full-precision model while reducing the model size using ultra-low bits (e.g. 3 bits), obtaining 8.97x compression ratio and 2.15 MB model size. We further show that TinyWASE can combine with other model compression techniques, such as parameter sharing, to achieve compression ratio as high as 23.81 with limited performance degradation. Our code is available at https://github.com/aispeech-lab/TinyWASE.}
}
@article{DONG2022543,
title = {Event stream learning using spatio-temporal event surface},
journal = {Neural Networks},
volume = {154},
pages = {543-559},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002659},
author = {Junfei Dong and Runhao Jiang and Rong Xiao and Rui Yan and Huajin Tang},
keywords = {Spatiotemporal feature descriptor, Spike-based learning, Event streams classification, Spiking neural network},
abstract = {Event cameras sense changes in light intensity and record them as an asynchronous event stream. Efficiently encoding and learning spatiotemporal information of the event streams remain challenging. In this paper, we propose a novel event descriptor to encode the spatio-temporal features for event streams and a local-search based multi-spike learning algorithm for spiking neural networks to classify encoded features. The spatio-temporal event surface (STES) descriptor explicitly captures both spatial and temporal correlations among events, and thus can characterize spatiotemporal features more accurately than existing feature descriptors that focus only on temporal or spatial information. In classification with multi-spike learning, we introduce a local search and gradient clipping mechanism to ensure the efficiency and stability of learning, which avoids other multi-spike learning rules’ time-consuming global search and the gradient explosion problem. Experimental results demonstrate the superior classification performance of our proposed model, especially for event streams with rich spatiotemporal dynamics.}
}
@article{WANG2022179,
title = {Neural network interpolation operators optimized by Lagrange polynomial},
journal = {Neural Networks},
volume = {153},
pages = {179-191},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200212X},
author = {Guoshun Wang and Dansheng Yu and Ping Zhou},
keywords = {Sigmoidal function, Neural network operators, Interpolation, Uniform approximate},
abstract = {In this paper, we introduce a new type of interpolation operators by using Lagrange polynomials of degree r, which can be regarded as feedforward neural networks with four layers. The approximation rate of the new operators can be estimated by the (r+1)-th modulus of smoothness of the objective functions. By adding some smooth assumptions on the activation function, we establish two important inequalities of the derivatives of the operators. With these two inequalities, by using the K-functional and Berens–Lorentz lemma in approximation theory, we establish the converse theorem of approximation. We also give the Voronovskaja-type asymptotic estimation of the operators for smooth functions. Furthermore, we extend our operators to the multivariate case, and investigate their approximation properties for multivariate functions. Finally, some numerical examples are given to demonstrate the validity of the theoretical results obtained and the superiority of the operators.}
}
@article{SAKAI2022119,
title = {Three approaches to facilitate invariant neurons and generalization to out-of-distribution orientations and illuminations},
journal = {Neural Networks},
volume = {155},
pages = {119-143},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200288X},
author = {Akira Sakai and Taro Sunagawa and Spandan Madan and Kanata Suzuki and Takashi Katoh and Hiromichi Kobashi and Hanspeter Pfister and Pawan Sinha and Xavier Boix and Tomotake Sasaki},
keywords = {Out-of-distribution generalization, Object recognition in novel conditions, Neural invariance, Neural selectivity, Neural activity analysis},
abstract = {The training data distribution is often biased towards objects in certain orientations and illumination conditions. While humans have a remarkable capability of recognizing objects in out-of-distribution (OoD) orientations and illuminations, Deep Neural Networks (DNNs) severely suffer in this case, even when large amounts of training examples are available. Neurons that are invariant to orientations and illuminations have been proposed as a neural mechanism that could facilitate OoD generalization, but it is unclear how to encourage the emergence of such invariant neurons. In this paper, we investigate three different approaches that lead to the emergence of invariant neurons and substantially improve DNNs in recognizing objects in OoD orientations and illuminations. Namely, these approaches are (i) training much longer after convergence of the in-distribution (InD) validation accuracy, i.e., late-stopping, (ii) tuning the momentum parameter of the batch normalization layers, and (iii) enforcing invariance of the neural activity in an intermediate layer to orientation and illumination conditions. Each of these approaches substantially improves the DNN’s OoD accuracy (more than 20% in some cases). We report results in four datasets: two datasets are modified from the MNIST and iLab datasets, and the other two are novel (one of 3D rendered cars and another of objects taken from various controlled orientations and illumination conditions). These datasets allow to study the effects of different amounts of bias and are challenging as DNNs perform poorly in OoD conditions. Finally, we demonstrate that even though the three approaches focus on different aspects of DNNs, they all tend to lead to the same underlying neural mechanism to enable OoD accuracy gains — individual neurons in the intermediate layers become invariant to OoD orientations and illuminations. We anticipate this study to be a basis for further improvement of deep neural networks’ OoD generalization performance, which is highly demanded to achieve safe and fair AI applications.}
}
@article{WEN20221,
title = {Sparse signal reconstruction via recurrent neural networks with hyperbolic tangent function},
journal = {Neural Networks},
volume = {153},
pages = {1-12},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001964},
author = {Hongsong Wen and Xing He and Tingwen Huang},
keywords = {-minimization, Hyperbolic tangent function, Sliding mode control technique, Finite-time RNN (FTRNN), Finite-time convergence},
abstract = {In this paper, several recurrent neural networks (RNNs) for solving the L1-minimization problem are proposed. First, a one-layer RNN based on the hyperbolic tangent function and the projection matrix is designed. In addition, the stability and global convergence of the previously presented RNN are proved by the Lyapunov method. Then, the sliding mode control technique is introduced into the former RNN to design finite-time RNN (FTRNN). Under the condition that the projection matrix satisfies the Restricted Isometry Property (RIP), a suitable Lyapunov function is constructed to prove that the FTRNN is stable in the Lyapunov sense and has the finite-time convergence property. Finally, we make a comparison of the proposed RNN and FTRNN with the existing RNNs. To achieve this, we implement experiments for sparse signal reconstruction and image reconstruction. The results further demonstrate the effectiveness and superior performance of the proposed RNN and FTRNN.}
}
@article{PENG2022203,
title = {Correntropy based semi-supervised concept factorization with adaptive neighbors for clustering},
journal = {Neural Networks},
volume = {154},
pages = {203-217},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002775},
author = {Siyuan Peng and Zhijing Yang and Feiping Nie and Badong Chen and Zhiping Lin},
keywords = {Concept factorization, Correntropy, Semi-supervised learning, Adaptive neighbors, Clustering},
abstract = {Concept factorization (CF) has shown the effectiveness in the field of data clustering. In this paper, a novel and robust semi-supervised CF method, called correntropy based semi-supervised concept factorization with adaptive neighbors (CSCF), is proposed with improved performance in clustering applications. Specifically, on the one hand, the CSCF method adopts correntropy as the cost function to increase the robustness for non-Gaussian noise and outliers, and combines two different types of supervised information simultaneously for obtaining a compact low-dimensional representation of the original data. On the other hand, CSCF assigns the adaptive neighbors for each data point to construct a good data similarity matrix for reducing the sensitiveness of data. Moreover, a generalized version of CSCF is derived for enlarging the clustering application ranges. Analysis is also presented for the relationship of CSCF with several typical CF methods. Experimental results have shown that CSCF has better clustering performance than several state-of-the-art CF methods.}
}
@article{GANAIE2022496,
title = {Oblique and rotation double random forest},
journal = {Neural Networks},
volume = {153},
pages = {496-517},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002258},
author = {M.A. Ganaie and M. Tanveer and P.N. Suganthan and V. Snasel},
keywords = {Double random forest, Oblique random forest, Ensemble learning, Bootstrap, Decision tree, classification},
abstract = {Random Forest is an ensemble of decision trees based on the bagging and random subspace concepts. As suggested by Breiman, the strength of unstable learners and the diversity among them are the ensemble models’ core strength. In this paper, we propose two approaches known as oblique and rotation double random forests. In the first approach, we propose rotation based double random forest. In rotation based double random forests, transformation or rotation of the feature space is generated at each node. At each node different random feature subspace is chosen for evaluation, hence the transformation at each node is different. Different transformations result in better diversity among the base learners and hence, better generalization performance. With the double random forest as base learner, the data at each node is transformed via two different transformations namely, principal component analysis and linear discriminant analysis. In the second approach, we propose oblique double random forest. Decision trees in random forest and double random forest are univariate, and this results in the generation of axis parallel split which fails to capture the geometric structure of the data. Also, the standard random forest may not grow sufficiently large decision trees resulting in suboptimal performance. To capture the geometric properties and to grow the decision trees of sufficient depth, we propose oblique double random forest. The oblique double random forest models are multivariate decision trees. At each non-leaf node, multisurface proximal support vector machine generates the optimal plane for better generalization performance. Also, different regularization techniques (Tikhonov regularization, axis-parallel split regularization, Null space regularization) are employed for tackling the small sample size problems in the decision trees of oblique double random forest. The proposed ensembles of decision trees produce trees with bigger size compared to the standard ensembles of decision trees as bagging is used at each non-leaf node which results in improved performance. The evaluation of the baseline models and the proposed oblique and rotation double random forest models is performed on benchmark 121 UCI datasets and real-world fisheries datasets. Both statistical analysis and the experimental results demonstrate the efficacy of the proposed oblique and rotation double random forest models compared to the baseline models on the benchmark datasets.}
}
@article{BAKHTIARNIA2022461,
title = {Single-layer vision transformers for more accurate early exits with less overhead},
journal = {Neural Networks},
volume = {153},
pages = {461-473},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.038},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002532},
author = {Arian Bakhtiarnia and Qi Zhang and Alexandros Iosifidis},
keywords = {Dynamic inference, Early exiting, Multi-exit architecture, Vision transformer, Multimodal deep learning},
abstract = {Deploying deep learning models in time-critical applications with limited computational resources, for instance in edge computing systems and IoT networks, is a challenging task that often relies on dynamic inference methods such as early exiting. In this paper, we introduce a novel architecture for early exiting based on the vision transformer architecture, as well as a fine-tuning strategy that significantly increase the accuracy of early exit branches compared to conventional approaches while introducing less overhead. Through extensive experiments on image and audio classification as well as audiovisual crowd counting, we show that our method works for both classification and regression problems, and in both single- and multi-modal settings. Additionally, we introduce a novel method for integrating audio and visual modalities within early exits in audiovisual data analysis, that can lead to a more fine-grained dynamic inference.}
}
@article{YU2022130,
title = {Exploring phase–amplitude coupling from primary motor cortex-basal ganglia–thalamus network model},
journal = {Neural Networks},
volume = {153},
pages = {130-141},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002015},
author = {Ying Yu and Fang Han and Qingyun Wang},
keywords = {Computational model, Beta-band oscillation, Phase–amplitude coupling, Synchronization, Parkinson disease},
abstract = {The purpose of this study is to develop a primary motor cortex (M1)-basal ganglia–thalamus model capable of reproducing the physiological phenomenon of exaggerated phase–amplitude coupling (PAC) in Parkinson’s disease and exploring the potential sources of PAC anomalies in M1. The subthalamic nucleus (STN) phase-STN amplitude coupling, STN phase–M1 amplitude coupling, and M1 phase–M1 amplitude coupling are reproduced, where the phase frequencies are distributed in the beta band and the amplitude frequencies are distributed in the broad gamma band. We mainly study the impacts of thalamus →M1 connections and STN↔M1 bidirectional synaptic connections. Abnormal beta oscillations generated within the basal ganglia are found to be transmitted to M1 through the STN or thalamus and could be one of the potential sources of PAC-related beta oscillations in M1, thereby interfering with high-frequency signals in the motor cortex. Furthermore, the weakening of M1→STN leads to a shift of the oscillations of the STN from the high beta band to the low beta band, which is more consistent with pathological experiments, thus supporting the experimental results that the hyper-direct path from M1 to STN drives the beta oscillations of STN. Finally, the suppression effect of STN deep brain stimulation on PAC is investigated. As the stimulation frequency increases, the PAC modulation index within different regions gradually decreases, in general agreement with the trend of synchronization level and beta oscillation energy, indirectly indicating that PAC can be used as a feedback indicator of parkinsonian state.}
}
@article{WU2022235,
title = {Transfer learning for motor imagery based brain–computer interfaces: A tutorial},
journal = {Neural Networks},
volume = {153},
pages = {235-253},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002131},
author = {Dongrui Wu and Xue Jiang and Ruimin Peng},
keywords = {Brain–computer interface, Electroencephalogram, Transfer learning, Euclidean alignment, Motor imagery},
abstract = {A brain–computer interface (BCI) enables a user to communicate directly with an external device, e.g., a computer, using brain signals. It can be used to research, map, assist, augment, or repair human cognitive or sensory–motor functions. A closed-loop BCI system performs signal acquisition, temporal filtering, spatial filtering, feature engineering and classification, before sending out the control signal to an external device. Transfer learning (TL) has been widely used in motor imagery (MI) based BCIs to reduce the calibration effort for a new subject, greatly increasing their utility. This tutorial describes how TL can be considered in as many components of a BCI system as possible, and introduces a complete TL pipeline for MI-based BCIs. Examples on two MI datasets demonstrated the advantages of considering TL in multiple components of MI-based BCIs. Especially, integrating data alignment and sophisticated TL approaches can significantly improve the classification performance, and hence greatly reduces the calibration effort.}
}
@article{KIM2022441,
title = {SLIDE: A surrogate fairness constraint to ensure fairness consistency},
journal = {Neural Networks},
volume = {154},
pages = {441-454},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002891},
author = {Kunwoong Kim and Ilsang Ohn and Sara Kim and Yongdai Kim},
keywords = {Fairness AI, Learning theory, Machine learning, Supervised learning, Classification},
abstract = {As they take a crucial role in social decision makings, AI algorithms based on ML models should be not only accurate but also fair. Among many algorithms for fair AI, learning a prediction ML model by minimizing the empirical risk (e.g., cross-entropy) subject to a given fairness constraint has received much attention. To avoid computational difficulty, however, a given fairness constraint is replaced by a surrogate fairness constraint as the 0–1 loss is replaced by a convex surrogate loss for classification problems. In this paper, we investigate the validity of existing surrogate fairness constraints and propose a new surrogate fairness constraint called SLIDE, which is computationally feasible and asymptotically valid in the sense that the learned model satisfies the fairness constraint asymptotically and achieves a fast convergence rate. Numerical experiments confirm that the SLIDE works well for various benchmark datasets.}
}
@article{VENUGOPAL2022339,
title = {Privacy preserving Generative Adversarial Networks to model Electronic Health Records},
journal = {Neural Networks},
volume = {153},
pages = {339-348},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002374},
author = {Rohit Venugopal and Noman Shafqat and Ishwar Venugopal and Benjamin Mark John Tillbury and Harry Demetrios Stafford and Aikaterini Bourazeri},
keywords = {AI, GAN, Machine learning, Privacy, Public health data},
abstract = {Hospitals and General Practitioner (GP) surgeries within National Health Services (NHS), collect patient information on a routine basis to create personal health records such as family medical history, chronic diseases, medications and dosing. The collected information could be used to build and model various machine learning algorithms, to simplify the task of those working within the NHS. However, such Electronic Health Records are not made publicly available due to privacy concerns. In our paper, we propose a privacy-preserving Generative Adversarial Network (pGAN), which can generate synthetic data of high quality, while preserving the privacy and statistical properties of the source data. pGAN is evaluated on two distinct datasets, one posing as a Classification task, and the other as a Regression task. Privacy score of generated data is calculated using the Nearest Neighbour Adversarial Accuracy. Cosine similarity scores of synthetic data from our proposed model indicate that the data generated is similar in nature, but not identical. Additionally, our proposed model was able to preserve privacy while maintaining high utility. Machine learning models trained on both synthetic data and original data have achieved accuracies of 74.3% and 74.5% respectively on the classification dataset; while they have attained an R2-Score of 0.84 and 0.85 on synthetic and original data of the regression task respectively. Our results, therefore, indicate that synthetic data from the proposed model could replace the use of original data for machine learning while preserving privacy.}
}
@article{XU202231,
title = {How does the brain represent the semantic content of an image?},
journal = {Neural Networks},
volume = {154},
pages = {31-42},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002490},
author = {Huawei Xu and Ming Liu and Delong Zhang},
keywords = {Deep neural networks, Neural style transfer, Early visual areas, Ground cognition, Encoding models, Representational similarity analysis},
abstract = {Using deep neural networks (DNNs) as models to explore the biological brain is controversial, which is mainly due to the impenetrability of DNNs. Inspired by neural style transfer, we circumvented this problem by using deep features that were given a clear meaning—the representation of the semantic content of an image. Using encoding models and the representational similarity analysis, we quantitatively showed that the deep features which represented the semantic content of an image mainly predicted the activity of voxels in the early visual areas (V1, V2, and V3) and these features were essentially depictive but also propositional. This result is in line with the core viewpoint of the grounded cognition to some extent, which suggested that the representation of information in our brain is essentially depictive and can implement symbolic functions naturally.}
}
@article{YAO2022564,
title = {Toward reliable designs of data-driven reinforcement learning tracking control for Euler–Lagrange systems},
journal = {Neural Networks},
volume = {153},
pages = {564-575},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001915},
author = {Zhikai Yao and Jianyong Yao},
keywords = {Reinforcement learning, Tracking control, Direct heuristic dynamic programming (dHDP), Backstepping},
abstract = {This paper addresses reinforcement learning based, direct signal tracking control with an objective of developing mathematically suitable and practically useful design approaches. Specifically, we aim to provide reliable and easy to implement designs in order to reach reproducible neural network-based solutions. Our proposed new design takes advantage of two control design frameworks: a reinforcement learning based, data-driven approach to provide the needed adaptation and (sub)optimality, and a backstepping based approach to provide closed-loop system stability framework. We develop this work based on an established direct heuristic dynamic programming (dHDP) learning paradigm to perform online learning and adaptation and a backstepping design for a class of important nonlinear dynamics described as Euler–Lagrange systems. We provide a theoretical guarantee for the stability of the overall dynamic system, weight convergence of the approximating nonlinear neural networks, and the Bellman (sub)optimality of the resulted control policy. We use simulations to demonstrate significantly improved design performance of the proposed approach over the original dHDP.}
}
@article{LIU202299,
title = {Neural extraction of multiscale essential structure for network dismantling},
journal = {Neural Networks},
volume = {154},
pages = {99-108},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002726},
author = {Qingxia Liu and Bang Wang},
keywords = {Complex network, Graph Neural Networks (GNN), Network dismantling, Self-supervised learning},
abstract = {Diverse real world systems can be abstracted as complex networks consisting of nodes and edges as functional components. Percolation theory has shown that the failure of a few of nodes could lead to the collapse of a whole network, which brings up the network dismantling problem: How to select the least number of nodes to decompose a network into disconnected components each smaller than a predefined threshold? For its NP-hardness, many heuristic approaches have been proposed to measure and rank each node according to its importance to network structural stability. However, these measures are from a uniscale viewpoint by regarding one complex network as a flatted topology. In this article, we argue that nodes’ structural importance can be measured in different scales of network topologies. Built upon recent deep learning techniques, we propose a self-supervised learning based network dismantling framework (NEES), which can hierarchically merge some compact substructures to convert a network into a coarser one with fewer nodes and edges. During the merging process, we design neural models to extract essential structures and utilize self-attention mechanisms to learn nodes’ importance hierarchy in each scale. Experiments on real world networks and synthetic model networks show that the proposed NEES outperforms the state-of-the-art schemes in most cases in terms of removing the least number of target nodes to dismantle a network. The dismantling effectiveness of our neural extraction framework also highlights the emerging role of multi-scale essential structures.}
}
@article{XIAO2022491,
title = {Extended analysis on the global Mittag-Leffler synchronization problem for fractional-order octonion-valued BAM neural networks},
journal = {Neural Networks},
volume = {154},
pages = {491-507},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002969},
author = {Jianying Xiao and Xiao Guo and Yongtao Li and Shiping Wen and Kaibo Shi and Yiqian Tang},
keywords = {Fractional-order neural networks, Bidirectional associative memory neural networks, Octonion-valued neural networks, Synchronization},
abstract = {In this paper, a new case of neural networks called fractional-order octonion-valued bidirectional associative memory neural networks (FOOVBAMNNs) is established. First, the higher dimensional models are formulated for FOOVBAMNNs with general activation functions and the special linear threshold ones, respectively. On one hand, employing Cayley–Dichson construction in octonion multiplication which is essentially neither commutative nor associative, the system of FOOVBAMNNs is divided into four fractional-order complex-valued ones. On the other hand, Caputo fractional derivative’s character and BAM’s interactive feature are also properly dealt with. Second, the general criteria are obtained by the new design of LKFs, the application of the related inequalities and the construction of the linear feedback controllers for the global Mittag-Leffler synchronization problem of FOOVBAMNNs. Finally, we present two numerical examples to show the realizability and progress of the derived results.}
}
@article{AMIRINEZHAD202222,
title = {Active learning of causal structures with deep reinforcement learning},
journal = {Neural Networks},
volume = {154},
pages = {22-30},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200243X},
author = {Amir Amirinezhad and Saber Salehkaleybar and Matin Hashemi},
keywords = {Casual structure learning, Experiment design, Active learning, Deep reinforcement learning},
abstract = {We study the problem of experiment design to learn causal structures from interventional data. We consider an active learning setting in which the experimenter decides to intervene on one of the variables in the system in each step and uses the results of the intervention to recover further causal relationships among the variables. The goal is to fully identify the causal structures with minimum number of interventions. We present the first deep reinforcement learning based solution for the problem of experiment design. In the proposed method, we embed input graphs to vectors using a graph neural network and feed them to another neural network which outputs a variable for performing intervention in each step. Both networks are trained jointly via a Q-iteration algorithm. Experimental results show that the proposed method achieves competitive performance in recovering causal structures with respect to previous works, while significantly reducing execution time in dense graphs.}
}
@article{MOCANU2022246,
title = {Breaking CAPTCHA with Capsule Networks},
journal = {Neural Networks},
volume = {154},
pages = {246-254},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.041},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002568},
author = {Ionela Georgiana Mocanu and Zhenxu Yang and Vaishak Belle},
keywords = {Capsule networks, CAPTCHA, Convolutional neural networks, Digit recognition, Spatial invariance},
abstract = {Convolutional Neural Networks have achieved state-of-the-art performance in image classification. Their lack of ability to recognise the spatial relationship between features, however, leads to misclassification of the variants of the same image. Capsule Networks were introduced to address this issue by incorporating the spatial information of image features into neural networks. In this paper, we are interested in showcasing the digit recognition task on CAPTCHA images, widely considered a challenge for computers in relation to human capabilities. Our intention is to provide a rigorous empirical regime in which we can compare the competitive performance of Capsule Networks against the Convolutional Neural Networks. Indeed since CAPTCHA distorts images, by adjusting the spatial positioning of features, we aim to demonstrate the advantages and limitations of Capsule Networks architecture. We train the Capsule Networks with Dynamic Routing version and the convolutional-neural-network-based deep-CAPTCHA baseline model to predict the digit sequences on numerical CAPTCHAs, investigate the performance results and propose two improvements to the Capsule Networks model.}
}
@article{RUPPRECHT202213,
title = {A survey for deep reinforcement learning in markovian cyber–physical systems: Common problems and solutions},
journal = {Neural Networks},
volume = {153},
pages = {13-36},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001873},
author = {Timothy Rupprecht and Yanzhi Wang},
keywords = {Deep reinforcement learning, Cyber–physical systems, Motor control, Resource allocation, HVAC},
abstract = {Deep Reinforcement Learning (DRL) is increasingly applied in cyber–physical systems for automation tasks. It is important to record the developing trends in DRL’s applications to help researchers overcome common problems using common solutions. This survey investigates trends seen within two applied settings: motor control tasks, and resource allocation tasks. The common problems include intractability of the action space, or state space, as well as hurdles associated with the prohibitive cost of training systems from scratch in the real-world. Real-world training data is sparse and difficult to derive and training in real-world can damage real-world learning systems. Researchers have provided a set of common as well as unique solutions. Tackling the problem of intractability, researchers have succeeded in guiding network training with handcrafted reward functions, auxiliary learning, and by simplifying the state or action spaces before performing transfer learning to more complex systems. Many state-of-the-art algorithms reformulate problems to use multi-agent or hierarchical learning to reduce the intractability of the state or action spaces for a single agent. Common solutions to the prohibitive cost of training include using benchmarks and simulations. This requires a shared feature space common to both simulation and the real world; without that you introduce what is known as the reality gap problem. This is the first survey, to our knowledge, that studies DRL as it is applied in the real world at this scope. It is our hope that the common solutions surveyed become common practice.}
}
@article{ZHAO2022521,
title = {Heterogeneous Pseudo-Supervised Learning for Few-shot Person Re-Identification},
journal = {Neural Networks},
volume = {154},
pages = {521-537},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002325},
author = {Jing Zhao and Long Lan and Da Huang and Jing Ren and Wenjing Yang},
keywords = {Pseudo-supervised learning, Heterogeneous pseudo-supervised learning, Knowledge fusion, Few-shot, Person re-identification},
abstract = {How to obtain good retrieval performance in the case of few-shot labeled samples is the current research focus of Person Re-Identification. To facilitate formal analysis, we formally put forward the concept of Pseudo-Supervised Learning (PSL) to represent a series of research works based on label generation under few-shot condition. Through extensive investigations, we find that the main problem that needs to be solved of PSL is how we can improve the quality of pseudo-label. To solve this problem, in this work, we proposed a simple yet effective Heterogeneous Pseudo-Supervised Learning (H-PSL) framework based on classical PSL to implement asynchronous match, which boosts the feature expression and then a better label prediction in the following. Specifically, a novel isomer is constructed as the feature extractor and is trained with a much larger amount of pseudo-supervised data, i.e., samples with pseudo-labels. In this way, the isomer obtains advanced feature expression. We then deliberately implement a cross-level asynchronous match mechanism between model and pseudo-supervised data. As a result, the quality of pseudo-label is greatly improved and the feature expression performance also be optimized accordingly. In addition, to make better use of pseudo-supervised data, we also designed a knowledge fusion strategy to integrate the pseudo labels and their confidence which are easily obtained by the base model and isomer. Encouragingly, knowledge fusion strategy further removes the noise-labeled samples from candidate data. We conduct experiments on four popular datasets to fully verify the universality of the proposed method. The experimental results show that the proposed method improves the performance of all compared baseline works.}
}
@article{HUANG2022450,
title = {The minimum regret path problem on stochastic fuzzy time-varying networks},
journal = {Neural Networks},
volume = {153},
pages = {450-460},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002441},
author = {Wei Huang and Zhilei Xu and Liehuang Zhu},
keywords = {Stochastic fuzzy time-varying minimum regret path, Stochastic fuzzy time-varying network, Stochastic fuzzy time-varying shortest path, Random fuzzy delay neural network},
abstract = {In this paper, we introduce a stochastic fuzzy time-varying minimum regret path problem (SFTMRP), which combines the characteristics of the min–max regret path and maximum probability path as a variant of the stochastic fuzzy time-varying shortest path problem, and its purpose is to find a path with the minimum regret degree in a given stochastic fuzzy time-varying network. To address this problem, we propose a random fuzzy delay neural network (RFDNN) based on novel random fuzzy delay neurons and without any training requirements. The random fuzzy delay neuron consists of six layers: an input layer, receiving layer, status layer, generation layer, sending layer, and output layer. Among them, the input and output layers are the ports of communication between neurons, and the receiving layer, status layer, generate layer, and sending layer are the information processing units of neurons. The information exchange between neurons is characterized by two kinds of signals: the shortest path signal and the maximum probability solution signal. The theoretical analysis of the proposed algorithm is carried out with respect to time-complexity and correctness. The numerical example and experimental results on 25 randomly generated stochastic fuzzy time-varying road networks with different numbers of 1000–5000 nodes show that the performance of the proposed algorithm is significantly better than that of existing algorithms.}
}
@article{LAMB2022218,
title = {Interpolated Adversarial Training: Achieving robust neural networks without sacrificing too much accuracy},
journal = {Neural Networks},
volume = {154},
pages = {218-233},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002684},
author = {Alex Lamb and Vikas Verma and Kenji Kawaguchi and Alexander Matyasko and Savya Khosla and Juho Kannala and Yoshua Bengio},
keywords = {Adversarial robustness, Mixup, Manifold Mixup, Standard test error},
abstract = {Adversarial robustness has become a central goal in deep learning, both in the theory and the practice. However, successful methods to improve the adversarial robustness (such as adversarial training) greatly hurt generalization performance on the unperturbed data. This could have a major impact on how the adversarial robustness affects real world systems (i.e. many may opt to forego robustness if it can improve accuracy on the unperturbed data). We propose Interpolated Adversarial Training, which employs recently proposed interpolation based training methods in the framework of adversarial training. On CIFAR-10, adversarial training increases the standard test error ( when there is no adversary) from 4.43% to 12.32%, whereas with our Interpolated adversarial training we retain the adversarial robustness while achieving a standard test error of only 6.45%. With our technique, the relative increase in the standard error for the robust model is reduced from 178.1% to just 45.5%. Moreover, we provide mathematical analysis of Interpolated Adversarial Training to confirm its efficiencies and demonstrate its advantages in terms of robustness and generalization.}
}
@article{YILMAZ202287,
title = {Successfully and efficiently training deep multi-layer perceptrons with logistic activation function simply requires initializing the weights with an appropriate negative mean},
journal = {Neural Networks},
volume = {153},
pages = {87-103},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002040},
author = {Ahmet Yilmaz and Riccardo Poli},
keywords = {Deep neural networks, Vanishing gradient, Weights initialization, Logistic activation function, Supervised learning},
abstract = {The vanishing gradient problem (i.e., gradients prematurely becoming extremely small during training, thereby effectively preventing a network from learning) is a long-standing obstacle to the training of deep neural networks using sigmoid activation functions when using the standard back-propagation algorithm. In this paper, we found that an important contributor to the problem is weight initialization. We started by developing a simple theoretical model showing how the expected value of gradients is affected by the mean of the initial weights. We then developed a second theoretical model that allowed us to identify a sufficient condition for the vanishing gradient problem to occur. Using these theories we found that initial back-propagation gradients do not vanish if the mean of the initial weights is negative and inversely proportional to the number of neurons in a layer. Numerous experiments with networks with 10 and 15 hidden layers corroborated the theoretical predictions: If we initialized weights as indicated by the theory, the standard back-propagation algorithm was both highly successful and efficient at training deep neural networks using sigmoid activation functions.}
}
@article{SAAB2022499,
title = {A multivariate adaptive gradient algorithm with reduced tuning efforts},
journal = {Neural Networks},
volume = {152},
pages = {499-509},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001903},
author = {Samer Saab and Khaled Saab and Shashi Phoha and Minghui Zhu and Asok Ray},
keywords = {Deep learning, Gradient descent optimization, Adaptive learning rate},
abstract = {Large neural networks usually perform well for executing machine learning tasks. However, models that achieve state-of-the-art performance involve arbitrarily large number of parameters and therefore their training is very expensive. It is thus desired to implement methods with small per-iteration costs, fast convergence rates, and reduced tuning. This paper proposes a multivariate adaptive gradient descent method that meets the above attributes. The proposed method updates every element of the model parameters separately in a computationally efficient manner using an adaptive vector-form learning rate, resulting in low per-iteration cost. The adaptive learning rate computes the absolute difference of current and previous model parameters over the difference in subgradients of current and previous state estimates. In the deterministic setting, we show that the cost function value converges at a linear rate for smooth and strongly convex cost functions. Whereas in both the deterministic and stochastic setting, we show that the gradient converges in expectation at the order of O(1/k) for a non-convex cost function with Lipschitz continuous gradient. In addition, we show that after T iterates, the cost function of the last iterate scales as O(log(T)/T) for non-smooth strongly convex cost functions. Effectiveness of the proposed method is validated on convex functions, smooth non-convex function, non-smooth convex function, and four image classification data sets, whilst showing that its execution requires hardly any tuning unlike existing popular optimizers that entail relatively large tuning efforts. Our empirical results show that our proposed algorithm provides the best overall performance when comparing it to tuned state-of-the-art optimizers.}
}
@article{LI2022560,
title = {Federated learning with workload-aware client scheduling in heterogeneous systems},
journal = {Neural Networks},
volume = {154},
pages = {560-573},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002957},
author = {Li Li and Duo Liu and Moming Duan and Yu Zhang and Ao Ren and Xianzhang Chen and Yujuan Tan and Chengliang Wang},
keywords = {Federated learning, Distributed machine learning, Heterogeneous systems, Neural Networks},
abstract = {Federated Learning (FL) is a novel distributed machine learning, which allows thousands of edge devices to train models locally without uploading data to the central server. Since devices in real federated settings are resource-constrained, FL encounters systems heterogeneity, which causes considerable stragglers and incurs significant accuracy degradation. To tackle the challenges of systems heterogeneity and improve the robustness of the global model, we propose a novel adaptive federated framework in this paper. Specifically, we propose FedSAE that leverages the workload completion history of clients to adaptively predict the affordable training workload for each device. Consequently, FedSAE can significantly reduce stragglers in highly heterogeneous systems. We incorporate Active Learning into FedSAE to dynamically schedule participants. The server evaluates the devices’ training value based on their training loss in each round, and larger-value clients are selected with a higher probability. As a result, the model convergence is accelerated. Furthermore, we propose q-FedSAE that combines FedSAE and q-FFL to improve global fairness in highly heterogeneous systems. The evaluations conducted in a highly heterogeneous system demonstrate that both FedSAE and q-FedSAE converge faster than FedAvg. In particular, FedSAE outperforms FedAvg across multiple federated datasets — FedSAE improves testing accuracy by 22.19% and reduces stragglers by 90.69% on average. Moreover, holding the same accuracy as FedSAE, q-FedSAE allows for more robust convergence and fairer model performance than q-FedAvg, FedSAE.}
}
@article{DAI2022234,
title = {MRGAT: Multi-Relational Graph Attention Network for knowledge graph completion},
journal = {Neural Networks},
volume = {154},
pages = {234-245},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002714},
author = {Guoquan Dai and Xizhao Wang and Xiaoying Zou and Chao Liu and Si Cen},
keywords = {Knowledge graph, Graph neural network, Attention mechanism},
abstract = {One of the most effective ways to solve the problem of knowledge graph completion is embedding-based models. Graph neural networks (GNNs) are popular and promising embedding models which can exploit and use the structural information of neighbors in knowledge graphs. The current GNN-based knowledge graph completion methods assume that all neighbors of a node have equal importance. This assumption which cannot assign different weights to neighbors is pointed out in our study to be unreasonable. In addition, since the knowledge graph is a kind of heterogeneous graph with multiple relations, multiple complex interactions between nodes and neighbors can bring challenges to the effective message passing of GNNs. We then design a multi-relational graph attention network (MRGAT) which can adapt to different cases of heterogeneous multi-relational connections and then calculate the importance of different neighboring nodes through a self-attention layer. The incorporation of self-attention mechanism into the network with different node weights optimizes the network structure, and therefore, significantly results in a promotion of performance. We experimentally validate the rationality of our models on multiple benchmark knowledge graphs, where MRGAT achieves the best performance on various evaluation metrics including MRR score, Hits@ score compared with other state-of-the-art baseline models.}
}
@article{JIANG2022204,
title = {MGLNN: Semi-supervised learning via Multiple Graph Cooperative Learning Neural Networks},
journal = {Neural Networks},
volume = {153},
pages = {204-214},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001988},
author = {Bo Jiang and Si Chen and Beibei Wang and Bin Luo},
keywords = {Multiple graph learning, Graph neural networks, Multi-graph semi-supervised classification},
abstract = {In many machine learning applications, data are coming with multiple graphs, which is known as the multiple graph learning problem. The problem of multiple graph learning is to learn consistent representation by exploiting the complementary information of multiple graphs. Graph Learning Neural Networks (GLNNs) have been demonstrated powerfully for graph data representation and semi-supervised classification tasks. However, Existing GLNNs are mainly developed for single graph data which cannot be utilized for multiple graph data representation. In this paper, we propose a novel learning framework, called Multiple Graph Learning Neural Networks (MGLNN), for multiple graph learning and multi-view semi-supervised classification. The goal of MGLNN is to learn an optimal graph structure from multiple graph structures that best serves GNNs’ learning which integrates multiple graph learning and GNNs’ representation simultaneously. The proposed MGLNN is a general framework which can incorporate any specific GNN model to deal with multiple graphs. A general algorithm has also been developed to optimize/train the proposed MGLNN model. Experimental results on several datasets demonstrate that MGLNN outperforms some other related methods on semi-supervised classification tasks.}
}
@article{WANG2022292,
title = {Graph regularized spatial–spectral subspace clustering for hyperspectral band selection},
journal = {Neural Networks},
volume = {153},
pages = {292-302},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002313},
author = {Jun Wang and Chang Tang and Xiao Zheng and Xinwang Liu and Wei Zhang and En Zhu},
keywords = {Clustering, Hyperspectral band selection, Feature learning, Similarity graph learning},
abstract = {Hyperspectral band selection, which aims to select a small number of bands to reduce data redundancy and noisy bands, has attracted widespread attention in recent years. Many effective clustering-based band selection methods have been proposed to accomplish the band selection task and have achieved satisfying performance. However, most of the previous methods reshape the original hyperspectral images (HSIs) into a set of stretched band vectors, which ignore the spatial information of HSIs and the difference between diverse regions. To address these issues, a graph regularized spatial–spectral subspace clustering method for hyperspectral band selection is proposed in this paper, referred to as GRSC. Specifically, the proposed method adopts superpixel segmentation to preserve the spatial information of HSIs by segmenting their first principal component into diverse homogeneous regions. Then the discriminative latent features are generated from each segmented region to represent the whole band, which can mitigate the effect of noise on the band selection. Finally, a self-representation subspace clustering model and an l2,1-norm regularization are utilized to explore the spectral correlation among all bands. In addition, a similarity graph between region-aware latent features is adaptively learned to preserve the spatial structure of HSIs in the latent representation space. Extensive classification experimental results on three public datasets verify the effectiveness of GRSC over several state-of-the-art methods. The demo code of this work is publicly available at https://github.com/WangJun2023/GRSC.}
}
@article{HON2022152,
title = {Simultaneous neural network approximation for smooth functions},
journal = {Neural Networks},
volume = {154},
pages = {152-164},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002556},
author = {Sean Hon and Haizhao Yang},
keywords = {Deep neural networks, Sobolev norm, ReLU activation functions, Approximation theory},
abstract = {We establish in this work approximation results of deep neural networks for smooth functions measured in Sobolev norms, motivated by recent development of numerical solvers for partial differential equations using deep neural networks. Our approximation results are nonasymptotic in the sense that the error bounds are explicitly characterized in terms of both the width and depth of the networks simultaneously with all involved constants explicitly determined. Namely, for f∈Cs([0,1]d), we show that deep ReLU networks of width O(NlogN) and of depth O(LlogL) can achieve a nonasymptotic approximation rate of O(N−2(s−1)/dL−2(s−1)/d) with respect to the W1,p([0,1]d) norm for p∈[1,∞). If either the ReLU function or its square is applied as activation functions to construct deep neural networks of width O(NlogN) and of depth O(LlogL) to approximate f∈Cs([0,1]d), the approximation rate is O(N−2(s−n)/dL−2(s−n)/d) with respect to the Wn,p([0,1]d) norm for p∈[1,∞).}
}
@article{ZHENG202276,
title = {Scalp EEG functional connection and brain network in infants with West syndrome},
journal = {Neural Networks},
volume = {153},
pages = {76-86},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002039},
author = {Runze Zheng and Yuanmeng Feng and Tianlei Wang and Jiuwen Cao and Duanpo Wu and Tiejia Jiang and Feng Gao},
keywords = {West epilepsy syndrome, Scalp EEG, Functional connection, Brain network, Network topology},
abstract = {The common age-dependent West syndrome can be diagnosed accurately by electroencephalogram (EEG), but its pathogenesis and evolution remain unclear. Existing research mainly aims at the study of West seizure markers in time/frequency domain, while less literature uses a graph-theoretic approach to analyze changes among different brain regions. In this paper, the scalp EEG based functional connectivity (including Correlation, Coherence, Time Frequency Cross Mutual Information, Phase-Locking Value, Phase Lag Index, Weighted Phase Lag Index) and network topology parameters (including Clustering coefficient, Feature path length, Global efficiency, and Local efficiency) are comprehensively studied for the prognostic analysis of the West episode cycle. The scalp EEGs of 15 children with clinically diagnosed string spasticity seizures are used for prospective study, where the signal is divided into pre-seizure, seizure, and post-seizure states in 5 typical brain wave rhythm frequency bands (δ (1–4 Hz), θ (4–8 Hz), α (8–13 Hz), β (13–30 Hz), and γ (30–80 Hz)) for functional connectivity analysis. The study shows that recurrent West seizures weaken connections between brain regions responsible for cognition and intelligence, while brain regions responsible for information synergy and visual reception have greater variability in connectivity during seizures. It is observed that the changes in β and γ frequency bands of the multiband brain network connectivity patterns calculated by Corr and WPLI can be preliminarily used as judgment of seizure cycle changes in West syndrome.}
}
@article{YANG2022269,
title = {Approximation in shift-invariant spaces with deep ReLU neural networks},
journal = {Neural Networks},
volume = {153},
pages = {269-281},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200226X},
author = {Yunfei Yang and Zhen Li and Yang Wang},
keywords = {Deep neural networks, Approximation complexity, Shift-invariant spaces, Sobolev spaces, Besov spaces},
abstract = {We study the expressive power of deep ReLU neural networks for approximating functions in dilated shift-invariant spaces, which are widely used in signal processing, image processing, communications and so on. Approximation error bounds are estimated with respect to the width and depth of neural networks. The network construction is based on the bit extraction and data-fitting capacity of deep neural networks. As applications of our main results, the approximation rates of classical function spaces such as Sobolev spaces and Besov spaces are obtained. We also give lower bounds of the Lp(1≤p≤∞) approximation error for Sobolev spaces, which show that our construction of neural network is asymptotically optimal up to a logarithmic factor.}
}
@article{DOYA2022542,
title = {Social impact and governance of AI and neurotechnologies},
journal = {Neural Networks},
volume = {152},
pages = {542-554},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001861},
author = {Kenji Doya and Arisa Ema and Hiroaki Kitano and Masamichi Sakagami and Stuart Russell},
keywords = {Artificial intelligence, Neurotechnology, AI scientist, Human compatible AI, Ethics, Governance},
abstract = {Advances in artificial intelligence (AI) and brain science are going to have a huge impact on society. While technologies based on those advances can provide enormous social benefits, adoption of new technologies poses various risks. This article first reviews the co-evolution of AI and brain science and the benefits of brain-inspired AI in sustainability, healthcare, and scientific discoveries. We then consider possible risks from those technologies, including intentional abuse, autonomous weapons, cognitive enhancement by brain–computer interfaces, insidious effects of social media, inequity, and enfeeblement. We also discuss practical ways to bring ethical principles into practice. One proposal is to stop giving explicit goals to AI agents and to enable them to keep learning human preferences. Another is to learn from democratic mechanisms that evolved in human society to avoid over-consolidation of power. Finally, we emphasize the importance of open discussions not only by experts, but also including a diverse array of lay opinions.}
}
@article{MA2022270,
title = {Context-guided entropy minimization for semi-supervised domain adaptation},
journal = {Neural Networks},
volume = {154},
pages = {270-282},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002672},
author = {Ning Ma and Jiajun Bu and Lixian Lu and Jun Wen and Sheng Zhou and Zhen Zhang and Jingjun Gu and Haifeng Li and Xifeng Yan},
keywords = {Domain adaptation, Transfer learning, Semi-supervised learning},
abstract = {Semi-Supervised Domain Adaptation has been widely studied with various approaches to address domain shift with labeled source-domain data combined with scarcely labeled target-domain data. Model adaptation is becoming promising with a paradigm of source pre-training and target fine-tuning, which eliminates the simultaneous availability of data from both domains and makes for data privacy. Among the model adaptation methods, Entropy Minimization (EM) is popularly incorporated to encourage a low-density separation on target samples. However, EM tends to brutally force models to make over-confident predictions, which could make the models collapse with deteriorated performance. In this paper, we first study the over-confidence of EM with a quantitative analysis, which shows the importance of capturing the dependency among labels. To address this issue, we propose to guide EM via longitudinal self-distillation. Specifically, we produce a dynamic “teacher” label distribution during training by constructing a graph on target data and perform pseudo-label propagation to encourage the “teacher” distribution to capture context category dependency based on a global data structure. Then EM is guided longitudinally by distilling the learned label distribution to combat the brute-force over-confidence. Extensive experiments demonstrate the effectiveness of our methods.}
}
@article{ZHAO2022427,
title = {ME-PLAN: A deep prototypical learning with local attention network for dynamic micro-expression recognition},
journal = {Neural Networks},
volume = {153},
pages = {427-443},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002398},
author = {Sirui Zhao and Huaying Tang and Shifeng Liu and Yangsong Zhang and Hao Wang and Tong Xu and Enhong Chen and Cuntai Guan},
keywords = {Emotion recognition, Facial micro-expression, ME spotting, Prototypical learning, 3D residual network},
abstract = {As one of the important psychological stress reactions, Micro-expressions (MEs) are spontaneous and subtle facial movements, which usually occur in a high-stake situation and can reveal genuine human feelings and cognition. ME, Recognition (MER) has essential applications in many fields such as lie detection, criminal investigation, and psychological healing. However, due to the challenges of learning discriminative ME features via fleeting facial subtle reactions as well as the shortage of available MEs data, this research topic is still far from well-studied. To this end, in this paper, we propose a deep prototypical learning framework, namely ME-PLAN, with a local attention mechanism for the MER problem. Specifically, ME-PLAN consists of two components, i.e., a 3D residual prototypical network and a local-wise attention module, where the former aims to learn the precise ME feature prototypes through expression-related knowledge transfer and episodic training, and the latter could facilitate the attention to the local facial movements. Furthermore, to alleviate the dilemma that most MER methods need to depend on manually annotated apex frames, we propose an apex frame spotting method with Unimodal Pattern Constrained (UPC) and further extract ME key-frames sequences based on the detected apex frames to train our proposed ME-PLAN in an end-to-end manner. Finally, through extensive experiments and interpretable analysis regarding the apex frame spotting and MER on composite-database, we demonstrate the superiority and effectiveness of the proposed methods.}
}
@article{CHEN202237,
title = {Adaptive 2-bits-triggered neural control for uncertain nonlinear multi-agent systems with full state constraints},
journal = {Neural Networks},
volume = {153},
pages = {37-48},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001939},
author = {Zicong Chen and Jianhui Wang and Tao Zou and Kemao Ma and Qinruo Wang},
keywords = {Multi-agent systems (MASs), Adaptive control, 2-bits-triggered control, Consensus control, Full state constraints},
abstract = {This paper investigates an adaptive 2-bits-triggered neural control for a class of uncertain nonlinear multi-agent systems (MASs) with full state constraints. Considering the limitations of practical physical devices and operating conditions, MASs may suffer performance degradation or even crash while the system states are not restricted. With this in mind, combined with barrier Lyapunov function (BLF), an adaptive neural consensus control is developed to guarantee that the state constraints of all followers are not violated. Further, the conversion relationship between the state constraints of MASs and the synchronization error constraints is clarified more precisely, which could improve the synchronization performance of MASs. In addition, considering both trigger threshold setting and control signal transmission bits issues, a 2-bit trigger strategy is proposed to maximize the utilization of MASs bandwidth resources. Theoretical analysis shows that all signals are uniformly ultimately bounded. And the simulation results demonstrate its effectiveness.}
}
@article{ZHAO202256,
title = {Deep reinforcement learning guided graph neural networks for brain network analysis},
journal = {Neural Networks},
volume = {154},
pages = {56-67},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002507},
author = {Xusheng Zhao and Jia Wu and Hao Peng and Amin Beheshti and Jessica J.M. Monaghan and David McAlpine and Heivet Hernandez-Perez and Mark Dras and Qiong Dai and Yangyang Li and Philip S. Yu and Lifang He},
keywords = {Brain network, Network representation learning, Graph neural network, Deep reinforcement learning},
abstract = {Modern neuroimaging techniques enable us to construct human brains as brain networks or connectomes. Capturing brain networks’ structural information and hierarchical patterns is essential for understanding brain functions and disease states. Recently, the promising network representation learning capability of graph neural networks (GNNs) has prompted related methods for brain network analysis to be proposed. Specifically, these methods apply feature aggregation and global pooling to convert brain network instances into vector representations encoding brain structure induction for downstream brain network analysis tasks. However, existing GNN-based methods often neglect that brain networks of different subjects may require various aggregation iterations and use GNN with a fixed number of layers to learn all brain networks. Therefore, how to fully release the potential of GNNs to promote brain network analysis is still non-trivial. In our work, a novel brain network representation framework, BN-GNN, is proposed to solve this difficulty, which searches for the optimal GNN architecture for each brain network. Concretely, BN-GNN employs deep reinforcement learning (DRL) to automatically predict the optimal number of feature propagations (reflected in the number of GNN layers) required for a given brain network. Furthermore, BN-GNN improves the upper bound of traditional GNNs’ performance in eight brain network disease analysis tasks.}
}
@article{LIU2022479,
title = {Set-membership filtering for complex networks with constraint communication channels},
journal = {Neural Networks},
volume = {152},
pages = {479-486},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001812},
author = {Chang Liu and Lixin Yang and Jie Tao and Yong Xu and Tingwen Huang},
keywords = {Set-membership filtering, Multi-rate sampling complex networks, Weighted try-once-discard protocol, Mixed compensation},
abstract = {The set-membership filtering is studied for a class of multi-rate sampling complex networks with communication capacity constraint. For reducing communication load, the weighted try-once-discard scheduling protocol is utilized to transmit the most needed measurement. To improve the filtering performance, a novel mixed compensation method is proposed to obtain a compensatory measurement that is closer to the actual value. Accordingly, a mixed compensation dependent filter is designed, and a filtering error system is obtained. Sufficient conditions are established to ensure that the filtering error system satisfies PTk-dependent constraint. Then, a new algorithm is designed to obtain the optimized ellipsoid by minimizing the constraint matrix. Finally, an illustrative example is given to demonstrate the validity of the developed filter.}
}
@article{ZHANG2022469,
title = {Mean-square stabilization of impulsive neural networks with mixed delays by non-fragile feedback involving random uncertainties},
journal = {Neural Networks},
volume = {154},
pages = {469-480},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002623},
author = {Xiaoyu Zhang and Chuandong Li and Hongfei Li and Zhengran Cao},
keywords = {Non-fragile feedback, Distributed delay, Lyapunov–Krasovskii functional, LMIs, Mean-square stability},
abstract = {In this paper, we consider a class of neural networks with mixed delays and impulsive interferences. Firstly, a sufficient condition is given to ensure the existence and uniqueness of the equilibrium point of the proposed neural networks by employing the contraction mapping theorem. Secondly, we discuss the issue of the exponential stability in mean-square of the equilibrium point by a non-fragilely delayed output coupling feedback which involves stochastically occurring gain oscillations. The designed feedback input can be tolerant of limited stochastic fluctuations of control gains and be robust against potential errors caused by factors like round-off. By combining methods of Lyapunov–Krasovskii functional and free-weighting matrix, a delay-dependent output coupling feedback with stochastically occurring uncertainties is designed and linear-matrix-inequalities(LMIs)-based sufficient conditions for the exponential stabilization in mean square are derived. Finally, three numerical examples are presented to illustrate the feasibility of theoretical results with a benchmark real-world problem.}
}
@article{GAO2022215,
title = {SepNet: A neural network for directionally correlated data},
journal = {Neural Networks},
volume = {153},
pages = {215-223},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002106},
author = {Fuchang Gao and Yiqing Ma and Boyu Zhang and Min Xian},
keywords = {Neural network, Correlation matrix, Directional linear operator, Directional convolutional operator, Spectrogram, Multichannel signal},
abstract = {Multi-dimensional tensor data appear in diverse settings, including multichannel signals, spectrograms, and hyperspectral data from remote sensing. In many cases, these data are directionally correlated, i.e. the correlation between variables from different dimensions is significantly weaker than the correlation between variables from the same dimension. Convolutional neural networks are readily applicable to directionally correlated data but are often inefficient, as they impose many unnecessary connections between neurons. Here we propose a novel architecture, SepNet, specifically for directionally correlated datasets. SepNet uses directional operators to extract directional features from each dimension separately, followed by a linear operator along the depth to generate higher-level features from the directional features. Experiments on two representative directionally correlated datasets showed that SepNet improved network efficiency up to 100-fold while maintaining high accuracy comparable with state-of-the-art convolutional neural network models. Furthermore, SepNet can be flexibly constructed with minimal restriction on the output shape of each layer. These results reveal the potential of data-specific architecting of neural networks.}
}
@article{TANG2022467,
title = {Semantic consistency learning on manifold for source data-free unsupervised domain adaptation},
journal = {Neural Networks},
volume = {152},
pages = {467-478},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001897},
author = {Song Tang and Yan Zou and Zihao Song and Jianzhi Lyu and Lijuan Chen and Mao Ye and Shouming Zhong and Jianwei Zhang},
keywords = {Unsupervised domain adaptation, Semantic consistency, Manifold, Self-supervised learning},
abstract = {Recently, source data-free unsupervised domain adaptation (SFUDA) attracts increasing attention. Current work shows that the geometry of the target data is helpful to solving this challenging problem. However, these methods define the geometric structures in Euclidean space. The geometry cannot completely draw the semantic relationship between the target data distributed on a manifold. This article proposed a new SFUDA method, semantic consistency learning on manifold (SCLM), to address this problem. Firstly, we generated pseudo-labels for the target data using a new clustering method, EntMomClustering, that enhanced k-means clustering by fusing the entropy momentum. Secondly, we constructed semantic neighbor topology (SNT) to capture complete geometric information on the manifold. Specifically, in SNT, the global neighbor was detected by a developed collaborative representation-based manifold projection, while the local neighbors were obtained by similarity comparison. Thirdly, we performed a semantic consistency learning on SNT to drive a new kind of deep clustering where SNT was taken as the basic clustering unit. To ensure SNT move as entirety, in the developed objective, the entropy regulator was constructed based on a semantic mixture fused on SNT, while the self-supervised regulator encouraged similar classification on SNT. Experiments on three benchmark datasets show that our method achieves state-of-the-art results. The code is available on https://github.com/tntek/SCLM.}
}
@article{LEE2022323,
title = {Two-level group convolution},
journal = {Neural Networks},
volume = {154},
pages = {323-332},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002866},
author = {Youngkyu Lee and Jongho Park and Chang-Ock Lee},
keywords = {Group convolution, Parallel computation, Block Jacobi approximation, Two-level method},
abstract = {Group convolution has been widely used in order to reduce the computation time of convolution, which takes most of the training time of convolutional neural networks. However, it is well known that a large number of groups significantly reduce the performance of group convolution. In this paper, we propose a new convolution methodology called “two-level” group convolution that is robust with respect to the increase of the number of groups and suitable for multi-GPU parallel computation. We first observe that the group convolution can be interpreted as a one-level block Jacobi approximation of the standard convolution, which is a popular notion in the field of numerical analysis. In numerical analysis, there have been numerous studies on the two-level method that introduces an intergroup structure that resolves the performance degradation issue without disturbing parallel computation. Motivated by these, we introduce a coarse-level structure which promotes intergroup communication without being a bottleneck in the group convolution. We show that all the additional work induced by the coarse-level structure can be efficiently processed in a distributed memory system. Numerical results that verify the robustness of the proposed method with respect to the number of groups are presented. Moreover, we compare the proposed method to various approaches for group convolution in order to highlight the superiority of the proposed method in terms of execution time, memory efficiency, and performance.}
}
@article{DENG2022411,
title = {Approximation rates of DeepONets for learning operators arising from advection–diffusion equations},
journal = {Neural Networks},
volume = {153},
pages = {411-426},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002349},
author = {Beichuan Deng and Yeonjong Shin and Lu Lu and Zhongqiang Zhang and George Em Karniadakis},
keywords = {Operator learning, Fixed-weight neural network, Advection–diffusion–reaction equations, Burgers equations, Approximation in Banach spaces},
abstract = {We present the analysis of approximation rates of operator learning in Chen and Chen (1995) and Lu et al. (2021), where continuous operators are approximated by a sum of products of branch and trunk networks. In this work, we consider the rates of learning solution operators from both linear and nonlinear advection–diffusion equations with or without reaction. We find that the approximation rates depend on the architecture of branch networks as well as the smoothness of inputs and outputs of solution operators.}
}
@article{DANIELS2022122,
title = {Reservoir computing with 3D nanowire networks},
journal = {Neural Networks},
volume = {154},
pages = {122-130},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200257X},
author = {R.K. Daniels and J.B. Mallinson and Z.E. Heywood and P.J. Bones and M.D. Arnold and S.A. Brown},
keywords = {Nanowire networks, Memristors, Reservoir computing},
abstract = {Networks of nanowires are currently being explored for a range of applications in brain-like (or neuromorphic) computing, and especially in reservoir computing (RC). Fabrication of real-world computing devices requires that the nanowires are deposited sequentially, leading to stacking of the wires on top of each other. However, most simulations of computational tasks using these systems treat the nanowires as 1D objects lying in a perfectly 2D plane — the effect of stacking on RC performance has not yet been established. Here we use detailed simulations to compare the performance of perfectly 2D and quasi-3D (stacked) networks of nanowires in two tasks: memory capacity and nonlinear transformation. We also show that our model of the junctions between nanowires is general enough to describe a wide range of memristive networks, and consider the impact of physically realistic electrode configurations on performance. We show that the various networks and configurations have a strikingly similar performance in RC tasks, which is surprising given their radically different topologies. Our results show that networks with an experimentally achievable number of electrodes perform close to the upper bounds achievable when using the information from every wire. However, we also show important differences, in particular that the quasi-3D networks are more resilient to changes in the input parameters, generalizing better to noisy training data. Since previous literature suggests that topology plays an important role in computing performance, these results may have important implications for future applications of nanowire networks in neuromorphic computing.}
}
@article{CHOKSI2022538,
title = {Multimodal neural networks better explain multivoxel patterns in the hippocampus},
journal = {Neural Networks},
volume = {154},
pages = {538-542},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002982},
author = {Bhavin Choksi and Milad Mozafari and Rufin VanRullen and Leila Reddy},
keywords = {Multimodal networks, Concept cells, Hippocampus, fMRI, Deep learning, Neuroscience},
abstract = {The human hippocampus possesses “concept cells”, neurons that fire when presented with stimuli belonging to a specific concept, regardless of the modality. Recently, similar concept cells were discovered in a multimodal network called CLIP (Radford et al., 2021). Here, we ask whether CLIP can explain the fMRI activity of the human hippocampus better than a purely visual (or linguistic) model. We extend our analysis to a range of publicly available uni- and multi-modal models. We demonstrate that “multimodality” stands out as a key component when assessing the ability of a network to explain the multivoxel activity in the hippocampus.}
}
@article{XU2022553,
title = {Convergence of deep convolutional neural networks},
journal = {Neural Networks},
volume = {153},
pages = {553-563},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002465},
author = {Yuesheng Xu and Haizhang Zhang},
keywords = {Deep learning, Deep convolutional neural networks, ReLU networks, Activation domains, Infinite product of matrices},
abstract = {Convergence of deep neural networks as the depth of the networks tends to infinity is fundamental in building the mathematical foundation for deep learning. In a previous study, we investigated this question for deep networks with the Rectified Linear Unit (ReLU) activation function and with a fixed width. This does not cover the important convolutional neural networks where the widths are increased from layer to layer. For this reason, we first study convergence of general ReLU networks with increased widths and then apply the results obtained to deep convolutional neural networks. It turns out the convergence reduces to convergence of infinite products of matrices with increased sizes, which has not been considered in the literature. We establish sufficient conditions for convergence of such infinite products of matrices. Based on the conditions, we present sufficient conditions for pointwise convergence of general deep ReLU networks with increasing widths, and as well as pointwise convergence of deep ReLU convolutional neural networks.}
}
@article{ZHAO202250,
title = {LGLNN: Label Guided Graph Learning-Neural Network for few-shot learning},
journal = {Neural Networks},
volume = {155},
pages = {50-57},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003033},
author = {Kangkang Zhao and Ziyan Zhang and Bo Jiang and Jin Tang},
keywords = {Few-shot learning, Graph learning, Graph neural network, Pairwise constraint propagation},
abstract = {Graph Neural Networks (GNNs) have been employed for few-shot learning (FSL) tasks. The aim of GNN based FSL is to transform the few-shot learning problem into a graph node classification or edge labeling tasks, which can thus fully explore the relationships among samples in support and query sets. However, existing works generally consider the graph learned by node features which ignore the initial pairwise label constraints and thus are generally not guaranteed to be optimal for FSL tasks. Also, existing works generally learn graph edges independently based on node’s own features which lack of considering the consistent relationships among different edges. To address these issues, we propose a novel Label Guided Graph Learning-Neural network (LGLNN) model for FSL tasks. The aim of LGLNN is to incorporate the label information to learn an optimal metric graph for GNN by employing the pairwise constraint propagation. The main advantage of LGLNN is that it can learn the metrics (both similarity and dissimilarity) for each graph edge by aggregating the metric information from its neighboring edges and thus can conduct metric learning of all edges cooperatively and consistently. Experimental results demonstrate the effectiveness and better performance of the proposed LGLNN method.}
}
@article{WU2022109,
title = {Reward prediction errors, not sensory prediction errors, play a major role in model selection in human reinforcement learning},
journal = {Neural Networks},
volume = {154},
pages = {109-121},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002581},
author = {Yihao Wu and Masahiko Morita and Jun Izawa},
keywords = {Reinforcement learning, Internal model, Model-based, Bayesian, Policy gradient},
abstract = {Model-based reinforcement learning enables an agent to learn in variable environments and tasks by optimizing its actions based on the predicted states and outcomes. This mechanism has also been considered in the brain. However, exactly how the brain selects an appropriate model for confronting environments has remained unclear. Here, we investigated the model selection algorithm in the human brain during a reinforcement learning task. One primary theory of model selection in the brain is based on sensory prediction errors. Here, we compared this theory with an alternative possibility of internal model selection with reward prediction errors. To compare these two theories, we devised a switching experiment from a first-order Markov decision process to a second-order Markov decision process that provides either reward- or sensory prediction error regarding environmental change. We tested two representative computational models driven by different prediction errors. One is the sensory prediction-error-driven Bayesian algorithm, which has been discussed as a representative internal model selection algorithm in the animal reinforcement learning task. The other is the reward-prediction-error-driven policy gradient algorithm. We compared the simulation results of these two computational models with human reinforcement learning behaviors. The model fitting result supports that the policy gradient algorithm is preferable to the Bayesian algorithm. This suggests that the human brain employs the reward prediction error to select an appropriate internal model in the reinforcement learning task.}
}
@article{MENG2022254,
title = {Training much deeper spiking neural networks with a small number of time-steps},
journal = {Neural Networks},
volume = {153},
pages = {254-268},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002064},
author = {Qingyan Meng and Shen Yan and Mingqing Xiao and Yisen Wang and Zhouchen Lin and Zhi-Quan Luo},
keywords = {Spiking neural networks, ANN-to-SNN conversion, Conversion error analysis},
abstract = {Spiking Neural Network (SNN) is a promising energy-efficient neural architecture when implemented on neuromorphic hardware. The Artificial Neural Network (ANN) to SNN conversion method, which is the most effective SNN training method, has successfully converted moderately deep ANNs to SNNs with satisfactory performance. However, this method requires a large number of time-steps, which hurts the energy efficiency of SNNs. How to effectively covert a very deep ANN (e.g., more than 100 layers) to an SNN with a small number of time-steps remains a difficult task. To tackle this challenge, this paper makes the first attempt to propose a novel error analysis framework that takes both the “quantization error” and the “deviation error” into account, which comes from the discretization of SNN dynamicsthe neuron’s coding scheme and the inconstant input currents at intermediate layers, respectively. Particularly, our theories reveal that the “deviation error” depends on both the spike threshold and the input variance. Based on our theoretical analysis, we further propose the Threshold Tuning and Residual Block Restructuring (TTRBR) method that can convert very deep ANNs (>100 layers) to SNNs with negligible accuracy degradation while requiring only a small number of time-steps. With very deep networks, our TTRBR method achieves state-of-the-art (SOTA) performance on the CIFAR-10, CIFAR-100, and ImageNet classification tasks.}
}
@article{GALMEANU2022528,
title = {Weighted Incremental–Decremental Support Vector Machines for concept drift with shifting window},
journal = {Neural Networks},
volume = {152},
pages = {528-541},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001927},
author = {Honorius Gâlmeanu and Răzvan Andonie},
keywords = {Support Vector Machines, Concept drift, Incremental learning, Shifting window},
abstract = {We study the problem of learning the data samples’ distribution as it changes in time. This change, known as concept drift, complicates the task of training a model, as the predictions become less and less accurate. It is known that Support Vector Machines (SVMs) can learn weighted input instances and that they can also be trained online (incremental–decremental learning). Combining these two SVM properties, the open problem is to define an online SVM concept drift model with shifting weighted window. The classic SVM model should be retrained from scratch after each window shift. We introduce the Weighted Incremental–Decremental SVM (WIDSVM), a generalization of the incremental–decremental SVM for shifting windows. WIDSVM is capable of learning from data streams with concept drift, using the weighted shifting window technique. The soft margin constrained optimization problem imposed on the shifting window is reduced to an incremental–decremental SVM. At each window shift, we determine the exact conditions for vector migration during the incremental–decremental process. We perform experiments on artificial and real-world concept drift datasets; they show that the classification accuracy of WIDSVM significantly improves compared to a SVM with no shifting window. The WIDSVM training phase is fast, since it does not retrain from scratch after each window shift.}
}
@article{REN2022165,
title = {A multi-birth metric learning framework based on binary constraints},
journal = {Neural Networks},
volume = {154},
pages = {165-178},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200260X},
author = {QiangQiang Ren and Chao Yuan and Yifeng Zhao and Liming Yang},
keywords = {Multi-metric learning, Pair constraints, Large margin classification, Alternating iteration algorithm, Classifications},
abstract = {Multi-metric learning plays a significant role in improving the generalization of algorithms related to distance metrics since using a single metric is sometimes insufficient to handle complex data. Metric learning can adjust automatically the distance between samples to make the intra-class samples compact while making the inter-class distance as far as possible. To implement this intention better,in this work, we propose a novel multi-metric learning framework based on the pair constraints instead of triple constraints to reduce computational burden. To solve effectively the problem, we first propose a multi-birth metric learning model (termed MBML), where for each class sample, the global metric and a local metric are jointly trained. Both global and local structural information are adapted to better depict sample information. Then two alternating iterative algorithms are developed to optimize the MBML. The convergence of the proposed algorithm and complexity are analyzed theoretically. Moreover, a fast diagonal multi-metric learning method is proposed based on binary constraints, and problem can be reformulated a linear programming, with fast training speed, low the computational burden and the global optimal solutions. Numerical experiments are carried out on different scales and different types of datasets including an artificial data, benchmark datasets and an image database from binary class and multi-class problems. Experiment results confirm the feasibility and effectiveness of the proposed methods.}
}
@article{WANG2022190,
title = {Subgraph-aware graph structure revision for spatial–temporal graph modeling},
journal = {Neural Networks},
volume = {154},
pages = {190-202},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002738},
author = {Yuhu Wang and Chunxia Zhang and Shiming Xiang and Chunhong Pan},
keywords = {Graph structure learning, Graph neural network, Spatial–temporal graph modeling},
abstract = {Spatial–temporal graph modeling has been widely studied in many fields, such as traffic forecasting and energy analysis, where data has time and space properties. Existing methods focus on capturing stable and dynamic spatial correlations by constructing physical and virtual graphs along with graph convolution and temporal modeling. However, existing methods tending to smooth node features may obscure the spatial–temporal patterns among nodes. Worse, the graph structure is not always available in some fields, while the manually constructed stable or dynamic graphs cannot necessarily reflect the true spatial correlations either. This paper proposes a Subgraph-Aware Graph Structure Revision network (SAGSR) to overcome these limitations. Architecturally, a subgraph-aware structure revision graph convolution module (SASR-GCM) is designed, which revises the learned stable graph to obtain a dynamic one to automatically infer the dynamics of spatial correlations. Each of these two graphs is separated into one homophilic subgraph and one heterophilic subgraph by a subgraph-aware graph convolution mechanism, which aggregates similar nodes in the homophilic subgraph with positive weights, while keeping nodes with dissimilar features in the heterophilic subgraph mutually away with negative aggregation weights to avoid pattern obfuscation. By combining a gated multi-scale temporal convolution module (GMS-TCM) for temporal modeling, SAGSR can efficiently capture the spatial–temporal correlations and extract complex spatial–temporal graph features. Extensive experiments, conducted on two specific tasks: traffic flow forecasting and energy consumption forecasting, indicate the effectiveness and superiority of our proposed approach over several competitive baselines.}
}
@article{HE2022120,
title = {Reducing noisy annotations for depression estimation from facial images},
journal = {Neural Networks},
volume = {153},
pages = {120-129},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200199X},
author = {Lang He and Prayag Tiwari and Chonghua Lv and WenShuai Wu and Liyong Guo},
keywords = {Depression, Self-adaptation network (SAN), Affective computing, Noisy labels},
abstract = {Depression has been considered the most dominant mental disorder over the past few years. To help clinicians effectively and efficiently estimate the severity scale of depression, various automated systems based on deep learning have been proposed. To estimate the severity of depression, i.e., the depression severity score (Beck Depression Inventory-II), various deep architectures have been designed to perform regression using the Euclidean loss. However, they do not consider the label distribution, and they do not learn the relationships between the facial images and BDI-II scores, which can be resulting in the noisy labeling for automatic depression estimation (ADE). To mitigate this problem, we propose an automated deep architecture, namely the self-adaptation network (SAN), to improve this uncertain labeling for ADE. Specifically, the architecture consists of four modules: (1) ResNet-18 and ResNet-50 are adopted in the deep feature extraction module (DFEM) to extract informative deep features; (2) a self-attention module (SAM) is adopted to learn the weights from the mini-batch; (3) a square ranking regularization module (SRRM) to create high partitions and low partitions is proposed; and (4) a re-label module (RM) is used to re-label the uncertain annotations for ADE in the low partitions. We conduct extensive experiments on depression databases (i.e., AVEC2013 and AVEC2014) and obtain a performance comparable to the performances of other ADE methods in assessing the severity of depression. More importantly, the proposed method can learn valuable depression patterns from facial videos and obtain a performance comparable to the performances of other methods for depression recognition.}
}
@article{ROBINSON2022333,
title = {Physics guided neural networks for modelling of non-linear dynamics},
journal = {Neural Networks},
volume = {154},
pages = {333-345},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002854},
author = {Haakon Robinson and Suraj Pawar and Adil Rasheed and Omer San},
keywords = {Physics guided neural networks, Non-linear dynamics, Ordinary differential equations},
abstract = {The success of the current wave of artificial intelligence can be partly attributed to deep neural networks, which have proven to be very effective in learning complex patterns from large datasets with minimal human intervention. However, it is difficult to train these models on complex dynamical systems from data alone due to their low data efficiency and sensitivity to hyperparameters and initialisation. This work demonstrates that injection of partially known information at an intermediate layer in a DNN can improve model accuracy, reduce model uncertainty, and yield improved convergence during the training. The value of these physics-guided neural networks has been demonstrated by learning the dynamics of a wide variety of nonlinear dynamical systems represented by five well-known equations in nonlinear systems theory: the Lotka–Volterra, Duffing, Van der Pol, Lorenz, and Henon–Heiles systems.}
}
@article{MAIMON2022282,
title = {A universal adversarial policy for text classifiers},
journal = {Neural Networks},
volume = {153},
pages = {282-291},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002337},
author = {Gallil Maimon and Lior Rokach},
keywords = {Adversarial learning, NLP, Text classification, Universal adversarial attacks, Reinforcement learning},
abstract = {Discovering the existence of universal adversarial perturbations had large theoretical and practical impacts on the field of adversarial learning. In the text domain, most universal studies focused on adversarial prefixes which are added to all texts. However, unlike the vision domain, adding the same perturbation to different inputs results in noticeably unnatural inputs. Therefore, we introduce a new universal adversarial setup – a universal adversarial policy, which has many advantages of other universal attacks but also results in valid texts – thus making it relevant in practice. We achieve this by learning a single search policy over a predefined set of semantics preserving text alterations, on many texts. This formulation is universal in that the policy is successful in finding adversarial examples on new texts efficiently. Our approach uses text perturbations which were extensively shown to produce natural attacks in the non-universal setup (specific synonym replacements). We suggest a strong baseline approach for this formulation which uses reinforcement learning. Its ability to generalise (from as few as 500 training texts) shows that universal adversarial patterns exist in the text domain as well.}
}
@article{RADMANESH202239,
title = {Online spike sorting via deep contractive autoencoder},
journal = {Neural Networks},
volume = {155},
pages = {39-49},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200301X},
author = {Mohammadreza Radmanesh and Ahmad Asgharian Rezaei and Mahdi Jalili and Alireza Hashemi and Morteza Moazami Goudarzi},
keywords = {Online spike sorting, Deep learning, Clustering, Optimization, Denoising autoencoders},
abstract = {Spike sorting – the process of separating spikes from different neurons – is often the first and most critical step in the neural data analysis pipeline. Spike-sorting techniques isolate a single neuron’s activity from background electrical noise based on the shapes of the waveforms obtained from extracellular recordings. Despite several advancements in this area, an important remaining challenge in neuroscience is online spike sorting, which has the potential to significantly advance basic neuroscience research and the clinical setting by providing the means to produce real-time perturbations of neurons via closed-loop control. Current approaches to online spike sorting are not fully automated, are computationally expensive and are often outperformed by offline approaches. In this paper, we present a novel algorithm for fast and robust online classification of single neuron activity. This algorithm is based on a deep contractive autoencoder (CAE) architecture. CAEs are neural networks that can learn a latent state representation of their inputs. The main advantage of CAE-based approaches is that they are less sensitive to noise (i.e., small perturbations in their inputs). We therefore reasoned that they can form the basis for robust online spike sorting algorithms. Overall, our deep CAE-based online spike sorting algorithm achieves over 90% accuracy in sorting unseen spike waveforms, outperforming existing models and maintaining a performance close to the offline case. In the offline scenario, our method substantially outperforms the existing models, providing an average improvement of 40% in accuracy over different datasets.}
}
@article{CAO2022141,
title = {QMEDNet: A quaternion-based multi-order differential encoder–decoder model for 3D human motion prediction},
journal = {Neural Networks},
volume = {154},
pages = {141-151},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002611},
author = {Wenming Cao and Shuangshuang Li and Jianqi Zhong},
keywords = {Human motion predicting, Quaternion, Graph neural networks},
abstract = {In order to deal with the sequence information in the task of 3D human motion prediction effectively, many previous methods seek to predict the motion state of the next moment using the traditional recurrent neural network in Euclidean space. However human motion representation in Euclidean space has high distortion and shows a weak semantic expression when using deep learning models. In this work, we try to process human motion by mapping Euclidean space into a Hypercomplex vector space. We propose a novel model based on quaternion to predict the three-dimensional motion of a human body. The core idea of this study is to use the fusion information to understand and process the human motion state in quaternion space. The multi-order differential information is fused both in the encoder and decoder of feature extraction and mapped to the quaternion space, respectively. The encoder takes graph convolution as the basic unit and the decoder adopts gated recurrent units. Numerous experiments have been carried out to prove that the multi-order information in quaternion space can help build a more reasonable description for 3D human motion. The performance of the proposed QMEDNet is superior to most of the advanced short and long-term motion prediction methods in both public datasets, Human 3.6M and CMU Mocap.}
}
@article{TIAN2022487,
title = {GIU-GANs: Global Information Utilization for Generative Adversarial Networks},
journal = {Neural Networks},
volume = {152},
pages = {487-498},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001885},
author = {Yongqi Tian and Xueyuan Gong and Jialin Tang and Binghua Su and Xiaoxiang Liu and Xinyuan Zhang},
keywords = {Image generation, Generative Adversarial Networks, Global Information Utilization, Involution, Representative Batch Normalization},
abstract = {Recently, with the rapid development of artificial intelligence, image generation based on deep learning has advanced significantly. Image generation based on Generative Adversarial Networks (GANs) is a promising study. However, because convolutions are limited by spatial-agnostic and channel-specific, features extracted by conventional GANs based on convolution are constrained. Therefore, GANs cannot capture in-depth details per image. Moreover, straightforwardly stacking of convolutions causes too many parameters and layers in GANs, yielding a high overfitting risk. To overcome the abovementioned limitations, in this study, we propose a GANs called GIU-GANs (where Global Information Utilization: GIU). GIU-GANs leverages a new module called the GIU module, which integrates the squeeze-and-excitation module and involution to focus on global information via the channel attention mechanism, enhancing the generated image quality. Moreover, Batch Normalization (BN) inevitably ignores the representation differences among noise sampled by the generator and thus degrades the generated image quality. Thus, we introduce the representative BN to the GANs’ architecture. The CIFAR-10 and CelebA datasets are employed to demonstrate the effectiveness of the proposed model. Numerous experiments indicate that the proposed model achieves state-of-the-art performance.}
}
@article{SUN2022179,
title = {Face image-sketch synthesis via generative adversarial fusion},
journal = {Neural Networks},
volume = {154},
pages = {179-189},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002696},
author = {Jianyuan Sun and Hongchuan Yu and Jian J. Zhang and Junyu Dong and Hui Yu and Guoqiang Zhong},
keywords = {U-net generator, Illumination distribution layer, Attention mechanism, Generated face image},
abstract = {Face image-sketch synthesis is widely applied in law enforcement and digital entertainment fields. Despite the extensive progression in face image-sketch synthesis, there are few methods focusing on generating a color face image from a sketch. The existing methods pay less attention to learning the illumination or highlight distribution on the face region. However, the illumination is the key factor that makes the generated color face image looks vivid and realistic. Moreover, existing methods tend to employ some image preprocessing technologies and facial region patching approaches to generate high-quality face images, which results in the high complexity and memory consumption in practice. In this paper, we propose a novel end-to-end generative adversarial fusion model, called GAF, which fuses two U-Net generators and a discriminator by jointly learning the content and adversarial loss functions. In particular, we propose a parametric tanh activation function to learn and control illumination highlight distribution over faces, which is integrated between the two U-Net generators by an illumination distribution layer. Additionally, we fuse the attention mechanism into the second U-Net generator of GAF to keep the identity consistency and refine the generated facial details. The qualitative and quantitative experiments on the public benchmark datasets show that the proposed GAF has better performance than existing image-sketch synthesis methods in synthesized face image quality (FSIM) and face recognition accuracy (NLDA). Meanwhile, the good generalization ability of GAF has also been verified. To further demonstrate the reliability and authenticity of face images generated using GAF, we use the generated face image to attack the well-known face recognition system. The result shows that the face images generated by GAF can maintain identity consistency and well maintain everyone’s unique facial characteristics, which can be further used in the benchmark of facial spoofing. Moreover, the experiments are implemented to verify the effectiveness and rationality of the proposed parametric tanh activation function and attention mechanism in GAF.}
}
@article{DUAN2022481,
title = {Multivariate time-series classification with hierarchical variational graph pooling},
journal = {Neural Networks},
volume = {154},
pages = {481-490},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002970},
author = {Ziheng Duan and Haoyan Xu and Yueyang Wang and Yida Huang and Anni Ren and Zhongbin Xu and Yizhou Sun and Wei Wang},
keywords = {Multivariate time series classification, Graph neural networks, Graph pooling, Graph classification},
abstract = {In recent years, multivariate time-series classification (MTSC) has attracted considerable attention owing to the advancement of sensing technology. Existing deep-learning-based MTSC techniques, which mostly rely on convolutional or recurrent neural networks, focus primarily on the temporal dependency of a single time series. Based on this, complex pairwise dependencies among multivariate variables can be better described using advanced graph methods, where each variable is regarded as a node in the graph, and their dependencies are regarded as edges. Furthermore, current spatial–temporal modeling (e.g., graph classification) methodologies based on graph neural networks (GNNs) are inherently flat and cannot hierarchically aggregate node information. To address these limitations, we propose a novel graph-pooling-based framework, MTPool, to obtain an expressive global representation of MTS. We first convert MTS slices into graphs using the interactions of variables via a graph structure learning module and obtain the spatial–temporal graph node features via a temporal convolutional module. To obtain global graph-level representation, we design an “encoder-decoder”-based variational graph pooling module to create adaptive centroids for cluster assignments. Then, we combine GNNs and our proposed variational graph pooling layers for joint graph representation learning and graph coarsening, after which the graph is progressively coarsened to one node. Finally, a differentiable classifier uses this coarsened representation to obtain the final predicted class. Experiments on ten benchmark datasets showed that MTPool outperforms state-of-the-art strategies in the MTSC task.}
}
@article{AVOLA2022386,
title = {SIRe-Networks: Convolutional neural networks architectural extension for information preservation via skip/residual connections and interlaced auto-encoders},
journal = {Neural Networks},
volume = {153},
pages = {386-398},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002453},
author = {Danilo Avola and Luigi Cinque and Alessio Fagioli and Gian Luca Foresti},
keywords = {Neural network architectures, Multi-task learning, Deep learning, Object classification},
abstract = {Improving existing neural network architectures can involve several design choices such as manipulating the loss functions, employing a diverse learning strategy, exploiting gradient evolution at training time, optimizing the network hyper-parameters, or increasing the architecture depth. The latter approach is a straightforward solution, since it directly enhances the representation capabilities of a network; however, the increased depth generally incurs in the well-known vanishing gradient problem. In this paper, borrowing from different methods addressing this issue, we introduce an interlaced multi-task learning strategy, defined SIRe, to reduce the vanishing gradient in relation to the object classification task. The presented methodology directly improves a convolutional neural network (CNN) by preserving information from the input image through interlaced auto-encoders (AEs), and further refines the base network architecture by means of skip and residual connections. To validate the presented methodology, a simple CNN and various implementations of famous networks are extended via the SIRe strategy and extensively tested on five collections, i.e., MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100, and Caltech-256; where the SIRe-extended architectures achieve significantly increased performances across all models and datasets, thus confirming the presented approach effectiveness.}
}
@article{CHRAIBIKAADOUD202295,
title = {Explaining Aha! moments in artificial agents through IKE-XAI: Implicit Knowledge Extraction for eXplainable AI},
journal = {Neural Networks},
volume = {155},
pages = {95-118},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003021},
author = {Ikram {Chraibi Kaadoud} and Adrien Bennetot and Barbara Mawhin and Vicky Charisi and Natalia Díaz-Rodríguez},
keywords = {Explainable AI, Reinforcement learning, Cognitive modeling, Developmental robotics, Post-hoc rule extraction, Knowledge extraction},
abstract = {During the learning process, a child develops a mental representation of the task he or she is learning. A Machine Learning algorithm develops also a latent representation of the task it learns. We investigate the development of the knowledge construction of an artificial agent through the analysis of its behavior, i.e., its sequences of moves while learning to perform the Tower of Hanoï (TOH) task. The TOH is a well-known task in experimental contexts to study the problem-solving processes and one of the fundamental processes of children’s knowledge construction about their world. We position ourselves in the field of explainable reinforcement learning for developmental robotics, at the crossroads of cognitive modeling and explainable AI. Our main contribution proposes a 3-step methodology named Implicit Knowledge Extraction with eXplainable Artificial Intelligence (IKE-XAI) to extract the implicit knowledge, in form of an automaton, encoded by an artificial agent during its learning. We showcase this technique to solve and explain the TOH task when researchers have only access to moves that represent observational behavior as in human–machine interaction. Therefore, to extract the agent acquired knowledge at different stages of its training, our approach combines: first, a Q-learning agent that learns to perform the TOH task; second, a trained recurrent neural network that encodes an implicit representation of the TOH task; and third, an XAI process using a post-hoc implicit rule extraction algorithm to extract finite state automata. We propose using graph representations as visual and explicit explanations of the behavior of the Q-learning agent. Our experiments show that the IKE-XAI approach helps understanding the development of the Q-learning agent behavior by providing a global explanation of its knowledge evolution during learning. IKE-XAI also allows researchers to identify the agent’s Aha! moment by determining from what moment the knowledge representation stabilizes and the agent no longer learns.}
}
@article{LIU2022152,
title = {A new predefined-time stability theorem and its application in the synchronization of memristive complex-valued BAM neural networks},
journal = {Neural Networks},
volume = {153},
pages = {152-163},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002052},
author = {Aidi Liu and Hui Zhao and Qingjie Wang and Sijie Niu and Xizhan Gao and Chuan Chen and Lixiang Li},
keywords = {Complex-valued neural networks, Bidirectional associative memory neural networks, Memristor, Predefined-time stability},
abstract = {In this paper, two novel and general predefined-time stability lemmas are given and applied to the predefined-time synchronization problem of memristive complex-valued bidirectional associative memory neural networks (MCVBAMNNs). Firstly, different from the generally fixed-time stability lemma, the setting of an adjustable time parameter in the derived predefined-time stability lemma causes it to be more flexible and more general. Secondly, the model studied in the complex-valued BAM neural networks model, which is different from the previous discussion of the real part and imaginary part respectively. It is more practical to study the complex-valued nonseparation. Thirdly, two effective controllers are designed to realize the synchronization performance of BAM neural networks based on the predefined-time stability, and the analysis is given based on general predefined-time synchronization. Finally, the correctness of the theoretical derivation is verified by numerical simulation. A secure communication scheme based on predefined-time synchronization of MCVBAMNNs is proposed, and the effectiveness and superiority of the results are proved.}
}
@article{MALIK2022325,
title = {From YouTube to the brain: Transfer learning can improve brain-imaging predictions with deep learning},
journal = {Neural Networks},
volume = {153},
pages = {325-338},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002295},
author = {Nahiyan Malik and Danilo Bzdok},
keywords = {Imaging neuroscience, Brain imaging, Deep learning, Transfer learning, Convolutional neural network algorithms, Machine learning},
abstract = {Deep learning has recently achieved best-in-class performance in several fields, including biomedical domains such as X-ray images. Yet, data scarcity poses a strict limit on training successful deep learning systems in many, if not most, biomedical applications, including those involving brain images. In this study, we translate state-of-the-art transfer learning techniques for single-subject prediction of simpler (sex and age) and more complex phenotypes (number of people in household, household income, fluid intelligence and smoking behavior). We fine-tuned 2D and 3D ResNet-18 convolutional neural networks for target phenotype predictions from brain images of ∼40,000 UK Biobank participants, after pretraining on YouTube videos from the Kinetics dataset and natural images from the ImageNet dataset. Transfer learning was effective on several phenotypes, especially sex and age classification. Additionally, transfer learning in particular outperformed deep learning models trained from scratch especially on smaller sample sizes. The out-of-sample performance using transfer learning from previously learned knowledge based on real-world images and videos could unlock the potential in many areas of imaging neuroscience where deep learning solutions are currently infeasible.}
}