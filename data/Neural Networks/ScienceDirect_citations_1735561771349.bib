@article{2022I,
title = {Current Events},
journal = {Neural Networks},
volume = {153},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00291-X},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200291X}
}
@article{HU2021229,
title = {DMMAN: A two-stage audio–visual fusion framework for sound separation and event localization},
journal = {Neural Networks},
volume = {133},
pages = {229-239},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303580},
author = {Ruihan Hu and Songbing Zhou and Zhi Ri Tang and Sheng Chang and Qijun Huang and Yisen Liu and Wei Han and Edmond Q. Wu},
keywords = {Two-stage fusion, Audio–visual tasks, Sound source separation, Sound event localization},
abstract = {Videos are used widely as the media platforms for human beings to touch the physical change of the world. However, we always receive the mixed sound from the multiple sound objects, and cannot distinguish and localize the sounds as the separate entities in videos. In order to solve this problem, a model named the Deep Multi-Modal Attention Network (DMMAN), is established to model the unconstrained video datasets for further finishing the sound source separation and event localization tasks in this paper. Based on the multi-modal separator and multi-modal matching classifier module, our model focuses on the sound separation and modal synchronization problems using two stage fusion of the sound and visual features. To link the multi-modal separator and multi-modal matching classifier modules, the regression and classification losses are employed to build the loss function of the DMMAN. The estimated spectrum masks and attention synchronization scores calculated by the DMMAN can be easily generalized to the sound source and event localization tasks. The quantitative experimental results show the DMMAN not only separates the high quality of the sound sources evaluated by Signal-to-Distortion Ratio and Signal-to-Interference Ratio metrics, but also is suitable for the mixed sound scenes that are never heard jointly. Meanwhile, DMMAN achieves better classification accuracy than other contrast baselines for the event localization tasks.}
}
@article{JIN2020166,
title = {SympNets: Intrinsic structure-preserving symplectic networks for identifying Hamiltonian systems},
journal = {Neural Networks},
volume = {132},
pages = {166-179},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303063},
author = {Pengzhan Jin and Zhen Zhang and Aiqing Zhu and Yifa Tang and George Em Karniadakis},
keywords = {Deep learning, Physics-informed, Dynamical systems, Hamiltonian systems, Symplectic maps, Symplectic integrators},
abstract = {We propose new symplectic networks (SympNets) for identifying Hamiltonian systems from data based on a composition of linear, activation and gradient modules. In particular, we define two classes of SympNets: the LA-SympNets composed of linear and activation modules, and the G-SympNets composed of gradient modules. Correspondingly, we prove two new universal approximation theorems that demonstrate that SympNets can approximate arbitrary symplectic maps based on appropriate activation functions. We then perform several experiments including the pendulum, double pendulum and three-body problems to investigate the expressivity and the generalization ability of SympNets. The simulation results show that even very small size SympNets can generalize well, and are able to handle both separable and non-separable Hamiltonian systems with data points resulting from short or long time steps. In all the test cases, SympNets outperform the baseline models, and are much faster in training and prediction. We also develop an extended version of SympNets to learn the dynamics from irregularly sampled data. This extended version of SympNets can be thought of as a universal model representing the solution to an arbitrary Hamiltonian system.}
}
@article{2023ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {157},
pages = {ii},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00482-8},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004828}
}
@article{XI202075,
title = {Exploiting bi-directional global transition patterns and personal preferences for missing POI category identification},
journal = {Neural Networks},
volume = {132},
pages = {75-83},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030304X},
author = {Dongbo Xi and Fuzhen Zhuang and Yanchi Liu and Hengshu Zhu and Pengpeng Zhao and Chang Tan and Qing He},
keywords = {Global transition patterns, Personal preferences, Missing POI category identification},
abstract = {Recent years have witnessed the increasing popularity of Location-based Social Network (LBSN) services, which provides unparalleled opportunities to build personalized Point-of-Interest (POI) recommender systems. Existing POI recommendation and location prediction tasks utilize past information for future recommendation or prediction from a single direction perspective, while the missing POI category identification task needs to utilize the check-in information both before and after the missing category. Therefore, a long-standing challenge is how to effectively identify the missing POI categories at any time in the real-world check-in data of mobile users. To this end, in this paper, we propose a novel neural network approach to identify the missing POI categories by integrating both bi-directional global non-personal transition patterns and personal preferences of users. Specifically, we delicately design an attention matching cell to model how well the check-in category information matches their non-personal transition patterns and personal preferences. Finally, we evaluate our model on two real-world datasets, which clearly validate its effectiveness compared with the state-of-the-art baselines. Furthermore, our model can be naturally extended to address next POI category recommendation and prediction tasks with competitive performance.}
}
@article{2022II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {153},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00292-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002921}
}
@article{2022II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {155},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00397-5},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003975}
}
@article{VARSEHI2021193,
title = {An EEG channel selection method for motor imagery based brain–computer interface and neurofeedback using Granger causality},
journal = {Neural Networks},
volume = {133},
pages = {193-206},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303853},
author = {Hesam Varsehi and S. Mohammad P. Firoozabadi},
keywords = {Motor imagery (MI), Electroencephalogram (EEG), EEG channel selection, Granger causality, Neurofeedback, Brain–computer interface (BCI)},
abstract = {Motor imagery (MI) brain–computer interface (BCI) and neurofeedback (NF) with electroencephalogram (EEG) signals are commonly used for motor function improvement in healthy subjects and to restore neurological functions in stroke patients. Generally, in order to decrease noisy and redundant information in unrelated EEG channels, channel selection methods are used which provide feasible BCI and NF implementations with better performances. Our assumption is that there are causal interactions between the channels of EEG signal in MI tasks that are repeated in different trials of a BCI and NF experiment. Therefore, a novel method for EEG channel selection is proposed which is based on Granger causality (GC) analysis. Additionally, the machine-learning approach is used to cluster independent component analysis (ICA) components of the EEG signal into artifact and normal EEG clusters. After channel selection, using the common spatial pattern (CSP) and regularized CSP (RCSP), features are extracted and with the k-nearest neighbor (k-NN), support vector machine (SVM) and linear discriminant analysis (LDA) classifiers, MI tasks are classified into left and right hand MI. The goal of this study is to achieve a method resulting in lower EEG channels with higher classification performance in MI-based BCI and NF by causal constraint. The proposed method based on GC, with only eight selected channels, results in 93.03% accuracy, 92.93% sensitivity, and 93.12% specificity, with RCSP feature extractor and best classifier for each subject, after being applied on Physionet MI dataset, which is increased by 3.95%, 3.73%, and 4.13%, in comparison with correlation-based channel selection method.}
}
@article{OU2020333,
title = {Multi-label zero-shot learning with graph convolutional networks},
journal = {Neural Networks},
volume = {132},
pages = {333-341},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303336},
author = {Guangjin Ou and Guoxian Yu and Carlotta Domeniconi and Xuequan Lu and Xiangliang Zhang},
keywords = {Zero-shot learning, Graph Convolutional Networks, Multi-label classification, Label correlations},
abstract = {The goal of zero-shot learning (ZSL) is to build a classifier that recognizes novel categories with no corresponding annotated training data. The typical routine is to transfer knowledge from seen classes to unseen ones by learning a visual-semantic embedding. Existing multi-label zero-shot learning approaches either ignore correlations among labels, suffer from large label combinations, or learn the embedding using only local or global visual features. In this paper, we propose a Graph Convolution Networks based Multi-label Zero-Shot Learning model, abbreviated as MZSL-GCN. Our model first constructs a label relation graph using label co-occurrences and compensates the absence of unseen labels in the training phase by semantic similarity. It then takes the graph and the word embedding of each seen (unseen) label as inputs to the GCN to learn the label semantic embedding, and to obtain a set of inter-dependent object classifiers. MZSL-GCN simultaneously trains another attention network to learn compatible local and global visual features of objects with respect to the classifiers, and thus makes the whole network end-to-end trainable. In addition, the use of unlabeled training data can reduce the bias toward seen labels and boost the generalization ability. Experimental results on benchmark datasets show that our MZSL-GCN competes with state-of-the-art approaches.}
}
@article{MAATTA2021123,
title = {Gradient-based training and pruning of radial basis function networks with an application in materials physics},
journal = {Neural Networks},
volume = {133},
pages = {123-131},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303579},
author = {Jussi Määttä and Viacheslav Bazaliy and Jyri Kimari and Flyura Djurabekova and Kai Nordlund and Teemu Roos},
keywords = {Radial basis function networks, Pruning, Interpretability, Materials physics},
abstract = {Many applications, especially in physics and other sciences, call for easily interpretable and robust machine learning techniques. We propose a fully gradient-based technique for training radial basis function networks with an efficient and scalable open-source implementation. We derive novel closed-form optimization criteria for pruning the models for continuous as well as binary data which arise in a challenging real-world material physics problem. The pruned models are optimized to provide compact and interpretable versions of larger models based on informed assumptions about the data distribution. Visualizations of the pruned models provide insight into the atomic configurations that determine atom-level migration processes in solid matter; these results may inform future research on designing more suitable descriptors for use with machine learning algorithms.}
}
@article{ZIAEEMEHR2020155,
title = {Frequency-dependent organization of the brain’s functional network through delayed-interactions},
journal = {Neural Networks},
volume = {132},
pages = {155-165},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302926},
author = {Abolfazl Ziaeemehr and Mina Zarei and Alireza Valizadeh and Claudio R. Mirasso},
keywords = {Connectome, Functional network, Hierarchical network, Delayed interaction},
abstract = {The structure of the brain network exhibits modularity at multiple spatial scales. The effect of the modular structure on the brain dynamics has been the focus of several studies in recent years but many aspects remain to be explored. For example, it is not well-known how the delays in the transmission of signals between the neurons and the brain regions interact with the modular structure to determine the brain dynamics. In this paper, we show an important impact of the delays on the collective dynamics of brain networks with modular structure; that is, the degree of the synchrony between different brain regions depends on the oscillating frequency. In particular, we show that when increasing the frequency of the nodes the network transits from a global synchrony state to an asynchronous state, through a transition region over which the local synchrony inside the modules is stronger than the global synchrony. When the delays depend on the distance between the nodes, the modular structure of different spatial scales appears in the correlation matrix over different specific frequency bands, so that, finer spatial modular structures reveal in higher frequency bands. The results are corroborated by a simple theoretical argument and elaborated by simulations on several simplified modular networks and the connectome with different spatial resolutions.}
}
@article{SUH202169,
title = {CEGAN: Classification Enhancement Generative Adversarial Networks for unraveling data imbalance problems},
journal = {Neural Networks},
volume = {133},
pages = {69-86},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303592},
author = {Sungho Suh and Haebom Lee and Paul Lukowicz and Yong Oh Lee},
keywords = {Imbalanced classification, Data augmentation, Generative adversarial networks, Classification enhancement, Ambiguous classes},
abstract = {The data imbalance problem in classification is a frequent but challenging task. In real-world datasets, numerous class distributions are imbalanced and the classification result under such condition reveals extreme bias in the majority data class. Recently, the potential of GAN as a data augmentation method on minority data has been studied. In this paper, we propose a classification enhancement generative adversarial networks (CEGAN) to enhance the quality of generated synthetic minority data and more importantly, to improve the prediction accuracy in data imbalanced condition. In addition, we propose an ambiguity reduction method using the generated synthetic minority data for the case of multiple similar classes that are degenerating the classification accuracy. The proposed method is demonstrated with five benchmark datasets. The results indicate that approximating the real data distribution using CEGAN improves the classification performance significantly in data imbalanced conditions compared with various standard data augmentation methods.}
}
@article{MHASKAR2020253,
title = {A direct approach for function approximation on data defined manifolds},
journal = {Neural Networks},
volume = {132},
pages = {253-268},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303075},
author = {H.N. Mhaskar},
keywords = {Manifold learning, Deep networks, Gaussian networks, Weighted polynomial approximation},
abstract = {In much of the literature on function approximation by deep networks, the function is assumed to be defined on some known domain, such as a cube or a sphere. In practice, the data might not be dense on these domains, and therefore, the approximation theory results are observed to be too conservative. In manifold learning, one assumes instead that the data is sampled from an unknown manifold; i.e., the manifold is defined by the data itself. Function approximation on this unknown manifold is then a two stage procedure: first, one approximates the Laplace–Beltrami operator (and its eigen-decomposition) on this manifold using a graph Laplacian, and next, approximates the target function using the eigen-functions. Alternatively, one estimates first some atlas on the manifold and then uses local approximation techniques based on the local coordinate charts. In this paper, we propose a more direct approach to function approximation on unknown, data defined manifolds without computing the eigen-decomposition of some operator or an atlas for the manifold, and without any kind of training in the classical sense. Our constructions are universal; i.e., do not require the knowledge of any prior on the target function other than continuity on the manifold. We estimate the degree of approximation. For smooth functions, the estimates do not suffer from the so-called saturation phenomenon. We demonstrate via a property called good propagation of errors how the results can be lifted for function approximation using deep networks where each channel evaluates a Gaussian network on a possibly unknown manifold.}
}
@article{2022II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {150},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00130-7},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001307}
}
@article{SHAO202132,
title = {Prespecified-time synchronization of switched coupled neural networks via smooth controllers},
journal = {Neural Networks},
volume = {133},
pages = {32-39},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303622},
author = {Shao Shao and Xiaoyang Liu and Jinde Cao},
keywords = {Coupled neural networks, Finite-time synchronization, Prespecified-time synchronization, Smooth controllers},
abstract = {This paper considers the prespecified-time synchronization issue of switched coupled neural networks (SCNNs) under some smooth controllers. Different from the traditional finite-time synchronization (FTS), the synchronization time obtained in this paper is independent of control gains, initial values or network topology, which can be pre-set as to the task requirements. Moreover, unlike the existing nonsmooth or even discontinuous FTS control strategies, the new proposed control protocols are fully smooth, which abandon the common fractional power feedbacks or signum functions. Finally, two illustrative examples are provided to illustrate the effectiveness of the theoretical results.}
}
@article{XIE2020180,
title = {MGAT: Multi-view Graph Attention Networks},
journal = {Neural Networks},
volume = {132},
pages = {180-189},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303105},
author = {Yu Xie and Yuanqiao Zhang and Maoguo Gong and Zedong Tang and Chao Han},
keywords = {Multi-view networks, Attention, Graph embedding},
abstract = {Multi-view graph embedding is aimed at learning low-dimensional representations of nodes that capture various relationships in a multi-view network, where each view represents a type of relationship among nodes. Multitudes of existing graph embedding approaches concentrate on single-view networks, that can only characterize one simple type of proximity relationships among objects. However, most of the real-world complex systems possess multiple types of relationships among entities. In this paper, a novel approach of graph embedding for multi-view networks is proposed, named Multi-view Graph Attention Networks (MGAT). We explore an attention-based architecture for learning node representations from each single view, the network parameters of which are constrained by a novel regularization term. In order to collaboratively integrate multiple types of relationships in different views, a view-focused attention method is explored to aggregate the view-wise node representations. We evaluate the proposed algorithm on several real-world datasets, and it demonstrates that the proposed approach outperforms existing state-of-the-art baselines.}
}
@article{2022I,
title = {CURRENT EVENTS},
journal = {Neural Networks},
volume = {155},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00396-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003963}
}
@article{LI2020364,
title = {Dual-regression model for visual tracking},
journal = {Neural Networks},
volume = {132},
pages = {364-374},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303348},
author = {Xin Li and Qiao Liu and Nana Fan and Zikun Zhou and Zhenyu He and Xiao-yuan Jing},
keywords = {Object tracking, Regression tracking model, Full convolutional network},
abstract = {Existing regression based tracking methods built on correlation filter model or convolution model do not take both accuracy and robustness into account at the same time. In this paper, we propose a dual-regression framework comprising a discriminative fully convolutional module and a fine-grained correlation filter component for visual tracking. The convolutional module trained in a classification manner with hard negative mining ensures the discriminative ability of the proposed tracker, which facilitates the handling of several challenging problems, such as drastic deformation, distractors, and complicated backgrounds. The correlation filter component built on the shallow features with fine-grained features enables accurate localization. By fusing these two branches in a coarse-to-fine manner, the proposed dual-regression tracking framework achieves a robust and accurate tracking performance. Extensive experiments on the OTB2013, OTB2015, and VOT2015 datasets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods.}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {155},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00401-4},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004014}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {150},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00126-5},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001265}
}
@article{2023xii,
title = {Neural Networks Referees in 2022},
journal = {Neural Networks},
volume = {157},
pages = {xii-xl},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00489-0},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004890}
}
@article{YANG202030,
title = {Event-driven H∞ control with critic learning for nonlinear systems},
journal = {Neural Networks},
volume = {132},
pages = {30-42},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302938},
author = {Xiong Yang and Zhongke Gao and Jinhui Zhang},
keywords = {Adaptive critic designs, Critic learning, Event-driven  control, Neural network control, Reinforcement learning},
abstract = {In this paper, we study an event-driven H∞ control problem of continuous-time nonlinear systems. Initially, with the introduction of a discounted cost function, we convert the nonlinear H∞ control problem into an event-driven nonlinear two-player zero-sum game. Then, we develop an event-driven Hamilton–Jacobi–Isaacs equation (HJIE) related to the two-player zero-sum game. After that, we propose a novel event-triggering condition guaranteeing Zeno behavior not to happen. The triggering threshold in the newly proposed event-triggering condition can be kept positive without requiring to properly choose the prescribed level of disturbance attenuation. To solve the event-driven HJIE, we employ an adaptive critic architecture which contains a unique critic neural network (NN). The weight parameters used in the critic NN are tuned via the gradient descent method. After that, we carry out stability analysis of the hybrid closed-loop system based on Lyapunov’s direct approach. Finally, we provide two nonlinear plants, including the pendulum system, to validate the proposed event-driven H∞ control scheme.}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {153},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00282-9},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002829}
}
@article{SALAZARGONZALEZ2020297,
title = {Real-time gun detection in CCTV: An open problem},
journal = {Neural Networks},
volume = {132},
pages = {297-308},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303361},
author = {Jose L. Salazar González and Carlos Zaccaro and Juan A. Álvarez-García and Luis M. Soria Morillo and Fernando Sancho Caparrini},
keywords = {Deep learning, Convolutional neural network, Weapon detection, Feature Pyramid Network, Synthetic data, Data augmentation},
abstract = {Object detectors have improved in recent years, obtaining better results and faster inference time. However, small object detection is still a problem that has not yet a definitive solution. The autonomous weapons detection on Closed-circuit television (CCTV) has been studied recently, being extremely useful in the field of security, counter-terrorism, and risk mitigation. This article presents a new dataset obtained from a real CCTV installed in a university and the generation of synthetic images, to which Faster R-CNN was applied using Feature Pyramid Network with ResNet-50 resulting in a weapon detection model able to be used in quasi real-time CCTV (90 ms of inference time with an NVIDIA GeForce GTX-1080Ti card) improving the state of the art on weapon detection in a two stages training. In this work, an exhaustive experimental study of the detector with these datasets was performed, showing the impact of synthetic datasets on the training of weapons detection systems, as well as the main limitations that these systems present nowadays. The generated synthetic dataset and the real CCTV dataset are available to the whole research community.}
}
@article{XU2020245,
title = {Low-rank tensor constrained co-regularized multi-view spectral clustering},
journal = {Neural Networks},
volume = {132},
pages = {245-252},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303087},
author = {Huiling Xu and Xiangdong Zhang and Wei Xia and Quanxue Gao and Xinbo Gao},
keywords = {Multi-views learning, Spectral clustering, Weighted tensor nuclear norm},
abstract = {Due to the efficiency of exploiting relationships and complex structures hidden in multi-views data, graph-oriented clustering methods have achieved remarkable progress in recent years. But most existing graph-based spectral methods still have the following demerits: (1) They regularize each view equally, which does not make sense in real applications. (2) By employing different norms, most existing methods calculate the error feature by feature, resulting in neglecting the spatial structure information and the complementary information. To tackle the aforementioned drawbacks, we propose an enhanced multi-view spectral clustering model. Our model characterizes the consistency among indicator matrices by minimizing our proposed weighted tensor nuclear norm, which explicitly exploits the salient different information between singular values of the matrix. Moreover, our model adaptively assigns a reasonable weight to each view, which helps improve robustness of the algorithm. Finally, the proposed tensor nuclear norm well exploits both high-order and complementary information, which helps mine the consistency between indicator matrices. Extensive experiments indicate the efficiency of our method.}
}
@article{LETHI2020220,
title = {Stochastic DCA for minimizing a large sum of DC functions with application to multi-class logistic regression},
journal = {Neural Networks},
volume = {132},
pages = {220-231},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303233},
author = {Hoai An {Le Thi} and Hoai Minh Le and Duy Nhat Phan and Bach Tran},
keywords = {Large sum of DC functions, DC programming, DCA, Stochastic DCA, Inexact stochastic DCA, Multi-class logistic regression},
abstract = {We consider the large sum of DC (Difference of Convex) functions minimization problem which appear in several different areas, especially in stochastic optimization and machine learning. Two DCA (DC Algorithm) based algorithms are proposed: stochastic DCA and inexact stochastic DCA. We prove that the convergence of both algorithms to a critical point is guaranteed with probability one. Furthermore, we develop our stochastic DCA for solving an important problem in multi-task learning, namely group variables selection in multi class logistic regression. The corresponding stochastic DCA is very inexpensive, all computations are explicit. Numerical experiments on several benchmark datasets and synthetic datasets illustrate the efficiency of our algorithms and their superiority over existing methods, with respect to classification accuracy, sparsity of solution as well as running time.}
}
@article{2022I,
title = {Current Events},
journal = {Neural Networks},
volume = {151},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00168-X},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200168X}
}
@article{XIAO202187,
title = {Improved approach to the problem of the global Mittag-Leffler synchronization for fractional-order multidimension-valued BAM neural networks based on new inequalities},
journal = {Neural Networks},
volume = {133},
pages = {87-100},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303634},
author = {Jianying Xiao and Shouming Zhong and Shiping Wen},
keywords = {Quaternion-valued neural networks, Complex-valued neural networks, Bidirectional associative memory, Synchronization},
abstract = {This paper studies the problem of the global Mittag-Leffler synchronization for fractional-order multidimension-valued BAM neural networks (FOMVBAMNNs) with general activation functions (AFs). First, the unified model is established for the researched systems of FOMVBAMNNs which can be turned into the corresponding multidimension-valued systems as long as the state variables, the connection weights and the AFs of the neural networks are valued to be real, complex, or quaternion. Then, without any decomposition, the criteria in unified form are derived by constructing the new Lyapunov–Krasovskii functionals (LKFs) in vector form, combining two new inequalities and considering the easy controllers. It is worth mentioning that the obtained criteria have many advantages in higher flexibility, more diversity, smaller computation, and lower conservatism. Finally, a simulation example is provided to illustrate the availability and improvements of the acquired results.}
}
@article{ADVANI2020428,
title = {High-dimensional dynamics of generalization error in neural networks},
journal = {Neural Networks},
volume = {132},
pages = {428-446},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303117},
author = {Madhu S. Advani and Andrew M. Saxe and Haim Sompolinsky},
keywords = {Neural networks, Generalization error, Random matrix theory},
abstract = {We perform an analysis of the average generalization dynamics of large neural networks trained using gradient descent. We study the practically-relevant “high-dimensional” regime where the number of free parameters in the network is on the order of or even larger than the number of examples in the dataset. Using random matrix theory and exact solutions in linear models, we derive the generalization error and training error dynamics of learning and analyze how they depend on the dimensionality of data and signal to noise ratio of the learning problem. We find that the dynamics of gradient descent learning naturally protect against overtraining and overfitting in large networks. Overtraining is worst at intermediate network sizes, when the effective number of free parameters equals the number of samples, and thus can be reduced by making a network smaller or larger. Additionally, in the high-dimensional regime, low generalization error requires starting with small initial weights. We then turn to non-linear neural networks, and show that making networks very large does not harm their generalization performance. On the contrary, it can in fact reduce overtraining, even without early stopping or regularization of any sort. We identify two novel phenomena underlying this behavior in overcomplete models: first, there is a frozen subspace of the weights in which no learning occurs under gradient descent; and second, the statistical properties of the high-dimensional regime yield better-conditioned input correlations which protect against overtraining. We demonstrate that standard application of theories such as Rademacher complexity are inaccurate in predicting the generalization performance of deep neural networks, and derive an alternative bound which incorporates the frozen subspace and conditioning effects and qualitatively matches the behavior observed in simulation.}
}
@article{ZHAO202154,
title = {Particle swarm optimized neural networks based local tracking control scheme of unknown nonlinear interconnected systems},
journal = {Neural Networks},
volume = {134},
pages = {54-63},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303518},
author = {Bo Zhao and Fangchao Luo and Haowei Lin and Derong Liu},
keywords = {Adaptive dynamic programming, Reinforcement learning, Particle swarm optimization, Neural networks, Tracking control, Nonlinear interconnected systems},
abstract = {In this paper, a local tracking control (LTC) scheme is developed via particle swarm optimized neural networks (PSONN) for unknown nonlinear interconnected systems. With the local input–output data, a local neural network identifier is constructed to approximate the local input gain matrix and the mismatched interconnection, which are utilized to derive the LTC. To solve the local Hamilton–Jacobi–Bellman equation, a local critic NN is established to estimate the proper local value function, which reflects the mismatched interconnection. The weight vector of the local critic NN is trained online by particle swarm optimization, thus the success rate of system execution is increased. The stability of the closed-loop unknown nonlinear interconnected system is guaranteed to be uniformly ultimately bounded through Lyapunov’s direct method. Simulation results of two examples demonstrate the effectiveness of the developed PSONN-based LTC scheme.}
}
@article{2022II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {151},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00169-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001691}
}
@article{2022I,
title = {Current Events},
journal = {Neural Networks},
volume = {150},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00129-0},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001290}
}
@article{KITAZONO2020232,
title = {Efficient search for informational cores in complex systems: Application to brain networks},
journal = {Neural Networks},
volume = {132},
pages = {232-244},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303099},
author = {Jun Kitazono and Ryota Kanai and Masafumi Oizumi},
keywords = {Network core, Brain network, Integrated information theory, Complex, Mutual information, Submodularity},
abstract = {An important step in understanding the nature of the brain is to identify “cores” in the brain network, where brain areas strongly interact with each other. Cores can be considered as essential sub-networks for brain functions. In the last few decades, an information-theoretic approach to identifying cores has been developed. In this approach, interactions between parts are measured by an information loss function, which quantifies how much information would be lost if interactions between parts were removed. Then, a core called a “complex” is defined as a subsystem wherein the amount of information loss is locally maximal. Although identifying complexes can be a novel and useful approach, its application is practically impossible because computation time grows exponentially with system size. Here we propose a fast and exact algorithm for finding complexes, called Hierarchical Partitioning for Complex search (HPC). HPC hierarchically partitions systems to narrow down candidates for complexes. The computation time of HPC is polynomial, enabling us to find complexes in large systems (up to several hundred) in a practical amount of time. We prove that HPC is exact when an information loss function satisfies a mathematical property, monotonicity. We show that mutual information is one such information loss function. We also show that a broad class of submodular functions can be considered as such information loss functions, indicating the expandability of our framework to the class. We applied HPC to electrocorticogram recordings from a monkey and demonstrated that HPC revealed temporally stable and characteristic complexes.}
}
@article{SUN2020342,
title = {Exponential synchronization of neural networks with time-varying delays and stochastic impulses},
journal = {Neural Networks},
volume = {132},
pages = {342-352},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303373},
author = {Yifan Sun and Lulu Li and Xiaoyang Liu},
keywords = {Delayed neural networks, Stochastic impulses, Synchronization, Halanay inequality, Markov chain},
abstract = {This paper concentrates on the exponential synchronization problem of the delayed neural networks (DNNs) with stochastic impulses. First, the impulsive Halanay differential inequality is further extended to the case that the impulsive strengths are random variables. Then, based on the generalized inequalities, synchronization criteria are respectively proposed for DNNs with two kinds of stochastic impulses, i.e., impulses with independent property/Markovian property. It should be pointed out that only some basic statistical characteristics are needed to verify the proposed criteria. Numerical examples are provided to show the validation of the obtained theoretical results at the end of this paper.}
}
@article{LI202066,
title = {CariGAN: Caricature generation through weakly paired adversarial learning},
journal = {Neural Networks},
volume = {132},
pages = {66-74},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303002},
author = {Wenbin Li and Wei Xiong and Haofu Liao and Jing Huo and Yang Gao and Jiebo Luo},
keywords = {Caricature generation, GANs, Image fusion mechanism},
abstract = {Caricature generation is an interesting yet challenging task. The primary goal is to generate a plausible caricature with reasonable exaggerations given a face image. Conventional caricature generation approaches mainly use low-level geometric transformations such as image warping to generate exaggerated images, which lack richness and diversity in terms of content and style. The recent progress in generative adversarial networks (GANs) makes it possible to learn an image-to-image transformation from data so as to generate diverse images. However, directly applying GAN-based models to this task leads to unsatisfactory results due to the large variance in the caricature distribution. Moreover, conventional models typically require pixel-wisely paired training data which largely limits their usage scenarios. In this paper, we model caricature generation as a weakly paired image-to-image translation task, and propose CariGAN to address these issues. Specifically, to enforce reasonable exaggeration and facial deformation, manually annotated caricature facial landmarks are used as an additional condition to constrain the generated image. Furthermore, an image fusion mechanism is designed to encourage our model to focus on the key facial parts so that more vivid details in these regions can be generated. Finally, a diversity loss is proposed to encourage the model to produce diverse results. Extensive experiments on a large-scale “WebCaricature” dataset show that the proposed CariGAN can generate more visually plausible caricatures with larger diversity compared with the state-of-the-art models.}
}
@article{LIN2021132,
title = {FPGAN: Face de-identification method with generative adversarial networks for social robots},
journal = {Neural Networks},
volume = {133},
pages = {132-147},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303245},
author = {Jiacheng Lin and Yang Li and Guanci Yang},
keywords = {Face de-identification, GAN, Privacy protection, Deep learning, Social robots, Computer vision},
abstract = {In this paper, we propose a new face de-identification method based on generative adversarial network (GAN) to protect visual facial privacy, which is an end-to-end method (herein, FPGAN). First, we propose FPGAN and mathematically prove its convergence. Then, a generator with an improved U-Net is used to enhance the quality of the generated image, and two discriminators with a seven-layer network architecture are designed to strengthen the feature extraction ability of FPGAN. Subsequently, we propose the pixel loss, content loss, adversarial loss functions and optimization strategy to guarantee the performance of FPGAN. In our experiments, we applied FPGAN to face de-identification in social robots and analyzed the related conditions that could affect the model. Moreover, we proposed a new face de-identification evaluation protocol to check the performance of the model. This protocol can be used for the evaluation of face de-identification and privacy protection. Finally, we tested our model and four other methods on the CelebA, MORPH, RaFD, and FBDe datasets. The results of the experiments show that FPGAN outperforms the baseline methods.}
}
@article{LI2020447,
title = {Event-triggered impulsive synchronization of discrete-time coupled neural networks with stochastic perturbations and multiple delays},
journal = {Neural Networks},
volume = {132},
pages = {447-460},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030335X},
author = {Huiyuan Li and Jian-an Fang and Xiaofan Li and Leszek Rutkowski and Tingwen Huang},
keywords = {Discrete-time coupled neural networks, Event-triggered impulsive control, Synchronization, Multiple delays},
abstract = {This paper deals with the synchronization for discrete-time coupled neural networks (DTCNNs), in which stochastic perturbations and multiple delays are simultaneously involved. The multiple delays mean that both discrete time-varying delays and distributed delays are included. Time-triggered impulsive control (TTIC) is proposed to investigate the synchronization issue of the DTCNNs based on the recently proposed impulsive control scheme for continuous neural networks with single time delays. Furthermore, a novel event-triggered impulsive control (ETIC) is designed to further reduce the communication bandwidth. By using linear matrix inequality (LMI) technique and constructing appropriate Lyapunov functions, some sufficient criteria guaranteeing the synchronization of the DTCNNs are obtained. Finally, We propose a simulation example to illustrate the validity and feasibility of the theoretical results obtained.}
}
@article{LIU2020121,
title = {H∞ and l2-l∞ state estimation for delayed memristive neural networks on finite horizon: The Round-Robin protocol},
journal = {Neural Networks},
volume = {132},
pages = {121-130},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302951},
author = {Hongjian Liu and Zidong Wang and Weiyin Fei and Jiahui Li},
keywords = {Memristive neural networks, State estimation,  and - performance, Finite-horizon, Round-Robin protocol},
abstract = {In this paper, a protocol-based finite-horizon H∞ and l2-l∞ estimation approach is put forward to solve the state estimation problem for discrete-time memristive neural networks (MNNs) subject to time-varying delays and energy-bounded disturbances. The Round-Robin protocol is utilized to mitigate unnecessary network congestion occurring in the sensor-to-estimator communication channel. For the delayed MNNs, our aim is to devise an estimator that not only ensures a prescribed disturbance attenuation level over a finite time-horizon, but also keeps the peak value of the estimation error within a given range. By resorting to the Lyapunov–Krasovskii functional method, the delay-dependent criteria are formulated that guarantee the existence of the desired estimator. Subsequently, the estimator gains are obtained via figuring out a bank of convex optimization problems. The validity of our estimator is finally shown via a numerical example.}
}
@article{BASHA2021112,
title = {AutoTune: Automatically Tuning Convolutional Neural Networks for Improved Transfer Learning},
journal = {Neural Networks},
volume = {133},
pages = {112-122},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303646},
author = {S.H. Shabbeer Basha and Sravan Kumar Vinakota and Viswanath Pulabaigari and Snehasis Mukherjee and Shiv Ram Dubey},
keywords = {Convolutional Neural Networks, Fine-tuning, Bayesian optimization, Neural Architecture Search, Transfer learning},
abstract = {Transfer learning enables solving a specific task having limited data by using the pre-trained deep networks trained on large-scale datasets. Typically, while transferring the learned knowledge from source task to the target task, the last few layers are fine-tuned (re-trained) over the target dataset. However, these layers are originally designed for the source task that might not be suitable for the target task. In this paper, we introduce a mechanism for automatically tuning the Convolutional Neural Networks (CNN) for improved transfer learning. The pre-trained CNN layers are tuned with the knowledge from target data using Bayesian Optimization. First, we train the final layer of the base CNN model by replacing the number of neurons in the softmax layer with the number of classes involved in the target task. Next, the CNN is tuned automatically by observing the classification performance on the validation data (greedy criteria). To evaluate the performance of the proposed method, experiments are conducted on three benchmark datasets, e.g., CalTech-101, CalTech-256, and Stanford Dogs. The classification results obtained through the proposed AutoTune method outperforms the standard baseline transfer learning methods over the three datasets by achieving 95.92%, 86.54%, and 84.67% accuracy over CalTech-101, CalTech-256, and Stanford Dogs, respectively. The experimental results obtained in this study depict that tuning of the pre-trained CNN layers with the knowledge from the target dataset confesses better transfer learning ability. The source codes are available at https://github.com/JekyllAndHyde8999/AutoTune_CNN_TransferLearning.}
}
@article{LIU2020211,
title = {Dynamic event-based state estimation for delayed artificial neural networks with multiplicative noises: A gain-scheduled approach},
journal = {Neural Networks},
volume = {132},
pages = {211-219},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303129},
author = {Shuai Liu and Zidong Wang and Yun Chen and Guoliang Wei},
keywords = {Artificial neural networks, State estimation, Randomly occurring delay, Time-varying probability, Dynamic event triggering mechanism, Gain-scheduled approach},
abstract = {This study is concerned with the state estimation issue for a kind of delayed artificial neural networks with multiplicative noises. The occurrence of the time delay is in a random way that is modeled by a Bernoulli distributed stochastic variable whose occurrence probability is time-varying and confined within a given interval. A gain-scheduled approach is proposed for the estimator design to accommodate the time-varying nature of the occurrence probability. For the sake of utilizing the communication resource as efficiently as possible, a dynamic event triggering mechanism is put forward to orchestrate the data delivery from the sensor to the estimator. Sufficient conditions are established to ensure that, in the simultaneous presence of the external noises, the randomly occurring time delays with time-varying occurrence probability as well as the dynamic event triggering communication protocol, the estimation error is exponentially ultimately bounded in the mean square. Moreover, the estimator gain matrices are explicitly calculated in terms of the solution to certain easy-to-solve matrix inequalities. Simulation examples are provided to show the validity of the proposed state estimation method.}
}
@article{ZHANG202111,
title = {Modality independent adversarial network for generalized zero shot image classification},
journal = {Neural Networks},
volume = {134},
pages = {11-22},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303920},
author = {Haofeng Zhang and Yinduo Wang and Yang Long and Longzhi Yang and Ling Shao},
keywords = {Generalized Zero Shot Learning (GZSL), Orthogonal constraint, Cross reconstruction, Adversarial network, Modality independent learning},
abstract = {Zero Shot Learning (ZSL) aims to classify images of unseen target classes by transferring knowledge from source classes through semantic embeddings. The core of ZSL research is to embed both visual representation of object instance and semantic description of object class into a joint latent space and learn cross-modal (visual and semantic) latent representations. However, the learned representations by existing efforts often fail to fully capture the underlying cross-modal semantic consistency, and some of the representations are very similar and less discriminative. To circumvent these issues, in this paper, we propose a novel deep framework, called Modality Independent Adversarial Network (MIANet) for Generalized Zero Shot Learning (GZSL), which is an end-to-end deep architecture with three submodules. First, both visual feature and semantic description are embedded into a latent hyper-spherical space, where two orthogonal constraints are employed to ensure the learned latent representations discriminative. Second, a modality adversarial submodule is employed to make the latent representations independent of modalities to make the shared representations grab more cross-modal high-level semantic information during training. Third, a cross reconstruction submodule is proposed to reconstruct latent representations into the counterparts instead of themselves to make them capture more modality irrelevant information. Comprehensive experiments on five widely used benchmark datasets are conducted on both GZSL and standard ZSL settings, and the results show the effectiveness of our proposed method.}
}
@article{CAO2020394,
title = {Deconvolutional neural network for image super-resolution},
journal = {Neural Networks},
volume = {132},
pages = {394-404},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303403},
author = {Feilong Cao and Kaixuan Yao and Jiye Liang},
keywords = {Deep learning, Single image super-resolution (SISR), Convolutional neural networks (CNNs), Deconvolutional neural networks},
abstract = {This study builds a fully deconvolutional neural network (FDNN) and addresses the problem of single image super-resolution (SISR) by using the FDNN. Although SISR using deep neural networks has been a major research focus, the problem of reconstructing a high resolution (HR) image with an FDNN has received little attention. A few recent approaches toward SISR are to embed deconvolution operations into multilayer feedforward neural networks. This paper constructs a deep FDNN for SISR that possesses two remarkable advantages compared to existing SISR approaches. The first improves the network performance without increasing the depth of the network or embedding complex structures. The second replaces all convolution operations with deconvolution operations to implement an effective reconstruction. That is, the proposed FDNN only contains deconvolution layers and learns an end-to-end mapping from low resolution (LR) to HR images. Furthermore, to avoid the oversmoothness of the mean squared error loss, the trained image is treated as a probability distribution, and the Kullback–Leibler divergence is introduced into the final loss function to achieve enhanced recovery. Although the proposed FDNN only has 10 layers, it is successfully evaluated through extensive experiments. Compared with other state-of-the-art methods and deep convolution neural networks with 20 or 30 layers, the proposed FDNN achieves better performance for SISR.}
}
@article{ZHANG20211,
title = {Episodic memory governs choices: An RNN-based reinforcement learning model for decision-making task},
journal = {Neural Networks},
volume = {134},
pages = {1-10},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303889},
author = {Xiaohan Zhang and Lu Liu and Guodong Long and Jing Jiang and Shenquan Liu},
keywords = {Actor–Critic, Prefrontal cortex-basal ganglia circuit, Episodic memory, Reinforcement learning},
abstract = {Typical methods to study cognitive function are to record the electrical activities of animal neurons during the training of animals performing behavioral tasks. A key problem is that they fail to record all the relevant neurons in the animal brain. To alleviate this problem, we develop an RNN-based Actor–Critic framework, which is trained through reinforcement learning (RL) to solve two tasks analogous to the monkeys’ decision-making tasks. The trained model is capable of reproducing some features of neural activities recorded from animal brain, or some behavior properties exhibited in animal experiments, suggesting that it can serve as a computational platform to explore other cognitive functions. Furthermore, we conduct behavioral experiments on our framework, trying to explore an open question in neuroscience: which episodic memory in the hippocampus should be selected to ultimately govern future decisions. We find that the retrieval of salient events sampled from episodic memories can effectively shorten deliberation time than common events in the decision-making process. The results indicate that salient events stored in the hippocampus could be prioritized to propagate reward information, and thus allow decision-makers to learn a strategy faster.}
}
@article{CHO202195,
title = {Efficient architecture for deep neural networks with heterogeneous sensitivity},
journal = {Neural Networks},
volume = {134},
pages = {95-106},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303804},
author = {Hyunjoong Cho and Jinhyeok Jang and Chanhyeok Lee and Seungjoon Yang},
keywords = {Deep neural networks, Efficient architecture, Heterogeneous sensitivity, Constrained optimization, Simultaneous regularization parameter selection},
abstract = {In this study, we present a neural network that consists of nodes with heterogeneous sensitivity. Each node in a network is assigned a variable that determines the sensitivity with which it learns to perform a given task. The network is trained via a constrained optimization that maximizes the sparsity of the sensitivity variables while ensuring optimal network performance. As a result, the network learns to perform a given task using only a few sensitive nodes. Insensitive nodes, which are nodes with zero sensitivity, can be removed from a trained network to obtain a computationally efficient network. Removing zero-sensitivity nodes has no effect on the performance of the network because the network has already been trained to perform the task without them. The regularization parameter used to solve the optimization problem was simultaneously found during the training of the networks. To validate our approach, we designed networks with computationally efficient architectures for various tasks such as autoregression, object recognition, facial expression recognition, and object detection using various datasets. In our experiments, the networks designed by our proposed method provided the same or higher performances but with far less computational complexity.}
}
@article{2022I,
title = {CURRENT EVENTS},
journal = {Neural Networks},
volume = {156},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00439-7},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004397}
}
@article{DOYA2022328,
title = {Neural Networks special issue on Artificial Intelligence and Brain Science},
journal = {Neural Networks},
volume = {155},
pages = {328-329},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003185},
author = {Kenji Doya and Karl Friston and Masashi Sugiyama and Josh Tenenbaum}
}
@article{YANG202053,
title = {Hierarchical fusion of common sense knowledge and classifier decisions for answer selection in community question answering},
journal = {Neural Networks},
volume = {132},
pages = {53-65},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030294X},
author = {Min Yang and Lei Chen and Ziyu Lyu and Junhao Liu and Ying Shen and Qingyao Wu},
keywords = {Answer selection, Common sense knowledge, Hierarchical attention, Semantic compositionality},
abstract = {The goal of answer selection is to select the most applicable answers from an answer candidate pool. It plays an essential role in numerous applications in information retrieval (IR) and natural language processing (NLP). In this paper, we introduce a novel Knowledge-enhanced Hierarchical Attention mechanism for Answer Selection (KHAAS), which fully exploits the common sense knowledge from knowledge bases (KBs) and input textual information. Specifically, we first devise a three-stage knowledge-enhanced hierarchical attention mechanism, including the word-level attention, the phrase-level attention, and the document-level attention to learn the fact-aware intra-document features within questions and answers by fusing the knowledge from both the question/answer and KB. Hence, we can leverage the semantic compositionality of the question/answer and learn more holistic knowledge-enhanced intra-document features of the question/answer at three levels of granularity. Second, after obtaining the knowledge-enhanced question and answer representations, we employ a multi-perspective co-attention network to learn the complex inter-document relationships between the question and answer representations from different representation subspaces, which can capture the interactive semantics of the question and answer representations at three levels. Finally, we propose an adaptive decision fusion method to learn a more effective and robust ensemble answer selection model by adaptively combining multiple classifiers learned with different levels of features. Experimental results on three large-scale answer selection datasets demonstrate that KHAAS consistently outperforms the compared methods.}
}
@article{TOYOIZUMI2023xli,
title = {Announcement of the Neural Networks Best Paper Award},
journal = {Neural Networks},
volume = {157},
pages = {xli},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00490-7},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004907},
author = {Taro Toyoizumi and DeLiang Wang}
}
@article{GUO2020491,
title = {Self-grouping convolutional neural networks},
journal = {Neural Networks},
volume = {132},
pages = {491-505},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303385},
author = {Qingbei Guo and Xiao-Jun Wu and Josef Kittler and Zhiquan Feng},
keywords = {Deep neural network, Group convolution, Compression, Acceleration},
abstract = {Although group convolution operators are increasingly used in deep convolutional neural networks to improve the computational efficiency and to reduce the number of parameters, most existing methods construct their group convolution architectures by a predefined partitioning of the filters of each convolutional layer into multiple regular filter groups with an equal spatial group size and data-independence, which prevents a full exploitation of their potential. To tackle this issue, we propose a novel method of designing self-grouping convolutional neural networks, called SG-CNN, in which the filters of each convolutional layer group themselves based on the similarity of their importance vectors. Concretely, for each filter, we first evaluate the importance value of their input channels to identify the importance vectors, and then group these vectors by clustering. Using the resulting data-dependent centroids, we prune the less important connections, which implicitly minimizes the accuracy loss of the pruning, thus yielding a set of diverse group convolution filters. Subsequently, we develop two fine-tuning schemes, i.e. (1) both local and global fine-tuning and (2) global only fine-tuning, which experimentally deliver comparable results, to recover the recognition capacity of the pruned network. Comprehensive experiments carried out on the CIFAR-10/100 and ImageNet datasets demonstrate that our self-grouping convolution method adapts to various state-of-the-art CNN architectures, such as ResNet and DenseNet, and delivers superior performance in terms of compression ratio, speedup and recognition accuracy. We demonstrate the ability of SG-CNN to generalize by transfer learning, including domain adaption and object detection, showing competitive results. Our source code is available at https://github.com/QingbeiGuo/SG-CNN.git.}
}
@article{WEN2021207,
title = {Consensus guided incomplete multi-view spectral clustering},
journal = {Neural Networks},
volume = {133},
pages = {207-219},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303774},
author = {Jie Wen and Huijie Sun and Lunke Fei and Jinxing Li and Zheng Zhang and Bob Zhang},
keywords = {Incomplete multi-view clustering, Co-regularization, Spectral clustering, Manifold learning},
abstract = {Incomplete multi-view clustering which aims to solve the difficult clustering challenge on incomplete multi-view data collected from diverse domains with missing views has drawn considerable attention in recent years. In this paper, we propose a novel method, called consensus guided incomplete multi-view spectral clustering (CGIMVSC), to address the incomplete clustering problem. Specifically, CGIMVSC seeks to explore the local information within every single-view and the semantic consistent information shared by all views in a unified framework simultaneously, where the local structure is adaptively obtained from the incomplete data rather than pre-constructed via a k-nearest neighbor approach in the existing methods. Considering the semantic consistency of multiple views, CGIMVSC introduces a co-regularization constraint to minimize the disagreement between the common representation and the individual representations with respect to different views, such that all views will obtain a consensus clustering result. Experimental comparisons with some state-of-the-art methods on seven datasets validate the effectiveness of the proposed method on incomplete multi-view clustering.}
}
@article{ZHU2021207,
title = {Image manipulation with natural language using Two-sided Attentive Conditional Generative Adversarial Network},
journal = {Neural Networks},
volume = {136},
pages = {207-217},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303257},
author = {Dawei Zhu and Aditya Mogadala and Dietrich Klakow},
keywords = {Generative Adversarial Network (GAN), Text-to-image generation, Image manipulation},
abstract = {Altering the content of an image with photo editing tools is a tedious task for an inexperienced user, especially, when modifying the visual attributes of a specific object in an image without affecting other constituents such as background etc. To simplify the process of image manipulation and to provide more control to users, it is better to utilize a simpler interface like natural language. It also enables to semantically modify parts of an image according to the given text. Therefore, in this paper, we address the challenge of manipulating images using natural language descriptions. We propose the Two-sidEd Attentive conditional Generative Adversarial Network (TEA-cGAN) to generate semantically manipulated images. TEA-cGAN’s contribution is seen as two-fold. The first contribution aims to attend locations that need to be modified during generation. It introduces two types of architectures that provide fine-grained attention both in the generator and discriminator of Generative Adversarial Network (GAN). To be specific, the first one i.e., the Single-scale architecture used in the generator focuses to modify only the text-relevant regions in an image and leaves other regions untouched. While the second one i.e., Multi-scale architecture further extended this idea by taking the different scales of image features into account. The second contribution purpose is to generate higher resolution images (e.g., 256 × 256) as they provide better quality and stability. Quantitative and qualitative experiments conducted on CUB and Oxford-102 datasets confirm that TEA-cGAN different scale architectures outperform existing methods while generating 128 × 128 resolution images including generating higher resolution image i.e., 256 × 256.}
}
@article{NA20211,
title = {Reverse graph self-attention for target-directed atomic importance estimation},
journal = {Neural Networks},
volume = {133},
pages = {1-10},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303531},
author = {Gyoung S. Na and Hyun Woo Kim},
keywords = {Scientific application, Representation learning, Graph neural networks, Attention mechanism},
abstract = {Estimating the importance of each atom in a molecule is one of the most appealing and challenging problems in chemistry, physics, and materials science. The most common way to estimate the atomic importance is to compute the electronic structure using density functional theory (DFT), and then to interpret it using domain knowledge of human experts. However, this conventional approach is impractical to the large molecular database because DFT calculation requires large computation, specifically, O(n4) time complexity w.r.t. the number of electronic basis functions. Furthermore, the calculation results should be manually interpreted by human experts to estimate the atomic importance in terms of the target molecular property. To tackle this problem, we first exploit the machine learning-based approach for the atomic importance estimation based on the reverse self-attention on graph neural networks and integrating it with graph-based molecular description. Our method provides an efficiently-automated and target-directed way to estimate the atomic importance without any domain knowledge of chemistry and physics.}
}
@article{PAN2020461,
title = {Latent Dirichlet allocation based generative adversarial networks},
journal = {Neural Networks},
volume = {132},
pages = {461-476},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303014},
author = {Lili Pan and Shen Cheng and Jian Liu and Peijun Tang and Bowen Wang and Yazhou Ren and Zenglin Xu},
keywords = {Multi-modal structure prior, Model interpretability, Generative adversarial networks (GANs), Latent Dirichlet allocation (LDA)},
abstract = {Generative adversarial networks have been extensively studied in recent years and powered a wide range of applications, ranging from image generation, image-to-image translation, to text-to-image generation, and visual recognition. These methods typically model the mapping from latent space to image with single or multiple generators. However, they have obvious drawbacks: (i) ignoring the multi-modal structure of images, and (ii) lacking model interpretability. Importantly, the existing methods mostly assume one or more generators can cover all image modes even if we do not know the structure of data. Thus, mode dropping and collapse often take place along with GANs training. Despite the importance of exploring the data structure in generation, it has been almost unexplored. In this work, aiming at generating multi-modal images and interpreting model explicitly, we explore the theory on how to integrate GANs with data structure prior, and propose latent Dirichlet allocation based generative adversarial networks (LDAGAN). This framework is extended to combine with a variety of state-of-the-art single-generator GANs and achieves improved performance. Extensive experiments on synthetic and real datasets demonstrate the efficacy of LDAGAN for multi-modal image generation. An implementation of LDAGAN is available at https://github.com/Sumching/LDAGAN.}
}
@article{2023II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {157},
pages = {II},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00486-5},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004865}
}
@article{BAI2020416,
title = {On the robustness of skeleton detection against adversarial attacks},
journal = {Neural Networks},
volume = {132},
pages = {416-427},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303415},
author = {Xiuxiu Bai and Ming Yang and Zhe Liu},
keywords = {Convolutional neural network, Skeleton detection, Adversarial attacks, Robustness},
abstract = {Human perception of an object’s skeletal structure is particularly robust to diverse perturbations of shape. This skeleton representation possesses substantial advantages for parts-based and invariant shape encoding, which is essential for object recognition. Multiple deep learning-based skeleton detection models have been proposed, while their robustness to adversarial attacks remains unclear. (1) This paper is the first work to study the robustness of deep learning-based skeleton detection against adversarial attacks, which are only slightly unlike the original data but still imperceptible to humans. We systematically analyze the robustness of skeleton detection models through exhaustive adversarial attacking experiments. (2) We propose a novel Frequency attack, which can directly exploit the regular and interpretable perturbations to sharply disrupt skeleton detection models. Frequency attack consists of an excitatory-inhibition waveform with high frequency attribution, which confuses edge-sensitive convolutional filters due to the sudden contrast between crests and troughs. Our comprehensive results verify that skeleton detection models are also vulnerable to adversarial attacks. The meaningful findings will inspire researchers to explore more potential robust models by involving explicit skeleton features.}
}
@article{XIE202157,
title = {Multiple graphs learning with a new weighted tensor nuclear norm},
journal = {Neural Networks},
volume = {133},
pages = {57-68},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303658},
author = {Deyan Xie and Quanxue Gao and Siyang Deng and Xiaojun Yang and Xinbo Gao},
keywords = {Graph learning, Multi-view clustering, Weighted tensor nuclear norm},
abstract = {As an effective convex relaxation of the rank minimization model, the tensor nuclear norm minimization based multi-view clustering methods have been attracting more and more interest in recent years. However, most existing clustering methods regularize each singular value equally, restricting their capability and flexibility in tackling many practical problems, where the singular values should be treated differently. To address this problem, we propose a novel weighted tensor nuclear norm minimization (WTNNM) based method for multi-view spectral clustering. Specifically, we firstly calculate a set of transition probability matrices from different views, and construct a 3-order tensor whose lateral slices are composed of probability matrices. Secondly, we learn a latent high-order transition probability matrix by using our proposed weighted tensor nuclear norm, which directly considers the prior knowledge of singular values. Finally, clustering is performed on the learned transition probability matrix, which well characterizes both the complementary information and high-order information embedded in multi-view data. An efficient optimization algorithm is designed to solve the optimal solution. Extensive experiments on five benchmarks demonstrate that our method outperforms the state-of-the-art methods.}
}
@article{GHAREHBAGHI2023107,
title = {Accuracy of a Deep Learning Method for Heart Sound Analysis is Unrealistic},
journal = {Neural Networks},
volume = {159},
pages = {107-108},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004981},
author = {Arash Gharehbaghi and Elaheh Partovi}
}
@article{2022I,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {154},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00349-5},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003495}
}
@article{HU2021218,
title = {Low Rank Regularization: A review},
journal = {Neural Networks},
volume = {136},
pages = {218-232},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030352X},
author = {Zhanxuan Hu and Feiping Nie and Rong Wang and Xuelong Li},
keywords = {Low rank, Regularization, Optimization},
abstract = {Low Rank Regularization (LRR), in essence, involves introducing a low rank or approximately low rank assumption to target we aim to learn, which has achieved great success in many data analysis tasks. Over the last decade, much progress has been made in theories and applications. Nevertheless, the intersection between these two lines is rare. In order to construct a bridge between practical applications and theoretical studies, in this paper we provide a comprehensive survey for LRR. Specifically, we first review the recent advances in two issues that all LRR models are faced with: (1) rank-norm relaxation, which seeks to find a relaxation to replace the rank minimization problem; (2) model optimization, which seeks to use an efficient optimization algorithm to solve the relaxed LRR models. For the first issue, we provide a detailed summarization for various relaxation functions and conclude that the non-convex relaxations can alleviate the punishment bias problem compared with the convex relaxations. For the second issue, we summarize the representative optimization algorithms used in previous studies, and analyze their advantages and disadvantages. As the main goal of this paper is to promote the application of non-convex relaxations, we conduct extensive experiments to compare different relaxation functions. The experimental results demonstrate that the non-convex relaxations generally provide a large advantage over the convex relaxations. Such a result is inspiring for further improving the performance of existing LRR models.}
}
@article{WEI2021166,
title = {FMixCutMatch for semi-supervised deep learning},
journal = {Neural Networks},
volume = {133},
pages = {166-176},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303816},
author = {Xiang Wei and Xiaotao Wei and Xiangyuan Kong and Siyang Lu and Weiwei Xing and Wei Lu},
keywords = {Semi-supervised learning, Mixed sample augmentation, Soft pseudo-labels, Regularization},
abstract = {Mixed sample augmentation (MSA) has witnessed great success in the research area of semi-supervised learning (SSL) and is performed by mixing two training samples as an augmentation strategy to effectively smooth the training space. Following the insights on the efficacy of cut-mix in particular, we propose FMixCut, an MSA that combines Fourier space-based data mixing (FMix) and the proposed Fourier space-based data cutting (FCut) for labeled and unlabeled data augmentation. Specifically, for the SSL task, our approach first generates soft pseudo-labels using the model’s previous predictions. The model is then trained to penalize the outputs of the FMix-generated samples so that they are consistent with their mixed soft pseudo-labels. In addition, we propose to use FCut, a new Cutout-based data augmentation strategy that adopts the two masked sample pairs from FMix for weighted cross-entropy minimization. Furthermore, by implementing two regularization techniques, namely, batch label distribution entropy maximization and sample confidence entropy minimization, we further boost the training efficiency. Finally, we introduce a dynamic labeled–unlabeled data mixing (DDM) strategy to further accelerate the convergence of the model. Combining the above process, we finally call our SSL approach as ”FMixCutMatch”, in short FMCmatch. As a result, the proposed FMCmatch achieves state-of-the-art performance on CIFAR-10/100, SVHN and Mini-Imagenet across a variety of SSL conditions with the CNN-13, WRN-28-2 and ResNet-18 networks. In particular, our method achieves a 4.54% test error on CIFAR-10 with 4K labels under the CNN-13 and a 41.25% Top-1 test error on Mini-Imagenet with 10K labels under the ResNet-18. Our codes for reproducing these results are publicly available at https://github.com/biuyq/FMixCutMatch.}
}
@article{ELAZAB2020321,
title = {GP-GAN: Brain tumor growth prediction using stacked 3D generative adversarial networks from longitudinal MR Images},
journal = {Neural Networks},
volume = {132},
pages = {321-332},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303270},
author = {Ahmed Elazab and Changmiao Wang and Syed Jamal Safdar Gardezi and Hongmin Bai and Qingmao Hu and Tianfu Wang and Chunqi Chang and Baiying Lei},
keywords = {Gliomas, Growth prediction, Longitudinal MR Images, Stacked 3D generative adversarial networks,  and  losses},
abstract = {Brain tumors are one of the major common causes of cancer-related death, worldwide. Growth prediction of these tumors, particularly gliomas which are the most dominant type, can be quite useful to improve treatment planning, quantify tumor aggressiveness, and estimate patients’ survival time towards precision medicine. Studying tumor growth prediction basically requires multiple time points of single or multimodal medical images of the same patient. Recent models are based on complex mathematical formulations that basically rely on a system of partial differential equations, e.g. reaction diffusion model, to capture the diffusion and proliferation of tumor cells in the surrounding tissue. However, these models usually have small number of parameters that are insufficient to capture different patterns and other characteristics of the tumors. In addition, such models consider tumor growth independently for each subject, not being able to get benefit from possible common growth patterns existed in the whole population under study. In this paper, we propose a novel data-driven method via stacked 3D generative adversarial networks (GANs), named GP-GAN, for growth prediction of glioma. Specifically, we use stacked conditional GANs with a novel objective function that includes both l1 and Dice losses. Moreover, we use segmented feature maps to guide the generator for better generated images. Our generator is designed based on a modified 3D U-Net architecture with skip connections to combine hierarchical features and thus have a better generated image. The proposed method is trained and tested on 18 subjects with 3 time points (9 subjects from collaborative hospital and 9 subjects from BRATS 2014 dataset). Results show that our proposed GP-GAN outperforms state-of-the-art methods for glioma growth prediction and attain average Jaccard index and Dice coefficient of 78.97% and 88.26%, respectively.}
}
@article{SHI202142,
title = {Distant Supervision Relation Extraction via adaptive dependency-path and additional knowledge graph supervision},
journal = {Neural Networks},
volume = {134},
pages = {42-53},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303671},
author = {Yong Shi and Yang Xiao and Pei Quan and MingLong Lei and Lingfeng Niu},
keywords = {Distant Supervision Relation Extraction, Dependency-path, Adaptive method, Additional knowledge graph supervision},
abstract = {Relation Extraction systems train an extractor by aligning relation instances in Knowledge Base with a large amount of labeled corpora. Since the labeled datasets are very expensive, Distant Supervision Relation Extraction (DSRE) utilizes rough corpus annotated with Knowledge Graph to reduce the cost of acquisition. Nevertheless, the data noise problem limits the performance of the DSRE. Dependency trees can be used to filter the wrong-labeled instances in the distant supervision bag. However, existing dependency tree relation extraction strategies are all based on manually-set paths between the subject and object entities, and suffer from the problem of pruning the trees too aggressively or too insufficiently. To circumvent the shortcomings, in this paper, we propose a novel DSRE framework A2DSRE, based on the Adaptive dependency-path and Additional KG supervision. To obtain the dependency paths related to entity relations adaptively, we introduce an advanced graph neural network—GeniePath into DSRE, which assigns higher weights to those direct neighbor words that contribute more to relation prediction through breadth exploration, and conducts depth exploration to determine the correlation between relations and high-order neighbors. In this way, the irrelevant nodes are pruned while the relevant nodes are kept, our method can obtain more appropriate paths associated with relations. At the same time, to further reduce the noises in the data, we incorporate additional supervision information from the knowledge graph by retracting the margin between the representation of the bag and the pre-training knowledge graph embedding. Extensive numerical experiments validate the effectiveness of our new method.}
}
@article{CHANG2022527,
title = {Corrigendum to “Event-centric Multi-modal Fusion Method for Dense Video Captioning” [Neural Networks 146 (2022) 120–129]},
journal = {Neural Networks},
volume = {152},
pages = {527},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200185X},
author = {Zhi Chang and Dexin Zhao and Huilin Chen and Jingdan Li and Pengfei Liu}
}
@article{2022II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {154},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00363-X},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200363X}
}
@article{FAYDASICOK2020532,
title = {An improved Lyapunov functional with application to stability of Cohen–Grossberg neural networks of neutral-type with multiple delays},
journal = {Neural Networks},
volume = {132},
pages = {532-539},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303543},
author = {Ozlem Faydasicok},
keywords = {Delayed neural networks, Neutral systems, Global stability analysis, Lyapunov functionals},
abstract = {The essential objective of this research article is to investigate stability issue of neutral-type Cohen–Grossberg neural networks involving multiple time delays in states of neurons and multiple neutral delays in time derivatives of states of neurons in the network. By exploiting a modified and improved version of a previously introduced Lyapunov functional, a new sufficient stability criterion is obtained for global asymptotic stability of Cohen–Grossberg neural networks of neutral-type possessing multiple delays. The proposed new stability condition does not involve the time and neutral delay parameters. The obtained stability criterion is totally dependent on the system elements of Cohen–Grossberg neural network model. Moreover, the validity of this novel global asymptotic stability condition may be tested by only checking simple appropriate algebraic equations established within the parameters of the considered neutral-type neural network. In addition, an instructive numerical example is presented to indicate the advantages of our proposed stability result over the existing literature results obtained for stability of various classes of neutral-type neural networks having multiple delays.}
}
@article{PANT2020405,
title = {Neurodynamical classifiers with low model complexity},
journal = {Neural Networks},
volume = {132},
pages = {405-415},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303026},
author = {Himanshu Pant and Sumit Soman and  Jayadeva and Amit Bhaya},
keywords = {Linear programming, Neural network, VC dimension, Minimal Complexity Machine, Classification},
abstract = {The recently proposed Minimal Complexity Machine (MCM) finds a hyperplane classifier by minimizing an upper bound on the Vapnik–Chervonenkis (VC) dimension. The VC dimension measures the capacity or model complexity of a learning machine. Vapnik’s risk formula indicates that models with smaller VC dimension are expected to show improved generalization. On many benchmark datasets, the MCM generalizes better than SVMs and uses far fewer support vectors than the number used by SVMs. In this paper, we describe a neural network that converges to the MCM solution. We employ the MCM neurodynamical system as the final layer of a neural network architecture. Our approach also optimizes the weights of all layers in order to minimize the objective, which is a combination of a bound on the VC dimension and the classification error. We illustrate the use of this model for robust binary and multi-class classification. Numerical experiments on benchmark datasets from the UCI repository show that the proposed approach is scalable and accurate, and learns models with improved accuracies and fewer support vectors.}
}
@article{HUSSAIN2020353,
title = {High-content image generation for drug discovery using generative adversarial networks},
journal = {Neural Networks},
volume = {132},
pages = {353-363},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303300},
author = {Shaista Hussain and Ayesha Anees and Ankit Das and Binh P. Nguyen and Mardiana Marzuki and Shuping Lin and Graham Wright and Amit Singhal},
keywords = {High-content imaging, Deep learning, Generative modeling, Drug discovery},
abstract = {Immense amount of high-content image data generated in drug discovery screening requires computationally driven automated analysis. Emergence of advanced machine learning algorithms, like deep learning models, has transformed the interpretation and analysis of imaging data. However, deep learning methods generally require large number of high-quality data samples, which could be limited during preclinical investigations. To address this issue, we propose a generative modeling based computational framework to synthesize images, which can be used for phenotypic profiling of perturbations induced by drug compounds. We investigated the use of three variants of Generative Adversarial Network (GAN) in our framework, viz., a basic Vanilla GAN, Deep Convolutional GAN (DCGAN) and Progressive GAN (ProGAN), and found DCGAN to be most efficient in generating realistic synthetic images. A pre-trained convolutional neural network (CNN) was used to extract features of both real and synthetic images, followed by a classification model trained on real and synthetic images. The quality of synthesized images was evaluated by comparing their feature distributions with that of real images. The DCGAN-based framework was applied to high-content image data from a drug screen to synthesize high-quality cellular images, which were used to augment the real image data. The augmented dataset was shown to yield better classification performance compared with that obtained using only real images. We also demonstrated the application of proposed method on the generation of bacterial images and computed feature distributions for bacterial images specific to different drug treatments. In summary, our results showed that the proposed DCGAN-based framework can be utilized to generate realistic synthetic high-content images, thus enabling the study of drug-induced effects on cells and bacteria.}
}
@article{MA2021177,
title = {Echo Memory-Augmented Network for time series classification},
journal = {Neural Networks},
volume = {133},
pages = {177-192},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303786},
author = {Qianli Ma and Zhenjing Zheng and Wanqing Zhuang and Enhuan Chen and Jia Wei and Jiabing Wang},
keywords = {Echo state networks, Attention mechanism, Time series classification},
abstract = {Echo State Networks (ESNs) are efficient recurrent neural networks (RNNs) which have been successfully applied to time series modeling tasks. However, ESNs are unable to capture the history information far from the current time step, since the echo state at the present step of ESNs mostly impacted by the previous one. Thus, ESN may have difficulty in capturing the long-term dependencies of temporal data. In this paper, we propose an end-to-end model named Echo Memory-Augmented Network (EMAN) for time series classification. An EMAN consists of an echo memory-augmented encoder and a multi-scale convolutional learner. First, the time series is fed into the reservoir of an ESN to produce the echo states, which are all collected into an echo memory matrix along with the time steps. After that, we design an echo memory-augmented mechanism employing the sparse learnable attention to the echo memory matrix to obtain the Echo Memory-Augmented Representations (EMARs). In this way, the input time series is encoded into the EMARs with enhancing the temporal memory of the ESN. We then use multi-scale convolutions with the max-over-time pooling to extract the most discriminative features from the EMARs. Finally, a fully-connected layer and a softmax layer calculate the probability distribution on categories. Experiments conducted on extensive time series datasets show that EMAN is state-of-the-art compared to existing time series classification methods. The visualization analysis also demonstrates the effectiveness of enhancing the temporal memory of the ESN.}
}
@article{GARCIARENA2020281,
title = {Analysis of the transferability and robustness of GANs evolved for Pareto set approximations},
journal = {Neural Networks},
volume = {132},
pages = {281-296},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303269},
author = {Unai Garciarena and Alexander Mendiburu and Roberto Santana},
keywords = {Generative adversarial networks, Neuro-evolution, Pareto front approximation, Multi-objective optimization, Knowledge transferability},
abstract = {The generative adversarial network (GAN) is a good example of a strong-performing, neural network-based generative model, even though it does have some drawbacks of its own. Mode collapsing and the difficulty in finding the optimal network structure are two of the most concerning issues. In this paper, we address these two issues at the same time by proposing a neuro-evolutionary approach with an agile evaluation method for the fast evolution of robust deep architectures that avoid mode collapsing. The computation of Pareto set approximations with GANs is chosen as a suitable benchmark to evaluate the quality of our approach. Furthermore, we demonstrate the consistency, scalability, and generalization capabilities of the proposed method, which shows its potential applications to many areas. We finally readdress the issue of designing this kind of models by analyzing the characteristics of the best performing GAN specifications, and conclude with a set of general guidelines. This results in a reduction of the many-dimensional problem of structural manual design or automated search.}
}
@article{2023I,
title = {Current Events},
journal = {Neural Networks},
volume = {157},
pages = {I},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00485-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004853}
}
@article{TOYOIZUMI2023471,
title = {Another bumper year},
journal = {Neural Networks},
volume = {157},
pages = {471-472},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004610},
author = {Taro Toyoizumi and DeLiang Wang}
}
@article{LIU202084,
title = {Improved dual-scale residual network for image super-resolution},
journal = {Neural Networks},
volume = {132},
pages = {84-95},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302975},
author = {Huan Liu and Feilong Cao},
keywords = {Deep learning, Convolutional neural networks, Super-resolution (SR), Residual networks},
abstract = {In recent years, convolutional neural networks have been successfully applied to single image super-resolution (SISR) tasks, making breakthrough progress both in accuracy and speed. In this work, an improved dual-scale residual network (IDSRN), achieving promising reconstruction performance without sacrificing too much calculations, is proposed for SISR. The proposed network extracts features through two independent parallel branches: dual-scale feature extraction branch and texture attention branch. The improved dual-scale residual block (IDSRB) combined with active weighted mapping strategy constitutes the dual-scale feature extraction branch, which aims to capture dual-scale features of the image. As regards the texture attention branch, an encoder–decoder network employing symmetric full convolutional-deconvolution structure acts as a feature selector to enhance the high-frequency details. The integration of two branches reaches the goal of capturing dual-scale features with high-frequency information. Comparative experiments and extensive studies indicate that the proposed IDSRN can catch up with the state-of-the-art approaches in terms of accuracy and efficiency.}
}
@article{NISHIMURA2020521,
title = {Human interaction behavior modeling using Generative Adversarial Networks},
journal = {Neural Networks},
volume = {132},
pages = {521-531},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303427},
author = {Yusuke Nishimura and Yutaka Nakamura and Hiroshi Ishiguro},
keywords = {Human robot interaction, Human motion modeling, Generative Adversarial Networks, Human behavior during dialog},
abstract = {Recently, considerable research has focused on personal assistant robots, and robots capable of rich human-like communication are expected. Among humans, non-verbal elements contribute to effective and dynamic communication. However, people use a wide range of diverse gestures, and a robot capable of expressing various human gestures has not been realized. In this study, we address human behavior modeling during interaction using a deep generative model. In the proposed method, to consider interaction motion, three factors, i.e., interaction intensity, time evolution, and time resolution, are embedded in the network structure. Subjective evaluation results suggest that the proposed method can generate high-quality human motions.}
}
@article{WAN2021233,
title = {Robust facial landmark detection by cross-order cross-semantic deep network},
journal = {Neural Networks},
volume = {136},
pages = {233-243},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303828},
author = {Jun Wan and Zhihui Lai and Linlin Shen and Jie Zhou and Can Gao and Gang Xiao and Xianxu Hou},
keywords = {Landmark detection, Semantic feature, Heavy occlusions, Large poses, Feature correlations},
abstract = {Recently, convolutional neural networks (CNNs)-based facial landmark detection methods have achieved great success. However, most of existing CNN-based facial landmark detection methods have not attempted to activate multiple correlated facial parts and learn different semantic features from them that they can not accurately model the relationships among the local details and can not fully explore more discriminative and fine semantic features, thus they suffer from partial occlusions and large pose variations. To address these problems, we propose a cross-order cross-semantic deep network (CCDN) to boost the semantic features learning for robust facial landmark detection. Specifically, a cross-order two-squeeze multi-excitation (CTM) module is proposed to introduce the cross-order channel correlations for more discriminative representations learning and multiple attention-specific part activation. Moreover, a novel cross-order cross-semantic (COCS) regularizer is designed to drive the network to learn cross-order cross-semantic features from different activation for facial landmark detection. It is interesting to show that by integrating the CTM module and COCS regularizer, the proposed CCDN can effectively activate and learn more fine and complementary cross-order cross-semantic features to improve the accuracy of facial landmark detection under extremely challenging scenarios. Experimental results on challenging benchmark datasets demonstrate the superiority of our CCDN over state-of-the-art facial landmark detection methods.}
}
@article{XIE2020477,
title = {AMD-GAN: Attention encoder and multi-branch structure based generative adversarial networks for fundus disease detection from scanning laser ophthalmoscopy images},
journal = {Neural Networks},
volume = {132},
pages = {477-490},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303282},
author = {Hai Xie and Haijun Lei and Xianlu Zeng and Yejun He and Guozhen Chen and Ahmed Elazab and Guanghui Yue and Jiantao Wang and Guoming Zhang and Baiying Lei},
keywords = {GAN, Attention encoder, Multi-branch structure, Scanning laser ophthalmoscopy, Fundus disease detection, Experts labeling},
abstract = {The scanning laser ophthalmoscopy (SLO) has become an important tool for the determination of peripheral retinal pathology, in recent years. However, the collected SLO images are easily interfered by the eyelash and frame of the devices, which heavily affect the key feature extraction of the images. To address this, we propose a generative adversarial network called AMD-GAN based on the attention encoder (AE) and multi-branch (MB) structure for fundus disease detection from SLO images. Specifically, the designed generator consists of two parts: the AE and generation flow network, where the real SLO images are encoded by the AE module to extract features and the generation flow network to handle the random Gaussian noise by a series of residual block with up-sampling (RU) operations to generate fake images with the same size as the real ones, where the AE is also used to mine features for generator. For discriminator, a ResNet network using MB is devised by copying the stage 3 and stage 4 structures of the ResNet-34 model to extract deep features. Furthermore, the depth-wise asymmetric dilated convolution is leveraged to extract local high-level contextual features and accelerate the training process. Besides, the last layer of discriminator is modified to build the classifier to detect the diseased and normal SLO images. In addition, the prior knowledge of experts is utilized to improve the detection results. Experimental results on the two local SLO datasets demonstrate that our proposed method is promising in detecting the diseased and normal SLO images with the experts labeling.}
}
@article{KAHEMBWE2020506,
title = {Lower dimensional kernels for video discriminators},
journal = {Neural Networks},
volume = {132},
pages = {506-520},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303397},
author = {Emmanuel Kahembwe and Subramanian Ramamoorthy},
keywords = {Generative Adversarial Networks, Discriminator analysis, Video generation},
abstract = {This work presents an analysis of the discriminators used in Generative Adversarial Networks (GANs) for Video. We show that unconstrained video discriminator architectures induce a loss surface with high curvature which make optimization difficult. We also show that this curvature becomes more extreme as the maximal kernel dimension of video discriminators increases. With these observations in hand, we propose a methodology for the design of a family of efficient Lower-Dimensional Video Discriminators for GANs (LDVD-GANs). The proposed methodology improves the performance and efficiency of video GAN models it is applied to and demonstrates good performance on complex and diverse datasets such as UCF-101. In particular, we show that LDVDs can double the performance of Temporal-GANs and provide for state-of-the-art performance on a single GPU using the proposed methodology.}
}
@article{MARTON2020375,
title = {Learning to select actions shapes recurrent dynamics in the corticostriatal system},
journal = {Neural Networks},
volume = {132},
pages = {375-393},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303312},
author = {Christian D. Márton and Simon R. Schultz and Bruno B. Averbeck},
keywords = {Learning, Recurrent neural network, Corticostriatal system, Dynamics, Reinforcement learning},
abstract = {Learning to select appropriate actions based on their values is fundamental to adaptive behavior. This form of learning is supported by fronto-striatal systems. The dorsal-lateral prefrontal cortex (dlPFC) and the dorsal striatum (dSTR), which are strongly interconnected, are key nodes in this circuitry. Substantial experimental evidence, including neurophysiological recordings, have shown that neurons in these structures represent key aspects of learning. The computational mechanisms that shape the neurophysiological responses, however, are not clear. To examine this, we developed a recurrent neural network (RNN) model of the dlPFC-dSTR circuit and trained it on an oculomotor sequence learning task. We compared the activity generated by the model to activity recorded from monkey dlPFC and dSTR in the same task. This network consisted of a striatal component which encoded action values, and a prefrontal component which selected appropriate actions. After training, this system was able to autonomously represent and update action values and select actions, thus being able to closely approximate the representational structure in corticostriatal recordings. We found that learning to select the correct actions drove action-sequence representations further apart in activity space, both in the model and in the neural data. The model revealed that learning proceeds by increasing the distance between sequence-specific representations. This makes it more likely that the model will select the appropriate action sequence as learning develops. Our model thus supports the hypothesis that learning in networks drives the neural representations of actions further apart, increasing the probability that the network generates correct actions as learning proceeds. Altogether, this study advances our understanding of how neural circuit dynamics are involved in neural computation, revealing how dynamics in the corticostriatal system support task learning.}
}
@article{2023iii,
title = {List of Editorial Board Members},
journal = {Neural Networks},
volume = {157},
pages = {iii-xi},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00488-9},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004889}
}
@article{LIU2021148,
title = {Adversarial symmetric GANs: Bridging adversarial samples and adversarial networks},
journal = {Neural Networks},
volume = {133},
pages = {148-156},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303798},
author = {Faqiang Liu and Mingkun Xu and Guoqi Li and Jing Pei and Luping Shi and Rong Zhao},
keywords = {Adversarial samples, Adversarial networks},
abstract = {Generative adversarial networks have achieved remarkable performance on various tasks but suffer from training instability. Despite many training strategies proposed to improve training stability, this issue remains as a challenge. In this paper, we investigate the training instability from the perspective of adversarial samples and reveal that adversarial training on fake samples is implemented in vanilla GANs, but adversarial training on real samples has long been overlooked. Consequently, the discriminator is extremely vulnerable to adversarial perturbation and the gradient given by the discriminator contains non-informative adversarial noises, which hinders the generator from catching the pattern of real samples. Here, we develop adversarial symmetric GANs (AS-GANs) that incorporate adversarial training of the discriminator on real samples into vanilla GANs, making adversarial training symmetrical. The discriminator is therefore more robust and provides more informative gradient with less adversarial noise, thereby stabilizing training and accelerating convergence. The effectiveness of the AS-GANs is verified on image generation on CIFAR-10, CIFAR-100, CelebA, and LSUN with varied network architectures. Not only the training is more stabilized, but the FID scores of generated samples are consistently improved by a large margin compared to the baseline. Theoretical analysis is also conducted to explain why AS-GAN can improve training. The bridging of adversarial samples and adversarial networks provides a new approach to further develop adversarial networks.}
}
@article{2022II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {156},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00440-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004403}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {151},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00165-4},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022001654}
}
@article{BILLAUDELLE202111,
title = {Structural plasticity on an accelerated analog neuromorphic hardware system},
journal = {Neural Networks},
volume = {133},
pages = {11-20},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303555},
author = {Sebastian Billaudelle and Benjamin Cramer and Mihai A. Petrovici and Korbinian Schreiber and David Kappel and Johannes Schemmel and Karlheinz Meier},
keywords = {Structural plasticity, Receptive fields, BrainScaleS, Spiking, Neural networks},
abstract = {In computational neuroscience, as well as in machine learning, neuromorphic devices promise an accelerated and scalable alternative to neural network simulations. Their neural connectivity and synaptic capacity depend on their specific design choices, but is always intrinsically limited. Here, we present a strategy to achieve structural plasticity that optimizes resource allocation under these constraints by constantly rewiring the pre- and postsynaptic partners while keeping the neuronal fan-in constant and the connectome sparse. In particular, we implemented this algorithm on the analog neuromorphic system BrainScaleS-2. It was executed on a custom embedded digital processor located on chip, accompanying the mixed-signal substrate of spiking neurons and synapse circuits. We evaluated our implementation in a simple supervised learning scenario, showing its ability to optimize the network topology with respect to the nature of its training data, as well as its overall computational efficiency.}
}
@article{HAMGHALAM202043,
title = {High tissue contrast image synthesis via multistage attention-GAN: Application to segmenting brain MR scans},
journal = {Neural Networks},
volume = {132},
pages = {43-52},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303038},
author = {Mohammad Hamghalam and Tianfu Wang and Baiying Lei},
keywords = {Attention mechanism, Segmentation, Cycle-GAN, Synthetic MRI image, Infant brain tissue, Glioma tumour},
abstract = {Magnetic resonance imaging (MRI) presents a detailed image of the internal organs via a magnetic field. Given MRI’s non-invasive advantage in repeated imaging, the low-contrast MR images in the target area make segmentation of tissue a challenging problem. This study shows the potential advantages of synthetic high tissue contrast (HTC) images through image-to-image translation techniques. Mainly, we use a novel cycle generative adversarial network (Cycle-GAN), which provides a mechanism of attention to increase the contrast within the tissue. The attention block and training on HTC images are beneficial to our model to enhance tissue visibility. We use a multistage architecture to concentrate on a single tissue as a preliminary and filter out the irrelevant context in every stage in order to increase the resolution of HTC images. The multistage architecture reduces the gap between source and target domains and alleviates synthetic images’ artefacts. We apply our HTC image synthesising method to two public datasets. In order to validate the effectiveness of these images we use HTC MR images in both end-to-end and two-stage segmentation structures. The experiments on three segmentation baselines on BraTS’18 demonstrate that joining the synthetic HTC images in the multimodal segmentation framework develops the average Dice similarity scores (DSCs) of 0.8%, 0.6%, and 0.5% respectively on the whole tumour (WT), tumour core (TC), and enhancing tumour (ET) while removing one real MRI channels from the segmentation pipeline. Moreover, segmentation of infant brain tissue in T1w MR slices through our framework improves DSCs approximately 1% in cerebrospinal fluid (CSF), grey matter (GM), and white matter (WM) compared to state-of-the-art segmentation techniques. The source code of synthesising HTC images is publicly available.}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {156},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00435-X},
url = {https://www.sciencedirect.com/science/article/pii/S089360802200435X}
}
@article{RYU2021103,
title = {Unsupervised feature learning for self-tuning neural networks},
journal = {Neural Networks},
volume = {133},
pages = {103-111},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030366X},
author = {Jongbin Ryu and Ming-Hsuan Yang and Jongwoo Lim},
keywords = {Self-tuning neural network, Unsupervised feature learning, Unsupervised transfer learning, Bagged clustering, Ranking violation for triplet sampling},
abstract = {In recent years transfer learning has attracted much attention due to its ability to adapt a well-trained model from one domain to another. Fine-tuning is one of the most widely-used methods which exploit a small set of labeled data in the target domain for adapting the network. Including a few methods using the labeled data in the source domain, most transfer learning methods require labeled datasets, and it restricts the use of transfer learning to new domains. In this paper, we propose a fully unsupervised self-tuning algorithm for learning visual features in different domains. The proposed method updates a pre-trained model by minimizing the triplet loss function using only unlabeled data in the target domain. First, we propose the relevance measure for unlabeled data by the bagged clustering method. Then triplets of the anchor, positive, and negative data points are sampled based on the ranking violations of the relevance scores and the Euclidean distances in the embedded feature space. This fully unsupervised self-tuning algorithm improves the performance of the network significantly. We extensively evaluate the proposed algorithm using various metrics, including classification accuracy, feature analysis, and clustering quality, on five benchmark datasets in different domains. Besides, we demonstrate that applying the self-tuning method on the fine-tuned network help achieve better results.}
}
@article{MOON202096,
title = {Emotional EEG classification using connectivity features and convolutional neural networks},
journal = {Neural Networks},
volume = {132},
pages = {96-107},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302987},
author = {Seong-Eun Moon and Chun-Jui Chen and Cho-Jui Hsieh and Jane-Ling Wang and Jong-Seok Lee},
keywords = {Electroencephalography (EEG), Convolutional neural network (CNN), Brain connectivity, Emotion},
abstract = {Convolutional neural networks (CNNs) are widely used to recognize the user’s state through electroencephalography (EEG) signals. In the previous studies, the EEG signals are usually fed into the CNNs in the form of high-dimensional raw data. However, this approach makes it difficult to exploit the brain connectivity information that can be effective in describing the functional brain network and estimating the perceptual state of the user. We introduce a new classification system that utilizes brain connectivity with a CNN and validate its effectiveness via the emotional video classification by using three different types of connectivity measures. Furthermore, two data-driven methods to construct the connectivity matrix are proposed to maximize classification performance. Further analysis reveals that the level of concentration of the brain connectivity related to the emotional property of the target video is correlated with classification performance.}
}
@article{2022II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {152},
pages = {II},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00222-2},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002222}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {154},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00355-0},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022003550}
}
@article{2022ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {152},
pages = {ii},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00218-0},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002180}
}
@article{DOSSANTOS2020131,
title = {Learning image features with fewer labels using a semi-supervised deep convolutional network},
journal = {Neural Networks},
volume = {132},
pages = {131-143},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303051},
author = {Fernando P. {dos Santos} and Cemre Zor and Josef Kittler and Moacir A. Ponti},
keywords = {Semi-supervised learning, Transfer learning, Feature generalisation},
abstract = {Learning feature embeddings for pattern recognition is a relevant task for many applications. Deep learning methods such as convolutional neural networks can be employed for this assignment with different training strategies: leveraging pre-trained models as baselines; training from scratch with the target dataset; or fine-tuning from the pre-trained model. Although there are separate systems used for learning features from labelled and unlabelled data, there are few models combining all available information. Therefore, in this paper, we present a novel semi-supervised deep network training strategy that comprises a convolutional network and an autoencoder using a joint classification and reconstruction loss function. We show our network improves the learned feature embedding when including the unlabelled data in the training process. The results using the feature embedding obtained by our network achieve better classification accuracy when compared with competing methods, as well as offering good generalisation in the context of transfer learning. Furthermore, the proposed network ensemble and loss function is highly extensible and applicable in many recognition tasks.}
}
@article{WU2020309,
title = {Hybrid tensor decomposition in neural network compression},
journal = {Neural Networks},
volume = {132},
pages = {309-320},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303294},
author = {Bijiao Wu and Dingheng Wang and Guangshe Zhao and Lei Deng and Guoqi Li},
keywords = {Neural network compression, Hybrid tensor decomposition, Hierarchical Tucker, Tensor-train, Balanced structure},
abstract = {Deep neural networks (DNNs) have enabled impressive breakthroughs in various artificial intelligence (AI) applications recently due to its capability of learning high-level features from big data. However, the current demand of DNNs for computational resources especially the storage consumption is growing due to that the increasing sizes of models are being required for more and more complicated applications. To address this problem, several tensor decomposition methods including tensor-train (TT) and tensor-ring (TR) have been applied to compress DNNs and shown considerable compression effectiveness. In this work, we introduce the hierarchical Tucker (HT), a classical but rarely-used tensor decomposition method, to investigate its capability in neural network compression. We convert the weight matrices and convolutional kernels to both HT and TT formats for comparative study, since the latter is the most widely used decomposition method and the variant of HT. We further theoretically and experimentally discover that the HT format has better performance on compressing weight matrices, while the TT format is more suited for compressing convolutional kernels. Based on this phenomenon we propose a strategy of hybrid tensor decomposition by combining TT and HT together to compress convolutional and fully connected parts separately and attain better accuracy than only using the TT or HT format on convolutional neural networks (CNNs). Our work illuminates the prospects of hybrid tensor decomposition for neural network compression.}
}
@article{XING2021157,
title = {PM2.5 concentration modeling and prediction by using temperature-based deep belief network},
journal = {Neural Networks},
volume = {133},
pages = {157-165},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303683},
author = {Haixia Xing and Gongming Wang and Caixia Liu and Minghe Suo},
keywords = {PM prediction, PLS, Temperature-based deep belief network, Structural optimization},
abstract = {Air quality prediction is a global hot issue, and PM2.5 is an important factor affecting air quality. Due to complicated causes of formation, PM2.5 prediction is a thorny and challenging task. In this paper, a novel deep learning model named temperature-based deep belief networks (TDBN) is proposed to predict the daily concentrations of PM2.5 for the next day. Firstly, the location of PM2.5 concentration prediction is Chaoyang Park in Beijing of China from January 1, 2018 to October 27, 2018. The auxiliary variables are selected as input variables of TDBN by Partial Least Square (PLS), and the corresponding data is divided into three independent sections: training samples, validating samples and testing samples. Secondly, the TDBN is composed of temperature-based restricted Boltzmann machine (RBM), where temperature is considered as an effective physical parameter in energy balance of training RBM. The structural parameters of TDBN are determined by minimizing the error in the training process, including hidden layers number, hidden neurons and value of temperature. Finally, the testing samples are used to test the performance of the proposed TDBN on PM2.5 prediction, and the other similar models are tested by the same testing samples for convenience of comparison with TDBN. The experimental results demonstrate that TDBN performs better than its peers in root mean square error (RMSE), mean absolute error (MAE) and coefficient of determination (R2).}
}
@article{ZHANG202140,
title = {Learning interaction dynamics with an interactive LSTM for conversational sentiment analysis},
journal = {Neural Networks},
volume = {133},
pages = {40-56},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303567},
author = {Yazhou Zhang and Prayag Tiwari and Dawei Song and Xiaoliu Mao and Panpan Wang and Xiang Li and Hari Mohan Pandey},
keywords = {Sentiment analysis, Interactive dynamics, Human conversation, LSTM network},
abstract = {Conversational sentiment analysis is an emerging, yet challenging subtask of the sentiment analysis problem. It aims to discover the affective state and sentimental change in each person in a conversation based on their opinions. There exists a wealth of interaction information that affects speaker sentiment in conversations. However, existing sentiment analysis approaches are insufficient in dealing with this subtask due to two primary reasons: the lack of benchmark conversational sentiment datasets and the inability to model interactions between individuals. To address these issues, in this paper, we first present a new conversational dataset that we created and made publicly available, named ScenarioSA, to support the development of conversational sentiment analysis models. Then, we investigate how interaction dynamics are associated with conversations and study the multidimensional nature of interactions, which is understandability, credibility and influence. Finally, we propose an interactive long short-term memory (LSTM) network for conversational sentiment analysis to model interactions between speakers in a conversation by (1) adding a confidence gate before each LSTM hidden unit to estimate the credibility of the previous speakers and (2) combining the output gate with the learned influence scores to incorporate the influences of the previous speakers. Extensive experiments are conducted on ScenarioSA and IEMOCAP, and the results show that our model outperforms a wide range of strong baselines and achieves competitive results with the state-of-art approaches.}
}
@article{LIU2020269,
title = {Boundary Mittag-Leffler stabilization of fractional reaction–diffusion cellular neural networks},
journal = {Neural Networks},
volume = {132},
pages = {269-280},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303324},
author = {Xiao-Zhen Liu and Ze-Tao Li and Kai-Ning Wu},
keywords = {Boundary control, Observer, Fractional reaction–diffusion systems, Cellular neural networks, Mittag-Leffler stability, Robust stability},
abstract = {Mittag-Leffler stabilization is studied for fractional reaction–diffusion cellular neural networks (FRDCNNs) in this paper. Different from previous literature, the FRDCNNs in this paper are high-dimensional systems, and boundary control and observed-based boundary control are both used to make FRDCNNs achieve Mittag-Leffler stability. First, a state-dependent boundary controller is designed when system states are available. By employing the spatial integral functional method and some inequalities, a criterion ensuring Mittag-Leffler stability of FRDCNNs is presented. Then, when the information of system states is not fully accessible, an observer is presented to estimate the system states based on boundary output and an observer-based boundary controller is provided aiming to stabilize the considered FRDCNNs. Furthermore, a robust observer-based boundary controller is proposed to ensure the Mittag-Leffler stability for FRDCNNs with uncertainties. Examples are given to illustrate the effectiveness of obtained theoretical results.}
}
@article{2022I,
title = {Current Events},
journal = {Neural Networks},
volume = {152},
pages = {I},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00221-0},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002210}
}
@article{XIE2020144,
title = {Unsupervised spectral mapping and feature selection for hyperspectral anomaly detection},
journal = {Neural Networks},
volume = {132},
pages = {144-154},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302999},
author = {Weiying Xie and Yunsong Li and Jie Lei and Jian Yang and Jiaojiao Li and Xiuping Jia and Zhen Li},
keywords = {Unsupervised neural network, Spectral mapping, Feature selection, Hyperspectral anomaly detection},
abstract = {Exploring techniques that breakthrough the unknown space or material species is of considerable significance to military and civilian fields, and it is a challenging task without any prior information. Nowadays, the use of material-specific spectral information to detect unknowns has received increasing interest. However, affected by noise and interference, high-dimensional hyperspectral anomaly detection is difficult to meet the requirements of high detection accuracy and low false alarm rate. Besides, there is a problem of insufficient and unbalanced samples. To address these problems, we propose a novel hyperspectral anomaly detection framework based on spectral mapping and feature selection (SMFS) in an unsupervised manner. The SMFS introduces the essential properties of hyperspectral data into an unsupervised neural network to construct the nonlinear mapping relationship from high-dimensional spectral space to low-dimensional deep feature space. And it searches the optimal feature subset from the candidate feature space for standing out anomalies. Because of the compelling characterization of the encoder, we develop it specifically for spectral signatures to reveal the hidden data. Quantitative and qualitative experiments on real hyperspectral datasets indicate that the proposed method can provide the compact features overcoming the problems of noise, interference, redundancy and time-consuming caused by high-dimensionality and limited samples. And it has advantages over some state-of-the-art competitors concerning detecting anomalies of different scales.}
}
@article{ZHANG2023328,
title = {Guest editorial: Special issue on advances in deep learning based speech processing},
journal = {Neural Networks},
volume = {158},
pages = {328-330},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.11.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022004750},
author = {Xiao-Lei Zhang and Lei Xie and Eric Fosler-Lussier and Emmanuel Vincent}
}
@article{2023ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {158},
pages = {ii},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(22)00516-0},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022005160}
}
@article{LIU2021220,
title = {ClsGAN: Selective Attribute Editing Model based on Classification Adversarial Network},
journal = {Neural Networks},
volume = {133},
pages = {220-228},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S089360802030383X},
author = {Ying Liu and Heng Fan and Fuchuan Ni and Jinhai Xiang},
keywords = {GAN, Attribute editing, ClsGAN, Upper convolution residual network (Tr-resnet), Attribute adversarial classifier (Atta-cls)},
abstract = {Attribution editing has achieved remarkable progress in recent years owing to the encoder–decoder structure and generative adversarial network (GAN). However, it remains challenging to generate high-quality images with accurate attribute transformation. Attacking these problems, the work proposes a novel selective attribute editing model based on classification adversarial network (referred to as ClsGAN) that shows good balance between attribute transfer accuracy and photo-realistic images. Considering that the editing images are prone to be affected by original attribute due to skip-connection in encoder–decoder structure, an upper convolution residual network (referred to as Tr-resnet) is presented to selectively extract information from the source image and target label. In addition, to further improve the transfer accuracy of generated images, an attribute adversarial classifier (referred to as Atta-cls) is introduced to guide the generator from the perspective of attribute through learning the defects of attribute transfer images. Experimental results on CelebA demonstrate that our ClsGAN performs favorably against state-of-the-art approaches in image quality and transfer accuracy. Moreover, ablation studies are also designed to verify the great performance of Tr-resnet and Atta-cls.}
}
@article{TAN202121,
title = {Model-free motion control of continuum robots based on a zeroing neurodynamic approach},
journal = {Neural Networks},
volume = {133},
pages = {21-31},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303609},
author = {Ning Tan and Peng Yu and Xinyu Zhang and Tao Wang},
keywords = {Continuum robots, Model-free, Zeroing neurodynamics, Feedback, Recurrent neural network},
abstract = {As a result of inherent flexibility and structural compliance, continuum robots have great potential in practical applications and are attracting more and more attentions. However, these characteristics make it difficult to acquire the accurate kinematics of continuum robots due to uncertainties, deformation and external loads. This paper introduces a method based on a zeroing neurodynamic approach to solve the trajectory tracking problem of continuum robots. The proposed method can achieve the control of a bellows-driven continuum robot just relying on the actuator input and sensory output information, without knowing any information of the kinematic model. This approach reduces the computational load and can guarantee the real time control. The convergence, stability, and robustness of the proposed approach are proved by theoretical analyses. The effectiveness of the proposed method is verified by simulation studies including tracking performance, comparisons with other three methods, and robustness tests.}
}