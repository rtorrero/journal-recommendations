@article{SALEHI2021726,
title = {ARAE: Adversarially robust training of autoencoders improves novelty detection},
journal = {Neural Networks},
volume = {144},
pages = {726-736},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003646},
author = {Mohammadreza Salehi and Atrin Arya and Barbod Pajoum and Mohammad Otoofi and Amirreza Shaeiri and Mohammad Hossein Rohban and Hamid R. Rabiee},
keywords = {Anomaly detection, Adversarial training, Autoencoders (AE)},
abstract = {Autoencoders have recently been widely employed to approach the novelty detection problem. Trained only on the normal data, the AE is expected to reconstruct the normal data effectively while failing to regenerate the anomalous data. Based on this assumption, one could utilize the AE for novelty detection. However, it is known that this assumption does not always hold. Such an AE can often perfectly reconstruct the anomalous data due to modeling low-level and generic features in the input. We propose a novel training algorithm for the AE that facilitates learning more semantically meaningful features to address this problem. For this purpose, we exploit the fact that adversarial robustness promotes the learning of significant features. Therefore, we force the AE to learn such features by making its bottleneck layer more stable against adversarial perturbations. This idea is general and can be applied to other autoencoder-based approaches as well. We show that despite using a much simpler architecture than the prior methods, the proposed AE outperforms or is competitive to the state-of-the-art on four benchmark datasets and two medical datasets.}
}
@article{SOLOPCHUK2021751,
title = {Active sensing with artificial neural networks},
journal = {Neural Networks},
volume = {143},
pages = {751-758},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003129},
author = {Oleg Solopchuk and Alexandre Zénon},
keywords = {Active sensing, Exploration, Artificial neural network},
abstract = {The fitness of behaving agents depends on their knowledge of the environment, which demands efficient exploration strategies. Active sensing formalizes exploration as reduction of uncertainty about the current state of the environment. Despite strong theoretical justifications, active sensing has had limited applicability due to difficulty in estimating information gain. Here we address this issue by proposing a linear approximation to information gain and by implementing efficient gradient-based action selection within an artificial neural network setting. We compare information gain estimation with state of the art, and validate our model on an active sensing task based on MNIST dataset. We also propose an approximation that exploits the amortized inference network, and performs equally well in certain contexts.}
}
@article{WANG202256,
title = {Approximation capabilities of neural networks on unbounded domains},
journal = {Neural Networks},
volume = {145},
pages = {56-67},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003920},
author = {Ming-Xi Wang and Yang Qu},
keywords = {Universal approximation, Unbounded domain, Benefit of depth},
abstract = {There is limited study in the literature on the representability of neural networks on unbounded domains. For some application areas, results in this direction provide additional value in the design of learning systems. Motivated by an old option pricing problem, we are led to the study of this subject. For networks with a single hidden layer, we show that under suitable conditions they are capable of universal approximation in Lp(R×[0,1]n) but not in Lp(R2×[0,1]n). For deeper networks, we prove that the ReLU network with two hidden layers is a universal approximator in Lp(Rn).}
}
@article{SHINOZAKI2021271,
title = {Biologically motivated learning method for deep neural networks using hierarchical competitive learning},
journal = {Neural Networks},
volume = {144},
pages = {271-278},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003403},
author = {Takashi Shinozaki},
keywords = {Semisupervised learning, Unsupervised learning, Deep neural network, Deep learning, Feature extraction},
abstract = {This study proposes a novel biologically motivated learning method for deep convolutional neural networks (CNNs). The combination of CNNs and backpropagation learning is the most powerful method in recent machine learning regimes. However, it requires a large amount of labeled data for training, and this requirement can occasionally become a barrier for real world applications. To address this problem and use unlabeled data, we introduce unsupervised competitive learning, which only requires forward propagating signals for CNNs. The method was evaluated on image discrimination tasks using the MNIST, CIFAR-10, and ImageNet datasets, and it achieved state-of-the-art performance with respect to other biologically motivated methods in the ImageNet benchmark. The results suggest that the method enables higher-level learning representations solely based on the forward propagating signals without the need for a backward error signal for training convolutional layers. The proposed method could be useful for a variety of poorly labeled data, for example, time series or medical data.}
}
@article{QIN2021766,
title = {TACN: A Topical Adversarial Capsule Network for textual network embedding},
journal = {Neural Networks},
volume = {144},
pages = {766-777},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003889},
author = {Xiaorui Qin and Yanghui Rao and Haoran Xie and Jiahai Wang and Fu Lee Wang},
keywords = {Textual network embedding, Document-topic distribution, Generative Adversarial Network, Capsule Network},
abstract = {Combining topological information and attributed information of nodes in networks effectively is a valuable task in network embedding. Nevertheless, many prior network embedding methods regarded attributed information of nodes as simple attribute sets or ignored them totally. In some scenarios, the hidden information contained in vertex attributes are essential to network embedding. For instance, networks that contain vertexes with text information play an increasingly important role in our life, including citation networks, social networks, and entry networks. In these textual networks, the latent topic relevance information of different vertexes contained in textual attributes information are valuable in the network analysis process. Shared latent topics of nodes in networks may influence the interaction between them, which is critical to network embedding. However, much prior work for textual network embedding only regarded the text information as simple word sets while ignored the embedded topic information. In this paper, we develop a model named Topical Adversarial Capsule Network (TACN) for textual network embedding, which extracts a low-dimensional latent space of the original network from node structures, vertex attributes, and topic information contained in text of nodes. The proposed TACN contains three parts. The first part is an embedding model, which extracts the embedding representation from the topological structure, vertex attributes, and document-topic distributions. To ensure a consistent training process by back-propagation, we generate document-topic distributions by the neural topic model with Gaussian Softmax constructions. The second part is a prediction model, which is used to exploit labels of vertices. In the third part, an adversarial capsule model is used to help distinguish the latent representations from node structure domain, vertex attribute domain, or document-topic distribution domain. The latent representations, which may come from the three domains, are the output of the embedding model. We incorporate the adversarial idea into the adversarial capsule model to combine the information from these three domains, rather than to distinguish the representations conventionally. Experiments on seven real-world datasets validate the effectiveness of our method.}
}
@article{NILSEN2022164,
title = {Epistemic uncertainty quantification in deep learning classification by the Delta method},
journal = {Neural Networks},
volume = {145},
pages = {164-176},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004056},
author = {Geir K. Nilsen and Antonella Z. Munthe-Kaas and Hans J. Skaug and Morten Brun},
keywords = {Uncertainty quantification, Predictive epistemic uncertainty, Neural networks, Deep learning, Hessian, Fisher information},
abstract = {The Delta method is a classical procedure for quantifying epistemic uncertainty in statistical models, but its direct application to deep neural networks is prevented by the large number of parameters P. We propose a low cost approximation of the Delta method applicable to L2-regularized deep neural networks based on the top K eigenpairs of the Fisher information matrix. We address efficient computation of full-rank approximate eigendecompositions in terms of the exact inverse Hessian, the inverse outer-products of gradients approximation and the so-called Sandwich estimator. Moreover, we provide bounds on the approximation error for the uncertainty of the predictive class probabilities. We show that when the smallest computed eigenvalue of the Fisher information matrix is near the L2-regularization rate, the approximation error will be close to zero even when K≪P. A demonstration of the methodology is presented using a TensorFlow implementation, and we show that meaningful rankings of images based on predictive uncertainty can be obtained for two LeNet and ResNet-based neural networks using the MNIST and CIFAR-10 datasets. Further, we observe that false positives have on average a higher predictive epistemic uncertainty than true positives. This suggests that there is supplementing information in the uncertainty measure not captured by the classification alone.}
}
@article{LAGANI2021719,
title = {Hebbian semi-supervised learning in a sample efficiency setting},
journal = {Neural Networks},
volume = {143},
pages = {719-731},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003087},
author = {Gabriele Lagani and Fabrizio Falchi and Claudio Gennaro and Giuseppe Amato},
keywords = {Convolutional Neural Networks, Computer vision, Semi-supervised learning, Hebbian learning, Sample efficiency},
abstract = {We propose to address the issue of sample efficiency, in Deep Convolutional Neural Networks (DCNN), with a semi-supervised training strategy that combines Hebbian learning with gradient descent: all internal layers (both convolutional and fully connected) are pre-trained using an unsupervised approach based on Hebbian learning, and the last fully connected layer (the classification layer) is trained using Stochastic Gradient Descent (SGD). In fact, as Hebbian learning is an unsupervised learning method, its potential lies in the possibility of training the internal layers of a DCNN without labels. Only the final fully connected layer has to be trained with labeled examples. We performed experiments on various object recognition datasets, in different regimes of sample efficiency, comparing our semi-supervised (Hebbian for internal layers + SGD for the final fully connected layer) approach with end-to-end supervised backprop training, and with semi-supervised learning based on Variational Auto-Encoder (VAE). The results show that, in regimes where the number of available labeled samples is low, our semi-supervised approach outperforms the other approaches in almost all the cases.}
}
@article{NIE2021690,
title = {Exact coexistence and locally asymptotic stability of multiple equilibria for fractional-order delayed Hopfield neural networks with Gaussian activation function},
journal = {Neural Networks},
volume = {142},
pages = {690-700},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003002},
author = {Xiaobing Nie and Pingping Liu and Jinling Liang and Jinde Cao},
keywords = {Fractional-order Hopfield neural networks, Multistability, Gaussian activation function, Multiple time delays},
abstract = {This paper explores the multistability issue for fractional-order Hopfield neural networks with Gaussian activation function and multiple time delays. First, several sufficient criteria are presented for ensuring the exact coexistence of 3n equilibria, based on the geometric characteristics of Gaussian function, the fixed point theorem and the contraction mapping principle. Then, different from the existing methods used in the multistability analysis of fractional-order neural networks without time delays, it is shown that 2n of 3n total equilibria are locally asymptotically stable, by applying the theory of fractional-order linear delayed system and constructing suitable Lyapunov function. The obtained results improve and extend some existing multistability works for classical integer-order neural networks and fractional-order neural networks without time delays. Finally, an illustrative example with comprehensive computer simulations is given to demonstrate the theoretical results.}
}
@article{XU2021307,
title = {Bipartite synchronization of signed networks via aperiodically intermittent control based on discrete-time state observations},
journal = {Neural Networks},
volume = {144},
pages = {307-319},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003488},
author = {Dongsheng Xu and Jiahuan Pang and Huan Su},
keywords = {Signed networks, Discrete-time state observations, Aperiodically intermittent control, Bipartite synchronization, Stochastic disturbances},
abstract = {In this paper, bipartite synchronization of signed networks with stochastic disturbances via aperiodically intermittent control is investigated. The aperiodically intermittent control presented is based on discrete-time state observations rather than continuous-time ones. To formulate signed networks and exhibit the competitive relation, a structurally balanced signed network is built and all the units are divided into two subcommunities. By employing Lyapunov method and graph theory, some sufficient conditions on bipartite synchronization are given. Meanwhile, when aperiodically intermittent control degenerates into periodically intermittent control and feedback control respectively, two corollaries are also provided to ensure the bipartite synchronization of the signed networks. Ultimately, two applications to coupled single-link robot arms and coupled oscillators are presented and corresponding numerical examples are respectively provided to verify the feasibility and effectiveness of the theoretical results.}
}
@article{ZHANG2021129,
title = {An end-to-end 3D convolutional neural network for decoding attentive mental state},
journal = {Neural Networks},
volume = {144},
pages = {129-137},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003245},
author = {Yangsong Zhang and Huan Cai and Li Nie and Peng Xu and Sirui Zhao and Cuntai Guan},
keywords = {EEG, Attention, BCI, Deep learning, 3D convolutional neural network},
abstract = {The detection of attentive mental state plays an essential role in the neurofeedback process and the treatment of Attention Deficit and Hyperactivity Disorder (ADHD). However, the performance of the detection methods is still not satisfactory. One of the challenges is to find a proper representation for the electroencephalogram (EEG) data, which could preserve the temporal information and maintain the spatial topological characteristics. Inspired by the deep learning (DL) methods in the research of brain–computer interface (BCI) field, a 3D representation of EEG signal was introduced into attention detection task, and a 3D convolutional neural network model with cascade and parallel convolution operations was proposed. The model utilized three cascade blocks, each consisting of two parallel 3D convolution branches, to simultaneously extract the multi-scale features. Evaluated on a public dataset containing twenty-six subjects, the proposed model achieved better performance compared with the baseline methods under the intra-subject, inter-subject and subject-adaptive classification scenarios. This study demonstrated the promising potential of the 3D CNN model for detecting attentive mental state.}
}
@article{2023II,
title = {INN/ENNS/JNNS - Membership Applic. Form},
journal = {Neural Networks},
volume = {165},
pages = {II},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00411-2},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004112}
}
@article{LIU2022308,
title = {Minimum spanning tree based graph neural network for emotion classification using EEG},
journal = {Neural Networks},
volume = {145},
pages = {308-318},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004226},
author = {Hanjie Liu and Jinren Zhang and Qingshan Liu and Jinde Cao},
keywords = {Emotion classification, MST, Graph neural network, DEAP},
abstract = {Emotion classification based on neurophysiology signals has been a challenging issue in the literature. Recent neuroscience findings suggest that brain network structure underlying the different emotions provides a window in understanding human affection. In this paper, we propose a novel method to capture the distinct minimum spanning tree (MST) topology underpinning the different emotions. Specifically, we propose a hierarchical aggregation-based graph neural network to investigate the MST structure in emotion recognition. Extensive experiments on the public available DEAP dataset demonstrate the superior performance of the model in emotion classification as compared to existing methods. In addition, the results show that the theta, lower beta and gamma frequency band network information are more sensitive to emotions, suggesting a multi-frequency interaction in emotion processing.}
}
@article{MORI2022107,
title = {Probabilistic generative modeling and reinforcement learning extract the intrinsic features of animal behavior},
journal = {Neural Networks},
volume = {145},
pages = {107-120},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003932},
author = {Keita Mori and Naohiro Yamauchi and Haoyu Wang and Ken Sato and Yu Toyoshima and Yuichi Iino},
keywords = {Probabilistic generative model, Mixture density network, Recurrent neural network, Reinforcement learning, Behavior analysis, Computational ethology},
abstract = {It is one of the ultimate goals of ethology to understand the generative process of animal behavior, and the ability to reproduce and control behavior is an important step in this field. However, it is not easy to achieve this goal in systems with complex and stochastic dynamics such as animal behavior. In this study, we have shown that MDN–RNN,a type of probabilistic deep generative model, is able to reproduce stochastic animal behavior with high accuracy by modeling the behavior of C. elegans. Furthermore, we found that the model learns different dynamics in a disentangled representation as a time-evolving Gaussian mixture. Finally, by combining the model and reinforcement learning, we were able to extract a behavioral policy of goal-directed behavior in silico, and showed that it can be used for regulating the behavior of real animals. This set of methods will be applicable not only to animal behavior but also to broader areas such as neuroscience and robotics.}
}
@article{WANG2021320,
title = {Nonlinear tensor train format for deep neural network compression},
journal = {Neural Networks},
volume = {144},
pages = {320-333},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003415},
author = {Dingheng Wang and Guangshe Zhao and Hengnu Chen and Zhexian Liu and Lei Deng and Guoqi Li},
keywords = {Tensor train decomposition, Nonlinear tensor train, Sequenced contractions, Sequenced convolutions, Neural network compression},
abstract = {Deep neural network (DNN) compression has become a hot topic in the research of deep learning since the scale of modern DNNs turns into too huge to implement on practical resource constrained platforms such as embedded devices. Among variant compression methods, tensor decomposition appears to be a relatively simple and efficient strategy owing to its solid mathematical foundations and regular data structure. Generally, tensorizing neural weights into higher-order tensors for better decomposition, and directly mapping efficient tensor structure to neural architecture with nonlinear activation functions, are the two most common ways. However, the considerable accuracy loss is still a fly in the ointment for the tensorizing way especially for convolutional neural networks (CNNs), while the number of studies in the mapping way is comparatively limited and corresponding compression ratio appears to be not considerable. Therefore, in this work, by researching multiple types of tensor decompositions, we realize that tensor train (TT), which has specific and efficient sequenced contractions, is potential to take into account both of tensorizing and mapping ways. Then we propose a novel nonlinear tensor train (NTT) format, which contains extra nonlinear activation functions embedded in sequenced contractions and convolutions on the top of the normal TT decomposition and the proposed TT format connected by convolutions, to compensate the accuracy loss that normal TT cannot give. Further than just shrinking the space complexity of original weight matrices and convolutional kernels, we prove that NTT can afford an efficient inference time as well. Extensive experiments and discussions demonstrate that the compressed DNNs in our NTT format can almost maintain the accuracy at least on MNIST, UCF11 and CIFAR-10 datasets, and the accuracy loss caused by normal TT could be compensated significantly on large-scale datasets such as ImageNet.}
}
@article{GUO2021614,
title = {Weak sub-network pruning for strong and efficient neural networks},
journal = {Neural Networks},
volume = {144},
pages = {614-626},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003658},
author = {Qingbei Guo and Xiao-Jun Wu and Josef Kittler and Zhiquan Feng},
keywords = {Deep neural network, Weak sub-network pruning, Compression, Acceleration},
abstract = {Pruning methods to compress and accelerate deep convolutional neural networks (CNNs) have recently attracted growing attention, with the view of deploying pruned networks on resource-constrained hardware devices. However, most existing methods focus on small granularities, such as weight, kernel and filter, for the exploration of pruning. Thus, it will be bound to iteratively prune the whole neural networks based on those small granularities for high compression ratio with little performance loss. To address these issues, we theoretically analyze the relationship between the activation and gradient sparsity, and the channel saliency. Based on our findings, we propose a novel and effective method of weak sub-network pruning (WSP). Specifically, for a well-trained network model, we divide the whole compression process into two non-iterative stages. The first stage is to directly obtain a strong sub-network by pruning the weakest one. We first identify the less important channels from all the layers and determine the weakest sub-network, whereby each selected channel makes a minimal contribution to both the feed-forward and feed-backward processes. Then, a one-shot pruning strategy is executed to form a strong sub-network enabling fine tuning, while significantly reducing the impact of the network depth and width on the compression efficiency, especially for deep and wide network architectures. The second stage is to globally fine-tune the strong sub-network using several epochs to restore its original recognition accuracy. Furthermore, our proposed method impacts on the fully-connected layers as well as the convolutional layers for simultaneous compression and acceleration. Comprehensive experiments on VGG16 and ResNet-50 involving a variety of popular benchmarks, such as ImageNet-1K, CIFAR-10, CUB-200 and PASCAL VOC, demonstrate that our WSP method achieves superior performance on classification, domain adaption and object detection tasks with small model size. Our source code is available at https://github.com/QingbeiGuo/WSP.git.}
}
@article{NIU2021553,
title = {Disturbance-immune weight sharing for neural architecture search},
journal = {Neural Networks},
volume = {144},
pages = {553-564},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100352X},
author = {Shuaicheng Niu and Jiaxiang Wu and Yifan Zhang and Yong Guo and Peilin Zhao and Junzhou Huang and Mingkui Tan},
keywords = {Neural architecture search, Weight sharing, Performance disturbance},
abstract = {Neural architecture search (NAS) has gained increasing attention in the community of architecture design. One of the key factors behind the success lies in the training efficiency brought by the weight sharing (WS) technique. However, WS-based NAS methods often suffer from a performance disturbance (PD) issue. That is, the training of subsequent architectures inevitably disturbs the performance of previously trained architectures due to the partially shared weights. This leads to inaccurate performance estimation for the previous architectures, which makes it hard to learn a good search strategy. To alleviate the performance disturbance issue, we propose a new disturbance-immune update strategy for model updating. Specifically, to preserve the knowledge learned by previous architectures, we constrain the training of subsequent architectures in an orthogonal space via orthogonal gradient descent. Equipped with this strategy, we propose a novel disturbance-immune training scheme for NAS. We theoretically analyze the effectiveness of our strategy in alleviating the PD risk. Extensive experiments on CIFAR-10 and ImageNet verify the superiority of our method.}
}
@article{JIAO2021767,
title = {Refined UNet v3: Efficient end-to-end patch-wise network for cloud and shadow segmentation with multi-channel spectral features},
journal = {Neural Networks},
volume = {143},
pages = {767-782},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003130},
author = {Libin Jiao and Lianzhi Huo and Changmiao Hu and Ping Tang},
keywords = {Semantic segmentation, Neural network, Conditional random fields, Efficient implementation},
abstract = {Semantic segmentation is one of the essential prerequisites for computer vision tasks, but edge-precise segmentation stays challenging due to the potential lack of a proper model indicating the low-level relation between pixels. We have presented Refined UNet v2, a concatenation of a network backbone and a subsequent embedded conditional random field (CRF) layer, which coarsely performs pixel-wise classification and refines edges of segmentation regions in a one-stage way. However, the CRF layer of v2 employs a gray-scale global observation (image) to construct contrast-sensitive bilateral features, which is not able to achieve the desired performance on ambiguous edges. In addition, the naïve depth-wise Gaussian filter cannot always compute efficiently, especially for a longer-range message-passing step. To address the aforementioned issues, we upgrade the bilateral message-passing kernel and the efficient implementation of Gaussian filtering in the CRF layer in this paper, referred to as Refined UNet v3, which is able to effectively capture ambiguous edges and accelerate the message-passing procedure. Specifically, the inherited UNet is employed to coarsely locate cloud and shadow regions and the embedded CRF layer refines the edges of the forthcoming segmentation proposals. The multi-channel guided Gaussian filter is applied to the bilateral message-passing step, which improves detecting ambiguous edges that are hard for the gray-scale counterpart to identify, and fast Fourier transform-based (FFT-based) Gaussian filtering facilitates an efficient and potentially range-agnostic implementation. Furthermore, Refined UNet v3 is able to be extended to segmentation on multi-spectral datasets, and the corresponding refinement examination confirms the development of shadow retrieval. Experiments and corresponding results demonstrate that the proposed update can outperform its counterpart in terms of the detection of vague edges, shadow retrieval, and isolated redundant regions, and it is practically efficient in our TensorFlow implementation. The demo source code is available at https://github.com/92xianshen/refined-unet-v3.}
}
@article{ZHANG202111,
title = {Intermittent control for finite-time synchronization of fractional-order complex networks},
journal = {Neural Networks},
volume = {144},
pages = {11-20},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003099},
author = {Lingzhong Zhang and Jie Zhong and Jianquan Lu},
keywords = {Finite-time synchronization, Intermittent control, Fractional-order, Complex network},
abstract = {This paper is concerned with the finite-time synchronization problem for fractional-order complex dynamical networks (FCDNs) with intermittent control. Using the definition of Caputo’s fractional derivative and the properties of Beta function, the Caputo fractional-order derivative of the power function is evaluated. A general fractional-order intermittent differential inequality is obtained with fewer additional constraints. Then, the criteria are established for the finite-time convergence of FCDNs under intermittent feedback control, intermittent adaptive control and intermittent pinning control indicate that the setting time is related to order of FCDNs and initial conditions. Finally, these theoretical results are illustrated by numerical examples.}
}
@article{MAO2021778,
title = {Theory of deep convolutional neural networks III: Approximating radial functions},
journal = {Neural Networks},
volume = {144},
pages = {778-790},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003890},
author = {Tong Mao and Zhongjie Shi and Ding-Xuan Zhou},
keywords = {Deep learning, Convolutional neural networks, Rates of approximation, Radial functions, Generalization analysis},
abstract = {We consider a family of deep neural networks consisting of two groups of convolutional layers, a downsampling operator, and a fully connected layer. The network structure depends on two structural parameters which determine the numbers of convolutional layers and the width of the fully connected layer. We establish an approximation theory with explicit approximation rates when the approximated function takes a composite form f∘Q with a feature polynomial Q and a univariate function f. In particular, we prove that such a network can outperform fully connected shallow networks in approximating radial functions with Q(x)=|x|2, when the dimension d of data from Rd is large. This gives the first rigorous proof for the superiority of deep convolutional neural networks in approximating functions with special structures. Then we carry out generalization analysis for empirical risk minimization with such a deep network in a regression framework with the regression function of the form f∘Q. Our network structure which does not use any composite information or the functions Q and f can automatically extract features and make use of the composite nature of the regression function via tuning the structural parameters. Our analysis provides an error bound which decreases with the network depth to a minimum and then increases, verifying theoretically a trade-off phenomenon observed for network depths in many practical applications.}
}
@article{PANG2021164,
title = {Predictive coding feedback results in perceived illusory contours in a recurrent neural network},
journal = {Neural Networks},
volume = {144},
pages = {164-175},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003373},
author = {Zhaoyang Pang and Callum Biggs O’May and Bhavin Choksi and Rufin VanRullen},
keywords = {Illusory contours, Predictive coding, Deep learning, Kanizsa squares, Feedback, Generative models},
abstract = {Modern feedforward convolutional neural networks (CNNs) can now solve some computer vision tasks at super-human levels. However, these networks only roughly mimic human visual perception. One difference from human vision is that they do not appear to perceive illusory contours (e.g. Kanizsa squares) in the same way humans do. Physiological evidence from visual cortex suggests that the perception of illusory contours could involve feedback connections. Would recurrent feedback neural networks perceive illusory contours like humans? In this work we equip a deep feedforward convolutional network with brain-inspired recurrent dynamics. The network was first pretrained with an unsupervised reconstruction objective on a natural image dataset, to expose it to natural object contour statistics. Then, a classification decision head was added and the model was finetuned on a form discrimination task: squares vs. randomly oriented inducer shapes (no illusory contour). Finally, the model was tested with the unfamiliar “illusory contour” configuration: inducer shapes oriented to form an illusory square. Compared with feedforward baselines, the iterative “predictive coding” feedback resulted in more illusory contours being classified as physical squares. The perception of the illusory contour was measurable in the luminance profile of the image reconstructions produced by the model, demonstrating that the model really “sees” the illusion. Ablation studies revealed that natural image pretraining and feedback error correction are both critical to the perception of the illusion. Finally we validated our conclusions in a deeper network (VGG): adding the same predictive coding feedback dynamics again leads to the perception of illusory contours.}
}
@article{ZHANG2022189,
title = {Exponential synchronization of coupled neural networks under stochastic deception attacks},
journal = {Neural Networks},
volume = {145},
pages = {189-198},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004068},
author = {Huihui Zhang and Lulu Li and Xiaodi Li},
keywords = {Neural networks, Synchronization, Time delay, Stochastic impulses, Deception attacks},
abstract = {In this paper, the issue of synchronization is investigated for coupled neural networks subject to stochastic deception attacks. Firstly, a general differential inequality with delayed impulses is given. Then, the established differential inequality is further extended to the case of delayed stochastic impulses, in which both the impulsive instants and impulsive intensity are stochastic. Secondly, by modeling the stochastic discrete-time deception attacks as stochastic impulses, synchronization criteria of the coupled neural networks under the corresponding attacks are given. Finally, two numerical examples are provided to demonstrate the correctness of the theoretical results.}
}
@article{MANCINI2021113,
title = {Extremely randomized neural networks for constructing prediction intervals},
journal = {Neural Networks},
volume = {144},
pages = {113-128},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003257},
author = {Tullio Mancini and Hector Calvo-Pardo and Jose Olmo},
keywords = {Neural networks, Ensemble methods, Prediction interval, Uncertainty quantification, Dropout},
abstract = {The aim of this paper is to propose a novel prediction model based on an ensemble of deep neural networks adapting the extremely randomized trees method originally developed for random forests. The extra-randomness introduced in the ensemble reduces the variance of the predictions and improves out-of-sample accuracy. As a byproduct, we are able to compute the uncertainty about our model predictions and construct interval forecasts. Some of the limitations associated with bootstrap-based algorithms can be overcome by not performing data resampling and thus, by ensuring the suitability of the methodology in low and mid-dimensional settings, or when the i.i.d. assumption does not hold. An extensive Monte Carlo simulation exercise shows the good performance of this novel prediction method in terms of mean square prediction error and the accuracy of the prediction intervals in terms of out-of-sample prediction interval coverage probabilities. The advanced approach delivers better out-of-sample accuracy in experimental settings, improving upon state-of-the-art methods like MC dropout and bootstrap procedures.}
}
@article{ZHANG2021279,
title = {Deep Tobit networks: A novel machine learning approach to microeconometrics},
journal = {Neural Networks},
volume = {144},
pages = {279-296},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003531},
author = {Jiaming Zhang and Zhanfeng Li and Xinyuan Song and Hanwen Ning},
keywords = {Deep Tobit network, Large dataset, Microeconometrics, Neural network, Significance test},
abstract = {Tobit models (also called as “censored regression models” or classified as “sample selection models” in microeconometrics) have been widely applied to microeconometric problems with censored outcomes. However, due to their linear parametric settings and restrictive normality assumptions, the traditional Tobit models fail to capture the pervading nonlinearities and thus may be inadequate for microeconometric analysis with large-scale datasets. This paper proposes two novel deep neural networks for Tobit problems and explores machine learning approaches in the context of microeconometric modeling. We connect the censored outputs in Tobit models with some deep learning techniques, which are thought to be unrelated to microeconometrics, and use the rectified linear unit activation and a particularly designed network structure to implement the censored output mechanisms and realize the underlying econometric conceptions. The benchmark Tobit-I and Tobit-II models are then reformulated as two carefully designed deep feedforward neural networks named deep Tobit-I network and deep Tobit-II network, respectively. A novel significance testing method is developed based on the proposed networks. Compared with the traditional models, our networks with deep structures can effectively describe the underlying highly nonlinear relationships and achieve considerable improvements in fitting and prediction. With the novel testing method, the proposed networks enable highly accurate and sophisticated econometric analysis with minimal random assumptions. The encouraging numerical experiments on synthetic and realistic datasets demonstrate the utility and advantages of the proposed method.}
}
@article{PARK202133,
title = {Distributed associative memory network with memory refreshing loss},
journal = {Neural Networks},
volume = {144},
pages = {33-48},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003014},
author = {Taewon Park and Inchul Choi and Minho Lee},
keywords = {Memory augmented neural network, Relational reasoning, Distributed representation, Auxiliary loss, Machine learning},
abstract = {Despite recent progress in memory augmented neural network (MANN) research, associative memory networks with a single external memory still show limited performance on complex relational reasoning tasks. Especially the content-based addressable memory networks often fail to encode input data into rich enough representation for relational reasoning and this limits the relation modeling performance of MANN for long temporal sequence data. To address these problems, here we introduce a novel Distributed Associative Memory architecture (DAM) with Memory Refreshing Loss (MRL) which enhances the relation reasoning performance of MANN. Inspired by how the human brain works, our framework encodes data with distributed representation across multiple memory blocks and repeatedly refreshes the contents for enhanced memorization similar to the rehearsal process of the brain. For this procedure, we replace a single external memory with a set of multiple smaller associative memory blocks and update these sub-memory blocks simultaneously and independently for the distributed representation of input data. Moreover, we propose MRL which assists a task’s target objective while learning relational information existing in data. MRL enables MANN to reinforce an association between input data and task objective by reproducing stochastically sampled input data from stored memory contents. With this procedure, MANN further enriches the stored representations with relational information. In experiments, we apply our approaches to Differential Neural Computer (DNC), which is one of the representative content-based addressing memory models and achieves the state-of-the-art performance on both memorization and relational reasoning tasks.}
}
@article{CHEN2021247,
title = {One-stage CNN detector-based benthonic organisms detection with limited training dataset},
journal = {Neural Networks},
volume = {144},
pages = {247-259},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003191},
author = {Tingkai Chen and Ning Wang and Rongfeng Wang and Hong Zhao and Guichen Zhang},
keywords = {Benthonic organisms detection, One-stage CNN detector, Generalized intersection over union, Benthonic organisms anchor boxes, Data augmentation},
abstract = {In this paper, focusing on the challenges in unique shape dimension and limited training dataset of benthonic organisms, an one-stage CNN detector-based benthonic organisms detection (OSCD-BOD) scheme is proposed. Main contributions are as follows: (1) The regression loss between the predicted bounding box and ground truth box is innovatively measured by the generalized intersection over union (GIoU), such that localization accuracy of benthonic organisms is dramatically enhanced. (2) By devising K-means-based dimension clustering, multiple benthonic organisms anchor boxes (BOAB) sufficiently exploring a priori dimension information can be finely derived from limited training dataset, and thereby significantly promoting the recall ability. (3) Geometric and color transformations (GCT)-based data augmentation technique is further resorted to not only efficiently prevent over-fitting training but also to significantly enhance detection generalization in complex and changeable underwater environments. (4) The OSCD-BOD scheme is eventually established in a modular manner by integrating GIoU, BOAB and GCT functionals. Comprehensive experiments and comparisons sufficiently demonstrate that the proposed OSCD-BOD scheme outperforms typical approaches including Faster R-CNN, SSD, YOLOv2, YOLOv3 and CenterNet in terms of mean average precision by 6.88%, 10.92%, 12.44%, 3.05% and 1.09%, respectively.}
}
@article{LI2022121,
title = {Learning policy scheduling for text augmentation},
journal = {Neural Networks},
volume = {145},
pages = {121-127},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003907},
author = {Shuokai Li and Xiang Ao and Feiyang Pan and Qing He},
keywords = {Data augmentation, Text classification},
abstract = {When training deep learning models, data augmentation is an important technique to improve the performance and alleviate overfitting. In natural language processing (NLP), existing augmentation methods often use fixed strategies. However, it might be preferred to use different augmentation policies in different stage of training, and different datasets may require different augmentation policies. In this paper, we take dynamic policy scheduling into consideration. We design a search space over augmentation policies by integrating several common augmentation operations. Then, we adopt a population based training method to search the best augmentation schedule. We conduct extensive experiments on five text classification and two machine translation tasks. The results show that the optimized dynamic augmentation schedules achieve significant improvements against previous methods.}
}
@article{HE2021465,
title = {ACSL: Adaptive correlation-driven sparsity learning for deep neural network compression},
journal = {Neural Networks},
volume = {144},
pages = {465-477},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003622},
author = {Wei He and Meiqing Wu and Siew-Kei Lam},
keywords = {Network pruning, Channel correlation, Sparsity learning, Deep convolutional neural networks},
abstract = {Deep convolutional neural network compression has attracted lots of attention due to the need to deploy accurate models on resource-constrained edge devices. Existing techniques mostly focus on compressing networks for image-level classification, and it is not clear if they generalize well on network architectures for more challenging pixel-level tasks, e.g., dense crowd counting or semantic segmentation. In this paper, we propose an adaptive correlation-driven sparsity learning (ACSL) framework for channel pruning that outperforms state-of-the-art methods on both image-level and pixel-level tasks. In our ACSL framework, we first quantify the data-dependent channel correlation information with a channel affinity matrix. Next, we leverage these inter-dependencies to induce sparsity into the channels with the introduced adaptive penalty strength. After removing the redundant channels, we obtain compact and efficient models, which have significantly less number of parameters while maintaining comparable performance with the original models. We demonstrate the advantages of our proposed approach on three popular vision tasks, i.e., dense crowd counting, semantic segmentation, and image-level classification. The experimental results demonstrate the superiority of our framework. In particular, for crowd counting on the Mall dataset, the proposed ACSL framework is able to reduce up to 94% parameters (VGG16-Decoder) and 84% FLOPs (ResNet101), while maintaining the same performance of (at times outperforming) the original model.}
}
@article{LIU202175,
title = {Non-differentiable saddle points and sub-optimal local minima exist for deep ReLU networks},
journal = {Neural Networks},
volume = {144},
pages = {75-89},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003105},
author = {Bo Liu and Zhaoying Liu and Ting Zhang and Tongtong Yuan},
keywords = {Deep learning, Loss landscape, Loss surface, Local minima, Saddle points},
abstract = {Whether sub-optimal local minima and saddle points exist in the highly non-convex loss landscape of deep neural networks has a great impact on the performance of optimization algorithms. Theoretically, we study in this paper the existence of non-differentiable sub-optimal local minima and saddle points for deep ReLU networks with arbitrary depth. We prove that there always exist non-differentiable saddle points in the loss surface of deep ReLU networks with squared loss or cross-entropy loss under reasonable assumptions. We also prove that deep ReLU networks with cross-entropy loss will have non-differentiable sub-optimal local minima if some outermost samples do not belong to a certain class. Experimental results on real and synthetic datasets verify our theoretical findings.}
}
@article{BERTONI202242,
title = {LGN-CNN: A biologically inspired CNN architecture},
journal = {Neural Networks},
volume = {145},
pages = {42-55},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003865},
author = {Federico Bertoni and Giovanna Citti and Alessandro Sarti},
keywords = {CNN, LGN, Visual system, Retinex theory, Minimal functional symmetry properties},
abstract = {In this paper we introduce a biologically inspired Convolutional Neural Network (CNN) architecture called LGN-CNN that has a first convolutional layer composed of a single filter that mimics the role of the Lateral Geniculate Nucleus (LGN). The first layer of the neural network shows a rotational symmetric pattern justified by the structure of the net itself that turns up to be an approximation of a Laplacian of Gaussian (LoG). The latter function is in turn a good approximation of the receptive field profiles (RFPs) of the cells in the LGN. The analogy with the visual system is established, emerging directly from the architecture of the neural network. A proof of rotation invariance of the first layer is given on a fixed LGN-CNN architecture and the computational results are shown. Thus, contrast invariance capability of the LGN-CNN is investigated and a comparison between the Retinex effects of the first layer of LGN-CNN and the Retinex effects of a LoG is provided on different images. A statistical study is done on the filters of the second convolutional layer with respect to biological data. In conclusion, the model we have introduced approximates well the RFPs of both LGN and V1 attaining similar behavior as regards long range connections of LGN cells that show Retinex effects.}
}
@article{XIA20221,
title = {Multi-view graph embedding clustering network: Joint self-supervision and block diagonal representation},
journal = {Neural Networks},
volume = {145},
pages = {1-9},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100397X},
author = {Wei Xia and Sen Wang and Ming Yang and Quanxue Gao and Jungong Han and Xinbo Gao},
keywords = {Multi-view clustering, Graph convolutional networks, Block diagonal representation, Self-supervision},
abstract = {Multi-view clustering has become an active topic in artificial intelligence. Yet, similar investigation for graph-structured data clustering has been absent so far. To fill this gap, we present a Multi-View Graph embedding Clustering network (MVGC). Specifically, unlike traditional multi-view construction methods, which are only suitable to describe Euclidean structure data, we leverage Euler transform to augment the node attribute, as a new view descriptor, for non-Euclidean structure data. Meanwhile, we impose block diagonal representation constraint, which is measured by the ℓ1,2-norm, on self-expression coefficient matrix to well explore the cluster structure. By doing so, the learned view-consensus coefficient matrix well encodes the discriminative information. Moreover, we make use of the learned clustering labels to guide the learnings of node representation and coefficient matrix, where the latter is used in turn to conduct the subsequent clustering. In this way, clustering and representation learning are seamlessly connected, with the aim to achieve better clustering performance. Extensive experimental results indicate that MVGC is superior to 11 state-of-the-art methods on four benchmark datasets. In particular, MVGC achieves an Accuracy of 96.17% (53.31%) on the ACM (IMDB) dataset, which is an up to 2.85% (1.97%) clustering performance improvement compared with the strongest baseline.}
}
@article{NIKITIN2021783,
title = {Constrained plasticity reserve as a natural way to control frequency and weights in spiking neural networks},
journal = {Neural Networks},
volume = {143},
pages = {783-797},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100321X},
author = {Oleg Nikitin and Olga Lukyanova and Alex Kunin},
keywords = {Neural homeostasis, Spike-timing-dependent plasticity, Synaptic scaling, Adaptive control, Bio-inspired cognitive architectures},
abstract = {Biological neurons have adaptive nature and perform complex computations involving the filtering of redundant information. However, most common neural cell models, including biologically plausible, such as Hodgkin–Huxley or Izhikevich, do not possess predictive dynamics on a single-cell level. Moreover, the modern rules of synaptic plasticity or interconnections weights adaptation also do not provide grounding for the ability of neurons to adapt to the ever-changing input signal intensity. While natural neuron synaptic growth is precisely controlled and restricted by protein supply and recycling, weight correction rules such as widely used STDP are efficiently unlimited in change rate and scale. The present article introduces new mechanics of interconnection between neuron firing rate homeostasis and weight change through STDP growth bounded by abstract protein reserve, controlled by the intracellular optimization algorithm. We show how these cellular dynamics help neurons filter out the intense noise signals to help neurons keep a stable firing rate. We also examine that such filtering does not affect the ability of neurons to recognize the correlated inputs in unsupervised mode. Such an approach might be used in the machine learning domain to improve the robustness of AI systems.}
}
@article{MANNELLA2021428,
title = {Active inference through whiskers},
journal = {Neural Networks},
volume = {144},
pages = {428-437},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003506},
author = {Francesco Mannella and Federico Maggiore and Manuel Baltieri and Giovanni Pezzulo},
keywords = {Active inference, Active sensing, Whiskers},
abstract = {Rodents use whisking to probe actively their environment and to locate objects in space, hence providing a paradigmatic biological example of active sensing. Numerous studies show that the control of whisking has anticipatory aspects. For example, rodents target their whisker protraction to the distance at which they expect objects, rather than just reacting fast to contacts with unexpected objects. Here we characterize the anticipatory control of whisking in rodents as an active inference process. In this perspective, the rodent is endowed with a prior belief that it will touch something at the end of the whisker protraction, and it continuously modulates its whisking amplitude to minimize (proprioceptive and somatosensory) prediction errors arising from an unexpected whisker–object contact, or from a lack of an expected contact. We will use the model to qualitatively reproduce key empirical findings about the ways rodents modulate their whisker amplitude during exploration and the scanning of (expected or unexpected) objects. Furthermore, we will discuss how the components of active inference model can in principle map to the neurobiological circuits of rodent whisking.}
}
@article{YANG2022144,
title = {On the capacity of deep generative networks for approximating distributions},
journal = {Neural Networks},
volume = {145},
pages = {144-154},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004032},
author = {Yunfei Yang and Zhen Li and Yang Wang},
keywords = {Deep ReLU networks, Generative adversarial networks, Approximation complexity, Wasserstein distance, Maximum mean discrepancy},
abstract = {We study the efficacy and efficiency of deep generative networks for approximating probability distributions. We prove that neural networks can transform a low-dimensional source distribution to a distribution that is arbitrarily close to a high-dimensional target distribution, when the closeness is measured by Wasserstein distances and maximum mean discrepancy. Upper bounds of the approximation error are obtained in terms of the width and depth of neural network. Furthermore, it is shown that the approximation error in Wasserstein distance grows at most linearly on the ambient dimension and that the approximation order only depends on the intrinsic dimension of the target distribution. On the contrary, when f-divergences are used as metrics of distributions, the approximation property is different. We show that in order to approximate the target distribution in f-divergences, the dimension of the source distribution cannot be smaller than the intrinsic dimension of the target distribution.}
}
@article{KIM2021591,
title = {The generalized extreme learning machines: Tuning hyperparameters and limiting approach for the Moore–Penrose generalized inverse},
journal = {Neural Networks},
volume = {144},
pages = {591-602},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003580},
author = {Meejoung Kim},
keywords = {Generalized extreme learning machine, Multiple hidden layer feedforward neural networks, Universal approximation, Moore–Penrose generalized inverse, Output weight matrix, Attack prediction},
abstract = {In this paper, we propose the generalized extreme learning machine (GELM). GELM is an ELM that incorporates the analyzed hyperparameters of ELM, such as sizes and ranks of weight matrices, and a limiting approach for the Moore–Penrose generalized inverse (M–P GI) into the learning process. ELM overcomes shortcomings of traditional deep learning, such as time-consuming due to iterative executions, as it learns quickly by removing the adjustment time of hyperparameters. There are desirable numbers of hidden nodes in ELM for single hidden layer feedforward neural networks, minimizing prediction error. However, it is difficult to use the desired number because it is related to the number of data used and datasets tend to be large. We consider ELM for multiple hidden layer feedforward neural networks. We analyze matrices derived in the network and figure out the characteristics of weight matrices and biases considering accurate prediction and learning speed, based on mathematical theories and a limiting approach for the M–P GI. The final output matrix of GELM is formulated explicitly. Experiments are conducted to verify the analysis using network traffic data, including DDoS attacks. The performances of GLEM, such as accuracies and learning speed, are compared for the networks with single and multiple hidden layers. Numerical results show the advantages of GELM in the performance measures, and the use of multiple hidden layers in GELM does not significantly affect performance. The theory-based prediction performances obtained from GELM will be the criterion for the margin of deep learning performance.}
}
@article{LI2021678,
title = {Smoothing neural network for L0 regularized optimization problem with general convex constraints},
journal = {Neural Networks},
volume = {143},
pages = {678-689},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003063},
author = {Wenjing Li and Wei Bian},
keywords = {Neural network, Differential inclusion,  regularization, General convex constraints, Smoothing method, Nonsmooth nonconvex optimization},
abstract = {In this paper, we propose a neural network modeled by a differential inclusion to solve a class of discontinuous and nonconvex sparse regression problems with general convex constraints, whose objective function is the sum of a convex but not necessarily differentiable loss function and L0 regularization. We construct a smoothing relaxation function of L0 regularization and propose a neural network to solve the considered problem. We prove that the solution of proposed neural network with any initial point satisfying linear equality constraints is global existent, bounded and reaches the feasible region in finite time and remains there thereafter. Moreover, the solution of proposed neural network is its slow solution and any accumulation point of it is a Clarke stationary point of the brought forward nonconvex smoothing approximation problem. In the box-constrained case, all accumulation points of the solution own a unified lower bound property and have a common support set. Except for a special case, any accumulation point of the solution is a local minimizer of the considered problem. In particular, the proposed neural network has a simple structure than most existing neural networks for solving the locally Lipschitz continuous but nonsmooth nonconvex problems. Finally, we give some numerical experiments to show the efficiency of proposed neural network.}
}
@article{LEUNG202268,
title = {Cardinality-constrained portfolio selection based on collaborative neurodynamic optimization},
journal = {Neural Networks},
volume = {145},
pages = {68-79},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003981},
author = {Man-Fai Leung and Jun Wang},
keywords = {Cardinality constraint, Neurodynamic optimization, Mixed-integer programming, Portfolio selection},
abstract = {Portfolio optimization is one of the most important investment strategies in financial markets. It is practically desirable for investors, especially high-frequency traders, to consider cardinality constraints in portfolio selection, to avoid odd lots and excessive costs such as transaction fees. In this paper, a collaborative neurodynamic optimization approach is presented for cardinality-constrained portfolio selection. The expected return and investment risk in the Markowitz framework are scalarized as a weighted Chebyshev function and the cardinality constraints are equivalently represented using introduced binary variables as an upper bound. Then cardinality-constrained portfolio selection is formulated as a mixed-integer optimization problem and solved by means of collaborative neurodynamic optimization with multiple recurrent neural networks repeatedly repositioned using a particle swarm optimization rule. The distribution of resulting Pareto-optimal solutions is also iteratively perfected by optimizing the weights in the scalarized objective functions based on particle swarm optimization. Experimental results with stock data from four major world markets are discussed to substantiate the superior performance of the collaborative neurodynamic approach to several exact and metaheuristic methods.}
}
@article{SAHA2021359,
title = {Physics-incorporated convolutional recurrent neural networks for source identification and forecasting of dynamical systems},
journal = {Neural Networks},
volume = {144},
pages = {359-371},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003464},
author = {Priyabrata Saha and Saurabh Dash and Saibal Mukhopadhyay},
keywords = {Dynamical systems, Partial differential equation, Recurrent neural networks, Physics-incorporated neural networks},
abstract = {Spatio-temporal dynamics of physical processes are generally modeled using partial differential equations (PDEs). Though the core dynamics follows some principles of physics, real-world physical processes are often driven by unknown external sources. In such cases, developing a purely analytical model becomes very difficult and data-driven modeling can be of assistance. In this paper, we present a hybrid framework combining physics-based numerical models with deep learning for source identification and forecasting of spatio-temporal dynamical systems with unobservable time-varying external sources. We formulate our model PhICNet as a convolutional recurrent neural network (RNN) which is end-to-end trainable for spatio-temporal evolution prediction of dynamical systems and learns the source behavior as an internal state of the RNN. Experimental results show that the proposed model can forecast the dynamics for a relatively long time and identify the sources as well.}
}
@article{UCHIBE2021138,
title = {Forward and inverse reinforcement learning sharing network weights and hyperparameters},
journal = {Neural Networks},
volume = {144},
pages = {138-153},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003221},
author = {Eiji Uchibe and Kenji Doya},
keywords = {Reinforcement learning, Inverse reinforcement learning, Imitation learning, Entropy regularization},
abstract = {This paper proposes model-free imitation learning named Entropy-Regularized Imitation Learning (ERIL) that minimizes the reverse Kullback–Leibler (KL) divergence. ERIL combines forward and inverse reinforcement learning (RL) under the framework of an entropy-regularized Markov decision process. An inverse RL step computes the log-ratio between two distributions by evaluating two binary discriminators. The first discriminator distinguishes the state generated by the forward RL step from the expert’s state. The second discriminator, which is structured by the theory of entropy regularization, distinguishes the state–action–next-state tuples generated by the learner from the expert ones. One notable feature is that the second discriminator shares hyperparameters with the forward RL, which can be used to control the discriminator’s ability. A forward RL step minimizes the reverse KL estimated by the inverse RL step. We show that minimizing the reverse KL divergence is equivalent to finding an optimal policy. Our experimental results on MuJoCo-simulated environments and vision-based reaching tasks with a robotic arm show that ERIL is more sample-efficient than the baseline methods. We apply the method to human behaviors that perform a pole-balancing task and describe how the estimated reward functions show how every subject achieves her goal.}
}
@article{YE2021755,
title = {A novel meta-learning framework: Multi-features adaptive aggregation method with information enhancer},
journal = {Neural Networks},
volume = {144},
pages = {755-765},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003919},
author = {Hailiang Ye and Yi Wang and Feilong Cao},
keywords = {Deep learning, Meta-learning, Feature extraction, Few-shot classification},
abstract = {Deep learning has shown its great potential in the field of image classification due to its powerful feature extraction ability, which heavily depends on the number of available training samples. However, it is still a huge challenge on how to obtain an effective feature representation and further learn a promising classifier by deep networks when faced with few-shot classification tasks. This paper proposes a multi-features adaptive aggregation meta-learning method with an information enhancer for few-shot classification tasks, referred to as MFAML. It contains three main modules, including a feature extraction module, an information enhancer, and a multi-features adaptive aggregation classifier (MFAAC). During the meta-training stage, the information enhancer comprised of some deconvolutional layers is designed to promote the effective utilization of samples and thereby capturing more valuable information in the process of feature extraction. Simultaneously, the MFAAC module integrates the features from several convolutional layers of the feature extraction module. The obtained features then feed into the similarity module so that implementing the adaptive adjustment of the predicted label. The information enhancer and MFAAC are connected by a hybrid loss, providing an excellent feature representation. During the meta-test stage, the information enhancer is removed and we keep the remaining architecture for fast adaption on the final target task. The whole MFAML framework is solved by the optimization strategy of model-agnostic meta-learner (MAML) and can effectively improve generalization performance. Experimental results on several benchmark datasets demonstrate the superiority of the proposed method over other representative few-shot classification methods.}
}
@article{WANG202222,
title = {Enriching query semantics for code search with reinforcement learning},
journal = {Neural Networks},
volume = {145},
pages = {22-32},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003877},
author = {Chaozheng Wang and Zhenhao Nong and Cuiyun Gao and Zongjie Li and Jichuan Zeng and Zhenchang Xing and Yang Liu},
keywords = {Code search, Query semantics, Semantic enrichment, Reinforcement learning},
abstract = {Code search is a common practice for developers during software implementation. The challenges of accurate code search mainly lie in the knowledge gap between source code and natural language (i.e., queries). Due to the limited code-query pairs and large code-description pairs available, the prior studies based on deep learning techniques focus on learning the semantic matching relation between source code and corresponding description texts for the task, and hypothesize that the semantic gap between descriptions and user queries is marginal. In this work, we found that the code search models trained on code-description pairs may not perform well on user queries, which indicates the semantic distance between queries and code descriptions. To mitigate the semantic distance for more effective code search, we propose QueCos, a Query-enriched Code search model. QueCos learns to generate semantic enriched queries to capture the key semantics of given queries with reinforcement learning (RL). With RL, the code search performance is considered as a reward for producing accurate semantic enriched queries. The enriched queries are finally employed for code search. Experiments on the benchmark datasets show that QueCos can significantly outperform the state-of-the-art code search models.}
}
@article{DOBORJEH2021522,
title = {Personalised predictive modelling with brain-inspired spiking neural networks of longitudinal MRI neuroimaging data and the case study of dementia},
journal = {Neural Networks},
volume = {144},
pages = {522-539},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003634},
author = {Maryam Doborjeh and Zohreh Doborjeh and Alexander Merkin and Helena Bahrami and Alexander Sumich and Rita Krishnamurthi and Oleg N. Medvedev and Mark Crook-Rumsey and Catherine Morgan and Ian Kirk and Perminder S. Sachdev and Henry Brodaty and Kristan Kang and Wei Wen and Valery Feigin and Nikola Kasabov},
keywords = {Personalised modelling, Spiking neural networks, Longitudinal MRI data, Dementia, Classification, Prediction},
abstract = {Background:
Longitudinal neuroimaging provides spatiotemporal brain data (STBD) measurement that can be utilised to understand dynamic changes in brain structure and/or function underpinning cognitive activities. Making sense of such highly interactive information is challenging, given that the features manifest intricate temporal, causal relations between the spatially distributed neural sources in the brain.
Methods:
The current paper argues for the advancement of deep learning algorithms in brain-inspired spiking neural networks (SNN), capable of modelling structural data across time (longitudinal measurement) and space (anatomical components). The paper proposes a methodology and a computational architecture based on SNN for building personalised predictive models from longitudinal brain data to accurately detect, understand, and predict the dynamics of an individual’s functional brain state. The methodology includes finding clusters of similar data to each individual, data interpolation, deep learning in a 3-dimensional brain-template structured SNN model, classification and prediction of individual outcome, visualisation of structural brain changes related to the predicted outcomes, interpretation of results, and individual and group predictive marker discovery.
Results:
To demonstrate the functionality of the proposed methodology, the paper presents experimental results on a longitudinal magnetic resonance imaging (MRI) dataset derived from 175 older adults of the internationally recognised community-based cohort Sydney Memory and Ageing Study (MAS) spanning 6 years of follow-up.
Significance:
The models were able to accurately classify and predict 2 years ahead of cognitive decline, such as mild cognitive impairment (MCI) and dementia with 95% and 91% accuracy, respectively. The proposed methodology also offers a 3-dimensional visualisation of the MRI models reflecting the dynamic patterns of regional changes in white matter hyperintensity (WMH) and brain volume over 6 years.
Conclusion:
The method is efficient for personalised predictive modelling on a wide range of neuroimaging longitudinal data, including also demographic, genetic, and clinical data. As a case study, it resulted in finding predictive markers for MCI and dementia as dynamic brain patterns using MRI data.}
}
@article{HUANG202190,
title = {A neural decoding algorithm that generates language from visual activity evoked by natural images},
journal = {Neural Networks},
volume = {144},
pages = {90-100},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003117},
author = {Wei Huang and Hongmei Yan and Kaiwen Cheng and Chong Wang and Jiyi Li and Yuting Wang and Chen Li and Chaorong Li and Yunhan Li and Zhentao Zuo and Huafu Chen},
keywords = {Neural decoding, Language decoding, Visual activity, Progressive transfer, Human–computer interaction},
abstract = {Transforming neural activities into language is revolutionary for human–computer interaction as well as functional restoration of aphasia. Present rapid development of artificial intelligence makes it feasible to decode the neural signals of human visual activities. In this paper, a novel Progressive Transfer Language Decoding Model (PT-LDM) is proposed to decode visual fMRI signals into phrases or sentences when natural images are being watched. The PT-LDM consists of an image-encoder, a fMRI encoder and a language-decoder. The results showed that phrases and sentences were successfully generated from visual activities. Similarity analysis showed that three often-used evaluation indexes BLEU, ROUGE and CIDEr reached 0.182, 0.197 and 0.680 averagely between the generated texts and the corresponding annotated texts in the testing set respectively, significantly higher than the baseline. Moreover, we found that higher visual areas usually had better performance than lower visual areas and the contribution curve of visual response patterns in language decoding varied at successively different time points. Our findings demonstrate that the neural representations elicited in visual cortices when scenes are being viewed have already contained semantic information that can be utilized to generate human language. Our study shows potential application of language-based brain–machine interfaces in the future, especially for assisting aphasics in communicating more efficiently with fMRI signals.}
}
@article{FROLOV2021187,
title = {Adversarial text-to-image synthesis: A review},
journal = {Neural Networks},
volume = {144},
pages = {187-209},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021002823},
author = {Stanislav Frolov and Tobias Hinz and Federico Raue and Jörn Hees and Andreas Dengel},
keywords = {Text-to-image synthesis, Generative adversarial networks},
abstract = {With the advent of generative adversarial networks, synthesizing images from text descriptions has recently become an active research area. It is a flexible and intuitive way for conditional image generation with significant progress in the last years regarding visual realism, diversity, and semantic alignment. However, the field still faces several challenges that require further research efforts such as enabling the generation of high-resolution images with multiple objects, and developing suitable and reliable evaluation metrics that correlate with human judgement. In this review, we contextualize the state of the art of adversarial text-to-image synthesis models, their development since their inception five years ago, and propose a taxonomy based on the level of supervision. We critically examine current strategies to evaluate text-to-image synthesis models, highlight shortcomings, and identify new areas of research, ranging from the development of better datasets and evaluation metrics to possible improvements in architectural design and model training. This review complements previous surveys on generative adversarial networks with a focus on text-to-image synthesis which we believe will help researchers to further advance the field.}
}
@article{LI2021443,
title = {Combination of certainty and uncertainty: Using FusionGAN to create abstract paintings},
journal = {Neural Networks},
volume = {144},
pages = {443-454},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003518},
author = {Mao Li and Jiancheng Lv and Chenwei Tang and Jian Wang and Zhichen Lai and Youcheng Huang},
keywords = {Abstract painting generation, Certainty and uncertainty, Structural information, Hierarchy elements, Generative adversarial network},
abstract = {In the study of generative art, it is relatively easy at present to achieve a high degree of certainty or uncertainty. However, the combination of certainty and uncertainty has always been an area of difficulty in generative art. In this paper, we present a novel FusionGAN system to automate the generation of abstract paintings. These generated abstract paintings combine the factors of certainty and uncertainty. First, we collect an APdataset consisting of three parts: abstract paintings drawn by artists, sketches, and abstract paintings generated by other neural network methods. We then train the proposed FusionGAN system on the collected dataset to learn the expression of abstract paintings. Corresponding to the two-step operation of the combination of certainty and uncertainty in the artist’s creation, the proposed FusionGAN system is also divided into two steps for the generation of abstract paintings. More specifically, the first step is the basic structure establishment, which corresponds to the fundamental certainty element in the painting creation. The second step is the realization of details, which integrates the uncertain details based on the basic structure. The experimental results achieved by our system in abstract painting generation enrich the diversity of artistic creation and have been recognized by art institutions, with some results displayed on their websites.}
}
@article{MACPHERSON2021507,
title = {Parallel and hierarchical neural mechanisms for adaptive and predictive behavioral control},
journal = {Neural Networks},
volume = {144},
pages = {507-521},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003592},
author = {Tom Macpherson and Masayuki Matsumoto and Hiroaki Gomi and Jun Morimoto and Eiji Uchibe and Takatoshi Hikida},
keywords = {Parallel processing, Hierarchical processing, Behavioral flexibility, Movement control, Artificial intelligence, Humanoid robotics},
abstract = {Our brain can be recognized as a network of largely hierarchically organized neural circuits that operate to control specific functions, but when acting in parallel, enable the performance of complex and simultaneous behaviors. Indeed, many of our daily actions require concurrent information processing in sensorimotor, associative, and limbic circuits that are dynamically and hierarchically modulated by sensory information and previous learning. This organization of information processing in biological organisms has served as a major inspiration for artificial intelligence and has helped to create in silico systems capable of matching or even outperforming humans in several specific tasks, including visual recognition and strategy-based games. However, the development of human-like robots that are able to move as quickly as humans and respond flexibly in various situations remains a major challenge and indicates an area where further use of parallel and hierarchical architectures may hold promise. In this article we review several important neural and behavioral mechanisms organizing hierarchical and predictive processing for the acquisition and realization of flexible behavioral control. Then, inspired by the organizational features of brain circuits, we introduce a multi-timescale parallel and hierarchical learning framework for the realization of versatile and agile movement in humanoid robots.}
}
@article{JIANG202121,
title = {Learning lightweight super-resolution networks with weight pruning},
journal = {Neural Networks},
volume = {144},
pages = {21-32},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003075},
author = {Xinrui Jiang and Nannan Wang and Jingwei Xin and Xiaobo Xia and Xi Yang and Xinbo Gao},
keywords = {Image super-resolution, Lightweight network, Model pruning},
abstract = {Single image super-resolution (SISR) has achieved significant performance improvements due to the deep convolutional neural networks (CNN). However, the deep learning-based method is computationally intensive and memory demanding, which limit its practical deployment, especially for mobile devices. Focusing on this issue, in this paper, we present a novel approach to compress SR networks by weight pruning. To achieve this goal, firstly, we explore a progressive optimization method to gradually zero out the redundant parameters. Then, we construct a sparse-aware attention module by exploring a pruning-based well-suited attention strategy. Finally, we propose an information multi-slicing network which extracts and integrates multi-scale features at a granular level to acquire a more lightweight and accurate SR network. Extensive experiments reflect the pruning method could reduce the model size without a noticeable drop in performance, making it possible to apply the start-of-the-art SR models in the real-world applications. Furthermore, our proposed pruning versions could achieve better accuracy and visual improvements than state-of-the-art methods.}
}
@article{LI2022128,
title = {Cross-attention-map-based regularization for adversarial domain adaptation},
journal = {Neural Networks},
volume = {145},
pages = {128-138},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004044},
author = {Jingwei Li and Huanjie Wang and Ke Wu and Chengbao Liu and Jie Tan},
keywords = {Domain adaptation, Few-shot learning, Attention mechanism, Contrastive learning},
abstract = {In unsupervised domain adaptation (UDA), many efforts are taken to pull the source domain and the target domain closer by adversarial training. Most methods focus on aligning distributions or features between the source domain and the target domain. However, little attention is paid to the interaction between finer-grained levels, such as classes or samples of the two domains. In contrast to UDA, another transfer learning task, i.e., few-shot learning (FSL), takes full advantage of the finer-grained-level alignment. Many FSL methods implement the interaction between samples of support sets and query sets, leading to significant improvements. We wonder whether we can get some inspiration from these methods and bring such ideas of FSL to UDA. To this end, we first take a closer look at the differences between FSL and UDA and bridge the gap between them by high-confidence sample selection (HCSS). Then we propose cross-attention map generation module (CAMGM) to interact samples selected by HCSS. Moreover, we propose a simple but efficient method called cross-attention-map-based regularization (CAMR) to regularize the feature maps generated by the feature extractor. Experiments on three challenging datasets demonstrate that CAMR can bring solid improvements when added to the original objective. More specifically, the proposed CAMR can outperform original methods by 1% to 2% in most tasks without bells and whistles.}
}
@article{MARKOVIC2021229,
title = {An empirical evaluation of active inference in multi-armed bandits},
journal = {Neural Networks},
volume = {144},
pages = {229-246},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003233},
author = {Dimitrije Marković and Hrvoje Stojić and Sarah Schwöbel and Stefan J. Kiebel},
keywords = {Decision making, Bayesian inference, Multi-armed bandits, Active inference, Upper confidence bound, Thompson sampling},
abstract = {A key feature of sequential decision making under uncertainty is a need to balance between exploiting—choosing the best action according to the current knowledge, and exploring—obtaining information about values of other actions. The multi-armed bandit problem, a classical task that captures this trade-off, served as a vehicle in machine learning for developing bandit algorithms that proved to be useful in numerous industrial applications. The active inference framework, an approach to sequential decision making recently developed in neuroscience for understanding human and animal behaviour, is distinguished by its sophisticated strategy for resolving the exploration–exploitation trade-off. This makes active inference an exciting alternative to already established bandit algorithms. Here we derive an efficient and scalable approximate active inference algorithm and compare it to two state-of-the-art bandit algorithms: Bayesian upper confidence bound and optimistic Thompson sampling. This comparison is done on two types of bandit problems: a stationary and a dynamic switching bandit. Our empirical evaluation shows that the active inference algorithm does not produce efficient long-term behaviour in stationary bandits. However, in the more challenging switching bandit problem active inference performs substantially better than the two state-of-the-art bandit algorithms. The results open exciting venues for further research in theoretical and applied machine learning, as well as lend additional credibility to active inference as a general framework for studying human and animal behaviour.}
}
@article{LIU2021759,
title = {Reliable impulsive synchronization for fuzzy neural networks with mixed controllers},
journal = {Neural Networks},
volume = {143},
pages = {759-766},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100318X},
author = {Fen Liu and Chang Liu and Hongxia Rao and Yong Xu and Tingwen Huang},
keywords = {Fuzzy neural networks, Synchronization, Random actuator failure, Impulsive control, Mixed controller},
abstract = {This work studies the synchronization of the master–slave (MS) fuzzy neural networks (FNNs) with random actuator failure, where the state information of the master FNNs can not be obtained directly. To reduce the loads of the communication channel and the controller, the simultaneously impulsive driven strategy of the communication channel and the controller is proposed. On the basis of the received measurements of the master FNNs, the mixed controller consisting of observer based controller and the static controller is designed. The randomly occurred actuator failure is also considered. According to the Lyapunov method, the sufficient conditions are achieved to ensure the synchronization of the MS FNNs, and the controller gains are designed by using the obtained results. The validity of the derived results is illustrated by a numerical example.}
}
@article{VERMA202290,
title = {Interpolation consistency training for semi-supervised learning},
journal = {Neural Networks},
volume = {145},
pages = {90-106},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003993},
author = {Vikas Verma and Kenji Kawaguchi and Alex Lamb and Juho Kannala and Arno Solin and Yoshua Bengio and David Lopez-Paz},
keywords = {Semi-supervised learning, Deep Neural Networks, Mixup, Consistency regularization},
abstract = {We introduce Interpolation Consistency Training (ICT), a simple and computation efficient algorithm for training Deep Neural Networks in the semi-supervised learning paradigm. ICT encourages the prediction at an interpolation of unlabeled points to be consistent with the interpolation of the predictions at those points. In classification problems, ICT moves the decision boundary to low-density regions of the data distribution. Our experiments show that ICT achieves state-of-the-art performance when applied to standard neural network architectures on the CIFAR-10 and SVHN benchmark datasets. Our theoretical analysis shows that ICT corresponds to a certain type of data-adaptive regularization with unlabeled points which reduces overfitting to labeled points under high confidence values.}
}
@article{SCHIESSLER2021384,
title = {Neural network surgery: Combining training with topology optimization},
journal = {Neural Networks},
volume = {144},
pages = {384-393},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003476},
author = {Elisabeth J. Schiessler and Roland C. Aydin and Kevin Linka and Christian J. Cyron},
keywords = {Neural architecture search, Topology optimization, Singular value decomposition, Genetic algorithm},
abstract = {With ever increasing computational capacities, neural networks become more and more proficient at solving complex tasks. However, picking a sufficiently good network topology usually relies on expert human knowledge. Neural architecture search aims to reduce the extent of expertise that is needed. Modern architecture search techniques often rely on immense computational power, or apply trained meta-controllers for decision making. We develop a framework for a genetic algorithm that is both computationally cheap and makes decisions based on mathematical criteria rather than trained parameters. It is a hybrid approach that fuses training and topology optimization together into one process. Structural modifications that are performed include adding or removing layers of neurons, with some re-training applied to make up for any incurred change in input–output behaviour. Our ansatz is tested on several benchmark datasets with limited computational overhead compared to training only the baseline. This algorithm can achieve a significant increase in accuracy (as compared to a fully trained baseline), rescue insufficient topologies that in their current state are only able to learn to a limited extent, and dynamically reduce network size without loss in achieved accuracy. On standard ML datasets, accuracy improvements compared to baseline performance can range from 20% for well performing starting topologies to more than 40% in case of insufficient baselines, or reduce network size by almost 15%.}
}
@article{MONTEIRO2021698,
title = {Quantum neuron with real weights},
journal = {Neural Networks},
volume = {143},
pages = {698-708},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.07.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003051},
author = {Cláudio A. Monteiro and Gustavo I.S. Filho and Matheus Hopper J. Costa and Fernando M. {de Paula Neto} and Wilson R. {de Oliveira}},
keywords = {Quantum artificial neurons, Quantum machine learning, Quantum computing, Artificial intelligence, Machine learning},
abstract = {This paper proposes a new model of a real weights quantum neuron exploiting the so-called quantum parallelism which allows for an exponential speedup of computations. The quantum neurons were trained in a classical–quantum approach, considering the delta rule to update the values of the weights in an image database of three distinct patterns. We performed classical simulations and also executed experiments in an actual small-scale quantum processor. The results of the experiments show that the proposed quantum real neuron model has a good generalisation capacity, demonstrating better accuracy than the traditional binary quantum perceptron model.}
}
@article{BOUCHERROUTHIER2021639,
title = {Extreme neural machines},
journal = {Neural Networks},
volume = {144},
pages = {639-647},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100383X},
author = {Megan Boucher-Routhier and Bill Ling Feng Zhang and Jean-Philippe Thivierge},
keywords = {Recurrent network, Spiking neurons, Visual cortex, Extreme learning machines, Image processing, Temporal sequences},
abstract = {Recurrent neural networks can solve a variety of computational tasks and produce patterns of activity that capture key properties of brain circuits. However, learning rules designed to train these models are time-consuming and prone to inaccuracies when tuning connection weights located deep within the network. Here, we describe a rapid one-shot learning rule to train recurrent networks composed of biologically-grounded neurons. First, inputs to the model are compressed onto a smaller number of recurrent neurons. Then, a non-iterative rule adjusts the output weights of these neurons based on a target signal. The model learned to reproduce natural images, sequential patterns, as well as a high-resolution movie scene. Together, results provide a novel avenue for one-shot learning in biologically realistic recurrent networks and open a path to solving complex tasks by merging brain-inspired models with rapid optimization rules.}
}
@article{CHEVTCHENKO2021496,
title = {Combining STDP and binary networks for reinforcement learning from images and sparse rewards},
journal = {Neural Networks},
volume = {144},
pages = {496-506},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003609},
author = {Sérgio F. Chevtchenko and Teresa B. Ludermir},
keywords = {Spiking neural networks, Binary neural networks, STDP, Reinforcement learning},
abstract = {Spiking neural networks (SNNs) aim to replicate energy efficiency, learning speed and temporal processing of biological brains. However, accuracy and learning speed of such networks is still behind reinforcement learning (RL) models based on traditional neural models. This work combines a pre-trained binary convolutional neural network with an SNN trained online through reward-modulated STDP in order to leverage advantages of both models. The spiking network is an extension of its previous version, with improvements in architecture and dynamics to address a more challenging task. We focus on extensive experimental evaluation of the proposed model with optimized state-of-the-art baselines, namely proximal policy optimization (PPO) and deep Q network (DQN). The models are compared on a grid-world environment with high dimensional observations, consisting of RGB images with up to 256 × 256 pixels. The experimental results show that the proposed architecture can be a competitive alternative to deep reinforcement learning (DRL) in the evaluated environment and provide a foundation for more complex future applications of spiking networks.}
}
@article{2023ii,
title = {Editorial Board},
journal = {Neural Networks},
volume = {165},
pages = {ii},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00415-X},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300415X}
}
@article{LI2021455,
title = {Detection of pancreatic cancer by convolutional-neural-network-assisted spontaneous Raman spectroscopy with critical feature visualization},
journal = {Neural Networks},
volume = {144},
pages = {455-464},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003567},
author = {Zhongqiang Li and Zheng Li and Qing Chen and Alexandra Ramos and Jian Zhang and J. Philip Boudreaux and Ramcharan Thiagarajan and Yvette Bren-Mattison and Michael E. Dunham and Andrew J. McWhorter and Xin Li and Ji-Ming Feng and Yanping Li and Shaomian Yao and Jian Xu},
keywords = {Deep learning, Pancreatic cancer, Convolutional neural network, Spontaneous Raman spectroscopy, Lab-designed hand-held Raman spectroscopic system},
abstract = {Pancreatic cancer is the deadliest cancer type with a five-year survival rate of less than 9%. Detection of tumor margins plays an essential role in the success of surgical resection. However, histopathological assessment is time-consuming, expensive, and labor-intensive. We constructed a lab-designed, hand-held Raman spectroscopic system that could enable intraoperative tissue diagnosis using convolutional neural network (CNN) models to efficiently distinguish between cancerous and normal pancreatic tissue. To our best knowledge, this is the first reported effort to diagnose pancreatic cancer by CNN-aided spontaneous Raman scattering with a lab-developed system designed for intraoperative applications. Classification based on the original one-dimensional (1D) Raman, two-dimensional (2D) Raman images, and the first principal component (PC1) from the principal component analysis on the 2D image, could all achieve high performance: the testing sensitivity, specificity, and accuracy were over 95%, and the area under the curve approached 0.99. Although CNN models often show great success in classification, it has always been challenging to visualize the CNN features in these models, which has never been achieved in the Raman spectroscopy application in cancer diagnosis. By studying individual Raman regions and by extracting and visualizing CNN features from max-pooling layers, we identified critical Raman peaks that could aid in the classification of cancerous and noncancerous tissues. 2D Raman PC1 yielded more critical peaks for pancreatic cancer identification than that of 1D Raman, as the Raman intensity was amplified by 2D Raman PC1. To our best knowledge, the feature visualization was achieved for the first time in the field of CNN-aided spontaneous Raman spectroscopy for cancer diagnosis. Based on these CNN feature peaks and their frequency at specific wavenumbers, pancreatic cancerous tissue was found to contain more biochemical components related to the protein contents (particularly collagen), whereas normal pancreatic tissue was found to contain more lipids and nucleic acid (particularly deoxyribonucleic acid/ribonucleic acid). Overall, the CNN model in combination with Raman spectroscopy could serve as a useful tool for the extraction of key features that can help differentiate pancreatic cancer from a normal pancreas.}
}
@article{KIM2021686,
title = {Optimizing Deeper Spiking Neural Networks for Dynamic Vision Sensing},
journal = {Neural Networks},
volume = {144},
pages = {686-698},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003841},
author = {Youngeun Kim and Priyadarshini Panda},
keywords = {Spiking neural networks, Event-driven data, Dynamic vision sensing, Energy-efficient deep learning, Neuromorphic computing},
abstract = {Spiking Neural Networks (SNNs) have recently emerged as a new generation of low-power deep neural networks due to sparse, asynchronous, and binary event-driven processing. Most previous deep SNN optimization methods focus on static datasets (e.g., MNIST) from a conventional frame-based camera. On the other hand, optimization techniques for event data from Dynamic Vision Sensor (DVS) cameras are still at infancy. Most prior SNN techniques handling DVS data are limited to shallow networks and thus, show low performance. Generally, we observe that the integrate-and-fire behavior of spiking neurons diminishes spike activity in deeper layers. The sparse spike activity results in a sub-optimal solution during training (i.e., performance degradation). To address this limitation, we propose novel algorithmic and architectural advances to accelerate the training of very deep SNNs on DVS data. Specifically, we propose Spike Activation Lift Training (SALT) which increases spike activity across all layers by optimizing both weights and thresholds in convolutional layers. After applying SALT, we train the weights based on the cross-entropy loss. SALT helps the networks to convey ample information across all layers during training and therefore improves the performance. Furthermore, we propose a simple and effective architecture, called Switched-BN, which exploits Batch Normalization (BN). Previous methods show that the standard BN is incompatible with the temporal dynamics of SNNs. Therefore, in Switched-BN architecture, we apply BN to the last layer of an SNN after accumulating all the spikes from previous layer with a spike voltage accumulator (i.e., converting temporal spike information to float value). Even though we apply BN in just one layer of SNNs, our results demonstrate a considerable performance gain without any significant computational overhead. Through extensive experiments, we show the effectiveness of SALT and Switched-BN for training very deep SNNs from scratch on various benchmarks including, DVS-Cifar10, N-Caltech, DHP19, CIFAR10, and CIFAR100. To the best of our knowledge, this is the first work showing state-of-the-art performance with deep SNNs on DVS data.}
}
@article{RODRIGUEZVAZQUEZ2022155,
title = {Zenithal isotropic object counting by localization using adversarial training},
journal = {Neural Networks},
volume = {145},
pages = {155-163},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004019},
author = {Javier Rodriguez-Vazquez and Adrian Alvarez-Fernandez and Martin Molina and Pascual Campoy},
keywords = {Object counting, Deep learning, Convolutional neural networks, Adversarial training},
abstract = {Counting objects in images is a very time-consuming task for humans that yields to errors caused by repetitiveness and boredom. In this paper, we present a novel object counting method that, unlike most of the recent works that focus on the regression of a density map, performs the counting procedure by localizing each single object. This key difference allows us to provide not only an accurate count but the position of every counted object, information that can be critical in some areas such as precision agriculture. The method is designed in two steps: first, a CNN is in charge of mapping arbitrary objects to blob-like structures. Then, using a Laplacian of Gaussian (LoG) filter, we are able to gather the position of all detected objects. We also propose a semi-adversarial training procedure that, combined with the former design, improves the result by a large margin. After evaluating the method on two public benchmarks of isometric objects, we stay on par with the state of the art while being able to provide extra position information.}
}
@article{DERYCK2021732,
title = {On the approximation of functions by tanh neural networks},
journal = {Neural Networks},
volume = {143},
pages = {732-750},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003208},
author = {Tim {De Ryck} and Samuel Lanthaler and Siddhartha Mishra},
keywords = {Neural networks, Tanh, Function approximation, Deep learning},
abstract = {We derive bounds on the error, in high-order Sobolev norms, incurred in the approximation of Sobolev-regular as well as analytic functions by neural networks with the hyperbolic tangent activation function. These bounds provide explicit estimates on the approximation error with respect to the size of the neural networks. We show that tanh neural networks with only two hidden layers suffice to approximate functions at comparable or better rates than much deeper ReLU neural networks.}
}
@article{AN2022177,
title = {IC neuron: An efficient unit to construct neural networks},
journal = {Neural Networks},
volume = {145},
pages = {177-188},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003968},
author = {Junyi An and Fengshan Liu and Furao Shen and Jian Zhao and Ruotong Li and Kepan Gao},
keywords = {Neural network, Neuron model, Elastic collision, Inter-layer collision neuron},
abstract = {As a popular machine learning method, neural networks can be used to solve many complex tasks. Their strong generalization ability comes from the representation ability of the basic neuron models. The most popular neuron model is the McCulloch–Pitts (MP) neuron, which uses a simple transformation to process the input signal. A common trend is to use the MP neuron to design various neural networks. However, the optimization of the neuron structure is rarely considered. Inspired by the elastic collision model in physics, we propose a new neuron model that can represent more complex distributions. We term it the Inter-layer Collision (IC) neuron which divides the input space into multiple subspaces to represent different linear transformations. Through this operation, the IC neuron enhances the non-linear representation ability and emphasizes useful input features for a given task. We build the IC networks by integrating the IC neurons into the fully-connected, the convolutional, and the recurrent structures. The IC networks outperform the traditional neural networks in a wide range of tasks. Besides, we combine the IC neuron with deep learning models and show the superiority of the IC neuron. Our research proves that the IC neuron can be an effective basic unit to build network structures and make the network performance better.}
}
@article{YIN2021260,
title = {Incremental multi-view spectral clustering with sparse and connected graph learning},
journal = {Neural Networks},
volume = {144},
pages = {260-270},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003440},
author = {Hongwei Yin and Wenjun Hu and Zhao Zhang and Jungang Lou and Minmin Miao},
keywords = {Multi-view clustering, Incremental clustering, Sparse graph learning, Connected graph learning, Spectral embedding},
abstract = {In recent years, a lot of excellent multi-view clustering methods have been proposed. Because most of them need to fuse all views at one time, they are infeasible as the number of views increases over time. If the present multi-view clustering methods are employed directly to re-fuse all views at each time, it is too expensive to store all historical views. In this paper, we proposed an efficient incremental multi-view spectral clustering method with sparse and connected graph learning (SCGL). In our method, only one consensus similarity matrix is stored to represent the structural information of all historical views. Once the newly collected view is available, the consensus similarity matrix is reconstructed by learning from its previous version and the current new view. To further improve the incremental multi-view clustering performance, the sparse graph learning and the connected graph learning are integrated into our model, which can not only reduce the noises, but also preserve the correct connections within clusters. Experiments on several multi-view datasets demonstrate that our method is superior to traditional methods in clustering accuracy, and is more suitable to deal with the multi-view clustering with the number of views increasing over time.}
}
@article{XUAN2022248,
title = {FCL-Net: Towards accurate edge detection via Fine-scale Corrective Learning},
journal = {Neural Networks},
volume = {145},
pages = {248-259},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004135},
author = {Wenjie Xuan and Shaoli Huang and Juhua Liu and Bo Du},
keywords = {Edge detection, Top-down attentional guidance, Pixel-level fusion, Fine-scale Corrective Learning},
abstract = {Integrating multi-scale predictions has become a mainstream paradigm in edge detection. However, most existing methods mainly focus on effective feature extraction and multi-scale feature fusion while ignoring the low learning capacity in fine-level branches, limiting the overall fusion performance. In light of this, we propose a novel Fine-scale Corrective Learning Net (FCL-Net) that exploits semantic information from deep layers to facilitate fine-scale feature learning. FCL-Net mainly consists of a Top-down Attentional Guiding (TAG) and a Pixel-level Weighting (PW) module. TAG module adopts semantic attentional cues from coarse-scale prediction into guiding the fine-scale branches by learning a top-down LSTM. PW module treats the contribution of each spatial location independently and promote fine-level branches to detect detailed edges with high confidence. Experiments on three benchmark datasets, i.e., BSDS500, Multicue, and BIPED, show that our approach significantly outperforms the baseline and achieves a competitive ODS F-measure of 0.826 on the BSDS500 benchmark. The source code and models are publicly available at https://github.com/DREAMXFAR/FCL-Net.}
}
@article{MACPHERSON2021603,
title = {Natural and Artificial Intelligence: A brief introduction to the interplay between AI and neuroscience research},
journal = {Neural Networks},
volume = {144},
pages = {603-613},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003683},
author = {Tom Macpherson and Anne Churchland and Terry Sejnowski and James DiCarlo and Yukiyasu Kamitani and Hidehiko Takahashi and Takatoshi Hikida},
keywords = {Artificial intelligence, Neuroscience, Neural imaging, Visual processing, Working memory, Computational psychiatry},
abstract = {Neuroscience and artificial intelligence (AI) share a long history of collaboration. Advances in neuroscience, alongside huge leaps in computer processing power over the last few decades, have given rise to a new generation of in silico neural networks inspired by the architecture of the brain. These AI systems are now capable of many of the advanced perceptual and cognitive abilities of biological systems, including object recognition and decision making. Moreover, AI is now increasingly being employed as a tool for neuroscience research and is transforming our understanding of brain functions. In particular, deep learning has been used to model how convolutional layers and recurrent connections in the brain’s cerebral cortex control important functions, including visual processing, memory, and motor control. Excitingly, the use of neuroscience-inspired AI also holds great promise for understanding how changes in brain networks result in psychopathologies, and could even be utilized in treatment regimes. Here we discuss recent advancements in four areas in which the relationship between neuroscience and AI has led to major advancements in the field; (1) AI models of working memory, (2) AI visual processing, (3) AI analysis of big neuroscience datasets, and (4) computational psychiatry.}
}
@article{GAO202149,
title = {Schematic memory persistence and transience for efficient and robust continual learning},
journal = {Neural Networks},
volume = {144},
pages = {49-60},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003166},
author = {Yuyang Gao and Giorgio A. Ascoli and Liang Zhao},
keywords = {Deep learning, Deep neural networks, Continual learning, Schematic memory, Memory efficiency, Robustness},
abstract = {Continual learning is considered a promising step toward next-generation Artificial Intelligence (AI), where deep neural networks (DNNs) make decisions by continuously learning a sequence of different tasks akin to human learning processes. It is still quite primitive, with existing works focusing primarily on avoiding (catastrophic) forgetting. However, since forgetting is inevitable given bounded memory and unbounded task loads, ‘how to reasonably forget’ is a problem continual learning must address in order to reduce the performance gap between AIs and humans, in terms of (1) memory efficiency, (2) generalizability, and (3) robustness when dealing with noisy data. To address this, we propose a novel ScheMAtic memory peRsistence and Transience (SMART)11Code available at: https://github.com/YuyangGao/SMART. framework for continual learning with external memory that builds on recent advances in neuroscience. The efficiency and generalizability are enhanced by a novel long-term forgetting mechanism and schematic memory, using sparsity and ‘backward positive transfer’ constraints with theoretical guarantees on the error bound. Robust enhancement is achieved using a novel short-term forgetting mechanism inspired by background information-gated learning. Finally, an extensive experimental analysis on both benchmark and real-world datasets demonstrates the effectiveness and efficiency of our model.}
}
@article{BRAMLAGE202210,
title = {Generalized attention-weighted reinforcement learning},
journal = {Neural Networks},
volume = {145},
pages = {10-21},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003853},
author = {Lennart Bramlage and Aurelio Cortese},
keywords = {Self-attention, Decision-making, Value function approximation, Deep reinforcement learning, Representation learning, Feature binding},
abstract = {In neuroscience, attention has been shown to bidirectionally interact with reinforcement learning (RL) to reduce the dimensionality of task representations, restricting computations to relevant features. In machine learning, despite their popularity, attention mechanisms have seldom been administered to decision-making problems. Here, we leverage a theoretical model from computational neuroscience – the attention-weighted RL (AWRL), defining how humans identify task-relevant features (i.e., that allow value predictions) – to design an applied deep RL paradigm. We formally demonstrate that the conjunction of the self-attention mechanism, widely employed in machine learning, with value function approximation is a general formulation of the AWRL model. To evaluate our agent, we train it on three Atari tasks at different complexity levels, incorporating both task-relevant and irrelevant features. Because the model uses semantic observations, we can uncover not only which features the agent elects to base decisions on, but also how it chooses to compile more complex, relational features from simpler ones. We first show that performance depends in large part on the ability to compile new compound features, rather than mere focus on individual features. In line with neuroscience predictions, self-attention leads to high resiliency to noise (irrelevant features) compared to other benchmark models. Finally, we highlight the importance and separate contributions of both bottom-up and top-down attention in the learning process. Together, these results demonstrate the broader validity of the AWRL framework in complex task scenarios, and illustrate the benefits of a deeper integration between neuroscience-derived models and RL for decision making in machine learning.}
}
@article{FRISTON2021573,
title = {World model learning and inference},
journal = {Neural Networks},
volume = {144},
pages = {573-590},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003610},
author = {Karl Friston and Rosalyn J. Moran and Yukie Nagai and Tadahiro Taniguchi and Hiroaki Gomi and Josh Tenenbaum},
keywords = {Generative model, Probabilistic inference, Predictive coding, Bayesian inference, Free energy principle, Cognitive development},
abstract = {Understanding information processing in the brain—and creating general-purpose artificial intelligence—are long-standing aspirations of scientists and engineers worldwide. The distinctive features of human intelligence are high-level cognition and control in various interactions with the world including the self, which are not defined in advance and are vary over time. The challenge of building human-like intelligent machines, as well as progress in brain science and behavioural analyses, robotics, and their associated theoretical formalisations, speaks to the importance of the world-model learning and inference. In this article, after briefly surveying the history and challenges of internal model learning and probabilistic learning, we introduce the free energy principle, which provides a useful framework within which to consider neuronal computation and probabilistic world models. Next, we showcase examples of human behaviour and cognition explained under that principle. We then describe symbol emergence in the context of probabilistic modelling, as a topic at the frontiers of cognitive robotics. Lastly, we review recent progress in creating human-like intelligence by using novel probabilistic programming languages. The striking consensus that emerges from these studies is that probabilistic descriptions of learning and inference are powerful and effective ways to create human-like artificial intelligent machines and to understand intelligence in the context of how humans interact with their world.}
}
@article{POMPONI2021407,
title = {Structured Ensembles: An approach to reduce the memory footprint of ensemble methods},
journal = {Neural Networks},
volume = {144},
pages = {407-418},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003579},
author = {Jary Pomponi and Simone Scardapane and Aurelio Uncini},
keywords = {Ensemble, Continual learning, Pruning, Structured pruning, Neural networks, Deep learning},
abstract = {In this paper, we propose a novel ensembling technique for deep neural networks, which is able to drastically reduce the required memory compared to alternative approaches. In particular, we propose to extract multiple sub-networks from a single, untrained neural network by solving an end-to-end optimization task combining differentiable scaling over the original architecture, with multiple regularization terms favouring the diversity of the ensemble. Since our proposal aims to detect and extract sub-structures, we call it Structured Ensemble. On a large experimental evaluation, we show that our method can achieve higher or comparable accuracy to competing methods while requiring significantly less storage. In addition, we evaluate our ensembles in terms of predictive calibration and uncertainty, showing they compare favourably with the state-of-the-art. Finally, we draw a link with the continual learning literature, and we propose a modification of our framework to handle continuous streams of tasks with a sub-linear memory cost. We compare with a number of alternative strategies to mitigate catastrophic forgetting, highlighting advantages in terms of average accuracy and memory.}
}
@article{MANELA2022260,
title = {Curriculum learning with Hindsight Experience Replay for sequential object manipulation tasks},
journal = {Neural Networks},
volume = {145},
pages = {260-270},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004020},
author = {B. Manela and A. Biess},
keywords = {Multi-goal reinforcement learning, Curriculum learning, Hindsight Experience Replay, Sparse reward function, Object manipulation tasks},
abstract = {Learning complex tasks from scratch is challenging and often impossible for humans as well as for artificial agents. Instead, a curriculum can be used, which decomposes a complex task – the target task – into a sequence of source tasks. Each source task is a simplified version of the next source task with increasing complexity. Learning then occurs gradually by training on each source task while using knowledge from the curriculum’s prior source tasks. In this study, we present a new algorithm that combines curriculum learning with Hindsight Experience Replay (HER), to learn sequential object manipulation tasks for multiple goals and sparse feedback. The algorithm exploits the recurrent structure inherent in many object manipulation tasks and implements the entire learning process in the original simulation without adjusting it to each source task. We test our algorithm on three challenging throwing tasks in simulation and show significant improvements compared to vanilla-HER.}
}
@article{LANDMAN2021648,
title = {Deep-Hook: A trusted deep learning-based framework for unknown malware detection and classification in Linux cloud environments},
journal = {Neural Networks},
volume = {144},
pages = {648-685},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003695},
author = {Tom Landman and Nir Nissim},
keywords = {Malware, Detection, Linux, Cloud, Deep learning, Virtual machine},
abstract = {Since the beginning of the 21st century, the use of cloud computing has increased rapidly, and it currently plays a significant role among most organizations’ information technology (IT) infrastructure. Virtualization technologies, particularly virtual machines (VMs), are widely used and lie at the core of cloud computing. While different operating systems can run on top of VM instances, in public cloud environments the Linux operating system is used 90% of the time. Because of their prevalence, organizational Linux-based virtual servers have become an attractive target for cyber-attacks, mainly launched by sophisticated malware designed at causing harm, sabotaging operations, obtaining data, or gaining financial profit. This has resulted in the need for an advanced and reliable unknown malware detection mechanism for Linux cloud-based environments. Antivirus software and today’s even more advanced malware detection solutions have limitations in detecting new, unseen, and evasive malware. Moreover, many existing solutions are considered untrusted, as they operate on the inspected machine and can be interfered with, and can even be detected by the malware itself, allowing malware to evade detection and cause damage. In this paper, we propose Deep-Hook, a trusted framework for unknown malware detection in Linux-based cloud environments. Deep-Hook hooks the VM’s volatile memory in a trusted manner and acquires the memory dump to discover malware footprints while the VM operates. The memory dumps are transformed into visual images which are analyzed using a convolutional neural network (CNN) based classifier. The proposed framework has some key advantages, such as its agility, its ability to eliminate the need for features defined by a cyber domain expert, and most importantly, its ability to analyze the entire memory dump and thus to better utilize the existing indication it conceals, thus allowing the induction of a more accurate detection model. Deep-Hook was evaluated on widely used Linux virtual servers; four state-of-the-art CNN architectures; eight image resolutions; and a total of 22,400 volatile memory dumps representing the execution of a broad set of benign and malicious Linux applications. Our experimental evaluation results demonstrate Deep-Hook’s ability to effectively, efficiently, and accurately detect and classify unknown malware (even evasive malware like rootkits), with an AUC and accuracy of up to 99.9%.}
}
@article{ZHANG2021101,
title = {Observer-based event-triggered control for zero-sum games of input constrained multi-player nonlinear systems},
journal = {Neural Networks},
volume = {144},
pages = {101-112},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003178},
author = {Shunchao Zhang and Bo Zhao and Derong Liu and Yongwei Zhang},
keywords = {Adaptive dynamic programming, Multi-player zero-sum games, Input constraints, Event-triggered control, Neural networks},
abstract = {In this paper, an event-triggered control (ETC) method is investigated to solve zero-sum game (ZSG) problems of unknown multi-player continuous-time nonlinear systems with input constraints by using adaptive dynamic programming (ADP). To relax the requirement of system dynamics, a neural network (NN) observer is constructed to identify the dynamics of multi-player system via the input and output data. Then, the event-triggered Hamilton–Jacobi–Isaacs (HJI) equation of the ZSG can be solved by constructing a critic NN, and the approximated optimal control law and the worst disturbance law can be obtained directly. A triggering scheme which determines the updating time instants of the control law and the disturbance law is developed. Thus, the proposed ADP-based ETC method cannot only reduce the computational burden, but also save communication resource and bandwidths. Furthermore, we prove that the signals of the closed-loop system and the approximate errors of the critic NN weights are uniformly ultimately bounded by using Lyapunov’s direct method, and the Zeno behavior is excluded. Finally, two simulation examples are provided to demonstrate the effectiveness of the proposed ETC scheme.}
}
@article{JIANG2021297,
title = {Recurrent neural network from adder’s perspective: Carry-lookahead RNN},
journal = {Neural Networks},
volume = {144},
pages = {297-306},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003452},
author = {Haowei Jiang and Feiwei Qin and Jin Cao and Yong Peng and Yanli Shao},
keywords = {Deep learning, Carry-lookahead, Parallel computation, Sequence modeling},
abstract = {The recurrent network architecture is a widely used model in sequence modeling, but its serial dependency hinders the computation parallelization, which makes the operation inefficient. The same problem was encountered in serial adder at the early stage of digital electronics. In this paper, we discuss the similarities between recurrent neural network (RNN) and serial adder. Inspired by carry-lookahead adder, we introduce carry-lookahead module to RNN, which makes it possible for RNN to run in parallel. Then, we design the method of parallel RNN computation, and finally Carry-lookahead RNN (CL-RNN) is proposed. CL-RNN takes advantages in parallelism and flexible receptive field. Through a comprehensive set of tests, we verify that CL-RNN can perform better than existing typical RNNs in sequence modeling tasks which are specially designed for RNNs. Code and models are available at: https://github.com/WinnieJiangHW/Carry-lookahead_RNN.}
}
@article{LYNCH2021798,
title = {Learning hierarchically-structured concepts},
journal = {Neural Networks},
volume = {143},
pages = {798-817},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.07.033},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100304X},
author = {Nancy Lynch and Frederik Mallmann-Trenn},
keywords = {Hierarchical concepts, Representing hierarchical concepts, Recognizing hierarchical concepts, Learning hierarchical concepts, Spiking Neural Networks, Brain-inspired algorithms},
abstract = {We use a recently developed synchronous Spiking Neural Network (SNN) model to study the problem of learning hierarchically-structured concepts. We introduce an abstract data model that describes simple hierarchical concepts. We define a feed-forward layered SNN model, with learning modeled using Oja’s local learning rule, a well known biologically-plausible rule for adjusting synapse weights. We define what it means for such a network to recognize hierarchical concepts; our notion of recognition is robust, in that it tolerates a bounded amount of noise. Then, we present a learning algorithm by which a layered network may learn to recognize hierarchical concepts according to our robust definition. We analyze correctness and performance rigorously; the amount of time required to learn each concept, after learning all of the sub-concepts, is approximately O1ηkℓmaxlog(k)+1ɛ+blog(k), where k is the number of sub-concepts per concept, ℓmax is the maximum hierarchical depth, η is the learning rate, ɛ describes the amount of uncertainty allowed in robust recognition, and b describes the amount of weight decrease for “irrelevant” edges. An interesting feature of this algorithm is that it allows the network to learn sub-concepts in a highly interleaved manner. This algorithm assumes that the concepts are presented in a noise-free way; we also extend these results to accommodate noise in the learning process. Finally, we give a simple lower bound saying that, in order to recognize concepts with hierarchical depth two with noise-tolerance, a neural network should have at least two layers. The results in this paper represent first steps in the theoretical study of hierarchical concepts using SNNs. The cases studied here are basic, but they suggest many directions for extensions to more elaborate and realistic cases.}
}
@article{2023I,
title = {Current Events},
journal = {Neural Networks},
volume = {165},
pages = {I},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(23)00410-0},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004100}
}
@article{HOU2022209,
title = {GuidedStyle: Attribute knowledge guided style manipulation for semantic face editing},
journal = {Neural Networks},
volume = {145},
pages = {209-220},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004081},
author = {Xianxu Hou and Xiaokang Zhang and Hanbang Liang and Linlin Shen and Zhihui Lai and Jun Wan},
keywords = {Generative Adversarial Networks, StyleGAN, Semantic face editing},
abstract = {Although significant progress has been made in synthesizing high-quality and visually realistic face images by unconditional Generative Adversarial Networks (GANs), there is still a lack of control over the generation process in order to achieve semantic face editing. In this paper, we propose a novel learning framework, called GuidedStyle, to achieve semantic face editing on pretrained StyleGAN by guiding the image generation process with a knowledge network. Furthermore, we allow an attention mechanism in StyleGAN generator to adaptively select a single layer for style manipulation. As a result, our method is able to perform disentangled and controllable edits along various attributes, including smiling, eyeglasses, gender, mustache, hair color and attractive. Both qualitative and quantitative results demonstrate the superiority of our method over other competing methods for semantic face editing. Moreover, we show that our model can be also applied to different types of real and artistic face editing, demonstrating strong generalization ability.}
}
@article{ZHANG2021154,
title = {Adversarial parameter defense by multi-step risk minimization},
journal = {Neural Networks},
volume = {144},
pages = {154-163},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003270},
author = {Zhiyuan Zhang and Ruixuan Luo and Xuancheng Ren and Qi Su and Liangyou Li and Xu Sun},
keywords = {Vulnerability of deep neural networks, Parameter corruption, Adversarial parameter defense},
abstract = {Previous studies demonstrate DNNs’ vulnerability to adversarial examples and adversarial training can establish a defense to adversarial examples. In addition, recent studies show that deep neural networks also exhibit vulnerability to parameter corruptions. The vulnerability of model parameters is of crucial value to the study of model robustness and generalization. In this work, we introduce the concept of parameter corruption and propose to leverage the loss change indicators for measuring the flatness of the loss basin and the parameter robustness of neural network parameters. On such basis, we analyze parameter corruptions and propose the multi-step adversarial corruption algorithm. To enhance neural networks, we propose the adversarial parameter defense algorithm that minimizes the average risk of multiple adversarial parameter corruptions. Experimental results show that the proposed algorithm can improve both the parameter robustness and accuracy of neural networks.}
}
@article{GRAZIANI2021627,
title = {A language modeling-like approach to sketching},
journal = {Neural Networks},
volume = {144},
pages = {627-638},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003828},
author = {Lisa Graziani and Marco Gori and Stefano Melacci},
keywords = {Sketch generation, Recurrent Neural Networks, Language Modeling},
abstract = {Sketching is a universal communication tool that, despite its simplicity, is able to efficiently express a large variety of concepts and, in some limited contexts, it can be even more immediate and effective than natural language. In this paper we explore the feasibility of using neural networks to approach sketching in the same way they are commonly used in Language Modeling. We propose a novel approach to what we refer to as “Sketch Modeling”, in which a neural network is exploited to learn a probabilistic model that estimates the probability of sketches. We focus on simple sketches and, in particular, on the case in which sketches are represented as sequences of segments. Segments and sequences can be either given – when the sketches are originally drawn in this format – or automatically generated from the input drawing by means of a procedure that we designed to create short sequences, loosely inspired by the human behavior. A Recurrent Neural Network is used to learn the sketch model and, afterward, the network is seeded with an incomplete sketch that it is asked to complete, generating one segment at each time step. We propose a set of measures to evaluate the outcome of a Beam Search-based generation procedure, showing how they can be used to identify the most promising generations. Our experimental analysis assesses the feasibility of this way of modeling sketches, also in the case in which several different categories of sketches are considered.}
}
@article{LI2021540,
title = {A conversational model for eliciting new chatting topics in open-domain conversation},
journal = {Neural Networks},
volume = {144},
pages = {540-552},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003269},
author = {Weizhao Li and Feng Ge and Yi Cai and Da Ren},
keywords = {Response generation, Proactive conversation, Topic elicitation, Open-domain},
abstract = {In human conversations, the emergence of new topics is a key factor in enabling dialogues to last longer. Additional information brought by new topics can make the conversation more diverse and interesting. Chat-bots also need to be equipped with this ability to proactively elicit new chatting topics. However, previous studies have neglected the elicitation of new topics in open-domain conversations. At the same time, previous works have represented topics with word-level keywords or entities. However, a topic is open to multiple keywords and a keyword can reflect multiple potential topics. To move towards a fine-grained topic representation, we represent topic with topically related words. In this paper, we design a novel model, named CMTE, which focuses not only on coherence with context, but also brings up new chatting topics. In order to extract topic information from conversational utterances, a Topic Fetcher module is designed to fetch semantic-coherent topics with the help of topic model. To equip model with the ability to elicit new topics, a Topic Manager module is designed to associate the new topic with context. Finally, responses are generated by a well-designed fusion decoding mechanism to explicitly distinguish between topic words and general words. Experiment results show that our model is better than state of the art in automatic metrics and manual evaluations.}
}
@article{CHEN2022139,
title = {New effective approach to quasi synchronization of coupled heterogeneous complex networks},
journal = {Neural Networks},
volume = {145},
pages = {139-143},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100410X},
author = {Tianping Chen},
keywords = {Quasi synchronization, Complete synchronization, Linearly coupled systems, Heterogeneous, Homogeneous},
abstract = {This short paper addresses quasi synchronization of linearly coupled heterogeneous systems. Similarity and difference between the complete synchronization of linearly coupled homogeneous systems and the quasi synchronization of linearly coupled heterogeneous systems will be revealed.}
}
@article{SUBRAMANIAN2022271,
title = {Reinforcement learning and its connections with neuroscience and psychology},
journal = {Neural Networks},
volume = {145},
pages = {271-287},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003944},
author = {Ajay Subramanian and Sharad Chitlangia and Veeky Baths},
keywords = {Reinforcement learning, Neuroscience, Psychology},
abstract = {Reinforcement learning methods have recently been very successful at performing complex sequential tasks like playing Atari games, Go and Poker. These algorithms have outperformed humans in several tasks by learning from scratch, using only scalar rewards obtained through interaction with their environment. While there certainly has been considerable independent innovation to produce such results, many core ideas in reinforcement learning are inspired by phenomena in animal learning, psychology and neuroscience. In this paper, we comprehensively review a large number of findings in both neuroscience and psychology that evidence reinforcement learning as a promising candidate for modeling learning and decision making in the brain. In doing so, we construct a mapping between various classes of modern RL algorithms and specific findings in both neurophysiological and behavioral literature. We then discuss the implications of this observed relationship between RL, neuroscience and psychology and its role in advancing research in both AI and brain science.}
}
@article{PENG2021372,
title = {Pinning multisynchronization of delayed fractional-order memristor-based neural networks with nonlinear coupling and almost-periodic perturbations},
journal = {Neural Networks},
volume = {144},
pages = {372-383},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003427},
author = {Libiao Peng and Xifeng Li and Dongjie Bi and Xuan Xie and Yongle Xie},
keywords = {Multisynchronization, Multistability, Fractional-order memristor-based neural networks, Nonlinear coupling, Almost periodicity},
abstract = {This paper concerns the multisynchronization issue for delayed fractional-order memristor-based neural networks with nonlinear coupling and almost-periodic perturbations. First, the coexistence of multiple equilibrium states for isolated subnetwork is analyzed. By means of state-space decomposition, fractional-order Halanay inequality and Caputo derivative properties, the novel algebraic sufficient conditions are derived to ensure that the addressed networks with arbitrary activation functions have multiple locally stable almost periodic orbits or equilibrium points. Then, based on the obtained multistability results, a pinning control strategy is designed to realize the multisynchronization of the N coupled networks. By the aid of graph theory, depth first search method and pinning control law, some sufficient conditions are formulated such that the considered neural networks can possess multiple synchronization manifolds. Finally, the multistability and multisynchronization performance of the considered neural networks with different activation functions are illustrated by numerical examples.}
}
@article{DEMB2021438,
title = {A note on computing with Kolmogorov Superpositions without iterations},
journal = {Neural Networks},
volume = {144},
pages = {438-442},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021002690},
author = {Robert Demb and David Sprecher},
keywords = {Kolmogorov, Superpositions, Function representations, Köppen’s recursive formula, Computational algorithms, Approximations, Iterations, Error bound, Parallel computations, Interpolants},
abstract = {We extend Kolmogorov’s Superpositions to approximating arbitrary continuous functions with a noniterative approach that can be used by any neural network that uses these superpositions. Our approximation algorithm uses a modified dimension reducing function that allows for an increased number of summands to achieve an error bound commensurate with that of r iterations for any r. This new variant of Kolmogorov’s Superpositions improves upon the original parallelism inherent in them by performing highly distributed parallel computations without synchronization. We note that this approach makes implementation much easier and more efficient on networks of modern parallel hardware, and thus makes it a more practical tool.}
}
@article{RAN2022199,
title = {Detecting out-of-distribution samples via variational auto-encoder with reliable uncertainty estimation},
journal = {Neural Networks},
volume = {145},
pages = {199-208},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004111},
author = {Xuming Ran and Mingkun Xu and Lingrui Mei and Qi Xu and Quanying Liu},
keywords = {Variational auto-encoder, Out-of-distribution detection, Uncertainty estimation, Noise contrastive prior},
abstract = {Variational autoencoders (VAEs) are influential generative models with rich representation capabilities from the deep neural network architecture and Bayesian method. However, VAE models have a weakness that assign a higher likelihood to out-of-distribution (OOD) inputs than in-distribution (ID) inputs. To address this problem, a reliable uncertainty estimation is considered to be critical for in-depth understanding of OOD inputs. In this study, we propose an improved noise contrastive prior (INCP) to be able to integrate into the encoder of VAEs, called INCPVAE. INCP is scalable, trainable and compatible with VAEs, and it also adopts the merits from the INCP for uncertainty estimation. Experiments on various datasets demonstrate that compared to the standard VAEs, our model is superior in uncertainty estimation for the OOD data and is robust in anomaly detection tasks. The INCPVAE model obtains reliable uncertainty estimation for OOD inputs and solves the OOD problem in VAE models.}
}
@article{HA2021176,
title = {Neural-network-based discounted optimal control via an integrated value iteration with accuracy guarantee},
journal = {Neural Networks},
volume = {144},
pages = {176-186},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003385},
author = {Mingming Ha and Ding Wang and Derong Liu},
keywords = {Adaptive dynamic programming, Data-based discounted optimal control, Value iteration, Lyapunov method, Uniformly ultimately bounded stability},
abstract = {A data-based value iteration algorithm with the bidirectional approximation feature is developed for discounted optimal control. The unknown nonlinear system dynamics is first identified by establishing a model neural network. To improve the identification precision, biases are introduced to the model network. The model network with biases is trained by the gradient descent algorithm, where the weights and biases across all layers are updated. The uniform ultimate boundedness stability with a proper learning rate is analyzed, by using the Lyapunov approach. Moreover, an integrated value iteration with the discounted cost is developed to fully guarantee the approximation accuracy of the optimal value function. Then, the effectiveness of the proposed algorithm is demonstrated by carrying out two simulation examples with physical backgrounds.}
}
@article{TEICHMANN2021210,
title = {Performance of biologically grounded models of the early visual system on standard object recognition tasks},
journal = {Neural Networks},
volume = {144},
pages = {210-228},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003142},
author = {Michael Teichmann and René Larisch and Fred H. Hamker},
keywords = {Brain-inspired neural networks, Spiking neural networks, Hebbian learning, Spike timing-dependent plasticity, Object recognition},
abstract = {Computational neuroscience models of vision and neural network models for object recognition are often framed by different research agendas. Computational neuroscience mainly aims at replicating experimental data, while (artificial) neural networks target high performance on classification tasks. However, we propose that models of vision should be validated on object recognition tasks. At some point, mechanisms of realistic neuro-computational models of the visual cortex have to convince in object recognition as well. In order to foster this idea, we report the recognition accuracy for two different neuro-computational models of the visual cortex on several object recognition datasets. The models were trained using unsupervised Hebbian learning rules on natural scene inputs for the emergence of receptive fields comparable to their biological counterpart. We assume that the emerged receptive fields result in a general codebook of features, which should be applicable to a variety of visual scenes. We report the performances on datasets with different levels of difficulty, ranging from the simple MNIST to the more complex CIFAR-10 or ETH-80. We found that both networks show good results on simple digit recognition, comparable with previously published biologically plausible models. We also observed that our deeper layer neurons provide for naturalistic datasets a better recognition codebook. As for most datasets, recognition results of biologically grounded models are not available yet, our results provide a broad basis of performance values to compare methodologically similar models.}
}
@article{YAMAKAWA2021478,
title = {The whole brain architecture approach: Accelerating the development of artificial general intelligence by referring to the brain},
journal = {Neural Networks},
volume = {144},
pages = {478-495},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003543},
author = {Hiroshi Yamakawa},
keywords = {Brain reference architecture, Structure-constrained interface decomposition method, Brain information flow, Hypothetical component diagram, Brain-inspired artificial general intelligence, Whole-brain architecture},
abstract = {The vastness of the design space that is created by the combination of numerous computational mechanisms, including machine learning, is an obstacle to creating artificial general intelligence (AGI). Brain-inspired AGI development; that is, the reduction of the design space to resemble a biological brain more closely, is a promising approach for solving this problem. However, it is difficult for an individual to design a software program that corresponds to the entire brain as the neuroscientific data that are required to understand the architecture of the brain are extensive and complicated. The whole-brain architecture approach divides the brain-inspired AGI development process into the task of designing the brain reference architecture (BRA), which provides the flow of information and a diagram of the corresponding components, and the task of developing each component using the BRA. This is known as BRA-driven development. Another difficulty lies in the extraction of the operating principles that are necessary for reproducing the cognitive–behavioral function of the brain from neuroscience data. Therefore, this study proposes structure-constrained interface decomposition (SCID), which is a hypothesis-building method for creating a hypothetical component diagram that is consistent with neuroscientific findings. The application of this approach has been initiated for constructing various regions of the brain. In the future, we will examine methods for evaluating the biological plausibility of brain-inspired software. This evaluation will also be used to prioritize different computational mechanisms, which should be integrated and associated with the same regions of the brain.}
}
@article{ZHANG2021709,
title = {Visual-guided attentive attributes embedding for zero-shot learning},
journal = {Neural Networks},
volume = {143},
pages = {709-718},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.07.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003026},
author = {Rui Zhang and Qi Zhu and Xiangyu Xu and Daoqiang Zhang and Sheng-Jun Huang},
keywords = {Zero-shot learning, Encoder–decoder, Attributes, Attention mechanism},
abstract = {Zero-shot learning (ZSL) aims to learn a classifier for unseen classes by exploiting both training data from seen classes and external knowledge. In many visual tasks such as image classification, a set of high-level attributes that describe the semantic properties of classes are used as the external knowledge to bridge seen and unseen classes. While the attributes are usually treated equally by previous ZSL studies, we observe that the contribution of different attributes varies significantly over model training. To adaptively exploit the discriminative information embedded in different attributes, we propose a novel encoder–decoder framework with attention mechanism on the attribute level for zero-shot learning. Specifically, by mapping the visual features into a semantic space, the more discriminative attributes are emphasized with larger attention weights. Further, the attentive attributes and the class prototypes are simultaneously decoded to the visual space so that the hubness problem can be eased. Finally, the labels are predicted in the visual space. Extensive experiments on multiple benchmark datasets demonstrate that our proposed model achieves a significant boost over several state-of-the-art methods for ZSL task and comparative results for generalized ZSL task.}
}
@article{FERNANDEZ2021419,
title = {Broad-UNet: Multi-scale feature learning for nowcasting tasks},
journal = {Neural Networks},
volume = {144},
pages = {419-427},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.036},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100349X},
author = {Jesús García Fernández and Siamak Mehrkanoon},
keywords = {Satellite imagery, Precipitation forecasting, Cloud cover forecasting, Deep learning, Convolutional neural network, U-net},
abstract = {Weather nowcasting consists of predicting meteorological components in the short term at high spatial resolutions. Due to its influence in many human activities, accurate nowcasting has recently gained plenty of attention. In this paper, we treat the nowcasting problem as an image-to-image translation problem using satellite imagery. We introduce Broad-UNet, a novel architecture based on the core UNet model, to efficiently address this problem. In particular, the proposed Broad-UNet is equipped with asymmetric parallel convolutions as well as Atrous Spatial Pyramid Pooling (ASPP) module. In this way, the Broad-UNet model learns more complex patterns by combining multi-scale features while using fewer parameters than the core UNet model. The proposed model is applied on two different nowcasting tasks, i.e. precipitation maps and cloud cover nowcasting. The obtained numerical results show that the introduced Broad-UNet model performs more accurate predictions compared to the other examined architectures.}
}
@article{DENG2022221,
title = {Sparsity-control ternary weight networks},
journal = {Neural Networks},
volume = {145},
pages = {221-232},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004093},
author = {Xiang Deng and Zhongfei Zhang},
keywords = {Ternary weight networks, Sparsity control, Model compression, Image classification},
abstract = {Deep neural networks (DNNs) have been widely and successfully applied to various applications, but they require large amounts of memory and computational power. This severely restricts their deployment on resource-limited devices. To address this issue, many efforts have been made on training low-bit weight DNNs. In this paper, we focus on training ternary weight {−1, 0, ＋1} networks which can avoid multiplications and dramatically reduce the memory and computation requirements. A ternary weight network can be considered as a sparser version of the binary weight counterpart by replacing some −1s or 1s in the binary weights with 0s, thus leading to more efficient inference but more memory cost. However, the existing approaches to train ternary weight networks cannot control the sparsity (i.e., percentage of 0s) of the ternary weights, which undermines the advantage of ternary weights. In this paper, we propose to our best knowledge the first sparsity-control approach (SCA) to train ternary weight networks, which is simply achieved by a weight discretization regularizer (WDR). SCA is different from all the existing regularizer-based approaches in that it can control the sparsity of the ternary weights through a controller α and does not rely on gradient estimators. We theoretically and empirically show that the sparsity of the trained ternary weights is positively related to α. SCA is extremely simple, easy-to-implement, and is shown to consistently outperform the state-of-the-art approaches significantly over several benchmark datasets and even matches the performances of the full-precision weight counterparts.}
}
@article{DAVEY2021737,
title = {Impact of axonal delay on structure development in a multi-layered network},
journal = {Neural Networks},
volume = {144},
pages = {737-754},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003282},
author = {Catherine E. Davey and David B. Grayden and Anthony N. Burkitt},
keywords = {Neural network, Rate-based neural plasticity, Axonal propagation delay, Spatial opponent cells},
abstract = {The mechanisms underlying how activity in the visual pathway gives rise through neural plasticity to many features observed experimentally in early stages of visual processing was provided by Linsker in a seminal, three-paper series. Owing to the complexity of multi-layer models, an implicit assumption in Linsker’s and subsequent papers has been that propagation delay is homogeneous, playing little functional role in neural behavior. In this paper, we relax this assumption to examine the impact of distance-dependent axonal propagation delay on neural learning. We show that propagation delay induces low-pass filtering by dispersing arrival times of spikes from presynaptic neurons, providing a natural correlation cancellation mechanism for distal connections. The cut-off frequency decreases as radial propagation delay within a layer increases relative to propagation delay between layers, introducing an upper limit on temporal resolution. Given that the postsynaptic potential acts as a low-pass filter, we show that the effective time constant of each should enable processing of similar scales of temporal information. This has implications for the visual system, in which receptive field size and, thus, propagation delay, increases with eccentricity. Furthermore, network response is frequency dependent since higher frequencies require increased input amplitude to compensate for attenuation. This concords with frequency-dependent contrast sensitivity, which changes with eccentricity and receptive field size. We further show that the proportion of inhibition relative to excitation is larger where radial propagation delay is long relative to inter-laminar delay, and that delay reduces the range in on-center size, providing stability to variations in homeostatic parameters.}
}
@article{PERRUSQUIA202233,
title = {A complementary learning approach for expertise transference of human-optimized controllers},
journal = {Neural Networks},
volume = {145},
pages = {33-41},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004007},
author = {Adolfo Perrusquía},
keywords = {Complementary learning, Hippocampus and neocortex learning systems, Q-learning, Inverse reinforcement learning, Batch least squares, Gradient-descent rule},
abstract = {In this paper, a complementary learning scheme for experience transference of unknown continuous-time linear systems is proposed. The algorithm is inspired in the complementary learning properties that exhibit the hippocampus and neocortex learning systems via the striatum. The hippocampus is modelled as pattern-separated data of a human optimized controller. The neocortex is modelled as a Q-reinforcement learning algorithm which improves the hippocampus control policy. The complementary learning (striatum) is designed as an inverse reinforcement learning algorithm which relates the hippocampus and neocortex learning models to seek and transfer the weights of the hidden expert’s utility function. Convergence of the proposed approach is analysed using Lyapunov recursions. Simulations are given to verify the proposed approach.}
}
@article{MAE2021394,
title = {Uncertainty propagation for dropout-based Bayesian neural networks},
journal = {Neural Networks},
volume = {144},
pages = {394-406},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003555},
author = {Yuki Mae and Wataru Kumagai and Takafumi Kanamori},
keywords = {Uncertainty evaluation, Sampling-free method, Variance propagation, LSTM, Out-of-distribution},
abstract = {Uncertainty evaluation is a core technique when deep neural networks (DNNs) are used in real-world problems. In practical applications, we often encounter unexpected samples that have not seen in the training process. Not only achieving the high-prediction accuracy but also detecting uncertain data is significant for safety-critical systems. In statistics and machine learning, Bayesian inference has been exploited for uncertainty evaluation. The Bayesian neural networks (BNNs) have recently attracted considerable attention in this context, as the DNN trained using dropout is interpreted as a Bayesian method. Based on this interpretation, several methods to calculate the Bayes predictive distribution for DNNs have been developed. Though the Monte-Carlo method called MC dropout is a popular method for uncertainty evaluation, it requires a number of repeated feed-forward calculations of DNNs with randomly sampled weight parameters. To overcome the computational issue, we propose a sampling-free method to evaluate uncertainty. Our method converts a neural network trained using dropout to the corresponding Bayesian neural network with variance propagation. Our method is available not only to feed-forward NNs but also to recurrent NNs such as LSTM. We report the computational efficiency and statistical reliability of our method in numerical experiments of language modeling using RNNs, and the out-of-distribution detection with DNNs.}
}
@article{ZHAO2021690,
title = {Capsule networks with non-iterative cluster routing},
journal = {Neural Networks},
volume = {143},
pages = {690-697},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.07.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003038},
author = {Zhihao Zhao and Samuel Cheng},
keywords = {Capsule networks, Routing procedure, Attention, Data-dependent},
abstract = {Capsule networks use routing algorithms to flow information between consecutive layers. In the existing routing procedures, capsules produce predictions (termed votes) for capsules of the next layer. In a nutshell, the next-layer capsule’s input is a weighted sum over all the votes it receives. In this paper, we propose non-iterative cluster routing for capsule networks. In the proposed cluster routing, capsules produce vote clusters instead of individual votes for next-layer capsules, and each vote cluster sends its centroid to a next-layer capsule. Generally speaking, the next-layer capsule’s input is a weighted sum over the centroid of each vote cluster it receives. The centroid that comes from a cluster with a smaller variance is assigned a larger weight in the weighted sum process. Compared with the state-of-the-art capsule networks, the proposed capsule networks achieve the best accuracy on the Fashion-MNIST and SVHN datasets with fewer parameters, and achieve the best accuracy on the smallNORB and CIFAR-10 datasets with a moderate number of parameters. The proposed capsule networks also produce capsules with disentangled representation and generalize well to images captured at novel viewpoints. The proposed capsule networks also preserve 2D spatial information of an input image in the capsule channels: if the capsule channels are rotated, the object reconstructed from these channels will be rotated by the same transformation.}
}
@article{CHEN2021565,
title = {Highly parallelized memristive binary neural network},
journal = {Neural Networks},
volume = {144},
pages = {565-572},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100366X},
author = {Jiadong Chen and Shiping Wen and Kaibo Shi and Yin Yang},
keywords = {Memristor crossbar, Binary convolutional neural networks, Hardware design, Deep learning},
abstract = {At present, in the new hardware design work of deep learning, memristor as a non-volatile memory with computing power has become a research hotspot. The weights in the deep neural network are the floating-point number. Writing a floating-point value into a memristor will result in a loss of accuracy, and the writing process will take more time. The binarized neural network (BNN) binarizes the weights and activation values that were originally floating-point numbers to +1 and -1. This will greatly reduce the storage space consumption and time consumption of programming the resistance value of the memristor. Furthermore, this will help to simplify the programming of memristors in deep neural network circuits and speed up the inference process. This paper provides a complete solution for implementing memristive BNN. Furthermore, we improved the design of the memristor crossbar by converting the input feature map and kernel before performing the convolution operation that can ensure the sign of the input voltage of each port constant. Therefore, we do not need to determine the sign of the input voltage required by the port in advance which simplifies the process of inputting the feature map elements to each port of the crossbar in the form of voltage. At the same time, in order to ensure that the output of the current convolution layer can be directly used as the input of the next layer, we have added a corresponding processing circuit, which integrates batch-normalization and binarization operations.}
}
@article{LANGDON202280,
title = {Meta-learning, social cognition and consciousness in brains and machines},
journal = {Neural Networks},
volume = {145},
pages = {80-89},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003956},
author = {Angela Langdon and Matthew Botvinick and Hiroyuki Nakahara and Keiji Tanaka and Masayuki Matsumoto and Ryota Kanai},
keywords = {Model-based reinforcement learning, Meta-learning, Social cognition, Consciousness},
abstract = {The intersection between neuroscience and artificial intelligence (AI) research has created synergistic effects in both fields. While neuroscientific discoveries have inspired the development of AI architectures, new ideas and algorithms from AI research have produced new ways to study brain mechanisms. A well-known example is the case of reinforcement learning (RL), which has stimulated neuroscience research on how animals learn to adjust their behavior to maximize reward. In this review article, we cover recent collaborative work between the two fields in the context of meta-learning and its extension to social cognition and consciousness. Meta-learning refers to the ability to learn how to learn, such as learning to adjust hyperparameters of existing learning algorithms and how to use existing models and knowledge to efficiently solve new tasks. This meta-learning capability is important for making existing AI systems more adaptive and flexible to efficiently solve new tasks. Since this is one of the areas where there is a gap between human performance and current AI systems, successful collaboration should produce new ideas and progress. Starting from the role of RL algorithms in driving neuroscience, we discuss recent developments in deep RL applied to modeling prefrontal cortex functions. Even from a broader perspective, we discuss the similarities and differences between social cognition and meta-learning, and finally conclude with speculations on the potential links between intelligence as endowed by model-based RL and consciousness. For future work we highlight data efficiency, autonomy and intrinsic motivation as key research areas for advancing both fields.}
}
@article{LANDI2021334,
title = {Working Memory Connections for LSTM},
journal = {Neural Networks},
volume = {144},
pages = {334-341},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003439},
author = {Federico Landi and Lorenzo Baraldi and Marcella Cornia and Rita Cucchiara},
keywords = {Long Short-Term Memory networks, Cell-to-gate connections, Gated RNNs, Language modeling, Image captioning},
abstract = {Recurrent Neural Networks with Long Short-Term Memory (LSTM) make use of gating mechanisms to mitigate exploding and vanishing gradients when learning long-term dependencies. For this reason, LSTMs and other gated RNNs are widely adopted, being the standard de facto for many sequence modeling tasks. Although the memory cell inside the LSTM contains essential information, it is not allowed to influence the gating mechanism directly. In this work, we improve the gate potential by including information coming from the internal cell state. The proposed modification, named Working Memory Connection, consists in adding a learnable nonlinear projection of the cell content into the network gates. This modification can fit into the classical LSTM gates without any assumption on the underlying task, being particularly effective when dealing with longer sequences. Previous research effort in this direction, which goes back to the early 2000s, could not bring a consistent improvement over vanilla LSTM. As part of this paper, we identify a key issue tied to previous connections that heavily limits their effectiveness, hence preventing a successful integration of the knowledge coming from the internal cell state. We show through extensive experimental evaluation that Working Memory Connections constantly improve the performance of LSTMs on a variety of tasks. Numerical results suggest that the cell state contains useful information that is worth including in the gate structure.}
}
@article{HUANG2022288,
title = {Structure inference of networked system with the synergy of deep residual network and fully connected layer network},
journal = {Neural Networks},
volume = {145},
pages = {288-299},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100407X},
author = {Keke Huang and Shuo Li and Wenfeng Deng and Zhaofei Yu and Lei Ma},
keywords = {Complex network, Network structure inference, Deep learning, Residual network, Compressive sensing},
abstract = {The networked systems are booming in multi-disciplines, including the industrial engineering system, the social system, and so on. The network structure is a prerequisite for the understanding and exploration of networked systems. However, the network structure is always unknown in practice, thus, it is significant yet challenging to investigate the inference of network structure. Although some model-based methods and data-driven methods, such as the phase-space based method and the compressive sensing based method, have investigated the structure inference tasks, they were time-consuming due to the greedy iterative optimization procedure, which makes them difficult to satisfy real-time structure inference requirements. Although the reconstruction time of L1 and other methods is short, the reconstruction accuracy is very low. Inspired by the powerful representation ability and time efficiency for the structure inference with the deep learning framework, a novel synergy method combines the deep residual network and fully connected layer network to solve the network structure inference task efficiently and accurately. This method perfectly solves the problems of long reconstruction time and low accuracy of traditional methods. Moreover, the proposed method can also fulfill the inference task of large scale complex network, which further indicates the scalability of the proposed method.}
}
@article{SCHILLING2021699,
title = {Decentralized control and local information for robust and adaptive decentralized Deep Reinforcement Learning},
journal = {Neural Networks},
volume = {144},
pages = {699-725},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003671},
author = {Malte Schilling and Andrew Melnik and Frank W. Ohl and Helge J. Ritter and Barbara Hammer},
keywords = {Deep Reinforcement Learning, Motor control, Decentralization, Local information},
abstract = {Decentralization is a central characteristic of biological motor control that allows for fast responses relying on local sensory information. In contrast, the current trend of Deep Reinforcement Learning (DRL) based approaches to motor control follows a centralized paradigm using a single, holistic controller that has to untangle the whole input information space. This motivates to ask whether decentralization as seen in biological control architectures might also be beneficial for embodied sensori-motor control systems when using DRL. To answer this question, we provide an analysis and comparison of eight control architectures for adaptive locomotion that were derived for a four-legged agent, but with their degree of decentralization varying systematically between the extremes of fully centralized and fully decentralized. Our comparison shows that learning speed is significantly enhanced in distributed architectures—while still reaching the same high performance level of centralized architectures—due to smaller search spaces and local costs providing more focused information for learning. Second, we find an increased robustness of the learning process in the decentralized cases—it is less demanding to hyperparameter selection and less prone to becoming trapped in poor local minima. Finally, when examining generalization to uneven terrains—not used during training—we find best performance for an intermediate architecture that is decentralized, but integrates only local information from both neighboring legs. Together, these findings demonstrate beneficial effects of distributing control into decentralized units and relying on local information. This appears as a promising approach towards more robust DRL and better generalization towards adaptive behavior.}
}
@article{YANG202161,
title = {TGAN: A simple model update strategy for visual tracking via template-guidance attention network},
journal = {Neural Networks},
volume = {144},
pages = {61-74},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003154},
author = {Kai Yang and Haijun Zhang and Dongliang Zhou and Linlin Liu},
keywords = {Visual tracking, Template update, Attention networks},
abstract = {Visual attention has been widely used in various fields of visual tasks in recent years. Recently, visual trackers based on probabilistic discriminative model prediction (PrDiMP) and Siamese box adaptive network (SiamBAN) have attracted much attention due to their excellent performance and high efficiency. However, the target template of the model in both the PrDiMP and SiamBAN is not updated online, and feature vectors of the template image and the search image are independent of each other in the IoU-Net and Siamese frameworks. In this research, we proposed a template-guidance attention network in both the IoU-Net (denoted as TGAN-I) and Siamese (denoted as TGAN-S) frameworks for visual tracking. TGAN-I and TGAN-S can comprehensively utilize the feature information of the template image and search image, and provide an implicit way to update the template. By utilizing a simple template update strategy, the TGAN-I and TGAN-S trackers can be more robust under certain challenging conditions such as occlusion and deformation. Besides, we introduce a channel and spatial attention module in feature maps of the template image and search image for adaptive feature refinement. Deformable convolutional networks are further used to enhance the model generalization capability in various transformations aspect ratios and scales of tracking targets. To verify the effectiveness of the proposed method, we evaluate the TGAN-I and TGAN-S trackers on six benchmarks and achieve state-of-the-art results. In particular, the TGAN-I method outperforms the strong baseline, PrDiMP, by 0.323 → 0.355 and 0.471 → 0.501 of EAO score on VOT2019 and VOT2016, respectively.}
}
@article{ALI2022233,
title = {Exploiting dynamic spatio-temporal graph convolutional neural networks for citywide traffic flows prediction},
journal = {Neural Networks},
volume = {145},
pages = {233-247},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021004123},
author = {Ahmad Ali and Yanmin Zhu and Muhammad Zakarya},
keywords = {Traffic flow prediction, Spatial and temporal dependencies, GCN, LSTM, Road safety},
abstract = {The prediction of crowd flows is an important urban computing issue whose purpose is to predict the future number of incoming and outgoing people in regions. Measuring the complicated spatial–temporal dependencies with external factors, such as weather conditions and surrounding point-of-interest (POI) distribution is the most difficult aspect of predicting crowd flows movement. To overcome the above issue, this paper advises a unified dynamic deep spatio-temporal neural network model based on convolutional neural networks and long short-term memory, termed as (DHSTNet) to simultaneously predict crowd flows in every region of a city. The DHSTNet model is made up of four separate components: a recent, daily, weekly, and an external branch component. Our proposed approach simultaneously assigns various weights to different branches and integrates the four properties’ outputs to generate final predictions. Moreover, to verify the generalization and scalability of the proposed model, we apply a Graph Convolutional Network (GCN) based on Long Short Term Memory (LSTM) with the previously published model, termed as GCN-DHSTNet; to capture the spatial patterns and short-term temporal features; and to illustrate its exceptional accomplishment in predicting the traffic crowd flows. The GCN-DHSTNet model not only depicts the spatio-temporal dependencies but also reveals the influence of different time granularity, which are recent, daily, weekly periodicity and external properties, respectively. Finally, a fully connected neural network is utilized to fuse the spatio-temporal features and external properties together. Using two different real-world traffic datasets, our evaluation suggests that the proposed GCN-DHSTNet method is approximately 7.9%–27.2% and 11.2%–11.9% better than the AAtt-DHSTNet method in terms of RMSE and MAPE metrics, respectively. Furthermore, AAtt-DHSTNet outperforms other state-of-the-art methods.}
}
@article{WU2021342,
title = {Deep learning based spectral CT imaging},
journal = {Neural Networks},
volume = {144},
pages = {342-358},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021003397},
author = {Weiwen Wu and Dianlin Hu and Chuang Niu and Lieza Vanden Broeke and Anthony P.H. Butler and Peng Cao and James Atlas and Alexander Chernoglazov and Varut Vardhanabhuti and Ge Wang},
keywords = {Spectral CT, Deep learning, Image reconstruction, Regularization prior,  loss},
abstract = {Spectral computed tomography (CT) has attracted much attention in radiation dose reduction, metal artifacts removal, tissue quantification and material discrimination. The x-ray energy spectrum is divided into several bins, each energy-bin-specific projection has a low signal-noise-ratio (SNR) than the current-integrating counterpart, which makes image reconstruction a unique challenge. Traditional wisdom is to use prior knowledge based iterative methods. However, this kind of methods demands a great computational cost. Inspired by deep learning, here we first develop a deep learning based reconstruction method; i.e., U-net with Lpp-norm, Total variation, Residual learning, and Anisotropic adaption (ULTRA). Specifically, we emphasize the various multi-scale feature fusion and multichannel filtering enhancement with a denser connection encoding architecture for residual learning and feature fusion. To address the image deblurring problem associated with the L22- loss, we propose a general Lpp-loss, p>0. Furthermore, the images from different energy bins share similar structures of the same object, the regularization characterizing correlations of different energy bins is incorporated into the Lpp- loss function, which helps unify the deep learning based methods with traditional compressed sensing based methods. Finally, the anisotropically weighted total variation is employed to characterize the sparsity in the spatial–spectral domain to regularize the proposed network In particular, we validate our ULTRA networks on three large-scale spectral CT datasets, and obtain excellent results relative to the competing algorithms. In conclusion, our quantitative and qualitative results in numerical simulation and preclinical experiments demonstrate that our proposed approach is accurate, efficient and robust for high-quality spectral CT image reconstruction.}
}