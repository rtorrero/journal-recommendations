@article{YU2023105,
title = {A survey on neural-symbolic learning systems},
journal = {Neural Networks},
volume = {166},
pages = {105-126},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003398},
author = {Dongran Yu and Bo Yang and Dayou Liu and Hui Wang and Shirui Pan},
keywords = {Neural-symbolic learning systems, Neural networks, Symbolic reasoning, Symbols, Logic, Knowledge graphs},
abstract = {In recent years, neural systems have demonstrated highly effective learning ability and superior perception intelligence. However, they have been found to lack effective reasoning and cognitive ability. On the other hand, symbolic systems exhibit exceptional cognitive intelligence but suffer from poor learning capabilities when compared to neural systems. Recognizing the advantages and disadvantages of both methodologies, an ideal solution emerges: combining neural systems and symbolic systems to create neural-symbolic learning systems that possess powerful perception and cognition. The purpose of this paper is to survey the advancements in neural-symbolic learning systems from four distinct perspectives: challenges, methods, applications, and future directions. By doing so, this research aims to propel this emerging field forward, offering researchers a comprehensive and holistic overview. This overview will not only highlight the current state-of-the-art but also identify promising avenues for future research.}
}
@article{MA2023174,
title = {Dual memory model for experience-once task-incremental lifelong learning},
journal = {Neural Networks},
volume = {166},
pages = {174-187},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003672},
author = {Gehua Ma and Runhao Jiang and Lang Wang and Huajin Tang},
keywords = {Experience-once lifelong learning, Task-incremental lifelong learning, Continual learning, Catastrophic forgetting, Dual-store memory model},
abstract = {Experience replay (ER) is a widely-adopted neuroscience-inspired method to perform lifelong learning. Nonetheless, existing ER-based approaches consider very coarse memory modules with simple memory and rehearsal mechanisms that cannot fully exploit the potential of memory replay. Evidence from neuroscience has provided fine-grained memory and rehearsal mechanisms, such as the dual-store memory system consisting of PFC-HC circuits. However, the computational abstraction of these processes is still very challenging. To address these problems, we introduce the Dual-Memory (Dual-MEM) model emulating the memorization, consolidation, and rehearsal process in the PFC-HC dual-store memory circuit. Dual-MEM maintains an incrementally updated short-term memory to benefit current-task learning. At the end of the current task, short-term memories will be consolidated into long-term ones for future rehearsal to alleviate forgetting. For the Dual-MEM optimization, we propose two learning policies that emulate different memory retrieval strategies: Direct Retrieval Learning and Mixup Retrieval Learning. Extensive evaluations on eight benchmarks demonstrate that Dual-MEM delivers compelling performance while maintaining high learning and memory utilization efficiencies under the challenging experience-once setting.}
}
@article{WANG2023540,
title = {H∞ master–slave synchronization for delayed impulsive implicit hybrid neural networks based on memory-state feedback control},
journal = {Neural Networks},
volume = {165},
pages = {540-552},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003271},
author = {Zekun Wang and Guangming Zhuang and Xiangpeng Xie and Jianwei Xia},
keywords = {Implicit/singular Markov jump systems, Delayed impulsive neural networks,  master–slave synchronization, Memory-state feedback control, Free-weighting matrix approach},
abstract = {This paper investigates the H∞ master–slave synchronization problem for delayed impulsive implicit hybrid neural networks based on memory-state feedback control. By developing a more holistic stochastic impulse-time-dependent Lyapunov–Krasovskii functional and dealing with the nonlinear neuron activation function, the stochastic admissibility and prescribed H∞ performance index for the synchronization error closed-loop system are achieved. In addition, the desired mode-dependent memory-state feedback synchronization controller is acquired in the form of linear matrix inequalities. The free-weighting matrix technique is adopted to remove the inherent limitation of time-varying delay derivative for the implicit delayed systems, and the derivative of time-varying delay is relaxed enough to be greater than 1. The simulation of genetic regulatory network in bio-economic system is given to verify validity of the derived results.}
}
@article{DING202392,
title = {ProxyMix: Proxy-based Mixup training with label refinery for source-free domain adaptation},
journal = {Neural Networks},
volume = {167},
pages = {92-103},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004240},
author = {Yuhe Ding and Lijun Sheng and Jian Liang and Aihua Zheng and Ran He},
keywords = {Source-free unsupervised domain adaptation, Pseudo labeling},
abstract = {Due to privacy concerns and data transmission issues, Source-free Unsupervised Domain Adaptation (SFDA) has gained popularity. It exploits pre-trained source models, rather than raw source data for target learning, to transfer knowledge from a labeled source domain to an unlabeled target domain. Existing methods solve this problem typically with additional parameters or noisy pseudo labels, and we propose an effective method named Proxy-based Mixup training with label refinery (ProxyMix) to avoid these drawbacks. To avoid additional parameters and leverages information in the source model, ProxyMix defines classifier weights as class prototypes and creates a class-balanced proxy source domain using nearest neighbors of the prototypes. To improve the reliability of pseudo labels, we further propose the frequency-weighted aggregation strategy to generate soft pseudo labels for unlabeled target data. Our strategy utilizes target features’ internal structure, increases weights of low-frequency class samples, and aligns the proxy and target domains using inter- and intra-domain mixup regularization. This mitigates the negative impact of noisy labels. Experiments on three 2D image and 3D point cloud object recognition benchmarks demonstrate that ProxyMix yields state-of-the-art performance for source-free UDA tasks.}
}
@article{LUO2023683,
title = {Long-range zero-shot generative deep network quantization},
journal = {Neural Networks},
volume = {166},
pages = {683-691},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.042},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004008},
author = {Yan Luo and Yangcheng Gao and Zhao Zhang and Jicong Fan and Haijun Zhang and Mingliang Xu},
keywords = {Deep network quantization, Long-range generator, Adversarial margin add, Synthetic data generation},
abstract = {Quantization approximates a deep network model with floating-point numbers by the model with low bit width numbers, thereby accelerating inference and reducing computation. Zero-shot quantization, which aims to quantize a model without access to the original data, can be achieved by fitting the real data distribution through data synthesis. However, it has been observed that zero-shot quantization leads to inferior performance compared to post-training quantization with real data for two primary reasons: 1) a normal generator has difficulty obtaining a high diversity of synthetic data since it lacks long-range information to allocate attention to global features, and 2) synthetic images aim to simulate the statistics of real data, which leads to weak intra-class heterogeneity and limited feature richness. To overcome these problems, we propose a novel deep network quantizer called long-range zero-shot generative deep network quantization (LRQ). Technically, we propose a long-range generator (LRG) to learn long-range information instead of simple local features. To incorporate more global features into the synthetic data, we use long-range attention with large-kernel convolution in the generator. In addition, we also present an adversarial margin add (AMA) module to force intra-class angular enlargement between the feature vector and class center. The AMA module forms an adversarial process that increases the convergence difficulty of the loss function, which is opposite to the training objective of the original loss function. Furthermore, to transfer knowledge from the full-precision network, we also utilize decoupled knowledge distillation. Extensive experiments demonstrate that LRQ obtains better performance than other competitors.}
}
@article{WARSI2023827,
title = {Dissociable default-mode subnetworks subserve childhood attention and cognitive flexibility: Evidence from deep learning and stereotactic electroencephalography},
journal = {Neural Networks},
volume = {167},
pages = {827-837},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003799},
author = {Nebras M. Warsi and Simeon M. Wong and Jürgen Germann and Alexandre Boutet and Olivia N. Arski and Ryan Anderson and Lauren Erdman and Han Yan and Hrishikesh Suresh and Flavia Venetucci Gouveia and Aaron Loh and Gavin J.B. Elias and Elizabeth Kerr and Mary Lou Smith and Ayako Ochi and Hiroshi Otsubo and Roy Sharma and Puneet Jain and Elizabeth Donner and Andres M. Lozano and O. Carter Snead and George M. Ibrahim},
keywords = {Deep learning, ADHD, Attention, Shapley values, Default mode network},
abstract = {Cognitive flexibility encompasses the ability to efficiently shift focus and forms a critical component of goal-directed attention. The neural substrates of this process are incompletely understood in part due to difficulties in sampling the involved circuitry. We leverage stereotactic intracranial recordings to directly resolve local-field potentials from otherwise inaccessible structures to study moment-to-moment attentional activity in children with epilepsy performing a flexible attentional task. On an individual subject level, we employed deep learning to decode neural features predictive of task performance indexed by single-trial reaction time. These models were subsequently aggregated across participants to identify predictive brain regions based on AAL atlas and FIND functional network parcellations. Through this approach, we show that fluctuations in beta (12–30 Hz) and gamma (30–80 Hz) power reflective of increased top-down attentional control and local neuronal processing within relevant large-scale networks can accurately predict single-trial task performance. We next performed connectomic profiling of these highly predictive nodes to examine task-related engagement of distributed functional networks, revealing exclusive recruitment of the dorsal default mode network during shifts in attention. The identification of distinct substreams within the default mode system supports a key role for this network in cognitive flexibility and attention in children. Furthermore, convergence of our results onto consistent functional networks despite significant inter-subject variability in electrode implantations supports a broader role for deep learning applied to intracranial electrodes in the study of human attention.}
}
@article{SONG2023424,
title = {Approximation of smooth functionals using deep ReLU networks},
journal = {Neural Networks},
volume = {166},
pages = {424-436},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003714},
author = {Linhao Song and Ying Liu and Jun Fan and Ding-Xuan Zhou},
keywords = {Approximation theory, Deep learning theory, ReLU, Smooth functionals, Fréchet derivative, Polynomial rates},
abstract = {In recent years, deep neural networks have been employed to approximate nonlinear continuous functionals F defined on Lp([−1,1]s) for 1≤p≤∞. However, the existing theoretical analysis in the literature either is unsatisfactory due to the poor approximation results, or does not apply to the rectified linear unit (ReLU) activation function. This paper aims to investigate the approximation power of functional deep ReLU networks in two settings: F is continuous with restrictions on the modulus of continuity, and F has higher order Fréchet derivatives. A novel functional network structure is proposed to extract features of higher order smoothness harbored by the target functional F. Quantitative rates of approximation in terms of the depth, width and total number of weights of neural networks are derived for both settings. We give logarithmic rates when measuring the approximation error on the unit ball of a Hölder space. In addition, we establish nearly polynomial rates (i.e., rates of the form exp−a(logM)b with a>0,0<b<1) when measuring the approximation error on a space of analytic functions.}
}
@article{WALTZ2023634,
title = {Spatial–temporal recurrent reinforcement learning for autonomous ships},
journal = {Neural Networks},
volume = {165},
pages = {634-653},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300326X},
author = {Martin Waltz and Ostap Okhrin},
keywords = {Deep reinforcement learning, Recurrency, Autonomous surface vehicle, COLREG},
abstract = {This paper proposes a spatial–temporal recurrent neural network architecture for deep Q-networks that can be used to steer an autonomous ship. The network design makes it possible to handle an arbitrary number of surrounding target ships while offering robustness to partial observability. Furthermore, a state-of-the-art collision risk metric is proposed to enable an easier assessment of different situations by the agent. The COLREG rules of maritime traffic are explicitly considered in the design of the reward function. The final policy is validated on a custom set of newly created single-ship encounters called ‘Around the Clock’ problems and the commonly used Imazu (1987) problems, which include 18 multi-ship scenarios. Performance comparisons with artificial potential field and velocity obstacle methods demonstrate the potential of the proposed approach for maritime path planning. Furthermore, the new architecture exhibits robustness when it is deployed in multi-agent scenarios and it is compatible with other deep reinforcement learning algorithms, including actor-critic frameworks.}
}
@article{SHEN2023953,
title = {GBT: Two-stage transformer framework for non-stationary time series forecasting},
journal = {Neural Networks},
volume = {165},
pages = {953-970},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.044},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003556},
author = {Li Shen and Yuning Wei and Yangzhu Wang},
keywords = {Time series forecasting, Non-stationary time series, Neural network, Transformer},
abstract = {This paper shows that time series forecasting Transformer (TSFT) suffers from severe over-fitting problem caused by improper initialization method of unknown decoder inputs, especially when handling non-stationary time series. Based on this observation, we propose GBT, a novel two-stage Transformer framework with Good Beginning. It decouples the prediction process of TSFT into two stages, including Auto-Regression stage and Self-Regression stage to tackle the problem of different statistical properties between input and prediction sequences. Prediction results of Auto-Regression stage serve as a ‘Good Beginning’, i.e., a better initialization for inputs of Self-Regression stage. We also propose the Error Score Modification module to further enhance the forecasting capability of the Self-Regression stage in GBT. Extensive experiments on seven benchmark datasets demonstrate that GBT outperforms SOTA TSFTs (FEDformer, Pyraformer, ETSformer, etc.) and many other forecasting models (SCINet, N-HiTS, etc.) with only canonical attention and convolution while owning less time and space complexity. It is also general enough to couple with these models to strengthen their forecasting capability. The source code is available at: https://github.com/OrigamiSL/GBT}
}
@article{SHARMA2023236,
title = {Node injection for class-specific network poisoning},
journal = {Neural Networks},
volume = {166},
pages = {236-247},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003830},
author = {Ansh Kumar Sharma and Rahul Kukreja and Mayank Kharbanda and Tanmoy Chakraborty},
keywords = {Adversarial attack, Network poisoning, Graph Neural Networks},
abstract = {Graph Neural Networks (GNNs) are powerful in learning rich network representations that aid the performance of downstream tasks. However, recent studies showed that GNNs are vulnerable to adversarial attacks involving node injection and network perturbation. Among these, node injection attacks are more practical as they do not require manipulation in the existing network and can be performed more realistically. In this paper, we propose a novel problem statement — a class-specific poison attack on graphs in which the attacker aims to misclassify specific nodes in the target class into a different class using node injection. Additionally, nodes are injected in such a way that they camouflage as benign nodes. We propose NICKI, a novel attacking strategy that utilizes an optimization-based approach to sabotage the performance of GNN-based node classifiers. NICKI works in two phases — it first learns the node representation and then generates the features and edges of the injected nodes. Extensive experiments and ablation studies on four benchmark networks show that NICKI is consistently better than four baseline attacking strategies for misclassifying nodes in the target class. We also show that the injected nodes are properly camouflaged as benign, thus making the poisoned graph indistinguishable from its clean version w.r.t various topological properties.}
}
@article{VASANTHI2023809,
title = {A reliable anchor regenerative-based transformer model for x-small and dense objects recognition},
journal = {Neural Networks},
volume = {165},
pages = {809-829},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003313},
author = {Ponduri Vasanthi and Laavanya Mohan},
keywords = {Object detection, Auto-anchor, Multi-head-self-attention, Spatial pyramid pooling-faster, YOLOv5},
abstract = {The past decade has witnessed significant progress in detecting objects by using enormous features of deep learning models. But, most of the existing models are unable to detect x-small and dense objects, due to the futility of feature extraction, and substantial misalignments between anchor boxes and axis-aligned convolution features, which leads to the discrepancy between the categorization score and positioning accuracy. This paper introduces an anchor regenerative-based transformer module in a feature refinement network to solve this problem. The anchor-regenerative module can generate anchor scales based on the semantic statistics of the objects present in the image, which avoids the inconsistency between the anchor boxes and axis-aligned convolution features. Whereas, the Multi-Head-Self-Attention (MHSA) based transformer module extracts the in-depth information from the feature maps based on the query, key, and value parameter information. This proposed model is experimentally verified on the VisDrone, VOC, and SKU-110K datasets. This model generates different anchor scales for these three datasets and achieves higher mAP, precision, and recall values on three datasets. These tested results prove that the suggested model has outstanding achievements compared with existing models in detecting x-small objects as well as dense objects. Finally, we evaluated the performance of these three datasets by using accuracy, kappa coefficient, and ROC metrics. These evaluated metrics demonstrate that our model is a good fit for VOC, and SKU-110K datasets.}
}
@article{ZOU2023609,
title = {MSSPA-GC: Multi-Scale Shape Prior Adaptation with 3D Graph Convolutions for Category-Level Object Pose Estimation},
journal = {Neural Networks},
volume = {166},
pages = {609-621},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003957},
author = {Lu Zou and Zhangjin Huang and Naijie Gu and Guoping Wang},
keywords = {Object pose estimation, 3D object detection, Point cloud processing, Shape recovery, 3D graph convolution network},
abstract = {Category-level object pose estimation aims to predict the 6D object pose and size of arbitrary objects from known categories. It remains a challenge due to the large intra-class shape variation. Recently, the introduction of the shape prior adaptation mechanism into the normalized canonical coordinates (i.e., NOCS) reconstruction process has been shown to be effective in mitigating the intra-class shape variation. However, existing shape prior adaptation methods simply map the observed point cloud to the normalized object space, and the extracted object descriptors are not sufficient for the perception of the object pose. As a result, they fail to predict the pose of objects with complex geometric structures (e.g., cameras). To this end, this paper proposes a novel shape prior adaption method named MSSPA-GC for category-level object pose estimation. Specifically, our main network takes the observed instance point cloud converted from the RGB-D image and the prior shape point cloud pre-trained on the object CAD models as inputs. Then, a novel 3D graph convolution network and a PointNet-like MLP network are designed to extract pose-aware object features and shape-aware object features from these two inputs, respectively. After that, the two-stream object features are aggregated through a multi-scale feature propagation mechanism to generate comprehensive 3D object descriptors that maintain both pose-sensitive geometric stability and intra-class shape consistency. Finally, by leveraging object descriptors aware of both object pose and shape when reconstructing the NOCS coordinates, our approach elegantly achieves state-of-the-art performance on the widely used REAL275 and CAMERA25 datasets using only 25% of the parameters compared with existing shape prior adaptation models. Moreover, our method also exhibits decent generalization ability on the unconstrained REDWOOD75 dataset.}
}
@article{SAKTHIVEL2023611,
title = {Observer-based state estimation for discrete-time semi-Markovian jump neural networks with round-robin protocol against cyber attacks},
journal = {Neural Networks},
volume = {165},
pages = {611-624},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.05.046},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023002903},
author = {Ramalingam Sakthivel and Oh-Min Kwon and Seong-Gon Choi and Rathinasamy Sakthivel},
keywords = {State estimation, Discrete-time systems, Neural networks, Semi-Markovian jump parameters, Round-robin protocol, Cyber attacks},
abstract = {This paper investigates an observer-based state estimation issue for discrete-time semi-Markovian jump neural networks with Round-Robin protocol and cyber attacks. In order to avoid the network congestion and save the communication resources, the Round-Robin protocol is used to schedule the data transmissions over the networks. Specifically, the cyber attacks are modeled as a set of random variables satisfying the Bernoulli distribution. On the basis of the Lyapunov functional and the discrete Wirtinger-based inequality technique, some sufficient conditions are established to guarantee the dissipativity performance and mean square exponential stability of the argument system. In order to compute the estimator gain parameters, a linear matrix inequality approach is utilized. Finally, two illustrative examples are provided to demonstrate the effectiveness of the proposed state estimation algorithm.}
}
@article{YAO2023410,
title = {Sparser spiking activity can be better: Feature Refine-and-Mask spiking neural network for event-based visual recognition},
journal = {Neural Networks},
volume = {166},
pages = {410-423},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003660},
author = {Man Yao and Hengyu Zhang and Guangshe Zhao and Xiyu Zhang and Dingheng Wang and Gang Cao and Guoqi Li},
keywords = {Spiking neural network, Event-based vision, Neuromorphic computing, Attention mechanism, Brain-inspired computing},
abstract = {Event-based visual, a new visual paradigm with bio-inspired dynamic perception and μs level temporal resolution, has prominent advantages in many specific visual scenarios and gained much research interest. Spiking neural network (SNN) is naturally suitable for dealing with event streams due to its temporal information processing capability and event-driven nature. However, existing works SNN neglect the fact that the input event streams are spatially sparse and temporally non-uniform, and just treat these variant inputs equally. This situation interferes with the effectiveness and efficiency of existing SNNs. In this paper, we propose the feature Refine-and-Mask SNN (RM-SNN), which has the ability of self-adaption to regulate the spiking response in a data-dependent way. We use the Refine-and-Mask (RM) module to refine all features and mask the unimportant features to optimize the membrane potential of spiking neurons, which in turn drops the spiking activity. Inspired by the fact that not all events in spatio-temporal streams are task-relevant, we execute the RM module in both temporal and channel dimensions. Extensive experiments on seven event-based benchmarks, DVS128 Gesture, DVS128 Gait, CIFAR10-DVS, N-Caltech101, DailyAction-DVS, UCF101-DVS, and HMDB51-DVS demonstrate that under the multi-scale constraints of input time window, RM-SNN can significantly reduce the network average spiking activity rate while improving the task performance. In addition, by visualizing spiking responses, we analyze why sparser spiking activity can be better. Code}
}
@article{BAEK2023860,
title = {Stereoscopic scalable quantum convolutional neural networks},
journal = {Neural Networks},
volume = {165},
pages = {860-867},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003386},
author = {Hankyul Baek and Won Joon Yun and Soohyun Park and Joongheon Kim},
keywords = {Quantum deep learning, Point cloud classification, Quantum convolutional neural network},
abstract = {As the noisy intermediate-scale quantum (NISQ) era has begun, a quantum neural network (QNN) is definitely a promising solution to many problems that classical neural networks cannot solve. In addition, a quantum convolutional neural network (QCNN) is now receiving a lot of attention because it can process high dimensional inputs comparing to QNN. However, due to the nature of quantum computing, it is difficult to scale up the QCNN to extract a sufficient number of features due to barren plateaus. This is especially challenging in classification operations with high-dimensional data input. However, due to the nature of quantum computing, it is difficult to scale up the QCNN to extract a sufficient number of features due to barren plateaus. This is especially challenging in classification operations with high dimensional data input. Motivated by this, a novel stereoscopic 3D scalable QCNN (sQCNN-3D) is proposed for point cloud data processing in classification applications. Furthermore, reverse fidelity training (RF-Train) is additionally considered on top of sQCNN-3D for diversifying features with a limited number of qubits using the fidelity of quantum computing. Our data-intensive performance evaluation verifies that the proposed algorithm achieves desired performance.}
}
@article{ERNST2023704,
title = {Sinogram upsampling using Primal–Dual UNet for undersampled CT and radial MRI reconstruction},
journal = {Neural Networks},
volume = {166},
pages = {704-721},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004239},
author = {Philipp Ernst and Soumick Chatterjee and Georg Rose and Oliver Speck and Andreas Nürnberger},
keywords = {CT, MRI, Sparse CT reconstruction, Undersampled MR reconstruction, Radial MRI reconstruction, Deep learning},
abstract = {Computed tomography (CT) and magnetic resonance imaging (MRI) are two widely used clinical imaging modalities for non-invasive diagnosis. However, both of these modalities come with certain problems. CT uses harmful ionising radiation, and MRI suffers from slow acquisition speed. Both problems can be tackled by undersampling, such as sparse sampling. However, such undersampled data leads to lower resolution and introduces artefacts. Several techniques, including deep learning based methods, have been proposed to reconstruct such data. However, the undersampled reconstruction problem for these two modalities was always considered as two different problems and tackled separately by different research works. This paper proposes a unified solution for both sparse CT and undersampled radial MRI reconstruction, achieved by applying Fourier transform-based pre-processing on the radial MRI and then finally reconstructing both modalities using sinogram upsampling combined with filtered back-projection. The Primal–Dual network is a deep learning based method for reconstructing sparsely-sampled CT data. This paper introduces Primal–Dual UNet, which improves the Primal–Dual network in terms of accuracy and reconstruction speed. The proposed method resulted in an average SSIM of 0.932±0.021 while performing sparse CT reconstruction for fan-beam geometry with a sparsity level of 16, achieving a statistically significant improvement over the previous model, which resulted in 0.919±0.016. Furthermore, the proposed model resulted in 0.903±0.019 and 0.957±0.023 average SSIM while reconstructing undersampled brain and abdominal MRI data with an acceleration factor of 16, respectively - statistically significant improvements over the original model, which resulted in 0.867±0.025 and 0.949±0.025. Finally, this paper shows that the proposed network not only improves the overall image quality, but also improves the image quality for the regions-of-interest: liver, kidneys, and spleen; as well as generalises better than the baselines in presence the of a needle.}
}
@article{LIU2023437,
title = {Value iteration for streaming data on a continuous space with gradient method in an RKHS},
journal = {Neural Networks},
volume = {166},
pages = {437-445},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003945},
author = {Jiamin Liu and Wangli Xu and Yue Wang and Heng Lian},
keywords = {Gradient descent, Value iteration, Reinforcement learning, RKHS, State-value function},
abstract = {The classical theory of reinforcement learning focused on the tabular setting when states and actions are finite, or for linear representation of the value function in a finite-dimensional approximation. Establishing theory on general continuous state and action space requires a careful treatment of complexity theory of appropriately chosen function spaces and the iterative update of the value function when stochastic gradient descent (SGD) is used. For the classical prediction problem in reinforcement learning based on i.i.d. streaming data in the framework of reproducing kernel Hilbert spaces, we establish polynomial sample complexity taking into account the smoothness of the value function. In particular, we prove that the gradient descent algorithm efficiently computes the value function with appropriately chosen step sizes, with a convergence rate that can be close to 1/N, which is the best possible rate for parametric SGD. The advantages of using the gradient descent algorithm include its computational convenience and it can naturally deal with streaming data.}
}
@article{MORGAN2023938,
title = {Domain-informed graph neural networks: A quantum chemistry case study},
journal = {Neural Networks},
volume = {165},
pages = {938-952},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003428},
author = {Jay Paul Morgan and Adeline Paiement and Christian Klinke},
keywords = {Graph neural network, Domain knowledge integration, Quantum chemistry application},
abstract = {We explore different strategies to integrate prior domain knowledge into the design of graph neural networks (GNN). Our study is supported by a use-case of estimating the potential energy of chemical systems (molecules and crystals) represented as graphs. We integrate two elements of domain knowledge into the design of the GNN to constrain and regularise its learning, towards higher accuracy and generalisation. First, knowledge on the existence of different types of relations/graph edges (e.g. chemical bonds in our case study) between nodes of the graph is used to modulate their interactions. We formulate and compare two strategies, namely specialised message production and specialised update of internal states. Second, knowledge of the relevance of some physical quantities is used to constrain the learnt features towards a higher physical relevance using a simple multi-task learning (MTL) paradigm. We explore the potential of MTL to better capture the underlying mechanisms behind the studied phenomenon. We demonstrate the general applicability of our two knowledge integrations by applying them to three architectures that rely on different mechanisms to propagate information between nodes and to update node states. Our implementations are made publicly available. To support these experiments, we release three new datasets of out-of-equilibrium molecules and crystals of various complexities.}
}
@article{NIE2023215,
title = {Context and detail interaction network for stereo rain streak and raindrop removal},
journal = {Neural Networks},
volume = {166},
pages = {215-224},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003702},
author = {Jing Nie and Jin Xie and Jiale Cao and Yanwei Pang},
keywords = {Convolutional neural networks, Stereo images, Rain streak removal, Raindrop removal, Interaction network},
abstract = {Recently stereo image deraining has attracted lots of attention due to its superiority of abundant information from cross views. Exploring interaction information across stereo views is the key to improving the performance of stereo image deraining. In this paper, we design a general coarse-to-fine deraining framework for stereo rain streak and raindrop removal, called CDINet, comprising a stereo rain removal subnet and a stereo detail recovery subnet to restore images progressively. Two types of interaction modules are devised to explore interaction information for rain removal and detail recovery, respectively. Specifically, a global context interaction module is proposed to learn long-range dependencies of stereo images and remove rain by utilizing stereo structural information. A local detail interaction module is designed to model local contextual correlation, which aims at restoring the detail information by using neighborhood information from cross views. Extensive experiments are conducted on the two datasets including a synthetic rain streak removal dataset (RainKITTI) and a real raindrop removal dataset (Stereo Waterdrop), which demonstrates that our method sets new state-of-the-art deraining performance in terms of both quantitative and qualitative metrics with faster speed.}
}
@article{DONG2023799,
title = {An unsupervised STDP-based spiking neural network inspired by biologically plausible learning rules and connections},
journal = {Neural Networks},
volume = {165},
pages = {799-808},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003301},
author = {Yiting Dong and Dongcheng Zhao and Yang Li and Yi Zeng},
keywords = {Spiking neural network, Unsupervised, Plasticity learning rule, Brain inspired connection},
abstract = {The backpropagation algorithm has promoted the rapid development of deep learning, but it relies on a large amount of labeled data and still has a large gap with how humans learn. The human brain can quickly learn various conceptual knowledge in a self-organized and unsupervised manner, accomplished through coordinating various learning rules and structures in the human brain. Spike-timing-dependent plasticity (STDP) is a general learning rule in the brain, but spiking neural networks (SNNs) trained with STDP alone is inefficient and perform poorly. In this paper, taking inspiration from short-term synaptic plasticity, we design an adaptive synaptic filter and introduce the adaptive spiking threshold as the neuron plasticity to enrich the representation ability of SNNs. We also introduce an adaptive lateral inhibitory connection to adjust the spikes balance dynamically to help the network learn richer features. To speed up and stabilize the training of unsupervised spiking neural networks, we design a samples temporal batch STDP (STB-STDP), which updates weights based on multiple samples and moments. By integrating the above three adaptive mechanisms and STB-STDP, our model greatly accelerates the training of unsupervised spiking neural networks and improves the performance of unsupervised SNNs on complex tasks. Our model achieves the current state-of-the-art performance of unsupervised STDP-based SNNs in the MNIST and FashionMNIST datasets. Further, we tested on the more complex CIFAR10 dataset, and the results fully illustrate the superiority of our algorithm. Our model is also the first work to apply unsupervised STDP-based SNNs to CIFAR10. At the same time, in the small-sample learning scenario, it will far exceed the supervised ANN using the same structure.}
}
@article{WANG2023326,
title = {Safe screening rules for multi-view support vector machines},
journal = {Neural Networks},
volume = {166},
pages = {326-343},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003787},
author = {Huiru Wang and Jiayi Zhu and Siyuan Zhang},
keywords = {Multi-view learning, Support vector machine, Safe screening, Speedup},
abstract = {Multi-view learning aims to make use of the advantages of different views to complement each other and fully mines the potential information in the data. However, the complexity of multi-view learning algorithm is much higher than that of single view learning algorithm. Based on the optimality conditions of two classical multi-view models: SVM-2K and multi-view twin support vector machine (MvTwSVM), this paper analyzes the corresponding relationship between dual variables and samples, and derives their safe screening rules for the first time, termed as SSR-SVM-2K and SSR-MvTwSVM. It can assign or delete four groups of different dual variables in advance before solving the optimization problem, so as to greatly reduce the scale of the optimization problem and improve the solution speed. More importantly, the safe screening criterion is “safe”, that is, the solution of the reduced optimization problem is the same as that of the original problem before screening. In addition, we further give a sequence screening rule to speed up the parameter optimization process, and analyze its properties, including the similarities and differences of safe screening rules between multi-view SVMs and single-view SVMs, the computational complexity, and the relationship between the parameter interval and screening rate. Numerical experiments verify the effectiveness of the proposed methods.}
}
@article{MAZUMDER2023999,
title = {Mitigate forgetting in few-shot class-incremental learning using different image views},
journal = {Neural Networks},
volume = {165},
pages = {999-1009},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.043},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003544},
author = {Pratik Mazumder and Pravendra Singh},
keywords = {Incremental learning, Few-shot learning, Catastrophic forgetting, Image classification},
abstract = {In the few-shot class incremental learning (FSCIL) setting, new classes with few training examples become available incrementally, and deep learning models suffer from catastrophic forgetting of the previous classes when trained on new classes. Data augmentation techniques are generally used to increase the training data and improve the model performance. In this work, we demonstrate that differently augmented views of the same image obtained by applying data augmentations may not necessarily activate the same set of neurons in the model. Therefore, the information gained by a model regarding a class, when trained using data augmentation, may not necessarily be stored in the same set of neurons in the model. Consequently, during incremental training, even if some of the model weights that store the previously seen class information for a particular view get overwritten, the information of the previous classes for the other views may still remain intact in the other model weights. Therefore, the impact of catastrophic forgetting on the model predictions is different for different data augmentations used during training. Based on this, we present an Augmentation-based Prediction Rectification (APR) approach to reduce the impact of catastrophic forgetting in the FSCIL setting. APR can also augment other FSCIL approaches and significantly improve their performance. We also propose a novel feature synthesis module (FSM) for synthesizing features relevant to the previously seen classes without requiring training data from these classes. FSM outperforms other generative approaches in this setting. We experimentally show that our approach outperforms other methods on benchmark datasets.}
}
@article{ZHAO2023366,
title = {Adaptive event-triggered extended dissipative synchronization of delayed reaction–diffusion neural networks under deception attacks},
journal = {Neural Networks},
volume = {166},
pages = {366-378},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003829},
author = {Feng-Liang Zhao and Zi-Peng Wang and Junfei Qiao and Huai-Ning Wu and Tingwen Huang},
keywords = {Adaptive event-triggered sampled-data (AETSD) control, Delayed reaction–diffusion neural networks (RDNNs), Extended dissipative performance, Spatially averaged measurements (SAMs), Deception attacks},
abstract = {Under spatially averaged measurements (SAMs) and deception attacks, this article mainly studies the problem of extended dissipativity output synchronization of delayed reaction–diffusion neural networks via an adaptive event-triggered sampled-data (AETSD) control strategy. Compared with the existing ETSD control methods with constant thresholds, our scheme can be adaptively adjusted according to the current sampling and latest transmitted signals and is realized based on limited sensors and actuators. Firstly, an AETSD control scheme is proposed to save the limited transmission channel. Secondly, some synchronization criteria under SAMs and deception attacks are established by utilizing Lyapunov–Krasovskii functional and inequality techniques. Then, by solving linear matrix inequalities (LMIs), we obtain the desired AETSD controller, which can satisfy the specified level of extended dissipativity behaviors. Lastly, one numerical example is given to demonstrate the validity of the proposed method.}
}
@article{ZHANG2023670,
title = {A biologically inspired auto-associative network with sparse temporal population coding},
journal = {Neural Networks},
volume = {166},
pages = {670-682},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.040},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003970},
author = {Ya Zhang and Kexin Shi and Xiaoling Luo and Yi Chen and Yucheng Wang and Hong Qu},
keywords = {Auto-associative network, Synaptic delay, Theta oscillation, Sparse representation, Associative learning},
abstract = {Associative system has attracted increasing attention for it can store basic information and then infer details to match perception with an efficient self-organization algorithm. However, the implementation of the associative system with the application of real-world data is relatively difficult. To address this issue, we propose a novel biologically inspired auto-associative (BIAA) network to explore the structure, encoding and formation of associative memory as well as to extend the ability to real-world application. Our network is constructed by imitating the organization of the cortical minicolumns where each minicolumn contains plenty of parallel biological spiking neurons. To allow the network to learn and predict one symbol per theta cycle, we incorporate synaptic delay and theta oscillation into the neuron dynamic process. Subsequently, we design a sparse temporal population (STP) coding scheme that allows each input symbol to be represented as stable, unique, and easily recallable sparsely distributed representations. By combining associative learning dynamics with the STP coding, our network realizes efficient storage and inference in an ordered manner. Experimental results indicate that the proposed network successfully performs sequence retrieval from partial text and sequence recovery from distorted information. BIAA network provides new insight into introducing biologically inspired mechanisms into associative system and has enormous potential for hardware and software applications.}
}
@article{HUANG2023868,
title = {TCGAN: Convolutional Generative Adversarial Network for time series classification and clustering},
journal = {Neural Networks},
volume = {165},
pages = {868-883},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003453},
author = {Fanling Huang and Yangdong Deng},
keywords = {Time series, Classification, Clustering, Generative Adversarial Networks, Deep Neural Networks, Representation learning},
abstract = {Recent works have demonstrated the superiority of supervised Convolutional Neural Networks (CNNs) in learning hierarchical representations from time series data for successful classification. These methods require sufficiently large labeled data for stable learning, however acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. Nonetheless, to our best knowledge, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. The above considerations inspire us to introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.}
}
@article{KARAMI2023188,
title = {Unsupervised feature selection based on variance–covariance subspace distance},
journal = {Neural Networks},
volume = {166},
pages = {188-203},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003295},
author = {Saeed Karami and Farid Saberi-Movahed and Prayag Tiwari and Pekka Marttinen and Sahar Vahdati},
keywords = {Feature selection, Subspace distance, Subspace learning, Regularization},
abstract = {Subspace distance is an invaluable tool exploited in a wide range of feature selection methods. The power of subspace distance is that it can identify a representative subspace, including a group of features that can efficiently approximate the space of original features. On the other hand, employing intrinsic statistical information of data can play a significant role in a feature selection process. Nevertheless, most of the existing feature selection methods founded on the subspace distance are limited in properly fulfilling this objective. To pursue this void, we propose a framework that takes a subspace distance into account which is called “Variance–Covariance subspace distance”. The approach gains advantages from the correlation of information included in the features of data, thus determines all the feature subsets whose corresponding Variance–Covariance matrix has the minimum norm property. Consequently, a novel, yet efficient unsupervised feature selection framework is introduced based on the Variance–Covariance distance to handle both the dimensionality reduction and subspace learning tasks. The proposed framework has the ability to exclude those features that have the least variance from the original feature set. Moreover, an efficient update algorithm is provided along with its associated convergence analysis to solve the optimization side of the proposed approach. An extensive number of experiments on nine benchmark datasets are also conducted to assess the performance of our method from which the results demonstrate its superiority over a variety of state-of-the-art unsupervised feature selection methods. The source code is available at https://github.com/SaeedKarami/VCSDFS.}
}
@article{LI202322,
title = {Active learning based on similarity level histogram and adaptive-scale sampling for very high resolution image classification},
journal = {Neural Networks},
volume = {167},
pages = {22-35},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004306},
author = {Guangfei Li and Quanxue Gao and Ming Yang and Xinbo Gao},
keywords = {Remote sensing, Classification, Active learning, Intra-class diversity},
abstract = {In remote sensing image classification, active learning aims to obtain an excellent classification model by selecting informative or representative training samples. However, due to the complexity of remote sensing images, the same class of ground objects usually have different spectral representations. The existing active learning methods may not take into account diverse representations of the same targets, which leads to a possible lack of intra-class diversity in the collected samples. To alleviate this problem, we propose an active learning method based on similarity level histogram (SLH) and adaptive-scale sampling to improve very high resolution remote sensing image classification. Specifically, we construct a SLH for each class of ground objects to effectively consider the intra-class diversity of the same target. To avoid the problem of sample imbalance caused by over-sampling or under-sampling, we design an adaptive-scale sampling strategy. Then, we utilize active learning to mine representative samples from each SLH warehouse according to adaptive-scale sampling strategies until the iteration condition is satisfied. Experiments show that the proposed algorithm can achieve better classification performance with limited training samples and is competitive with other methods based on four sets of publicly available data.}
}
@article{MUKHTAR2023396,
title = {CCGN: Centralized collaborative graphical transformer multi-agent reinforcement learning for multi-intersection signal free-corridor},
journal = {Neural Networks},
volume = {166},
pages = {396-409},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003854},
author = {Hamza Mukhtar and Adil Afzal and Sultan Alahmari and Saud Yonbawi},
keywords = {Collaborative intersection signal control, Graph convolutional network, Multi-agent centralized reinforcement learning, Cooperative traffic signal control, Markov decision processes, Intelligent transportation},
abstract = {Tackling traffic signal control through multi-agent reinforcement learning is a widely-employed approach. However, current state-of-the-art models have drawbacks: intersections optimize their own local rewards and cause traffic to waste time and fuel with a start-stop mode at each intersection. They also lack information sharing among intersections and their specialized policy hinders the ability to adapt to new traffic scenarios. To overcome these limitations, This work presents a centralized collaborative graph network (CCGN) with the core objective of a signal-free corridor once the traffic flows have waited at the entry intersection of the traffic intersection network on either side, the subsequent intersection gives the open signal as the traffic flows arrive. CCGN combines local policy networks (LPN) and global policy networks, where LPN employed at each intersection predicts actions based on Transformer and Graph Convolutional Network (GCN). In contrast, GPN is based on GCN and Q-network that receives the LPN states, traffic flow and road information to manage intersections to provide a signal-free corridor. We developed the Deep Graph Convolution Q-Network (DGCQ) by combining Deep Q-Network (DQN) and GCN to achieve a signal-free corridor. DGCQ leverages GCN’s intersection collaboration and DQN’s information aggregation for traffic control decisions Proposed CCGN model is trained on the robust synthetic traffic network and evaluated on the real-world traffic networks that outperform the other state-of-the-art models.}
}
@article{JIANG2023846,
title = {Adaptive neural-network-based sliding mode control of switching distributed delay systems with Markov jump parameters},
journal = {Neural Networks},
volume = {165},
pages = {846-859},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003337},
author = {Baoping Jiang and Hamid Reza Karimi and Xin Zhang and Zhengtian Wu},
keywords = {Neural network, Sliding mode control, Distributed delay systems, Switching systems},
abstract = {This paper is devoted to the issue of observer-based adaptive sliding mode control of distributed delay systems with deterministic switching rules and stochastic jumping process, simultaneously, through a neural network approach. Firstly, relying on the designed Lebesgue observer, a sliding mode hyperplane in the integral form is put forward, on which a desired sliding mode dynamic system is derived. Secondly, in consideration of complexity of real transition rates information, a novel adaptive dynamic controller that fits to universal mode information is designed to ensure the existence of sliding motion in finite-time, especially for the case that the mode information is totally unknown. In addition, an observer-based neural compensator is developed to attenuate the effectiveness of unknown system nonlinearity. Thirdly, an average dwell-time approach is utilized to check the mean-square exponential stability of the obtained sliding mode dynamics, particularly, the proposed criteria conditions are successfully unified with the designed controller in the type of mode information. Finally, a practical example is provided to verify the validity of the proposed method.}
}
@article{SAKAMOTO2023446,
title = {ATNAS: Automatic Termination for Neural Architecture Search},
journal = {Neural Networks},
volume = {166},
pages = {446-458},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003696},
author = {Kotaro Sakamoto and Hideaki Ishibashi and Rei Sato and Shinichi Shirakawa and Youhei Akimoto and Hideitsu Hino},
keywords = {Neural Architecture Search, Deep learning},
abstract = {Neural architecture search (NAS) is a framework for automating the design process of a neural network structure. While the recent one-shot approaches have reduced the search cost, there still exists an inherent trade-off between cost and performance. It is important to appropriately stop the search and further reduce the high cost of NAS. Meanwhile, the differentiable architecture search (DARTS), a typical one-shot approach, is known to suffer from overfitting. Heuristic early-stopping strategies have been proposed to overcome such performance degradation. In this paper, we propose a more versatile and principled early-stopping criterion on the basis of the evaluation of a gap between expectation values of generalisation errors of the previous and current search steps with respect to the architecture parameters. The stopping threshold is automatically determined at each search epoch without cost. In numerical experiments, we demonstrate the effectiveness of the proposed method. We stop the one-shot NAS algorithms and evaluate the acquired architectures on the benchmark datasets: NAS-Bench-201 and NATS-Bench. Our algorithm is shown to reduce the cost of the search process while maintaining a high performance.}
}
@article{HAO2023566,
title = {End-to-end neural speaker diarization with an iterative adaptive attractor estimation},
journal = {Neural Networks},
volume = {166},
pages = {566-578},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.043},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300401X},
author = {Fengyuan Hao and Xiaodong Li and Chengshi Zheng},
keywords = {Speaker diarization, End-to-end, Adaptive attractor estimation, Iterative refinement, Unified training},
abstract = {End-to-end neural diarization (EEND) which has the capability to directly output speaker diarization results and handle overlapping speech has attracted more and more attention due to its promising performance. Although existing EEND-based methods often outperform clustering-based methods, they cannot generalize well to unseen test sets because fixed attractors are often utilized to estimate speech activities of each speaker. An iterative adaptive attractor estimation (IAAE) network was proposed to refine diarization results, in which the self-attentive EEND (SA-EEND) was implemented to initialize diarization results and frame-wise embeddings. There are two main parts in the proposed IAAE network: an attention-based pooling was designed to obtain a rough estimation of the attractors based on the diarization results of the previous iteration, and an adaptive attractor was then calculated by using transformer decoder blocks. A unified training framework was proposed to further improve the diarization performance, making the embeddings more discriminable based on the well separated attractors. We evaluated the proposed method on both the simulated mixtures and the real CALLHOME dataset using the diarization error rate (DER). Our proposed method provides relative reductions in DER by up to 44.8% on simulated 2-speaker mixtures and 23.6% on the CALLHOME dataset over the baseline SA-EEND at the 2nd iteration step. We also demonstrated that with an increasing number of refinement steps applied, the DER on the CALLHOME dataset could be further reduced to 7.36%, achieving the state-of-the-art diarization results when compared with other methods.}
}
@article{GENDY2023286,
title = {Lightweight image super-resolution based multi-order gated aggregation network},
journal = {Neural Networks},
volume = {166},
pages = {286-295},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003611},
author = {Garas Gendy and Nabil Sabor and Guanghui He},
keywords = {Convolution neural network, Spatial aggregation, Adaptive channel aggregation, Multi-order gated aggregation, Lightweight image super-resolution},
abstract = {Recently, Transformer-based models are taken much focus on solving the task of image super-resolution (SR) due to their ability to achieve better performance. However, these models combined huge computational cost during the computing self-attention mechanism. To solve this problem, we proposed a multi-order gated aggregation super-resolution network (MogaSRN) for low-level vision based on the concept of the MogaNet that is developed for high-level vision. The concept of the MogaSRN model is based on spatial multi-order context aggregation and adaptive channel-wise reallocation with the aid of the multi-layer perceptron (MLP). In contrast to the MogaNet model, in which the resolution of each stage decreased by a factor of 2, the resolution of the MogaSRN is stayed fixed during the deep features extraction. Moreover, the structure of the MogaSRN model is built based on balancing the performance and the model complexity. We evaluated our model based on five benchmark datasets concluding that the MogaSRN model can achieve significant improvements compared to the state-of-the-art. Moreover, our model shows the good visual quality and accuracy of the reconstruction. Finally, our model has 3.7 × faster runtime at the scale of × 4 compared to LWSwinIR with better performance.}
}
@article{TANG2023204,
title = {A bio-inspired positional embedding network for transformer-based models},
journal = {Neural Networks},
volume = {166},
pages = {204-214},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003738},
author = {Xue-song Tang and Kuangrong Hao and Hui Wei},
keywords = {Transformers, Dorsal pathway modeling, Image classification, Position embedding, Zero padding},
abstract = {Owing to the progress of transformer-based networks, there have been significant improvements in the performance of vision models in recent years. However, there is further potential for improvement in positional embeddings that play a crucial role in distinguishing information across different positions. Based on the biological mechanisms of human visual pathways, we propose a positional embedding network that adaptively captures position information by modeling the dorsal pathway, which is responsible for spatial perception in human vision. Our proposed double-stream architecture leverages large zero-padding convolutions to learn local positional features and utilizes transformers to learn global features, effectively capturing the interaction between dorsal and ventral pathways. To evaluate the effectiveness of our method, we implemented experiments on various datasets, employing differentiated designs. Our statistical analysis demonstrates that the simple implementation significantly enhances image classification performance, and the observed trends demonstrate its biological plausibility.}
}
@article{LI2023148,
title = {Quantum recurrent neural networks for sequential learning},
journal = {Neural Networks},
volume = {166},
pages = {148-161},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300360X},
author = {Yanan Li and Zhimin Wang and Rongbing Han and Shangshang Shi and Jiaxin Li and Ruimin Shang and Haiyong Zheng and Guoqiang Zhong and Yongjian Gu},
keywords = {Quantum deep neural networks, Quantum recurrent neural networks, Temporal sequential data, Meteorological indicators, Stock price, Text categorization},
abstract = {Quantum neural network (QNN) is one of the promising directions where the near-term noisy intermediate-scale quantum (NISQ) devices could find advantageous applications against classical resources. Recurrent neural networks are the most fundamental networks for sequential learning, but up to now there is still a lack of canonical model of quantum recurrent neural network (QRNN), which certainly restricts the research in the field of quantum deep learning. In the present work, we propose a new kind of QRNN which would be a good candidate as the canonical QRNN model, where, the quantum recurrent blocks (QRBs) are constructed in the hardware-efficient way, and the QRNN is built by stacking the QRBs in a staggered way that can greatly reduce the algorithm’s requirement with regard to the coherent time of quantum devices. That is, our QRNN is much more accessible on NISQ devices. Furthermore, the performance of the present QRNN model is verified concretely using three different kinds of classical sequential data, i.e., meteorological indicators, stock price, and text categorization. The numerical experiments show that our QRNN achieves much better performance in prediction (classification) accuracy against the classical RNN and state-of-the-art QNN models for sequential learning, and can predict the changing details of temporal sequence data. The practical circuit structure and superior performance indicate that the present QRNN is a promising learning model to find quantum advantageous applications in the near term.}
}
@article{HUANG2023313,
title = {Perceptual Contrastive Generative Adversarial Network based on image warping for unsupervised image-to-image translation},
journal = {Neural Networks},
volume = {166},
pages = {313-325},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003684},
author = {Lin-Chieh Huang and Hung-Hsu Tsai},
keywords = {Image-to-image translation, Generative adversarial network, Image warping, Residual prediction, Patch-wise contrastive learning},
abstract = {This paper proposes an unsupervised image-to-image (UI2I) translation model, called Perceptual Contrastive Generative Adversarial Network (PCGAN), which can mitigate the distortion problem to enhance performance of the traditional UI2I methods. The PCGAN is designed with a two-stage UI2I model. In the first stage of the PCGAN, it leverages a novel image warping to transform shapes of objects in input (source) images. In the second stage of the PCGAN, the residual prediction is devised in refinements of the outputs of the first stage of the PCGAN. To promote performance of the image warping, a loss function, called Perceptual Patch-Wise InfoNCE, is developed in the PCGAN to effectively memorize the visual correspondences between warped images and refined images. Experimental results on quantitative evaluation and visualization comparison for UI2I benchmarks show that the PCGAN is superior to other existing methods considered here.}
}
@article{CHEN20231,
title = {Adaptive prescribed settling time periodic event-triggered control for uncertain robotic manipulators with state constraints},
journal = {Neural Networks},
volume = {166},
pages = {1-10},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003441},
author = {Zicong Chen and Hui Zhang and Jianqi Liu and Qinruo Wang and Jianhui Wang},
keywords = {Prescribed settling time control, Periodic event-triggered control, State constraints, Robotic manipulators},
abstract = {In this paper, an adaptive prescribed settling time periodic event-triggered control (APST-PETC) is investigated for uncertain robotic manipulators with state constraints. In order to economize network bandwidth occupancy and reduce computational burden, a periodic event-triggered control (PETC) strategy is proposed to reduce the update frequency of the control signal and avoid unnecessary continuous monitoring. Besides, considering that the maneuverable space of the actual robotic manipulators is often limited, the barrier Lyapunov function (BLF) is applied to deal with the influence of the constraint characteristics on the robotic manipulators. Further, based on the one-to-one nonlinear mapping function of the system tracking error, an adaptive prescribed settling time control (APSTC) is designed to ensure that the system tracking error reaches the predetermined precision residual set within the prescribed settling time. Finally, theoretical analysis and comparative experiments are given to verify its feasibility.}
}
@article{KASHEFI202380,
title = {Prediction of fluid flow in porous media by sparse observations and physics-informed PointNet},
journal = {Neural Networks},
volume = {167},
pages = {80-91},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004252},
author = {Ali Kashefi and Tapan Mukerji},
keywords = {Deep learning, Physics-informed PointNet, Stokes flow, Porous media, Sparse data},
abstract = {We predict steady-state Stokes flow of fluids within porous media at pore scales using sparse point observations and a novel class of physics-informed neural networks, called “physics-informed PointNet” (PIPN). Taking the advantages of PIPN into account, three new features become available compared to physics-informed convolutional neural networks for porous medium applications. First, the input of PIPN is exclusively the pore spaces of porous media (rather than both the pore and grain spaces). This feature diminishes required computer memory. Second, PIPN represents the boundary of pore spaces smoothly and realistically (rather than pixel-wise representations). Third, spatial resolution can vary over the physical domain (rather than equally spaced resolutions). This feature enables users to reach an optimal resolution with a minimum computational cost. The performance of our framework is evaluated by the study of the influence of noisy sensor data, pressure observations, and spatial correlation length.}
}
@article{PU2023740,
title = {Preassigned-time projective synchronization of delayed fully quaternion-valued discontinuous neural networks with parameter uncertainties},
journal = {Neural Networks},
volume = {165},
pages = {740-754},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003283},
author = {Hao Pu and Fengjun Li and Qingyun Wang and Pengzhen Li},
keywords = {Preassigned-time synchronization, Quaternion-valued neural networks, Chattering-free controller, Non-separation method, Parameter uncertainties},
abstract = {This paper concerns with the preassigned-time projective synchronization issue for delayed fully quaternion-valued discontinuous neural networks involving parameter uncertainties through the non-separation method. Above all, based on the existing works, a new preassigned-time stability theorem is established. Subsequently, to realize the control goals, two types of novel and simple chattering-free quaternion controllers are designed, one without the power-law term and the other with a hyperbolic-tangent function. They are different from the existing common power-law controller and exponential controller. Thirdly, under the Filippov discontinuity theories and with the aid of quaternion inequality techniques, some novel succinct sufficient criteria are obtained to ensure the addressed systems to achieve the preassigned-time synchronization by using the preassigned-time stability theory. The preassigned settling time is free from any parameter and any initial value of the system, and can be preset according to the actual task demands. Particularly, unlike the existing results, the proposed control methods can effectively avoid the chattering phenomenon, and the time delay part is removed for simplicity. Additionally, the projection coefficient is generic quaternion-valued instead of real-valued or complex-valued, and some of the previous relevant results are extended. Lastly, numerical simulations are reported to substantiate the effectiveness of the control strategies, the merits of preassigned settling time, and the correctness of the acquired results.}
}
@article{LIU20231021,
title = {SNR: Symbolic network-based rectifiable learning framework for symbolic regression},
journal = {Neural Networks},
volume = {165},
pages = {1021-1034},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.046},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003568},
author = {Jingyi Liu and Weijun Li and Lina Yu and Min Wu and Linjun Sun and Wenqiang Li and Yanjie Li},
keywords = {Symbolic regression, Symbolic network, Learning-from-scratch, Learning-with-experience},
abstract = {Symbolic regression (SR) can be utilized to unveil the underlying mathematical expressions that describe a given set of observed data. At present, SR can be categorized into two methods: learning-from-scratch and learning-with-experience. Compared to learning-from-scratch, learning-with-experience yields results that are comparable to those of several benchmarks and incurs significantly lower time costs for obtaining expressions. However, the learning-with-experience model performs poorly in terms of unseen data distributions and lacks a rectification tool, apart from constant optimization, which exhibits limited performance. In this study, we propose a Symbolic Network-based Rectifiable Learning Framework (SNR) that possesses the ability to correct errors. SNR adopts Symbolic Network (SymNet) to represent an expression, and the encoding of SymNet is designed to provide supervised information, with numerous self-generated expressions, to train a policy net (PolicyNet). The training of PolicyNet can offer prior knowledge to guide effective searches. Subsequently, the incorrectly predicted expressions are revised via a rectification mechanism. This rectification mechanism endows SNR with broader applicability. Experimental results demonstrate that our proposed method achieves the highest averaged coefficient of determination on self-generated datasets when compared with other state-of-the-art methods and yields more accurate results in public datasets.}
}
@article{LI2023925,
title = {Strengthening transferability of adversarial examples by adaptive inertia and amplitude spectrum dropout},
journal = {Neural Networks},
volume = {165},
pages = {925-937},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.031},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300343X},
author = {Huanhuan Li and Wenbo Yu and He Huang},
keywords = {Adversarial examples, Transferability, Gradient-based attack, Adaptive inertia, Amplitude spectrum dropout},
abstract = {Deep neural networks are sensitive to adversarial examples and would produce wrong results with high confidence. However, most existing attack methods exhibit weak transferability, especially for adversarially trained models and defense models. In this paper, two methods are proposed to generate highly transferable adversarial examples, namely Adaptive Inertia Iterative Fast Gradient Sign Method (AdaI2-FGSM) and Amplitude Spectrum Dropout Method (ASDM). Specifically, AdaI2-FGSM aims to integrate adaptive inertia into the gradient-based attack, and leverage the looking ahead property to search for a flatter maximum, which is essential to strengthen the transferability of adversarial examples. By introducing a loss-preserving transformation in the frequency domain, the proposed ASDM with the dropout invariance property can craft the copies of input images to overcome the poor generalization on the surrogate models. Furthermore, AdaI2-FGSM and ASDM can be naturally integrated as an efficient gradient-based attack method to yield more transferable adversarial examples. Extensive experimental results on the ImageNet-compatible dataset demonstrate that higher transferability is achieved by our method than some advanced gradient-based attacks.}
}
@article{GUO2023273,
title = {RegraphGAN: A graph generative adversarial network model for dynamic network anomaly detection},
journal = {Neural Networks},
volume = {166},
pages = {273-285},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003842},
author = {Dezhi Guo and Zhaowei Liu and Ranran Li},
keywords = {Anomaly detection, Generative adversarial network, Dynamic networks},
abstract = {Due to the wide application of dynamic graph anomaly detection in cybersecurity, social networks, e-commerce, etc., research in this area has received increasing attention. Graph generative adversarial networks can be used in dynamic graph anomaly detection due to their ability to model complex data, but the original graph generative adversarial networks do not have a method to learn reverse mapping and require an expensive process in recovering the potential representation of a given input. Therefore, this paper proposes a novel graph generative adversarial network by adding encoders to map real data to latent space to improve the training efficiency and stability of graph generative adversarial network models, which is named RegraphGAN in this paper. And this paper proposes a dynamic network anomaly edge detection method by combining RegraphGAN with spatiotemporal coding to solve the complex dynamic graph data and the problem of attribute-free node information coding challenges. Meanwhile, anomaly detection experiments are conducted on six real dynamic network datasets, and the results show that the dynamic network anomaly detection method proposed in this paper outperforms other existing methods.}
}
@article{LIANG2023830,
title = {Stochastic momentum methods for non-convex learning without bounded assumptions},
journal = {Neural Networks},
volume = {165},
pages = {830-845},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003325},
author = {Yuqing Liang and Jinlan Liu and Dongpo Xu},
keywords = {Non-convex optimization, Last-iterate convergence rate, Stochastic momentum methods, PL condition, Machine learning},
abstract = {Stochastic momentum methods are widely used to solve stochastic optimization problems in machine learning. However, most of the existing theoretical analyses rely on either bounded assumptions or strong stepsize conditions. In this paper, we focus on a class of non-convex objective functions satisfying the Polyak–Łojasiewicz (PL) condition and present a unified convergence rate analysis for stochastic momentum methods without any bounded assumptions, which covers stochastic heavy ball (SHB) and stochastic Nesterov accelerated gradient (SNAG). Our analysis achieves the more challenging last-iterate convergence rate of function values under the relaxed growth (RG) condition, which is a weaker assumption than those used in related work. Specifically, we attain the sub-linear rate for stochastic momentum methods with diminishing stepsizes, and the linear convergence rate for constant stepsizes if the strong growth (SG) condition holds. We also examine the iteration complexity for obtaining an ϵ-accurate solution of the last-iterate. Moreover, we provide a more flexible stepsize scheme for stochastic momentum methods in three points: (i) relaxing the last-iterate convergence stepsize from square summable to zero limitation; (ii) extending the minimum-iterate convergence rate stepsize to the non-monotonic case; (iii) expanding the last-iterate convergence rate stepsize to a more general form. Finally, we conduct numerical experiments on benchmark datasets to validate our theoretical findings.}
}
@article{ZHOU2023501,
title = {InfraNet: Accurate forehead temperature measurement framework for people in the wild with monocular thermal infrared camera},
journal = {Neural Networks},
volume = {166},
pages = {501-511},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.038},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003969},
author = {Xichuan Zhou and Dongshan Lei and Chunqiao Long and Jing Nie and Haijun Liu},
keywords = {COVID-19, Forehead temperature calibration, Monocular thermal infrared camera, Depth estimation},
abstract = {During an epidemic, accurate human temperature screening based on neural networks for disease surveillance is important and challenging. Existing distant human forehead temperature measuring device usually adopts a dual-camera system using paired RGB and thermal infrared images to conduct face detection and temperature measurement. Since the facial RGB image may undermine people’s privacy, we designed a monocular thermal system and proposed an effective framework called the InfraNet to measure and calibrate forehead temperature of people in the wild. To address the challenge of temperature floating, the InfraNet calibrates the subject’s temperature with one’s physical depth and horizontal offset predicted by a single infrared image. Our InfraNet framework mainly consists of three parts: face detection subnet, depth and horizontal offset estimation subnet and temperature calibration subnet. The temperature calibration performance can be improved with the help of spatial regularization term concentrating on predicting precise depth and horizontal offset of people. Besides, we collected a large-scale infrared image dataset in the both lab and wild scenarios, including 8,215 thermal infrared images. Experiments on our wild dataset demonstrated that the InfraNet achieved 91.6% high accuracy of distant multi-subject temperature measurement on average under the standard temperature threshold of strict 0.3°C.}
}
@article{DORNAIKA2023248,
title = {A unified semi-supervised model with joint estimation of graph, soft labels and latent subspace},
journal = {Neural Networks},
volume = {166},
pages = {248-259},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003726},
author = {Fadi Dornaika and Abdullah Baradaaji},
keywords = {Semi-supervised learning, Discriminant embedding, Soft labels, Graph construction, Graph-based embedding, Image categorization},
abstract = {Since manually labeling images is expensive and labor intensive, in practice we often do not have enough labeled images to train an effective classifier for the new image classification tasks. The graph-based SSL methods have received more attention in practice due to their convexity, scalability and efficiency. In this paper, we propose a novel graph-based semi-supervised learning method that takes full advantage of a small set of labeled graphs and a large set of unlabeled graph data. First, we explain the concept of graph-based semi-supervised learning. The core idea of these models is to jointly estimate a low-rank graph with soft labels and a latent subspace. The proposed scheme leverages the synergy between the graph structure and the data representation in terms of soft labels and latent features. This improves the monitoring information and leads to better discriminative linear transformation. Several experiments were conducted on five image datasets using state-of-the-art methods. These experiments show the effectiveness of the proposed semi-supervised method.}
}
@article{XING2023622,
title = {Event-based fixed-time synchronization of neural networks under DoS attack and its applications},
journal = {Neural Networks},
volume = {166},
pages = {622-633},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.046},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004045},
author = {Mengping Xing and Jianquan Lu and Jungang Lou and Lingzhong Zhang},
keywords = {Fixed-time synchronization, Event-triggered control, DoS attack, Chaotic networks, Image and audio encryption},
abstract = {In this paper, the fixed-time synchronization control for neural networks with discontinuous data communication is investigated. Due to the transmission blocking caused by DoS attack, it is intractable to establish a monotonically decreasing Lyapunov function like the conventional analysis of fixed-time stability. Therefore, by virtue of recursive and reduction to absurdity approaches, novel fixed-time stability criteria where the estimated upper bound of settling-time is inherently different from existing results are presented. Then, based on the developed conditions, an event-triggered control scheme that can avoid Zeno behavior is designed to achieve synchronization of master–slave neural networks under DoS attack within a prescribed time. For comparison, the established control scheme is further discussed under the case without DoS attack, and the circumstance that there is no attack or event-triggered mechanism, respectively. Simulation results are finally provided to illustrate the significant and validity of our theoretical research. Especially, in terms of encryption and decryption keys generated from the synchronization behavior of chaotic networks, we specifically discuss the application of the proposed fixed-time synchronization scheme to image and audio encryption.}
}
@article{SINGHAL20231050,
title = {Enhanced regularization for on-chip training using analog and temporary memory weights},
journal = {Neural Networks},
volume = {165},
pages = {1050-1057},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003593},
author = {Raghav Singhal and Vivek Saraswat and Shreyas Deshmukh and Sreenivas Subramoney and Laxmeesha Somappa and Maryam Shojaei Baghini and Udayan Ganguly},
keywords = {Temporary memory, Regularization, On-chip learning, Artificial neural network, In-memory computing, ML hardware},
abstract = {In-memory computing techniques are used to accelerate artificial neural network (ANN) training and inference tasks. Memory technology and architectural innovations allow efficient matrix–vector multiplications, gradient calculations, and updates to network weights. However, on-chip learning for edge devices is quite challenging due to the frequent updates. Here, we propose using an analog and temporary on-chip memory (ATOM) cell with controllable retention timescales for implementing the weights of an on-chip training task. Measurement results for Read–Write timescales are presented for an ATOM cell fabricated in GlobalFoundries’ 45 nm RFSOI technology. The effect of limited retention and its variability is evaluated for training a fully connected neural network with a variable number of layers for the MNIST hand-written digit recognition task. Our studies show that weight decay due to temporary memory can have benefits equivalent to regularization, achieving a ∼33% reduction in the validation error (from 3.6% to 2.4%). We also show that the controllability of the decay timescale can be advantageous in achieving a further ∼26% reduction in the validation error. This strongly suggests the utility of temporary memory during learning before on-chip non-volatile memories can take over for the storage and inference tasks using the neural network weights. We thus propose an algorithm-circuit codesign in the form of temporary analog memory for high-performing on-chip learning of ANNs.}
}
@article{YANG20231,
title = {Visual-quality-driven unsupervised image dehazing},
journal = {Neural Networks},
volume = {167},
pages = {1-9},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004288},
author = {Aiping Yang and Yumeng Liu and Jinbin Wang and Xiaoxiao Li and Jiale Cao and Zhong Ji and Yanwei Pang},
keywords = {Image dehazing, Unsupervised learning, Visual-quality-driven, Interactive fusion, Iterative enhancement},
abstract = {Most of the existing learning-based dehazing methods require a diverse and large collection of paired hazy/clean images, which is intractable to obtain. Therefore, existing dehazing methods resort to training on synthetic images. This may result in a possible domain shift when treating real scenes. In this paper, we propose a novel unsupervised dehazing (lightweight) network without any reference images to directly predict clear images from the original hazy images, which consists of an interactive fusion module (IFM) and an iterative optimization module (IOM). Specifically, IFM interactively fuses multi-level features to make up for the missing information among deep and shallow features while IOM iteratively optimizes dehazed results to obtain pleasing visual effects. Particularly, based on the observation that hazy images usually suffer from quality degradation, four non-reference visual-quality-driven loss functions are designed to enable the network trained in an unsupervised way, including dark channel loss, contrast loss, saturation loss, and edge sharpness loss. Extensive experiments on two synthetic datasets and one real-world dataset demonstrate that our method performs favorably against the state-of-the-art unsupervised dehazing methods and even matches some supervised methods in terms of metrics such as PSNR, SSIM, and UQI.}
}
@article{HE20231010,
title = {Graph structure learning layer and its graph convolution clustering application},
journal = {Neural Networks},
volume = {165},
pages = {1010-1020},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003350},
author = {Xiaxia He and Boyue Wang and Ruikun Li and Junbin Gao and Yongli Hu and Guangyu Huo and Baocai Yin},
keywords = {Graph convolutional network, Subspace clustering, Graph structure learning},
abstract = {To learn the embedding representation of graph structure data corrupted by noise and outliers, existing graph structure learning networks usually follow the two-step paradigm, i.e., constructing a “good” graph structure and achieving the message passing for signals supported on the learned graph. However, the data corrupted by noise may make the learned graph structure unreliable. In this paper, we propose an adaptive graph convolutional clustering network that alternatively adjusts the graph structure and node representation layer-by-layer with back-propagation. Specifically, we design a Graph Structure Learning layer before each Graph Convolutional layer to learn the sparse graph structure from the node representations, where the graph structure is implicitly determined by the solution to the optimal self-expression problem. This is one of the first works that uses an optimization process as a Graph Network layer, which is obviously different from the function operation in traditional deep learning layers. An efficient iterative optimization algorithm is given to solve the optimal self-expression problem in the Graph Structure Learning layer. Experimental results show that the proposed method can effectively defend the negative effects of inaccurate graph structures. The code is available at https://github.com/HeXiax/SSGNN.}
}
@article{YU2023162,
title = {A super-resolution network for medical imaging via transformation analysis of wavelet multi-resolution},
journal = {Neural Networks},
volume = {166},
pages = {162-173},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003635},
author = {Yue Yu and Kun She and Jinhua Liu and Xiao Cai and Kaibo Shi and O.M. Kwon},
keywords = {Multi-resolution analysis, Super-resolution, Convolutional neural network, Wavelet transform, Medical imaging, COVID-19},
abstract = {In recent years, deep learning super-resolution models for progressive reconstruction have achieved great success. However, these models which refer to multi-resolution analysis basically ignore the information contained in the lower subspaces and do not explore the correlation between features in the wavelet and spatial domain, resulting in not fully utilizing the auxiliary information brought by multi-resolution analysis with multiple domains. Therefore, we propose a super-resolution network based on the wavelet multi-resolution framework (WMRSR) to capture the auxiliary information contained in multiple subspaces and to be aware of the interdependencies between spatial domain and wavelet domain features. Initially, the wavelet multi-resolution input (WMRI) is generated by combining wavelet sub-bands obtained from each subspace through wavelet multi-resolution analysis and the corresponding spatial domain image content, which serves as input to the network. Then, the WMRSR captures the corresponding features from the WMRI in the wavelet domain and spatial domain, respectively, and fuses them adaptively, thus learning fully explored features in multi-resolution and multi-domain. Finally, the high-resolution images are gradually reconstructed in the wavelet multi-resolution framework by our convolution-based wavelet transform module which is suitable for deep neural networks. Extensive experiments conducted on two public datasets demonstrate that our method outperforms other state-of-the-art methods in terms of objective and visual qualities.}
}
@article{CAI2023344,
title = {EPC-DARTS: Efficient partial channel connection for differentiable architecture search},
journal = {Neural Networks},
volume = {166},
pages = {344-353},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003878},
author = {Zicheng Cai and Lei Chen and Hai-Lin Liu},
keywords = {Neural architecture search, Partial channel connection, Efficient channel attention},
abstract = {With weight-sharing and continuous relaxation strategies, the differentiable architecture search (DARTS) proposes a fast and effective solution to perform neural network architecture search in various deep learning tasks. However, unresolved issues, such as the inefficient memory utilization, and the poor stability of the search architecture due to channels randomly selected, which has even caused performance collapses, are still perplexing researchers and practitioners. In this paper, a novel efficient channel attention mechanism based on partial channel connection for differentiable neural architecture search, termed EPC-DARTS, is proposed to address these two issues. Specifically, we design an efficient channel attention module, which is applied to capture cross-channel interactions and assign weight based on channel importance, to dramatically improve search efficiency and reduce memory occupation. Moreover, only partial channels with higher weights in the mixed calculation of operation are used through the efficient channel attention mechanism, and thus unstable network architectures obtained by the random selection operation can also be avoided in the proposed EPC-DARTS. Experimental results show that the proposed EPC-DARTS achieves remarkably competitive performance (CIFAR-10/CIFAR-100: a test accuracy rate of 97.60%/84.02%), compared to other state-of-the-art NAS methods using only 0.2 GPU-Days.}
}
@article{PAROLI2023634,
title = {Solving classification tasks by a receptron based on nonlinear optical speckle fields},
journal = {Neural Networks},
volume = {166},
pages = {634-644},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004203},
author = {B. Paroli and G. Martini and M.A.C. Potenza and M. Siano and M. Mirigliano and P. Milani},
keywords = {Perceptron, Classification, Non-linear networks, Optical device, Boolean functions},
abstract = {Among several approaches to tackle the problem of energy consumption in modern computing systems, two solutions are currently investigated: one consists of artificial neural networks (ANNs) based on photonic technologies, the other is a different paradigm compared to ANNs and it is based on random networks of non-linear nanoscale junctions resulting from the assembling of nanoparticles or nanowires as substrates for neuromorphic computing. These networks show the presence of emergent complexity and collective phenomena in analogy with biological neural networks characterized by self-organization, redundancy, and non-linearity. Starting from this background, we propose and formalize a generalization of the perceptron model to describe a classification device based on a network of interacting units where the input weights are non-linearly dependent. We show that this model, called “receptron”, provides substantial advantages compared to the perceptron as, for example, the solution of non-linearly separable Boolean functions with a single device. The receptron model is used as a starting point for the implementation of an all-optical device that exploits the non-linearity of optical speckle fields produced by a solid scatterer. By encoding these speckle fields we generated a large variety of target Boolean functions. We demonstrate that by properly setting the model parameters, different classes of functions with different multiplicity can be solved efficiently. The optical implementation of the receptron scheme opens the way for the fabrication of a completely new class of optical devices for neuromorphic data processing based on a very simple hardware.}
}
@article{WANG2023595,
title = {An adaptive neurodynamic approach for solving nonsmooth N-cluster games},
journal = {Neural Networks},
volume = {166},
pages = {595-608},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.041},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003994},
author = {Mengxin Wang and Shihui Zhu and Sitian Qin},
keywords = {-cluster games, Leader-following consensus, Generalized Nash equilibrium, Singular perturbation, Private and coupling constraints},
abstract = {In this paper, N-cluster games with coupling and private constraints are studied, where each player’s cost function is nonsmooth and depends on the actions of all players. In order to seek the generalized Nash equilibrium (GNE) of the nonsmooth N-cluster games, a distributed seeking neurodynamic approach with two-time-scale structure is proposed. An adaptive leader-following consensus technique is adapted to dynamically adjust parameters according to the degree of consensus violation, so as to quickly obtain accurate estimation information of other players’ actions which facilitates the evaluation of its own cost. Benefitting from the unique structure of the approach based on primal dual and adaptive penalty methods, the players’ actions enter the constraints while completing the seeking for GNE. As a result, the neurodynamic approach is completely distributed, and prior estimation of penalty parameters is avoided. Finally, two engineering examples of power system game and company capacity allocation verify the effectiveness and feasibility of the neurodynamic approach.}
}
@article{OLADYSHKIN202385,
title = {The deep arbitrary polynomial chaos neural network or how Deep Artificial Neural Networks could benefit from data-driven homogeneous chaos theory},
journal = {Neural Networks},
volume = {166},
pages = {85-104},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003477},
author = {Sergey Oladyshkin and Timothy Praditia and Ilja Kroeker and Farid Mohammadi and Wolfgang Nowak and Sebastian Otte},
keywords = {Artificial Intelligence, Machine learning, Deep Artificial Neural Network, Polynomial chaos expansion, Orthogonal decomposition, High-order neural interactions},
abstract = {Artificial Intelligence and Machine learning have been widely used in various fields of mathematical computing, physical modeling, computational science, communication science, and stochastic analysis. Approaches based on Deep Artificial Neural Networks (DANN) are very popular in our days. Depending on the learning task, the exact form of DANNs is determined via their multi-layer architecture, activation functions and the so-called loss function. However, for a majority of deep learning approaches based on DANNs, the kernel structure of neural signal processing remains the same, where the node response is encoded as a linear superposition of neural activity, while the non-linearity is triggered by the activation functions. In the current paper, we suggest to analyze the neural signal processing in DANNs from the point of view of homogeneous chaos theory as known from polynomial chaos expansion (PCE). From the PCE perspective, the (linear) response on each node of a DANN could be seen as a 1st degree multi-variate polynomial of single neurons from the previous layer, i.e. linear weighted sum of monomials. From this point of view, the conventional DANN structure relies implicitly (but erroneously) on a Gaussian distribution of neural signals. Additionally, this view revels that by design DANNs do not necessarily fulfill any orthogonality or orthonormality condition for a majority of data-driven applications. Therefore, the prevailing handling of neural signals in DANNs could lead to redundant representation as any neural signal could contain some partial information from other neural signals. To tackle that challenge, we suggest to employ the data-driven generalization of PCE theory known as arbitrary polynomial chaos (aPC) to construct a corresponding multi-variate orthonormal representations on each node of a DANN. Doing so, we generalize the conventional structure of DANNs to Deep arbitrary polynomial chaos neural networks (DaPC NN). They decompose the neural signals that travel through the multi-layer structure by an adaptive construction of data-driven multi-variate orthonormal bases for each layer. Moreover, the introduced DaPC NN provides an opportunity to go beyond the linear weighted superposition of single neurons on each node. Inheriting fundamentals of PCE theory, the DaPC NN offers an additional possibility to account for high-order neural effects reflecting simultaneous interaction in multi-layer networks. Introducing the high-order weighted superposition on each node of the network mitigates the necessity to introduce non-linearity via activation functions and, hence, reduces the room for potential subjectivity in the modeling procedure. Although the current DaPC NN framework has no theoretical restrictions on the use of activation functions. The current paper also summarizes relevant properties of DaPC NNs inherited from aPC as analytical expressions for statistical quantities and sensitivity indexes on each node. We also offer an analytical form of partial derivatives that could be used in various training algorithms. Technically, DaPC NNs require similar training procedures as conventional DANNs, and all trained weights determine automatically the corresponding multi-variate data-driven orthonormal bases for all layers of DaPC NN. The paper makes use of three test cases to illustrate the performance of DaPC NN, comparing it with the performance of the conventional DANN and also with plain aPC expansion. Evidence of convergence over the training data size against validation data sets demonstrates that the DaPC NN outperforms the conventional DANN systematically. Overall, the suggested re-formulation of the kernel network structure in terms of homogeneous chaos theory is not limited to any particular architecture or any particular definition of the loss function. The DaPC NN Matlab Toolbox is available online and users are invited to adopt it for own needs.}
}
@article{KONG2023354,
title = {Fixed-time periodic stabilization of discontinuous reaction–diffusion Cohen–Grossberg neural networks},
journal = {Neural Networks},
volume = {166},
pages = {354-365},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003751},
author = {Fanchao Kong and Quanxin Zhu and Hamid Reza Karimi},
keywords = {Fixed-time stability, Periodicity, Filippov systems, Cohen–Grossberg networks, Reaction–diffusion},
abstract = {This paper aims to study the fixed-time stabilization of a class of delayed discontinuous reaction–diffusion Cohen–Grossberg neural networks. Firstly, by providing some relaxed conditions containing indefinite functions and based on inequality techniques, a new fixed-time stability lemma is given, which can improve the traditional ones. Secondly, based on state-dependent switching laws, the periodic wave solution of the formulated networks is transformed into the periodic solution of ordinary differential system. By utilizing differential inclusions theory and coincidence theorem, the existence of periodic solutions is obtained. Thirdly, based on the new fixed-time stability lemma, the periodic solutions are stabilized at zero in a fixed-time, which is a new topic on reaction–diffusion networks. Moreover, the established criteria are all delay-dependent, which are less conservative than the previous delay-independent ones for ensuring the stabilization of delayed reaction–diffusion networks. Finally, two examples give numerical explanations of the proposed results and highlight the influence of delays.}
}
@article{LU2023786,
title = {Analysis on the inherent noise tolerance of feedforward network and one noise-resilient structure},
journal = {Neural Networks},
volume = {165},
pages = {786-798},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003234},
author = {Wenhao Lu and Zhengyuan Zhang and Feng Qin and Wenwen Zhang and Yuncheng Lu and Yue Liu and Yuanjin Zheng},
keywords = {Feedforward neural network, Noise tolerance, Mean square error, Noise-resilient architecture},
abstract = {In the past few decades, feedforward neural networks have gained much attraction in their hardware implementations. However, when we realize a neural network in analog circuits, the circuit-based model is sensitive to hardware nonidealities. The nonidealities, such as random offset voltage drifts and thermal noise, may lead to variation in hidden neurons and further affect neural behaviors. This paper considers that time-varying noise exists at the input of hidden neurons, with zero-mean Gaussian distribution. First, we derive lower and upper bounds on the mean square error loss to estimate the inherent noise tolerance of a noise-free trained feedforward network. Then, the lower bound is extended for any non-Gaussian noise cases based on the Gaussian mixture model concept. The upper bound is generalized for any non-zero-mean noise case. As the noise could degrade the neural performance, a new network architecture is designed to suppress the noise effect. This noise-resilient design does not require any training process. We also discuss its limitation and give a closed-form expression to describe the noise tolerance when the limitation is exceeded.}
}
@article{REN2023487,
title = {Reconstructing controllable faces from brain activity with hierarchical multiview representations},
journal = {Neural Networks},
volume = {166},
pages = {487-500},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300374X},
author = {Ziqi Ren and Jie Li and Xuetong Xue and Xin Li and Fan Yang and Zhicheng Jiao and Xinbo Gao},
keywords = {Neural decoding, fMRI, Face reconstruction, Hierarchical multiview representations, Feature disentanglement, StyleGAN},
abstract = {Reconstructing visual experience from brain responses measured by functional magnetic resonance imaging (fMRI) is a challenging yet important research topic in brain decoding, especially it has proved more difficult to decode visually similar stimuli, such as faces. Although face attributes are known as the key to face recognition, most existing methods generally ignore how to decode facial attributes more precisely in perceived face reconstruction, which often leads to indistinguishable reconstructed faces. To solve this problem, we propose a novel neural decoding framework called VSPnet (voxel2style2pixel) by establishing hierarchical encoding and decoding networks with disentangled latent representations as media, so that to recover visual stimuli more elaborately. And we design a hierarchical visual encoder (named HVE) to pre-extract features containing both high-level semantic knowledge and low-level visual details from stimuli. The proposed VSPnet consists of two networks: Multi-branch cognitive encoder and style-based image generator. The encoder network is constructed by multiple linear regression branches to map brain signals to the latent space provided by the pre-extracted visual features and obtain representations containing hierarchical information consistent to the corresponding stimuli. We make the generator network inspired by StyleGAN to untangle the complexity of fMRI representations and generate images. And the HVE network is composed of a standard feature pyramid over a ResNet backbone. Extensive experimental results on the latest public datasets have demonstrated the reconstruction accuracy of our proposed method outperforms the state-of-the-art approaches and the identifiability of different reconstructed faces has been greatly improved. In particular, we achieve feature editing for several facial attributes in fMRI domain based on the multiview (i.e., visual stimuli and evoked fMRI) latent representations.}
}
@article{CHANG202322,
title = {A look into feedback neural computation upon collision selectivity},
journal = {Neural Networks},
volume = {166},
pages = {22-37},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.039},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003519},
author = {Zefang Chang and Qinbing Fu and Hao Chen and Haiyang Li and Jigen Peng},
keywords = {Bio-inspired, Collision selectivity, LGMD, Feedback neural computation, ON/OFF channels},
abstract = {Physiological studies have shown that a group of locust’s lobula giant movement detectors (LGMDs) has a diversity of collision selectivity to approaching objects, relatively darker or brighter than their backgrounds in cluttered environments. Such diversity of collision selectivity can serve locusts to escape from attack by natural enemies, and migrate in swarm free of collision. For computational studies, endeavours have been made to realize the diverse selectivity which, however, is still one of the most challenging tasks especially in complex and dynamic real world scenarios. The existing models are mainly formulated as multi-layered neural networks with merely feed-forward information processing, and do not take into account the effect of re-entrant signals in feedback loop, which is an essential regulatory loop for motion perception, yet never been explored in looming perception. In this paper, we inaugurate feedback neural computation for constructing a new LGMD-based model, named F-LGMD to look into the efficacy upon implementing different collision selectivity. Accordingly, the proposed neural network model features both feed-forward processing and feedback loop. The feedback control propagates output signals of parallel ON/OFF channels back into their starting neurons, thus makes part of the feed-forward neural network, i.e. the ON/OFF channels and the feedback loop form an iterative cycle system. Moreover, the feedback control is instantaneous, which leads to the existence of a fixed point whereby the fixed point theorem is applied to rigorously derive valid range of feedback coefficients. To verify the effectiveness of the proposed method, we conduct systematic experiments covering synthetic and natural collision datasets, and also online robotic tests. The experimental results show that the F-LGMD, with a unified network, can fulfil the diverse collision selectivity revealed in physiology, which not only reduces considerably the handcrafted parameters compared to previous studies, but also offers a both efficient and robust scheme for collision perception through feedback neural computation.}
}
@article{ZHANG2023183,
title = {MI-DAGSC: A domain adaptation approach incorporating comprehensive information from MI-EEG signals},
journal = {Neural Networks},
volume = {167},
pages = {183-198},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004276},
author = {Dongxue Zhang and Huiying Li and Jingmeng Xie and Dajun Li},
keywords = {Motor imagery (MI), Domain adaptation (DA), Graph convolutional networks (GCNs), Electroencephalography (EEG), Brain–computer interface (BCI)},
abstract = {Non-stationarity of EEG signals leads to high variability between subjects, making it challenging to directly use data from other subjects (source domain) for the classifier in the current subject (target domain). In this study, we propose MI-DAGSC to address domain adaptation challenges in EEG-based motor imagery (MI) decoding. By combining domain-level information, class-level information, and inter-sample structure information, our model effectively aligns the feature distributions of source and target domains. This work is an extension of our previous domain adaptation work MI-DABAN (Li et al., 2023). Based on MI-DABAN, MI-DAGSC designs Sample-Feature Blocks (SFBs) and Graph Convolution Blocks (GCBs) to focus on intra-sample and inter-sample information. The synergistic integration of SFBs and GCBs enable the model to capture comprehensive information and understand the relationship between samples, thus improving representation learning. Furthermore, we introduce a triplet loss to enhance the alignment and compactness of feature representations. Extensive experiments on real EEG datasets demonstrate the effectiveness of MI-DAGSC, confirming that our method makes a valuable contribution to the MI-EEG decoding. Moreover, it holds great potential for various applications in brain–computer interface systems and neuroscience research. And the code of the proposed architecture in this study is available under https://github.com/zhangdx21/MI-DAGSC.}
}
@article{LONG2023459,
title = {Synchronization of coupled switched neural networks subject to hybrid stochastic disturbances},
journal = {Neural Networks},
volume = {166},
pages = {459-470},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.045},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004033},
author = {Han Long and Jingxuan Ci and Zhenyuan Guo and Shiping Wen and Tingwen Huang},
keywords = {Synchronization, Switched neural networks, Stochastic disturbances, Stochastic impulses, State-dependent switching},
abstract = {In this paper, the theoretical analysis on exponential synchronization of a class of coupled switched neural networks suffering from stochastic disturbances and impulses is presented. A control law is developed and two sets of sufficient conditions are derived for the synchronization of coupled switched neural networks. First, for desynchronizing stochastic impulses, the synchronization of coupled switched neural networks is analyzed by Lyapunov function method, the comparison principle and a impulsive delay differential inequality. Then, for general stochastic impulses, by partitioning impulse interval and using the convex combination technique, a set of sufficient condition on the basis of linear matrix inequalities (LMIs) is derived for the synchronization of coupled switched neural networks. Eventually, two numerical examples and a practical application are elaborated to illustrate the effectiveness of the theoretical results.}
}
@article{CAI2023705,
title = {SiamDF: Tracking training data-free siamese tracker},
journal = {Neural Networks},
volume = {165},
pages = {705-720},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003222},
author = {Huayue Cai and Long Lan and Jing Zhang and Xiang Zhang and Zhigang Luo},
keywords = {Siamese tracking, Tracking training data-free, Pre-training, Scale estimation, Sharing computation},
abstract = {Much progress has been made in siamese tracking, primarily benefiting from increasing huge training data. However, very little attention has been really paid to the role of huge training data in learning an effective siamese tracker. In this study, we undertake an in-depth analysis of this issue from a novel optimization perspective, and observe that training data is particularly adept at background suppression, thereby refining target representation. Inspired by this insight, we present a data-free siamese tracking algorithm named SiamDF, which requires only a pre-trained backbone and no further fine-tuning on additional training data. Particularly, to suppress background distractors, we separately improve two branches of siamese tracking by retaining the pure target region as target input with the removal of template background, and by exploring an efficient inverse transformation to maintain the constant aspect ratio of target state in search region. Besides, we further promote the center displacement prediction of the entire backbone by eliminating its spatial stride deviations caused by convolution-like quantification operations. Our experimental results on several popular benchmarks demonstrate that SiamDF, free from both offline fine-tuning and online update, achieves impressive performance compared to well-established unsupervised and supervised tracking methods.}
}
@article{SHUKLA2023127,
title = {Trustworthy Medical Image Segmentation with improved performance for in-distribution samples},
journal = {Neural Networks},
volume = {166},
pages = {127-136},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.047},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003581},
author = {Sneha Shukla and Lokendra Birla and Anup Kumar Gupta and Puneet Gupta},
keywords = {Confidence measure, Deep Learning, In-Distribution samples, Medical Image Segmentation, Trustworthiness},
abstract = {Despite the enormous achievements of Deep Learning (DL) based models, their non-transparent nature led to restricted applicability and distrusted predictions. Such predictions emerge from erroneous In-Distribution (ID) and Out-Of-Distribution (OOD) samples, which results in disastrous effects in the medical domain, specifically in Medical Image Segmentation (MIS). To mitigate such effects, several existing works accomplish OOD sample detection; however, the trustworthiness issues from ID samples still require thorough investigation. To this end, a novel method TrustMIS (Trustworthy Medical Image Segmentation) is proposed in this paper, which provides the trustworthiness and improved performance of ID samples for DL-based MIS models. TrustMIS works in three folds: IT (Investigating Trustworthiness), INT (Improving Non-Trustworthy prediction) and CSO (Classifier Switching Operation). Initially, the IT method investigates the trustworthiness of MIS by leveraging similar characteristics and consistency analysis of input and its variants. Subsequently, the INT method employs the IT method to improve the performance of the MIS model. It leverages the observation that an input providing erroneous segmentation can provide correct segmentation with rotated input. Eventually, the CSO method employs the INT method to scrutinise several MIS models and selects the model that delivers the most trustworthy prediction. The experiments conducted on publicly available datasets using well-known MIS models reveal that TrustMIS has successfully provided a trustworthiness measure, outperformed the existing methods, and improved the performance of state-of-the-art MIS models. Our implementation is available at https://github.com/SnehaShukla937/TrustMIS.}
}
@article{ANDEOL2023233,
title = {Learning domain invariant representations by joint Wasserstein distance minimization},
journal = {Neural Networks},
volume = {167},
pages = {233-243},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003866},
author = {Léo Andéol and Yusei Kawakami and Yuichiro Wada and Takafumi Kanamori and Klaus-Robert Müller and Grégoire Montavon},
keywords = {Domain invariance, Subpopulation shift, Joint distribution matching, Wasserstein distance, Neural networks, Supervised learning},
abstract = {Domain shifts in the training data are common in practical applications of machine learning; they occur for instance when the data is coming from different sources. Ideally, a ML model should work well independently of these shifts, for example, by learning a domain-invariant representation. However, common ML losses do not give strong guarantees on how consistently the ML model performs for different domains, in particular, whether the model performs well on a domain at the expense of its performance on another domain. In this paper, we build new theoretical foundations for this problem, by contributing a set of mathematical relations between classical losses for supervised ML and the Wasserstein distance in joint space (i.e. representation and output space). We show that classification or regression losses, when combined with a GAN-type discriminator between domains, form an upper-bound to the true Wasserstein distance between domains. This implies a more invariant representation and also more stable prediction performance across domains. Theoretical results are corroborated empirically on several image datasets. Our proposed approach systematically produces the highest minimum classification accuracy across domains, and the most invariant representation.}
}
@article{WANG2023755,
title = {A novel framework of prescribed time/fixed time/finite time stochastic synchronization control of neural networks and its application in image encryption},
journal = {Neural Networks},
volume = {165},
pages = {755-773},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003349},
author = {Xin Wang and Jinde Cao and Xianghui Zhou and Ying Liu and Yaoxi Yan and Jiangtao Wang},
keywords = {Framework, Control gain, PAT/FXT/FNT stochastic synchronization control, SMS-QVNNs, Image encryption/decryption},
abstract = {In this paper, we investigate a novel framework for achieving prescribed-time (PAT), fixed-time (FXT) and finite-time (FNT) stochastic synchronization control of semi-Markov switching quaternion-valued neural networks (SMS-QVNNs), where the setting time (ST) of PAT/FXT/FNT stochastic synchronization control is effectively preassigned beforehand and estimated. Different from the existing frameworks of PAT/FXT/FNT control and PAT/FXT control (where PAT control is deeply dependent on FXT control, meaning that if the FXT control task is removed, it is impossible to implement the PAT control task), and different from the existing frameworks of PAT control (where a time-varying control gain such as μ(t)=T/(T−t) with t∈[0,T) was employed, leading to an unbounded control gain as t→T− from the initial time to prescribed time T), the investigated framework is only built on a control strategy, which can accomplish its three control tasks (PAT/FXT/FNT control), and the control gains are bounded even though time t tends to the prescribed time T. Four numerical examples and an application of image encryption/decryption are given to illustrate the feasibility of our proposed framework.}
}
@article{XU202311,
title = {Adaptive event-triggered synchronization of neural networks under stochastic cyber-attacks with application to Chua’s circuit},
journal = {Neural Networks},
volume = {166},
pages = {11-21},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003623},
author = {Yao Xu and Chunyu Yang and Linna Zhou and Lei Ma and Song Zhu},
keywords = {Synchronization control, Neural networks, Adaptive event-triggered scheme, Stochastic cyber-attacks, Chua’s circuit},
abstract = {This paper focuses on the synchronization control problem for neural networks (NNs) subject to stochastic cyber-attacks. Firstly, an adaptive event-triggered scheme (AETS) is adopted to improve the utilization rate of network resources, and an output feedback controller is constructed for improving the performance of the system subject to the conventional deception attack and accumulated dynamic cyber-attack. Secondly, the synchronization problem of master–slave NNs is transformed into the stability analysis problem of the synchronization error system. Thirdly, by constructing a customized Lyapunov–Krasovskii functional (LKF), the adaptive event-triggered output feedback controller is designed to ensure the synchronization error system is asymptotically stable with a given H∞ performance index. Lastly, in the simulation part, two examples, including Chua’s circuit, illustrate the feasibility and universality of the related technologies in this paper.}
}
@article{LIU2023625,
title = {Dual Distillation Discriminator Networks for Domain Adaptive Few-Shot Learning},
journal = {Neural Networks},
volume = {165},
pages = {625-633},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003106},
author = {Xiyao Liu and Zhong Ji and Yanwei Pang and Zhi Han},
keywords = {Few-shot learning, Domain adaption, Knowledge distillation, Adversarial training},
abstract = {Domain Adaptive Few-Shot Learning (DA-FSL) aims at accomplishing few-shot classification tasks on a novel domain with the aid of a large number of source-style samples and several target-style samples. It is essential for DA-FSL to transfer task knowledge from the source domain to the target domain and overcome the asymmetry amount of labeled data in both domains. To this end, we propose Dual Distillation Discriminator Networks (D3Net) from the perspective of the lack of labeled target domain style samples in DA-FSL. Specifically, we employ the idea of distillation discrimination to avoid the over-fitting caused by the unequal number of samples in the target and source domains, which trains the student discriminator by the soft labels from the teacher discriminator. Meanwhile, we design the task propagation stage and the mixed domain stage respectively from the level of feature space and instances to generate more target-style samples, which apply the task distributions and the sample diversity of the source domain to enhance the target domain. Our D3Net realizes the distribution alignment between the source domain and the target domain and constraints the FSL task distribution by prototype distributions on the mixed domain. Extensive experiments on three DA-FSL benchmark datasets, i.e., mini-ImageNet, tiered-ImageNet, and DomainNet, demonstrate that our D3Net achieves competitive performance.}
}
@article{ZHANG2023199,
title = {ShuffleTrans: Patch-wise weight shuffle for transparent object segmentation},
journal = {Neural Networks},
volume = {167},
pages = {199-212},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004318},
author = {Boxiang Zhang and Zunran Wang and Yonggen Ling and Yuanyuan Guan and Shenghao Zhang and Wenhui Li and Lei Wei and Chunxu Zhang},
keywords = {Transparent object segmentation, Semantic segmentation},
abstract = {Transparent objects widely exist in the world. The task of transparent object segmentation is challenging as the object lacks its own texture. The cue of shape information therefore gets more critical. Most existing methods, however, rely on the mechanism of simple convolution, which is good at local cues and performs weakly on global cues like shape. To solve this problem, an operation named Patch-wise Weight Shuffle is proposed to bring in the global context cue by being combined with the dynamic convolution. A network ShuffleTrans that recognizes shape better is then designed based on this operation. Besides, fitter for this task, two auxiliary modules are presented in ShuffleTrans: a Boundary and Direction Refinement Module which collects two additional information, and a Channel Attention Enhancement Module that assists the above operation. Experiments on four texture-less object segmentation datasets and two normal datasets verify the effectiveness and generality of the method. Especially, the ShuffleTrans achieved 74.93% mIoU on the Trans10k v2 test set, which is more accurate than existing methods.}
}
@article{MOOSAEI2023471,
title = {Sparse solution of least-squares twin multi-class support vector machine using ℓ0 and ℓp-norm for classification and feature selection},
journal = {Neural Networks},
volume = {166},
pages = {471-486},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.039},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003982},
author = {Hossein Moosaei and Milan Hladík},
keywords = {Multi-class classification, Twin k-class support vector classification, Least-squares, Cardinality-constrained optimization problem, -norm, Feature selection},
abstract = {In the realm of multi-class classification, the twin K-class support vector classification (Twin-KSVC) generates ternary outputs {−1,0,+1} by evaluating all training data in a “1-versus-1-versus-rest” structure. Recently, inspired by the least-squares version of Twin-KSVC and Twin-KSVC, a new multi-class classifier called improvements on least-squares twin multi-class classification support vector machine (ILSTKSVC) has been proposed. In this method, the concept of structural risk minimization is achieved by incorporating a regularization term in addition to the minimization of empirical risk. Twin-KSVC and its improvements have an influence on classification accuracy. Another aspect influencing classification accuracy is feature selection, which is a critical stage in machine learning, especially when working with high-dimensional datasets. However, most prior studies have not addressed this crucial aspect. In this study, motivated by ILSTKSVC and the cardinality-constrained optimization problem, we propose ℓp-norm least-squares twin multi-class support vector machine (PLSTKSVC) with 0<p<1 to perform classification and feature selection at the same time. The technique employed to solve the optimization problems associated with PLSTKSVC is user-friendly, as it involves solving systems of linear equations to obtain an approximate solution for the proposed model. Under certain assumptions, we investigate the properties of the optimum solutions to the related optimization problems. Several real-world datasets were tested using the suggested method. According to the results of our experiments, the proposed method outperforms all current strategies in most datasets in terms of classification accuracy while also reducing the number of features.}
}
@article{ZHOU2023884,
title = {Safe control of logical control networks with random impulses},
journal = {Neural Networks},
volume = {165},
pages = {884-895},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003465},
author = {Rongpei Zhou and Yuqian Guo and Yuhao Wang and Zejun Sun and Xinzhi Liu},
keywords = {Logical control networks, State-dependent random impulses, Safe control problems, Semi-tensor product of matrices},
abstract = {Under the framework of a hybrid-index model, this paper investigates safe control problems of state-dependent random impulsive logical control networks (RILCNs) on both finite and infinite horizons, respectively. By using the ξ-domain method and the constructed transition probability matrix, the necessary and sufficient conditions for the solvability of safe control problems have been established. Further, based on the technique of state-space partition, two algorithms are proposed to design feedback controllers such that RILCNs can achieve the goal of safe control. Finally, two examples are shared to demonstrate the main results.}
}
@article{YU202338,
title = {Multi-view graph representation with similarity diffusion for general zero-shot learning},
journal = {Neural Networks},
volume = {166},
pages = {38-50},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.045},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300357X},
author = {Beibei Yu and Cheng Xie and Peng Tang and Haoran Duan},
keywords = {Zero-shot learning, Knowledge graph, Graph representation, Knowledge-based model, Feature diffusion},
abstract = {Zero-shot learning (ZSL) aims to predict unseen classes without using samples of these classes in model training. The ZSL has been widely used in many knowledge-based models and applications to predict various parameters, including categories, subjects, and anomalies, in different domains. Nonetheless, most existing ZSL methods require the pre-defined semantics or attributes of particular data environments. Therefore, these methods are difficult to be applied to general data environments, such as ImageNet and other real-world datasets and applications. Recent research has tried to use open knowledge to enhance the ZSL methods to adapt it to an open data environment. However, the performance of these methods is relatively low, namely the accuracy is normally below 10%, which is due to the inadequate semantics that can be used from open knowledge. Moreover, the latest methods suffer from a significant ”semantic gap” problem between the generated features of unseen classes and the real features of seen classes. To this end, this paper proposes a multi-view graph representation with a similarity diffusion model, applying the ZSL tasks to general data environments. This model applies a multi-view graph to enhance the semantics fully and proposes an innovative diffusion method to augment the graph representation. In addition, a feature diffusion method is proposed to augment the multi-view graph representation and bridge the semantic gap to realize zero-shot predicting. The results of numerous experiments in general data environments and on benchmark datasets show that the proposed method can achieve new state-of-the-art results in the field of general zero-shot learning. Furthermore, seven ablation studies analyze the effects of the settings and different modules of the proposed method on its performance in detail and prove the effectiveness of each module.}
}
@article{HAN202310,
title = {Spatial oblivion channel attention targeting intra-class diversity feature learning},
journal = {Neural Networks},
volume = {167},
pages = {10-21},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003908},
author = {Honggui Han and Qiyu Zhang and Fangyu Li and Yongping Du},
keywords = {Intra-class, Diversity feature, Convolutional neural network, Spatial regularization, Attention},
abstract = {Convolutional neural networks (CNNs) have successfully driven many visual recognition tasks including image classification. However, when dealing with classification tasks with intra-class sample style diversity, the network tends to be disturbed by more diverse features, resulting in limited feature learning. In this article, a spatial oblivion channel attention (SOCA) for intra-class diversity feature learning is proposed. Specifically, SOCA performs spatial structure oblivion in a progressive regularization for each channel after convolution, so that the network is not restricted to a limited feature learning, and pays attention to more regionally detailed features. Further, SOCA reassigns channel weights in the progressively oblivious feature space from top to bottom along the channel direction, to ensure the network learns more image details in an orderly manner while not falling into feature redundancy. Experiments are conducted on the standard classification dataset CIFAR-10/100 and two garbage datasets with intra-class diverse styles. SOCA improves SqueezeNet, MobileNet, BN-VGG-19, Inception and ResNet-50 in classification accuracy by 1.31%, 1.18%, 1.57%, 2.09% and 2.27% on average, respectively. The feasibility and effectiveness of intra-class diversity feature learning in SOCA-enhanced networks are verified. Besides, the class activation map shows that more local detail feature regions are activated by adding the SOCA module, which also demonstrates the interpretability of the method for intra-class diversity feature learning.}
}
@article{JU2023971,
title = {Neurodynamic optimization approaches with finite/fixed-time convergence for absolute value equations},
journal = {Neural Networks},
volume = {165},
pages = {971-981},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.041},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003507},
author = {Xingxing Ju and Xinsong Yang and Gang Feng and Hangjun Che},
keywords = {Neurodynamic approaches, Absolute value equations, Finite-time convergence, Fixed-time convergence, Robustness},
abstract = {This paper proposes three novel accelerated inverse-free neurodynamic approaches to solve absolute value equations (AVEs). The first two are finite-time converging approaches and the third one is a fixed-time converging approach. It is shown that the proposed first two neurodynamic approaches converge to the solution of the concerned AVEs in a finite-time while, under some mild conditions, the third one converges to the solution in a fixed-time. It is also shown that the settling time for the proposed fixed-time converging approach has an uniform upper bound for all initial conditions, while the settling times for the proposed finite-time converging approaches are dependent on initial conditions. The proposed neurodynamic approaches have the advantage that they are all robust against bounded vanishing perturbations. The theoretical results are validated by means of a numerical example and an application in boundary value problems.}
}
@article{RYOO2023141,
title = {Event fusion photometric stereo network},
journal = {Neural Networks},
volume = {167},
pages = {141-158},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300429X},
author = {Wonjeong Ryoo and Giljoo Nam and Jae-Sang Hyun and Sangpil Kim},
keywords = {Optical profilometry, Event camera, 3D reconstruction, Photometric stereo, Deep learning},
abstract = {Photometric stereo methods typically rely on RGB cameras and are usually performed in a dark room to avoid ambient illumination. Ambient illumination poses a great challenge in photometric stereo due to the restricted dynamic range of the RGB cameras. To address this limitation, we present a novel method, namely Event Fusion Photometric Stereo Network (EFPS-Net), which estimates the surface normals of an object in an ambient light environment by utilizing a deep fusion of RGB and event cameras. The high dynamic range of event cameras provides a broader perspective of light representations that RGB cameras cannot provide. Specifically, we propose an event interpolation method to obtain ample light information, which enables precise estimation of the surface normals of an object. By using RGB-event fused observation maps, our EFPS-Net outperforms previous state-of-the-art methods that depend only on RGB frames, resulting in a 7.94% reduction in mean average error. In addition, we curate a novel photometric stereo dataset by capturing objects with RGB and event cameras under numerous ambient light environments.}
}
@article{VLASOV2023512,
title = {Memristor-based spiking neural network with online reinforcement learning},
journal = {Neural Networks},
volume = {166},
pages = {512-523},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003891},
author = {Danila Vlasov and Anton Minnekhanov and Roman Rybka and Yury Davydov and Alexander Sboev and Alexey Serenko and Alexander Ilyasov and Vyacheslav Demin},
keywords = {Memristor, Resistive switching, Conductive filament, STDP, Reinforcement learning, Spiking neural network},
abstract = {Neural networks implemented in memristor-based hardware can provide fast and efficient in-memory computation, but traditional learning methods such as error back-propagation are hardly feasible in it. Spiking neural networks (SNNs) are highly promising in this regard, as their weights can be changed locally in a self-organized manner without the demand for high-precision changes calculated with the use of information almost from the entire network. This problem is rather relevant for solving control tasks with neural-network reinforcement learning methods, as those are highly sensitive to any source of stochasticity in a model initialization, training, or decision-making procedure. This paper presents an online reinforcement learning algorithm in which the change of connection weights is carried out after processing each environment state during interaction-with-environment data generation. Another novel feature of the algorithm is that it is applied to SNNs with memristor-based STDP-like learning rules. The plasticity functions are obtained from real memristors based on poly-p-xylylene and CoFeB-LiNbO3 nanocomposite, which were experimentally assembled and analyzed. The SNN is comprised of leaky integrate-and-fire neurons. Environmental states are encoded by the timings of input spikes, and the control action is decoded by the first spike. The proposed learning algorithm solves the Cart-Pole benchmark task successfully. This result could be the first step towards implementing a real-time agent learning procedure in a continuous-time environment that can be run on neuromorphic systems with memristive synapses.}
}
@article{MU2023987,
title = {Attribute-driven streaming edge partitioning with reconciliations for distributed graph neural network training},
journal = {Neural Networks},
volume = {165},
pages = {987-998},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003374},
author = {Zongshen Mu and Siliang Tang and Yueting Zhuang and Dianhai Yu},
keywords = {Distributed graph neural network training, Attribute-driven streaming edge partitioning, Reconciliations},
abstract = {Current distributed graph training frameworks evenly partition a large graph into small chunks to suit distributed storage, leverage a uniform interface to access neighbors, and train graph neural networks in a cluster of machines to update weights. Nevertheless, they consider a separate design of storage and training, resulting in huge communication costs for retrieving neighborhoods. During the storage phase, traditional heuristic graph partitioning not only suffers from memory overhead because of loading the full graph into the memory but also damages semantically related structures because of its neglecting meaningful node attributes. What is more, in the weight-update phase, directly averaging synchronization is difficult to tackle with heterogeneous local models where each machine’s data are loaded from different subgraphs, resulting in slow convergence. To solve these problems, we propose a novel distributed graph training approach, attribute-driven streaming edge partitioning with reconciliations (ASEPR), where the local model loads only the subgraph stored on its own machine to make fewer communications. ASEPR firstly clusters nodes with similar attributes in the same partition to maintain semantic structure and keep multihop neighbor locality. Then streaming partitioning combined with attribute clustering is applied to subgraph assignment to alleviate memory overhead. After local graph neural network training on distributed machines, we deploy cross-layer reconciliation strategies for heterogeneous local models to improve the averaged global model by knowledge distillation and contrastive learning. Extensive experiments conducted on four large graph datasets on node classification and link prediction tasks show that our model outperforms DistDGL, with fewer resource requirements and up to quadruple the convergence speed.}
}
@article{ZOU2023692,
title = {Visual information processing through the interplay between fine and coarse signal pathways},
journal = {Neural Networks},
volume = {166},
pages = {692-703},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.048},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004069},
author = {Xiaolong Zou and Zilong Ji and Tianqiu Zhang and Tiejun Huang and Si Wu},
keywords = {Visual information processing, Two-pathway model, Convolution neural network, Imitation learning, Backward masking},
abstract = {Object recognition is often viewed as a feedforward, bottom-up process in machine learning, but in real neural systems, object recognition is a complicated process which involves the interplay between two signal pathways. One is the parvocellular pathway (P-pathway), which is slow and extracts fine features of objects; the other is the magnocellular pathway (M-pathway), which is fast and extracts coarse features of objects. It has been suggested that the interplay between the two pathways endows the neural system with the capacity of processing visual information rapidly, adaptively, and robustly. However, the underlying computational mechanism remains largely unknown. In this study, we build a two-pathway model to elucidate the computational properties associated with the interactions between two visual pathways. Specifically, we model two visual pathways using two convolution neural networks: one mimics the P-pathway, referred to as FineNet, which is deep, has small-size kernels, and receives detailed visual inputs; the other mimics the M-pathway, referred to as CoarseNet, which is shallow, has large-size kernels, and receives blurred visual inputs. We show that CoarseNet can learn from FineNet through imitation to improve its performance, FineNet can benefit from the feedback of CoarseNet to improve its robustness to noise; and the two pathways interact with each other to achieve rough-to-fine information processing. Using visual backward masking as an example, we further demonstrate that our model can explain visual cognitive behaviors that involve the interplay between two pathways. We hope that this study gives us insight into understanding the interaction principles between two visual pathways.}
}
@article{WEI2023168,
title = {Finite/fixed-time synchronization of inertial memristive neural networks by interval matrix method for secure communication},
journal = {Neural Networks},
volume = {167},
pages = {168-182},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004343},
author = {Fei Wei and Guici Chen and Zhigang Zeng and Nallappan Gunasekaran},
keywords = {Finite/fixed-time synchronization, Delayed inertial memristive neural networks (DIMNNs), Unified control framework, Settling time functions, Image encryption},
abstract = {This paper investigates the finite/fixed-time synchronization problem of delayed inertial memristive neural networks (DIMNNs) using interval matrix-based methods within a unified control framework. By employing set-valued mapping and differential inclusion theory, two distinct methods are applied to handle the switching behavior of memristor parameters: the maximum absolute value method and the interval matrix method. Based on these different approaches, two control strategies are proposed to select appropriate control parameters, enabling the system to achieve finite and fixed-time synchronization, respectively. Additionally, the resulting theoretical criteria differ based on the chosen control strategy, with one expressed in algebraic form and the other in the form of linear matrix inequalities (LMIs). Numerical simulations demonstrate that the interval matrix method outperforms the maximum absolute value method in terms of handling memristor parameter switching, achieving faster finite/fixed-time synchronization. Furthermore, the theoretical results are extended to the field of image encryption, where the response system is utilized for decryption and expanding the keyspace.}
}
@article{YUN2023137,
title = {Low-rank discrete multi-view spectral clustering},
journal = {Neural Networks},
volume = {166},
pages = {137-147},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.038},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003490},
author = {Yu Yun and Jing Li and Quanxue Gao and Ming Yang and Xinbo Gao},
keywords = {Discrete label learning, Spectral clustering, Low-rank},
abstract = {Spectral clustering has attracted intensive attention in multimedia applications due to its good performance on arbitrary shaped clusters and well-defined mathematical framework. However, most existing multi-view spectral clustering methods still have the following demerits: (1) They ignore useful complementary information embedded in indicator matrices of different views. (2) The conventional post-processing methods based on the relax and discrete strategy inevitably result in the sub-optimal discrete solution. To tackle the aforementioned drawbacks, we propose a low-rank discrete multi-view spectral clustering model. Drawing inspiration from the fact that the difference between indicator matrices of different views provides useful complementary information for clustering, our model exploits the complementary information embedded in indicator matrices with tensor Schatten p-norm constraint. Further, we integrate low-rank tensor learning and discrete label recovering into a uniform framework, which avoids the uncertainty of the relaxed and discrete strategy. Extensive experiments on benchmark datasets have demonstrated the effectiveness and superiority of the proposed method.}
}
@article{SUZUKI202350,
title = {Distorted image classification using neural activation pattern matching loss},
journal = {Neural Networks},
volume = {167},
pages = {50-64},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.050},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004185},
author = {Satoshi Suzuki and Shoichiro Takeda and Ryuichi Tanida and Yukihiro Bandoh and Hayaru Shouno},
keywords = {Distorted image classification, Neural activation pattern matching loss, Deep neural network},
abstract = {In image classification, a deep neural network (DNN) that is trained on undistorted images constitutes an effective decision boundary. Unfortunately, this boundary does not support distorted images, such as noisy or blurry ones, leading to accuracy drop-off. As a simple approach for classifying distorted images as well as undistorted ones, previous methods have optimized the trained DNN again on both kinds of images. However, in these methods, the decision boundary may become overly complicated during optimization because there is no regularization of the decision boundary. Consequently, this decision boundary limits efficient optimization. In this paper, we study a simple yet effective decision boundary for distorted image classification through the use of a novel loss, called a “neural activation pattern matching (NAPM) loss”. The NAPM loss is based on recent findings that the decision boundary is a piecewise linear function, where each linear segment is constructed from a neural activation pattern in the DNN when an image is fed to it. The NAPM loss extracts the neural activation patterns when the distorted image and its undistorted version are fed to the DNN and then matches them with each other via the sigmoid cross-entropy. Therefore, it constrains the DNN to classify the distorted image and its undistorted version by the same linear segment. As a result, our loss accelerates efficient optimization by preventing the decision boundary from becoming overly complicated. Our experiments demonstrate that our loss increases the accuracy of the previous methods in all conditions evaluated.}
}
@article{WEI2023555,
title = {Class-imbalanced complementary-label learning via weighted loss},
journal = {Neural Networks},
volume = {166},
pages = {555-565},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300388X},
author = {Meng Wei and Yong Zhou and Zhongnian Li and Xinzheng Xu},
keywords = {Weakly supervised learning, Complementary labels, Class imbalanced, Multi-class classification},
abstract = {Complementary-label learning (CLL) is widely used in weakly supervised classification, but it faces a significant challenge in real-world datasets when confronted with class-imbalanced training samples. In such scenarios, the number of samples in one class is considerably lower than in other classes, which consequently leads to a decline in the accuracy of predictions. Unfortunately, existing CLL approaches have not investigate this problem. To alleviate this challenge, we propose a novel problem setting that enables learning from class-imbalanced complementary labels for multi-class classification. To tackle this problem, we propose a novel CLL approach called Weighted Complementary-Label Learning (WCLL). The proposed method models a weighted empirical risk minimization loss by utilizing the class-imbalanced complementary labels, which is also applicable to multi-class imbalanced training samples. Furthermore, we derive an estimation error bound to provide theoretical assurance. To evaluate our approach, we conduct extensive experiments on several widely-used benchmark datasets and a real-world dataset, and compare our method with existing state-of-the-art methods. The proposed approach shows significant improvement in these datasets, even in the case of multiple class-imbalanced scenarios. Notably, the proposed method not only utilizes complementary labels to train a classifier but also solves the problem of class imbalance.}
}
@article{LI2023838,
title = {Measuring multivariate phase synchronization with symbolization and permutation},
journal = {Neural Networks},
volume = {167},
pages = {838-846},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003659},
author = {Zhaohui Li and Xinyan Wang and Yanyu Xing and Xi Zhang and Tao Yu and Xiaoli Li},
keywords = {Multivariate neural signal, Global phase synchronization, Symbolization, Permutation, Seizure classification},
abstract = {Phase synchronization is an important mechanism for the information processing of neurons in the brain. Most of the current phase synchronization measures are bivariate and focus on the synchronization between pairs of time series. However, these methods do not provide a full picture of global interactions in neural systems. Considering the prevalence and importance of multivariate neural signal analysis, there is an urgent need to quantify global phase synchronization (GPS) in neural networks. Therefore, we propose a new measure named symbolic phase difference and permutation entropy (SPDPE), which symbolizes the phase difference in multivariate neural signals and estimates GPS according to the permutation patterns of the symbolic sequences. The performance of SPDPE was evaluated using simulated data generated by Kuramoto and Rössler model. The results demonstrate that SPDPE exhibits low sensitivity to data length and outperforms existing methods in accurately characterizing GPS and effectively resisting noise. Moreover, to validate the method with real data, it was applied to classify seizures and non-seizures by calculating the GPS of stereoelectroencephalography (SEEG) data recorded from the onset zones of ten epilepsy patients. We believe that SPDPE will improve the estimation of GPS in many applications, such as EEG-based brain–computer interfaces, brain modeling, and simultaneous EEG-fMRI analysis.}
}
@article{LU2023524,
title = {Adaptive pinning cluster synchronization of a stochastic reaction–diffusion complex network},
journal = {Neural Networks},
volume = {166},
pages = {524-540},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003933},
author = {Binglong Lu and Haijun Jiang and Cheng Hu and Abdujelil Abdurahman and Mei Liu},
keywords = {Reaction–diffusion complex network, Stochastic noise, Markovian switching, Cluster synchronization, Adaptive pinning control},
abstract = {This work aims to achieve cluster synchronization of a complex network by some pinning control strategies. Firstly, the network not only is affected by the reaction–diffusion and the directed coupling phenomena, but also is disturbed by the stochastic noise and Markovian switching. Secondly, switched constant gain pinning, centralized and decentralized adaptive pinning are proposed respectively to realize the cluster synchronization of the considered network. In these adaptive pinning controllers, the control gain and coupling strength can been adjusted automatically while only a part of the nodes are controlled. Thirdly, the target state of cluster synchronization is taken as the average state related to the directed topology of all nodes in the same cluster, and does not need to be given separately as an isolated node. Finally, to verify the theoretical results, some simulations of directed coupled reaction–diffusion neural networks with stochastic noise and Markovian switching are given.}
}
@article{WANG2023909,
title = {Graph convolutional network with tree-guided anisotropic message passing},
journal = {Neural Networks},
volume = {165},
pages = {909-924},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003416},
author = {Ruixiang Wang and Yuhu Wang and Chunxia Zhang and Shiming Xiang and Chunhong Pan},
keywords = {Deep learning, Graph convolutional networks, Graph structure learning, Anisotropic message passing},
abstract = {Graph Convolutional Networks (GCNs) with naive message passing mechanisms have limited performance due to the isotropic aggregation strategy. To remedy this drawback, some recent works focus on how to design anisotropic aggregation strategies with tricks on feature mapping or structure mining. However, these models still suffer from the low ability of expressiveness and long-range modeling for the needs of high performance in practice. To this end, this paper proposes a tree-guided anisotropic GCN, which applies an anisotropic aggregation strategy with competitive expressiveness and a large receptive field. Specifically, the anisotropic aggregation is decoupled into two stages. The first stage is to establish the path of the message passing on a tree-like hypergraph consisting of substructures. The second one is to aggregate the messages with constrained intensities by employing an effective gating mechanism. In addition, a novel anisotropic readout mechanism is constructed to generate representative and discriminative graph-level features for downstream tasks. Our model outperforms baseline methods and recent works on several synthetic benchmarks and datasets from different real-world tasks. In addition, extensive ablation studies and theoretical analyses indicate the effectiveness of our proposed method.}
}
@article{GAO202351,
title = {Online dynamic ensemble deep random vector functional link neural network for forecasting},
journal = {Neural Networks},
volume = {166},
pages = {51-69},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.042},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003532},
author = {Ruobin Gao and Ruilin Li and Minghui Hu and P.N. Suganthan and Kum Fai Yuen},
keywords = {Forecasting, Random vector functional link network, Deep learning, Machine learning, Online learning, Continual learning},
abstract = {This paper proposes a three-stage online deep learning model for time series based on the ensemble deep random vector functional link (edRVFL). The edRVFL stacks multiple randomized layers to enhance the single-layer RVFL’s representation ability. Each hidden layer’s representation is utilized for training an output layer, and the ensemble of all output layers forms the edRVFL’s output. However, the original edRVFL is not designed for online learning, and the randomized nature of the features is harmful to extracting meaningful temporal features. In order to address the limitations and extend the edRVFL to an online learning mode, this paper proposes a dynamic edRVFL consisting of three online components, the online decomposition, the online training, and the online dynamic ensemble. First, an online decomposition is utilized as a feature engineering block for the edRVFL. Then, an online learning algorithm is designed to learn the edRVFL. Finally, an online dynamic ensemble method, which can measure the change in the distribution, is proposed for aggregating all layers’ outputs. This paper evaluates and compares the proposed model with state-of-the-art methods on sixteen time series.}
}
@article{TREESATAYAPUN2023541,
title = {Discrete-time robust event-triggered actuator fault-tolerant control based on adaptive networks and reinforcement learning},
journal = {Neural Networks},
volume = {166},
pages = {541-554},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004227},
author = {C. Treesatayapun},
keywords = {Reinforcement learning, Fault tolerant control, Active and passive actuator faults, Discrete-time systems, Fuzzy rules emulated networks},
abstract = {This paper focuses on the topic of fault-tolerant control for discrete-time systems with nonlinear uncertainties and actuator faults. It considers both passive and active faults as part of the analysis and design. The proposed adaptive controller, based on a nonlinear electronic circuit, handles offset-biasing, sensitivity variation, and dead-zone effects. An event-triggered mechanism, utilizing a sliding surface, enhances robustness and reduces data transmission. Adaptive networks called MiFRENs are employed, trained using reinforcement learning. Theoretical analysis guarantees boundedness of internal signals and tracking error. Experimental results validate the scheme, demonstrating required conditions, reduced data transmission, and robust performance. Comparative evaluations confirm its superiority}
}
@article{ZAREIESKIKAND2023296,
title = {Inhibitory stabilized network behaviour in a balanced neural mass model of a cortical column},
journal = {Neural Networks},
volume = {166},
pages = {296-312},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003775},
author = {Parvin {Zarei Eskikand} and Artemio Soto-Breceda and Mark J. Cook and Anthony N. Burkitt and David B. Grayden},
keywords = {Neural mass model, Inhibitory stabilized networks, Paradoxical response, Excitation–inhibition balance},
abstract = {Strong inhibitory recurrent connections can reduce the tendency for a neural network to become unstable. This is known as inhibitory stabilization; networks that are unstable in the absence of strong inhibitory feedback because of their unstable excitatory recurrent connections are known as Inhibition Stabilized Networks (ISNs). One of the characteristics of ISNs is their “paradoxical response”, where perturbing the inhibitory neurons with additional excitatory input results in a decrease in their activity after a temporal delay instead of increasing their activity. Here, we develop a model of populations of neurons across different layers of cortex. Within each layer, there is one population of inhibitory neurons and one population of excitatory neurons. The connectivity weights across different populations in the model are derived from a synaptic physiology database provided by the Allen Institute. The model shows a gradient of excitation–inhibition balance across different layers in the cortex, where superficial layers are more inhibitory dominated compared to deeper layers. To investigate the presence of ISNs across different layers, we measured the membrane potentials of neural populations in the model after perturbing inhibitory populations. The results show that layer 2/3 in the model does not operate in the ISN regime but layers 4 and 5 do operate in the ISN regime. These results accord with neurophysiological findings that explored the presence of ISNs across different layers in the cortex. The results show that there may be a systematic macroscopic gradient of inhibitory stabilization across different layers in the cortex that depends on the level of excitation–inhibition balance, and that the strength of the paradoxical response increases as the model moves closer to bifurcation points.}
}
@article{PICCO2023662,
title = {High speed human action recognition using a photonic reservoir computer},
journal = {Neural Networks},
volume = {165},
pages = {662-675},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003258},
author = {Enrico Picco and Piotr Antonik and Serge Massar},
keywords = {Reservoir computing, Computer vision, Human action recognition, Photonics},
abstract = {The recognition of human actions in videos is one of the most active research fields in computer vision. The canonical approach consists in a more or less complex preprocessing stages of the raw video data, followed by a relatively simple classification algorithm. Here we address recognition of human actions using the reservoir computing algorithm, which allows us to focus on the classifier stage. We introduce a new training method for the reservoir computer, based on “Timesteps Of Interest”, which combines in a simple way short and long time scales. We study the performance of this algorithm using both numerical simulations and a photonic implementation based on a single non-linear node and a delay line on the well known KTH dataset. We solve the task with high accuracy and speed, to the point of allowing for processing multiple video streams in real time. The present work is thus an important step towards developing efficient dedicated hardware for video processing.}
}
@article{LAMBRECHTS2023645,
title = {Warming up recurrent neural networks to maximise reachable multistability greatly improves learning},
journal = {Neural Networks},
volume = {166},
pages = {645-669},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003817},
author = {Gaspard Lambrechts and Florent {De Geeter} and Nicolas Vecoven and Damien Ernst and Guillaume Drion},
keywords = {Recurrent neural network, Multistability, Initialisation procedure, Long-term memory, Warmup, Long time dependencies},
abstract = {Training recurrent neural networks is known to be difficult when time dependencies become long. In this work, we show that most standard cells only have one stable equilibrium at initialisation, and that learning on tasks with long time dependencies generally occurs once the number of network stable equilibria increases; a property known as multistability. Multistability is often not easily attained by initially monostable networks, making learning of long time dependencies between inputs and outputs difficult. This insight leads to the design of a novel way to initialise any recurrent cell connectivity through a procedure called “warmup” to improve its capability to learn arbitrarily long time dependencies. This initialisation procedure is designed to maximise network reachable multistability, i.e., the number of equilibria within the network that can be reached through relevant input trajectories, in few gradient steps. We show on several information restitution, sequence classification, and reinforcement learning benchmarks that warming up greatly improves learning speed and performance, for multiple recurrent cells, but sometimes impedes precision. We therefore introduce a double-layer architecture initialised with a partial warmup that is shown to greatly improve learning of long time dependencies while maintaining high levels of precision. This approach provides a general framework for improving learning abilities of any recurrent cell when long time dependencies are present. We also show empirically that other initialisation and pretraining procedures from the literature implicitly foster reachable multistability of recurrent cells.}
}
@article{KANG2023722,
title = {Content preserving image translation with texture co-occurrence and spatial self-similarity for texture debiasing and domain adaptation},
journal = {Neural Networks},
volume = {166},
pages = {722-737},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.049},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004070},
author = {Myeongkyun Kang and Dongkyu Won and Miguel Luna and Philip Chikontwe and Kyung Soo Hong and June Hong Ahn and Sang Hyun Park},
keywords = {Debiasing, Self-similarity, Texture co-occurrence, Unsupervised domain adaptation, Unpaired image translation},
abstract = {Models trained on datasets with texture bias usually perform poorly on out-of-distribution samples since biased representations are embedded into the model. Recently, various image translation and debiasing methods have attempted to disentangle texture biased representations for downstream tasks, but accurately discarding biased features without altering other relevant information is still challenging. In this paper, we propose a novel framework that leverages image translation to generate additional training images using the content of a source image and the texture of a target image with a different bias property to explicitly mitigate texture bias when training a model on a target task. Our model ensures texture similarity between the target and generated images via a texture co-occurrence loss while preserving content details from source images with a spatial self-similarity loss. Both the generated and original training images are combined to train improved classification or segmentation models robust to inconsistent texture bias. Evaluation on five classification- and two segmentation-datasets with known texture biases demonstrates the utility of our method, and reports significant improvements over recent state-of-the-art methods in all cases.}
}
@article{MA2023774,
title = {A continuation method for image registration based on dynamic adaptive kernel},
journal = {Neural Networks},
volume = {165},
pages = {774-785},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003362},
author = {Yuandong Ma and Boyuan Wang and Hezheng Lin and Chun Liu and Mengjie Hu and Qing Song},
keywords = {Image registration, Convolutional neural network, Coarse to fine level registration, Adaptive kernel},
abstract = {Image registration is a fundamental problem in computer vision and robotics. Recently, learning-based image registration methods have made great progress. However, these methods are sensitive to abnormal transformation and have insufficient robustness, which leads to more mismatched points in the actual environment. In this paper, we propose a new registration framework based on ensemble learning and dynamic adaptive kernel. Specifically, we first use a dynamic adaptive kernel to extract deep features at the coarse level to guide fine-level registration. Then we added an adaptive feature pyramid network based on the integrated learning principle to realize the fine-level feature extraction. Through different scale, receptive fields, not only the local geometric information of each point is considered, but also its low texture information at the pixel level is considered. According to the actual registration environment, fine features are adaptively obtained to reduce the sensitivity of the model to abnormal transformation. We use the global receptive field provided in the transformer to obtain feature descriptors based on these two levels. In addition, we use the cosine loss directly defined on the corresponding relationship to train the network and balance the samples, to achieve feature point registration based on the corresponding relationship. Extensive experiments on object-level and scene-level datasets show that the proposed method outperforms existing state-of-the-art techniques by a large margin. More critically, it has the best generalization ability in unknown scenes with different sensor modes.}
}
@article{ROY202365,
title = {Subspace distillation for continual learning},
journal = {Neural Networks},
volume = {167},
pages = {65-79},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.047},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023004057},
author = {Kaushik Roy and Christian Simon and Peyman Moghadam and Mehrtash Harandi},
keywords = {Lifelong learning, Subspace distillation, Knowledge distillation, Continual semantic segmentation, Catastrophic forgetting, Background shift},
abstract = {An ultimate objective in continual learning is to preserve knowledge learned in preceding tasks while learning new tasks. To mitigate forgetting prior knowledge, we propose a novel knowledge distillation technique that takes into the account the manifold structure of the latent/output space of a neural network in learning novel tasks. To achieve this, we propose to approximate the data manifold up-to its first order, hence benefiting from linear subspaces to model the structure and maintain the knowledge of a neural network while learning novel concepts. We demonstrate that the modeling with subspaces provides several intriguing properties, including robustness to noise and therefore effective for mitigating Catastrophic Forgetting in continual learning. We also discuss and show how our proposed method can be adopted to address both classification and segmentation problems. Empirically, we observe that our proposed method outperforms various continual learning methods on several challenging datasets including Pascal VOC, and Tiny-Imagenet. Furthermore, we show how the proposed method can be seamlessly combined with existing learning approaches to improve their performances. The codes of this article will be available at https://github.com/csiro-robotics/SDCL.}
}
@article{LIU202336,
title = {Spiking neural P systems with lateral inhibition},
journal = {Neural Networks},
volume = {167},
pages = {36-49},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300432X},
author = {Yuping Liu and Yuzhen Zhao},
keywords = {Membrane computing, Spiking neural P systems, Lateral inhibition, Turing universality},
abstract = {As a member of the third generation of artificial neural network models, spiking neural P systems (SN P systems) have gained a hot research spot in recent years. This work introduces the phenomenon of lateral inhibition in biological nervous systems into SN P systems, and proposes SN P systems with lateral inhibition (LISN P systems). LISN P systems add the property of synaptic length to portray the lateral distance between neurons, and adopt a new form of rules, lateral interaction rules, to describe the reception of spikes by postsynaptic neurons with different lateral distances from the presynaptic neuron. Specifically, an excited neuron produces lateral inhibition on surrounding postsynaptic neurons. Postsynaptic neurons close to the excited neuron, i.e., neurons with small lateral distances, are more susceptible to lateral inhibition and either receive a fewer number of spikes generated by the excited neuron or fail to receive spikes. As the lateral distance increases, the lateral inhibition weakens, and the number of spikes received by postsynaptic neurons increases. Based on the above mechanism, four specific LISN P systems are designed for generating arbitrary odd numbers, arbitrary even numbers, arbitrary natural numbers and arithmetic series, respectively, as examples. By designing working modules, LISN P systems provide equivalence in computational power to the universal register machines in both generating and accepting modes. This verifies the computational completeness of LISN P systems. A universal LISN P system using merely 65 neurons is devised for function computation. According to comparisons among several systems, universal LISN P systems require fewer computational resources.}
}
@article{DEPATER2023579,
title = {A mathematical framework for improved weight initialization of neural networks using Lagrange multipliers},
journal = {Neural Networks},
volume = {166},
pages = {579-594},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003921},
author = {Ingeborg {de Pater} and Mihaela Mitici},
keywords = {Weight initialization, Neural network training, Linear regression, Lagrange function, Remaining useful life},
abstract = {A good weight initialization is crucial to accelerate the convergence of the weights in a neural network. However, training a neural network is still time-consuming, despite recent advances in weight initialization approaches. In this paper, we propose a mathematical framework for the weight initialization in the last layer of a neural network. We first derive analytically a tight constraint on the weights that accelerates the convergence of the weights during the back-propagation algorithm. We then use linear regression and Lagrange multipliers to analytically derive the optimal initial weights and initial bias of the last layer, that minimize the initial training loss given the derived tight constraint. We also show that the restrictive assumption of traditional weight initialization algorithms that the expected value of the weights is zero is redundant for our approach. We first apply our proposed weight initialization approach to a Convolutional Neural Network that predicts the Remaining Useful Life of aircraft engines. The initial training and validation loss are relatively small, the weights do not get stuck in a local optimum, and the convergence of the weights is accelerated. We compare our approach with several benchmark strategies. Compared to the best performing state-of-the-art initialization strategy (Kaiming initialization), our approach needs 34% less epochs to reach the same validation loss. We also apply our approach to ResNets for the CIFAR-100 dataset, combined with transfer learning. Here, the initial accuracy is already at least 53%. This gives a faster weight convergence and a higher test accuracy than the benchmark strategies.}
}
@article{CHEN2023896,
title = {Lightweight image de-snowing: A better trade-off between network capacity and performance},
journal = {Neural Networks},
volume = {165},
pages = {896-908},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003404},
author = {Zheng Chen and Yiwen Sun and Xiaojun Bi and Jianyu Yue},
keywords = {Single image de-snowing, Lightweight neural network, Multi-scale, Feature distillation, Recursive strategy},
abstract = {The single image de-snowing task is an essential topic in computer vision, as images captured on snowy days degrade the performance of current vision-based intelligent systems. Existing methods build complex network structures with numerous parameters to pursue continuous performance improvement. Nonetheless, they generally ignore the negative impact of large memory consumption in real applications. This paper aims to address the above problem by making a trade-off between network capacity and performance. We propose two novel networks suitable for different application scenarios. For devices with small memory and requiring fast inference speed, we propose an extremely lightweight recursive network (XLRNet). XLRNet is constructed by a single recursive strategy and two novel lightweight modules. For devices with large memory and pursuing better de-snowing performance, we propose a coupled lightweight dual recursive network (CLDRNet). CLDRNet cascades two XLRNets by a novel dual recursive strategy and a novel dual coupled LSTM module (DC-LSTM). Extensive experiments demonstrate the effectiveness and superiority of our two models on three synthetic datasets and real-world datasets.}
}
@article{TIAN202370,
title = {Tackling higher-order relations and heterogeneity: Dynamic heterogeneous hypergraph network for spatiotemporal activity prediction},
journal = {Neural Networks},
volume = {166},
pages = {70-84},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003647},
author = {Changyuan Tian and Zequn Zhang and Fanglong Yao and Zhi Guo and Shiyao Yan and Xian Sun},
keywords = {Spatiotemporal activity prediction, Hypergraph neural network, Set representation learning, Hypergraph structure learning},
abstract = {Spatiotemporal activity prediction aims to predict user activities at a particular time and location, which is applicable in city planning, activity recommendations, and other domains. The fundamental endeavor in spatiotemporal activity prediction is to model the intricate interaction patterns among users, locations, time, and activities, which is characterized by higher-order relations and heterogeneity. Recently, graph-based methods have gained popularity due to the advancements in graph neural networks. However, these methods encounter two significant challenges. Firstly, higher-order relations and heterogeneity are not adequately modeled. Secondly, the majority of established methods are designed around the static graph structures that rely solely on co-occurrence relations, which can be imprecise. To overcome these challenges, we propose DyH2N, a dynamic heterogeneous hypergraph network for spatiotemporal activity prediction. Specifically, to enhance the capacity for modeling higher-order relations, hypergraphs are employed in lieu of graphs. Then we propose a set representation learning-inspired heterogeneous hyperedge learning module, which models higher-order relations and heterogeneity in spatiotemporal activity prediction using a non-decomposable manner. To improve the encoding of heterogeneous spatiotemporal activity hyperedges, a knowledge representation-regularized loss is introduced. Moreover, we present a hypergraph structure learning module to update the hypergraph structures dynamically. Our proposed DyH2N model has been extensively tested on four real-world datasets, proving to outperform previous state-of-the-art methods by 5.98% to 27.13%. The effectiveness of all framework components is demonstrated through ablation experiments.}
}
@article{TANG2023379,
title = {A simple and reliable instance selection for fast training support vector machine: Valid Border Recognition},
journal = {Neural Networks},
volume = {166},
pages = {379-395},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003763},
author = {Long Tang and Yingjie Tian and Xiaowei Wang and Panos M. Pardalos},
keywords = {Instance selection, Support vector machine, Neighborhood approach, Distance-based approach, Valid border instance},
abstract = {Support vector machines (SVMs) are powerful statistical learning tools, but their application to large datasets can cause time-consuming training complexity. To address this issue, various instance selection (IS) approaches have been proposed, which choose a small fraction of critical instances and screen out others before training. However, existing methods have not been able to balance accuracy and efficiency well. Some methods miss critical instances, while others use complicated selection schemes that require even more execution time than training with all original instances, thus violating the initial intention of IS. In this work, we present a newly developed IS method called Valid Border Recognition (VBR). VBR selects the closest heterogeneous neighbors as valid border instances and incorporates this process into the creation of a reduced Gaussian kernel matrix, thus minimizing the execution time. To improve reliability, we propose a strengthened version of VBR (SVBR). Based on VBR, SVBR gradually adds farther heterogeneous neighbors as complements until the Lagrange multipliers of already selected instances become stable. In numerical experiments, the effectiveness of our proposed methods is verified on benchmark and synthetic datasets in terms of accuracy, execution time and inference time.}
}
@article{KHAN2023553,
title = {A multi-modal deep neural network for multi-class liver cancer diagnosis},
journal = {Neural Networks},
volume = {165},
pages = {553-561},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003246},
author = {Rayyan Azam Khan and Minghan Fu and Brent Burbridge and Yigang Luo and Fang-Xiang Wu},
keywords = {Computer-aided diagnosis, Liver malignancy, Preprocessing, Medical imaging, Hepatocellular carcinoma, Metastasis},
abstract = {Liver disease is a potentially asymptomatic clinical entity that may progress to patient death. This study proposes a multi-modal deep neural network for multi-class malignant liver diagnosis. In parallel with the portal venous computed tomography (CT) scans, pathology data is utilized to prognosticate primary liver cancer variants and metastasis. The processed CT scans are fed to the deep dilated convolution neural network to explore salient features. The residual connections are further added to address vanishing gradient problems. Correspondingly, five pathological features are learned using a wide and deep network that gives a benefit of memorization with generalization. The down-scaled hierarchical features from CT scan and pathology data are concatenated to pass through fully connected layers for classification between liver cancer variants. In addition, the transfer learning of pre-trained deep dilated convolution layers assists in handling insufficient and imbalanced dataset issues. The fine-tuned network can predict three-class liver cancer variants with an average accuracy of 96.06% and an Area Under Curve (AUC) of 0.832. To the best of our knowledge, this is the first study to classify liver cancer variants by integrating pathology and image data, hence following the medical perspective of malignant liver diagnosis. The comparative analysis on the benchmark dataset shows that the proposed multi-modal neural network outperformed most of the liver diagnostic studies and is comparable to others.}
}
@article{ZHANG20231035,
title = {Differentiating brain states via multi-clip random fragment strategy-based interactive bidirectional recurrent neural network},
journal = {Neural Networks},
volume = {165},
pages = {1035-1049},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003520},
author = {Shu Zhang and Enze Shi and Lin Wu and Ruoyang Wang and Sigang Yu and Zhengliang Liu and Shaochen Xu and Tianming Liu and Shijie Zhao},
keywords = {Recurrent neural network, Random fragment strategy, Interactive, EEG, Differentiate brain states},
abstract = {EEG is widely adopted to study the brain and brain computer interface (BCI) for its non-invasiveness and low costs. Specifically EEG can be applied to differentiate brain states, which is important for better understanding the working mechanisms of the brain. Recurrent neural network (RNN)-based learning strategy has been widely utilized to differentiate brain states, because its optimization architectures improve the classification performance for differentiating brain states at the group level. However, present classification performance is still far from satisfactory. We have identified two major focal points for improvements: one is about organizing the input EEG signals, and the other is related to the design of the RNN architecture. To optimize the above-mentioned issues and achieve better brain state classification performance, we propose a novel multi-clip random fragment strategy-based interactive bidirectional recurrent neural network (McRFS-IBiRNN) model in this work. This model has two advantages over previous methods. First, the McRFS component is designed to re-organize the input EEG signals to make them more suitable for the RNN architecture. Second, the IBiRNN component is an innovative design to model the RNN layers with interaction connections to enhance the fusion of bidirectional features. By adopting the proposed model, promising brain states classification performances are obtained. For example, 96.97% and 99.34% of individual and group level four-category classification accuracies are successfully obtained on the EEG motor/imagery dataset, respectively. A 99.01% accuracy can be observed for four-category classification tasks with new subjects not seen before, which demonstrates the generalization of our proposed method. Compared with existing methods, our model outperforms them with superior results. Overall, the proposed McRFS-IBiRNN model demonstrates great superiority in differentiating brain states on EEG signals}
}
@article{FENG2023982,
title = {Analytical interpretation of the gap of CNN’s cognition between SAR and optical target recognition},
journal = {Neural Networks},
volume = {165},
pages = {982-986},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003489},
author = {Zhenpeng Feng and Hongbing Ji and Miloš Daković and Mingzhe Zhu and Ljubiša Stanković},
keywords = {SAR imaging, Target recognition, Interpretable CNN, Multi-order interaction},
abstract = {Synthetic aperture radar (SAR) automatic target recognition (ATR) is a crucial technique utilized in various scenarios of geoscience and remote sensing. Despite the remarkable success of convolutional neural networks (CNNs) in optical vision tasks, the application of CNNs in SAR ATR is still a challenging area due to the significant differences in the imaging mechanisms of SAR and optical images. This paper analytically addresses the cognitive gap of CNNs between optical and SAR images by leveraging multi-order interactions to measure their representation capacity. Furthermore, we propose a subjective evaluation strategy to compare human interactions with those of CNNs. Our findings reveal that CNNs operate differently for optical and SAR images. Specifically, for SAR images, CNNs’ representation capacity is comparable to that of humans, as they can encode intermediate interactions better than simple and complex ones. In contrast, for optical images, CNNs excel at encoding simple and complex interactions, but not intermediate interactions.}
}
@article{ZHOU2023741,
title = {A novel neural network for improved in-hospital mortality prediction with irregular and incomplete multivariate data},
journal = {Neural Networks},
volume = {167},
pages = {741-750},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.033},
url = {https://www.sciencedirect.com/science/article/pii/S089360802300391X},
author = {Xi Zhou and Wei Xiang and Tao Huang},
keywords = {Irregularly sampled time series, Multivariate time series, Missing values, Neural network, Machine learning, Precision medicine},
abstract = {Accurate estimation of in-hospital mortality based on patients’ physiological time series data improves the performance of the clinical decision support systems and assists hospital providers in allocating resources. In practice, the data quality issues of missing values are ubiquitous in electronic health records (EHRs). Since the vital signs are usually observed with irregular temporal intervals and different sampling rates, it is challenging to predict clinical outcomes with sparse and incomplete multivariate time series. We propose an auto-regressive recurrent neural network (RNN) based model, dubbed the bi-directional recursive encoder–decoder network (BiRED), to jointly perform data imputation and mortality prediction. To capture complex patterns of medical time sequences, a 2D cross-regression with an RNN unit (2DCR-RNN) and an imputation block with an RNN unit (IB-RNN) are designed as the recurrent component of the encoder and decoder, respectively. Furthermore, a state initialization method is proposed to alleviate errors accumulated in the generated sequence. The experimental results on two real EHR datasets show that our proposed method can predict hospital mortality with high AUC scores.}
}
@article{SUN2023260,
title = {Balance guided incomplete multi-view spectral clustering},
journal = {Neural Networks},
volume = {166},
pages = {260-272},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.07.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003805},
author = {Lilei Sun and Jie Wen and Chengliang Liu and Lunke Fei and Lusi Li},
keywords = {Incomplete multi-view clustering, Graph clustering, Subspace learning, Missing views},
abstract = {There is a large volume of incomplete multi-view data in the real-world. How to partition these incomplete multi-view data is an urgent realistic problem since almost all of the conventional multi-view clustering methods are inapplicable to cases with missing views. In this paper, a novel graph learning-based incomplete multi-view clustering (IMVC) method is proposed to address this issue. Different from existing works, our method aims at learning a common consensus graph from all incomplete views and obtaining a clustering indicator matrix in a unified framework. To achieve a stable clustering result, a relaxed spectral clustering model is introduced to obtain a probability consensus representation with all positive elements that reflect the data clustering result. Considering the different contributions of views to the clustering task, a weighted multi-view learning mechanism is introduced to automatically balance the effects of different views in model optimization. In this way, the intrinsic information of the incomplete multi-view data can be fully exploited. The experiments on several incomplete multi-view datasets show that our method outperforms the compared state-of-the-art clustering methods, which demonstrates the effectiveness of our method for IMVC.}
}