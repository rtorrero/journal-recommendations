@article{ZHAO202152,
title = {Combining a parallel 2D CNN with a self-attention Dilated Residual Network for CTC-based discrete speech emotion recognition},
journal = {Neural Networks},
volume = {141},
pages = {52-60},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000939},
author = {Ziping Zhao and Qifei Li and Zixing Zhang and Nicholas Cummins and Haishuai Wang and Jianhua Tao and Björn W. Schuller},
keywords = {Speech emotion recognition, Parallel 2D CNN, Connectionist temporal classification, Residual dilated network, Self-attention},
abstract = {A challenging issue in the field of the automatic recognition of emotion from speech is the efficient modelling of long temporal contexts. Moreover, when incorporating long-term temporal dependencies between features, recurrent neural network (RNN) architectures are typically employed by default. In this work, we aim to present an efficient deep neural network architecture incorporating Connectionist Temporal Classification (CTC) loss for discrete speech emotion recognition (SER). Moreover, we also demonstrate the existence of further opportunities to improve SER performance by exploiting the properties of convolutional neural networks (CNNs) when modelling contextual information. Our proposed model uses parallel convolutional layers (PCN) integrated with Squeeze-and-Excitation Network (SEnet), a system herein denoted as PCNSE, to extract relationships from 3D spectrograms across timesteps and frequencies; here, we use the log-Mel spectrogram with deltas and delta–deltas as input. In addition, a self-attention Residual Dilated Network (SADRN) with CTC is employed as a classification block for SER. To the best of the authors’ knowledge, this is the first time that such a hybrid architecture has been employed for discrete SER. We further demonstrate the effectiveness of our proposed approach on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) and FAU-Aibo Emotion corpus (FAU-AEC). Our experimental results reveal that the proposed method is well-suited to the task of discrete SER, achieving a weighted accuracy (WA) of 73.1% and an unweighted accuracy (UA) of 66.3% on IEMOCAP, as well as a UA of 41.1% on the FAU-AEC dataset.}
}
@article{ZHANG2021282,
title = {Manifold adversarial training for supervised and semi-supervised learning},
journal = {Neural Networks},
volume = {140},
pages = {282-293},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001192},
author = {Shufei Zhang and Kaizhu Huang and Jianke Zhu and Yang Liu},
keywords = {Adversarial examples, Manifold learning, Semi-supervised learning},
abstract = {We propose a new regularization method for deep learning based on the manifold adversarial training (MAT). Unlike previous regularization and adversarial training methods, MAT further considers the local manifold of latent representations. Specifically, MAT manages to build an adversarial framework based on how the worst perturbation could affect the statistical manifold in the latent space rather than the output space. Particularly, a latent feature space with the Gaussian Mixture Model (GMM) is first derived in a deep neural network. We then define the smoothness by the largest variation of Gaussian mixtures when a local perturbation is given around the input data point. On one hand, the perturbations are added in the way that would rough the statistical manifold of the latent space the worst. On the other hand, the model is trained to promote the manifold smoothness the most in the latent space. Importantly, since the latent space is more informative than the output space, the proposed MAT can learn a more robust and compact data representation, leading to further performance improvement. The proposed MAT is important in that it can be considered as a superset of one recently-proposed discriminative feature learning approach called center loss. We conduct a series of experiments in both supervised and semi-supervised learning on four benchmark data sets, showing that the proposed MAT can achieve remarkable performance, much better than those of the state-of-the-art approaches. In addition, we present a series of visualization which could generate further understanding or explanation on adversarial examples.}
}
@article{XU202117,
title = {Convergence of the RMSProp deep learning method with penalty for nonconvex optimization},
journal = {Neural Networks},
volume = {139},
pages = {17-23},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000538},
author = {Dongpo Xu and Shengdong Zhang and Huisheng Zhang and Danilo P. Mandic},
keywords = {Nonconvex optimization, Convergence, RMSProp, Penalty term, Generalization ability, Deep learning},
abstract = {A norm version of the RMSProp algorithm with penalty (termed RMSPropW) is introduced into the deep learning framework and its convergence is addressed both analytically and numerically. For rigour, we consider the general nonconvex setting and prove the boundedness and convergence of the RMSPropW method in both deterministic and stochastic cases. This equips us with strict upper bounds on both the moving average squared norm of the gradient and the norm of weight parameters throughout the learning process, owing to the penalty term within the proposed cost function. In the deterministic (batch) case, the boundedness of the moving average squared norm of the gradient is employed to prove that the gradient sequence converges to zero when using a fixed step size, while with diminishing stepsizes, the minimum of the gradient sequence converges to zero. In the stochastic case, due to the boundedness of the weight evolution sequence, it is further shown that the weight sequence converges to a stationary point with probability 1. Finally, illustrative simulations are provided to support the theoretical analysis, including a comparison with the standard RMSProp on MNIST, CIFAR-10, and IMDB datasets.}
}
@article{ZHENG2021355,
title = {Generative Adversarial Network with Multi-branch Discriminator for imbalanced cross-species image-to-image translation},
journal = {Neural Networks},
volume = {141},
pages = {355-371},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001507},
author = {Ziqiang Zheng and Zhibin Yu and Yang Wu and Haiyong Zheng and Bing Zheng and Minho Lee},
keywords = {Multi-branch discriminator, Image-to-image translation, Generative adversarial network, Cross-species},
abstract = {There has been an increased interest in high-level image-to-image translation to achieve semantic matching. Through a powerful translation model, we can efficiently synthesize high-quality images with diverse appearances while retaining semantic matching. In this paper, we address an imbalanced learning problem using a cross-species image-to-image translation. We aim to perform the data augmentation through the image translation to boost the recognition performance of imbalanced learning. It requires a strong ability of the model to perform a biomorphic transformation on a semantic level. To tackle this problem, we propose a novel, simple, and effective structure of Multi-Branch Discriminator (termed as MBD) based on Generative Adversarial Networks (GANs). We demonstrate the effectiveness of the proposed MBD through theoretical analysis as well as empirical evaluation. We provide theoretical proof of why the proposed MBD is an effective and optimal case to achieve remarkable performance. Comprehensive experiments on various cross-species image translation tasks illustrate that our MBD can dramatically promote the performance of popular GANs with state-of-the-art results in terms of both objective and subjective assessments. Extensive downstream image recognition evaluations at a few-shot setting have also been conducted to demonstrate that the proposed method can effectively boost the performance of imbalanced learning.}
}
@article{SHEN2021160,
title = {Neural network approximation: Three hidden layers are enough},
journal = {Neural Networks},
volume = {141},
pages = {160-173},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001465},
author = {Zuowei Shen and Haizhao Yang and Shijun Zhang},
keywords = {Exponential convergence, Curse of dimensionality, Deep neural network, Floor-Exponential-Step activation function, Continuous function},
abstract = {A three-hidden-layer neural network with super approximation power is introduced. This network is built with the floor function (⌊x⌋), the exponential function (2x), the step function (1x≥0), or their compositions as the activation function in each neuron and hence we call such networks as Floor-Exponential-Step (FLES) networks. For any width hyper-parameter N∈N+, it is shown that FLES networks with width max{d,N} and three hidden layers can uniformly approximate a Hölder continuous function f on [0,1]d with an exponential approximation rate 3λ(2d)α2−αN, where α∈(0,1] and λ>0 are the Hölder order and constant, respectively. More generally for an arbitrary continuous function f on [0,1]d with a modulus of continuity ωf(⋅), the constructive approximation rate is 2ωf(2d)2−N+ωf(2d2−N). Moreover, we extend such a result to general bounded continuous functions on a bounded set E⊆Rd. As a consequence, this new class of networks overcomes the curse of dimensionality in approximation power when the variation of ωf(r) as r→0 is moderate (e.g., ωf(r)≲rα for Hölder continuous functions), since the major term to be concerned in our approximation rate is essentially d times a function of N independent of d within the modulus of continuity. Finally, we extend our analysis to derive similar approximation results in the Lp-norm for p∈[1,∞) via replacing Floor-Exponential-Step activation functions by continuous activation functions.}
}
@article{AFEBU202149,
title = {LSTM-based approach for predicting periodic motions of an impacting system via transient dynamics},
journal = {Neural Networks},
volume = {140},
pages = {49-64},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000770},
author = {Kenneth Omokhagbo Afebu and Yang Liu and Evangelos Papatheou and Bingyong Guo},
keywords = {Vibro-impact, Coexisting attractor, Long Short-Term Memory network, Basin prediction, Percussive drilling},
abstract = {Dynamically impacting systems are characterised with inherent instability and complex non-linear phenomena which makes it practically difficult to predict the steady state response of the system at transient periods. This study investigates the ability of a data driven machine learning method using Long Short-Term Memory networks to learn the complex nonlinearity associated with co-existing impact responses from limited transient data. A one-degree-of-freedom impact oscillator has been used to represent the bit–rock interaction for percussive drilling. Simulated data results show velocity measurements to contribute most to predicting steady state responses from transient dynamics with most of the network models reaching an accuracy of over 95%. Limitations to practically measurable variables in dynamic systems warranted the development of a feature based network model for impact motion classification. Experimental data from a two-degrees-of-freedom impacting system representing percussive bit penetration has been used to demonstrate the effectiveness of this method. The study thus provides a precise and less computational means of detecting and avoiding underperforming impact modes in percussive drilling.}
}
@article{CHEN2021336,
title = {Basic theorem and global exponential stability of differential–algebraic neural networks with delay},
journal = {Neural Networks},
volume = {140},
pages = {336-343},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000253},
author = {Jiejie Chen and Boshan Chen and Zhigang Zeng},
keywords = {Global existence and uniqueness theorem, Global exponential stability, Differential–algebraic neural networks, Singular neural networks, Neutral-type neural networks},
abstract = {A differential–algebraic neural network (DANN) with delay (DDANN) is proposed. Firstly, the global existence and uniqueness theorems are established for a DDANN, respectively. Next, a new differential–algebraic inequality is established. Then, a theorem on global exponential stability of DDANN is shown by using this inequality. As an application of DDANN, a very concise criterion on global exponential stability for a neutral-type neural network is given by using DDANNs. Finally, two examples are given to illustrate the theoretical results.}
}
@article{SUN2021372,
title = {Combination of deep speaker embeddings for diarisation},
journal = {Neural Networks},
volume = {141},
pages = {372-384},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100157X},
author = {Guangzhi Sun and Chao Zhang and Philip C. Woodland},
keywords = {Speaker diarisation, System combination, Speaker embedding, Attention mechanism, Gating mechanism, Bilinear pooling},
abstract = {Significant progress has recently been made in speaker diarisation after the introduction of d-vectors as speaker embeddings extracted from neural network (NN) speaker classifiers for clustering speech segments. To extract better-performing and more robust speaker embeddings, this paper proposes a c-vector method by combining multiple sets of complementary d-vectors derived from systems with different NN components. Three structures are used to implement the c-vectors, namely 2D self-attentive, gated additive, and bilinear pooling structures, relying on attention mechanisms, a gating mechanism, and a low-rank bilinear pooling mechanism respectively. Furthermore, a neural-based single-pass speaker diarisation pipeline is also proposed in this paper, which uses NNs to achieve voice activity detection, speaker change point detection, and speaker embedding extraction. Experiments and detailed analyses are conducted on the challenging AMI and NIST RT05 datasets which consist of real meetings with 4–10 speakers and a wide range of acoustic conditions. For systems trained on the AMI training set, relative speaker error rate (SER) reductions of 13% and 29% are obtained by using c-vectors instead of d-vectors on the AMI dev and eval sets respectively, and a relative SER reduction of 15% in SER is observed on RT05, which shows the robustness of the proposed methods. By incorporating VoxCeleb data into the training set, the best c-vector system achieved 7%, 17% and 16% relative SER reduction compared to the d-vector on the AMI dev, eval and RT05 sets respectively.}
}
@article{LIU202120,
title = {Enhancing Graph Neural Networks by a High-quality Aggregation of Beneficial Information},
journal = {Neural Networks},
volume = {142},
pages = {20-33},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001623},
author = {Chuang Liu and Jia Wu and Weiwei Liu and Wenbin Hu},
keywords = {Graph neural networks, Neighborhood aggregation, Semi-supervised node classification},
abstract = {Graph Neural Networks (GNNs), such as GCN, GraphSAGE, GAT, and SGC, have achieved state-of-the-art performance on a wide range of graph-based tasks. These models all use a technique called neighborhood aggregation, in which the embedding of each node is updated by aggregating the embeddings of its neighbors. However, not all information aggregated from neighbors is beneficial. In some cases, a portion of the neighbor information may be harmful to the downstream tasks. For the high-quality aggregation of beneficial information, we propose a flexible method EGAI (Enhancing Graph neural networks by a high-quality Aggregation of beneficial Information). The core concept of this method is to filter out the redundant and harmful information by removing specific edges during each training epoch. The practical and theoretical motivations, considerations, and strategies related to this method are discussed in detail. EGAI is a general method that can be combined with many backbone models (e.g., GCN, GraphSAGE, GAT, and SGC) to enhance their performance in the node classification task. In addition, EGAI reduces the convergence speed of over-smoothing that occurs when models are deepened. Extensive experiments on three real-world networks demonstrate that EGAI indeed improves the performance for both shallow and deep GNN models, and to some extent, mitigates over-smoothing. The code is available at https://github.com/liucoo/egai.}
}
@article{ZHONG2021428,
title = {Learning to reweight examples in multi-label classification},
journal = {Neural Networks},
volume = {142},
pages = {428-436},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001106},
author = {Yongjian Zhong and Bo Du and Chang Xu},
keywords = {Multi-label classification, Self-paced learning, Reweight instance},
abstract = {This paper presents a new method for reweighting examples in the multi-label classification problem. Existing weighting functions in self-paced learning simply determine the weights of examples according to their loss values given the current multi-label model, but neglect the unique properties of multi-label examples. It is inaccurate to treat two distinct examples as equal even if their loss values are the same. Therefore, we upgrade the classical weight functions by considering instance complexities, which are described by the distances between instance features and their corresponding labels. The distance metric can be easily optimized during training. Experimental results on real-world datasets demonstrate the significance of investigating both the dynamic and static complexities of multi-label examples, as well as the advantages of the proposed example reweighting algorithm in multi-label classification problems.}
}
@article{MIAO2021174,
title = {Pinning bipartite synchronization for coupled reaction–diffusion neural networks with antagonistic interactions and switching topologies},
journal = {Neural Networks},
volume = {141},
pages = {174-183},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001349},
author = {Baojun Miao and Xuechen Li and Jungang Lou and Jianquan Lu},
keywords = {Bipartite synchronization, Reaction–diffusion networks, Pinning control, Dirichlet boundary condition, Signed graph},
abstract = {In this paper, the bipartite synchronization issue for a class of coupled reaction–diffusion networks with antagonistic interactions and switching topologies is investigated. First of all, by virtue of Lyapunov functional method and pinning control technique, we obtain some sufficient conditions which can guarantee that networks with signed graph topologies realize bipartite synchronization under any initial conditions and arbitrary switching signals. Secondly, for the general switching signal and periodic switching signal, a pinning controller that can ensure bipartite synchronization of reaction–diffusions networks is designed based on the obtained conditions. Meanwhile, a directed relationship between coupling strength and control gains is presented. Thirdly, numerical simulation is provided to demonstrate the correctness and validity of the derived theoretical results for reaction–diffusion systems. We briefly conclude our findings and future work.}
}
@article{NAPOLES202139,
title = {Long-term Cognitive Network-based architecture for multi-label classification},
journal = {Neural Networks},
volume = {140},
pages = {39-48},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000812},
author = {Gonzalo Nápoles and Marilyn Bello and Yamisleydi Salgueiro},
keywords = {Long-term cognitive networks, Recurrent neural networks, Backpropagation, Multi-label classification},
abstract = {This paper presents a neural system to deal with multi-label classification problems that might involve sparse features. The architecture of this model involves three sequential blocks with well-defined functions. The first block consists of a multilayered feed-forward structure that extracts hidden features, thus reducing the problem dimensionality. This block is useful when dealing with sparse problems. The second block consists of a Long-term Cognitive Network-based model that operates on features extracted by the first block. The activation rule of this recurrent neural network is modified to prevent the vanishing of the input signal during the recurrent inference process. The modified activation rule combines the neurons’ state in the previous abstract layer (iteration) with the initial state. Moreover, we add a bias component to shift the transfer functions as needed to obtain good approximations. Finally, the third block consists of an output layer that adapts the second block’s outputs to the label space. We propose a backpropagation learning algorithm that uses a squared hinge loss function to maximize the margins between labels to train this network. The results show that our model outperforms the state-of-the-art algorithms in most datasets.}
}
@article{DAHMANI2021315,
title = {Learning emotions latent representation with CVAE for text-driven expressive audiovisual speech synthesis},
journal = {Neural Networks},
volume = {141},
pages = {315-329},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001581},
author = {Sara Dahmani and Vincent Colotte and Valérian Girard and Slim Ouni},
keywords = {Expressive audiovisual speech synthesis, Conditional variational auto-encoder, Expressive talking avatar, Deep learning, Bidirectional long short-term memory (BLSTM)},
abstract = {Great improvement has been made in the field of expressive audiovisual Text-to-Speech synthesis (EAVTTS) thanks to deep learning techniques. However, generating realistic speech is still an open issue and researchers in this area have been focusing lately on controlling the speech variability. In this paper, we use different neural architectures to synthesize emotional speech. We study the application of unsupervised learning techniques for emotional speech modeling as well as methods for restructuring emotions representation to make it continuous and more flexible. This manipulation of the emotional representation should allow us to generate new styles of speech by mixing emotions. We first present our expressive audiovisual corpus. We validate the emotional content of this corpus with three perceptual experiments using acoustic only, visual only and audiovisual stimuli. After that, we analyze the performance of a fully connected neural network in learning characteristics specific to different emotions for the phone duration aspect and the acoustic and visual modalities. We also study the contribution of a joint and separate training of the acoustic and visual modalities in the quality of the generated synthetic speech. In the second part of this paper, we use a conditional variational auto-encoder (CVAE) architecture to learn a latent representation of emotions. We applied this method in an unsupervised manner to generate features of expressive speech. We used a probabilistic metric to compute the overlapping degree between emotions latent clusters to choose the best parameters for the CVAE. By manipulating the latent vectors, we were able to generate nuances of a given emotion and to generate new emotions that do not exist in our database. For these new emotions, we obtain a coherent articulation. We conducted four perceptual experiments to evaluate our findings.}
}
@article{OLSZEWSKI2021247,
title = {A clustering-based adaptive Neighborhood Retrieval Visualizer},
journal = {Neural Networks},
volume = {140},
pages = {247-260},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001064},
author = {Dominik Olszewski},
keywords = {Neighborhood Retrieval Visualizer, Adaptive Neighborhood Retrieval Visualizer, Information retrieval, Data clustering, Data visualization},
abstract = {We introduce a novel adaptive version of the Neighborhood Retrieval Visualizer (NeRV). We maintain the advantages of the conventional NeRV method, while proposing an improvement of the data samples’ neighborhood width calculation, in the input and output data space. In the standard NeRV, the data samples’ neighborhood widths are determined in an arbitrary manner, in this way, inhibiting the possible quality of the resulting data visualization. We propose to compute the widths adaptively, on the basis of the input data scattering. Therefore, we first perform the preliminary input data clustering, next, we calculate the values of the inner-cluster variances, which convey the information on the input data scattering, then, we assign them to each data sample, and finally, we use them as the basis for the data samples’ neighborhood widths determination. The results of the experiments conducted on the three different real datasets confirm the effectiveness and usefulness of the proposed approach.}
}
@article{CASTILLOBOLADO2021294,
title = {Design and independent training of composable and reusable neural modules},
journal = {Neural Networks},
volume = {139},
pages = {294-304},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001222},
author = {David Castillo-Bolado and Cayetano Guerra-Artal and Mario Hernández-Tejera},
keywords = {Modular training, Modularity, Compositionality, Methodology, Learning by role, Visual Question Answering},
abstract = {Monolithic neural networks and end-to-end training have become the dominating trend in the field of deep learning, but the steady increase in complexity and training costs has raised concerns about the effectiveness and efficiency of this approach. We propose modular training as an alternative strategy for building modular neural networks by composing neural modules that can be trained independently and then kept for future use. We analyse the requirements and challenges regarding modularity and compositionality and, with that information in hand, we provide a detailed design and implementation guideline. We show experimental results of applying this modular approach to a Visual Question Answering (VQA) task parting from a previously published modular network and we evaluate its impact on the final performance, with respect to a baseline trained end-to-end. We also perform compositionality tests on CLEVR.}
}
@article{BORGSTROM2021136,
title = {Speaker separation in realistic noise environments with applications to a cognitively-controlled hearing aid},
journal = {Neural Networks},
volume = {140},
pages = {136-147},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000708},
author = {Bengt J. Borgström and Michael S. Brandstein and Gregory A. Ciccarelli and Thomas F. Quatieri and Christopher J. Smalt},
keywords = {Speaker separation, Noise suppression, Convolutional Neural Networks, Attention masking, Auditory attention decoding},
abstract = {Future wearable technology may provide for enhanced communication in noisy environments and for the ability to pick out a single talker of interest in a crowded room simply by the listener shifting their attentional focus. Such a system relies on two components, speaker separation and decoding the listener’s attention to acoustic streams in the environment. To address the former, we present a system for joint speaker separation and noise suppression, referred to as the Binaural Enhancement via Attention Masking Network (BEAMNET). The BEAMNET system is an end-to-end neural network architecture based on self-attention. Binaural input waveforms are mapped to a joint embedding space via a learned encoder, and separate multiplicative masking mechanisms are included for noise suppression and speaker separation. Pairs of output binaural waveforms are then synthesized using learned decoders, each capturing a separated speaker while maintaining spatial cues. A key contribution of BEAMNET is that the architecture contains a separation path, an enhancement path, and an autoencoder path. This paper proposes a novel loss function which simultaneously trains these paths, so that disabling the masking mechanisms during inference causes BEAMNET to reconstruct the input speech signals. This allows dynamic control of the level of suppression applied by BEAMNET via a minimum gain level, which is not possible in other state-of-the-art approaches to end-to-end speaker separation. This paper also proposes a perceptually-motivated waveform distance measure. Using objective speech quality metrics, the proposed system is demonstrated to perform well at separating two equal-energy talkers, even in high levels of background noise. Subjective testing shows an improvement in speech intelligibility across a range of noise levels, for signals with artificially added head-related transfer functions and background noise. Finally, when used as part of an auditory attention decoder (AAD) system using existing electroencephalogram (EEG) data, BEAMNET is found to maintain the decoding accuracy achieved with ideal speaker separation, even in severe acoustic conditions. These results suggest that this enhancement system is highly effective at decoding auditory attention in realistic noise environments, and could possibly lead to improved speech perception in a cognitively controlled hearing aid.}
}
@article{MASHHADI2021167,
title = {Parallel orthogonal deep neural network},
journal = {Neural Networks},
volume = {140},
pages = {167-183},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000824},
author = {Peyman Sheikholharam Mashhadi and Sławomir Nowaczyk and Sepideh Pashami},
keywords = {Ensemble learning, Deep learning, Orthogonalization, Diversity, Uncertainty},
abstract = {Ensemble learning methods combine multiple models to improve performance by exploiting their diversity. The success of these approaches relies heavily on the dissimilarity of the base models forming the ensemble. This diversity can be achieved in many ways, with well-known examples including bagging and boosting. It is the diversity of the models within an ensemble that allows the ensemble to correct the errors made by its members, and consequently leads to higher classification or regression performance. A mistake made by a base model can only be rectified if other members behave differently on that particular instance, and provide the aggregator with enough information to make an informed decision. On the contrary, lack of diversity not only lowers model performance, but also wastes computational resources. Nevertheless, in the current state of the art ensemble approaches, there is no guarantee on the level of diversity achieved, and no mechanism ensuring that each member will learn a different decision boundary from the others. In this paper, we propose a parallel orthogonal deep learning architecture in which diversity is enforced by design, through imposing an orthogonality constraint. Multiple deep neural networks are created, parallel to each other. At each parallel layer, the outputs of different base models are subject to Gram–Schmidt orthogonalization. We demonstrate that this approach leads to a high level of diversity from two perspectives. First, the models make different errors on different parts of feature space, and second, they exhibit different levels of uncertainty in their decisions. Experimental results confirm the benefits of the proposed method, compared to standard deep learning models and well-known ensemble methods, in terms of diversity and, as a result, classification performance.}
}
@article{LI20211,
title = {Augmented semantic feature based generative network for generalized zero-shot learning},
journal = {Neural Networks},
volume = {143},
pages = {1-11},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001519},
author = {Zhiqun Li and Qiong Chen and Qingfa Liu},
keywords = {Generalized zero-shot learning, Augmented semantic feature, Feature generation, Generative network, Mode collapse},
abstract = {Zero-shot learning (ZSL) aims to recognize objects in images when no training data is available for the object classes. Under generalized zero-shot learning (GZSL) setting, the test objects belong to seen or unseen categories. In many recent studies, zero-shot learning is performed by leveraging generative networks to synthesize visual features for unseen class from class-specific semantic features. The user-defined semantic information is incomplete and lack of discriminability. However, most generative methods use user-defined semantic information directly as constraints of the generative model, which makes the visual features synthesized by the models lack of diversity and separability. In this paper, we propose a novel method to improve the semantic feature by utilizing discriminative visual features. Furthermore, a novel Augmented Semantic Feature Based Generative Network (ASFGN) is built to synthesize the separable visual representations for unseen classes. Since GAN-based generative model may suffer from mode collapse, we propose a novel collapse-alleviate loss to improve the training stability and generalization performance of our generative network. Extensive experiments on four benchmark datasets prove that our method outperforms the state-of-art approaches in both ZSL and GZSL settings.}
}
@article{SCHILLING2021278,
title = {Quantifying the separability of data classes in neural networks},
journal = {Neural Networks},
volume = {139},
pages = {278-293},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001234},
author = {Achim Schilling and Andreas Maier and Richard Gerum and Claus Metzner and Patrick Krauss},
keywords = {Neural network analysis, Data class separability, Neural architecture search, Discrimination value, Deep learning interpretability, Representational similarity analysis},
abstract = {We introduce the Generalized Discrimination Value (GDV) that measures, in a non-invasive manner, how well different data classes separate in each given layer of an artificial neural network. It turns out that, at the end of the training period, the GDV in each given layer L attains a highly reproducible value, irrespective of the initialization of the network’s connection weights. In the case of multi-layer perceptrons trained with error backpropagation, we find that classification of highly complex data sets requires a temporal reduction of class separability, marked by a characteristic ‘energy barrier’ in the initial part of the GDV(L) curve. Even more surprisingly, for a given data set, the GDV(L) is running through a fixed ‘master curve’, independently from the total number of network layers. Finally, due to its invariance with respect to dimensionality, the GDV may serve as a useful tool to compare the internal representational dynamics of artificial neural networks with different architectures for neural architecture search or network compression; or even with brain activity in order to decide between different candidate models of brain function.}
}
@article{KIRANYAZ2021294,
title = {Self-organized Operational Neural Networks with Generative Neurons},
journal = {Neural Networks},
volume = {140},
pages = {294-308},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000782},
author = {Serkan Kiranyaz and Junaid Malik and Habib Ben Abdallah and Turker Ince and Alexandros Iosifidis and Moncef Gabbouj},
keywords = {Convolutional Neural Networks, Operational Neural Networks, Generative neurons, Heterogeneous networks},
abstract = {Operational Neural Networks (ONNs) have recently been proposed to address the well-known limitations and drawbacks of conventional Convolutional Neural Networks (CNNs) such as network homogeneity with the sole linear neuron model. ONNs are heterogeneous networks with a generalized neuron model. However the operator search method in ONNs is not only computationally demanding, but the network heterogeneity is also limited since the same set of operators will then be used for all neurons in each layer. Moreover, the performance of ONNs directly depends on the operator set library used, which introduces a certain risk of performance degradation especially when the optimal operator set required for a particular task is missing from the library. In order to address these issues and achieve an ultimate heterogeneity level to boost the network diversity along with computational efficiency, in this study we propose Self-organized ONNs (Self-ONNs) with generative neurons that can adapt (optimize) the nodal operator of each connection during the training process. Moreover, this ability voids the need of having a fixed operator set library and the prior operator search within the library in order to find the best possible set of operators. We further formulate the training method to back-propagate the error through the operational layers of Self-ONNs. Experimental results over four challenging problems demonstrate the superior learning capability and computational efficiency of Self-ONNs over conventional ONNs and CNNs.}
}
@article{WU2021261,
title = {Saturated impulsive control for synchronization of coupled delayed neural networks},
journal = {Neural Networks},
volume = {141},
pages = {261-269},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001477},
author = {Shuchen Wu and Xiaodi Li and Yanhui Ding},
keywords = {Impulse saturation, Synchronization control, Coupled neural networks, Delay, Domain of attraction, Algorithm},
abstract = {The paper focuses on the synchronization problem for a class of coupled neural networks with impulsive control, where the saturation structure of impulse action is fully considered. The coupled neural networks under consideration are subject to mixed delays including transmission delay and coupled delay. The sector condition in virtue of a new constraint of set inclusion is given for a addressed network, based on which a sufficient condition for exponential synchronization problem is obtained by replacing saturation nonlinearity with a dead-zone function. In the framework of saturated impulses, our results relying on the domain of attraction can still achieve the synchronization of coupled delayed neural networks. In addition, the estimating domain of attraction is proposed as large as possible by solving an optimization problem. Finally, a numerical simulation example is presented to demonstrate the effectiveness of the proposed results.}
}
@article{ZHANG202134,
title = {Cluster synchronization of delayed coupled neural networks: Delay-dependent distributed impulsive control},
journal = {Neural Networks},
volume = {142},
pages = {34-43},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001635},
author = {Xiaoyu Zhang and Chuandong Li and Zhilong He},
keywords = {Cluster synchronization, Time-varying delay, Distributed impulsive control, Delayed impulsive control},
abstract = {This paper investigates the issue of cluster synchronization (CS) for the coupled neural networks (CNNs) with time-varying delays via the delay-dependent distributed impulsive control. A new Halanay-like inequality, where delayed impulses are taken into consideration, is proposed. Based on the Lyapunov theory and the new differential inequality, sufficient conditions of CS for delayed CNNs with fixed and switching coupling topology are obtained, respectively. Moreover, delay-dependent distributed impulsive controllers with fixed or switching topology are designed thereby. Finally, we present a numerical example of CNNs with fixed or switching coupling to verify the effectiveness of our results, respectively.}
}
@article{GRIDACH2021274,
title = {PyDiNet: Pyramid Dilated Network for medical image segmentation},
journal = {Neural Networks},
volume = {140},
pages = {274-281},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001118},
author = {Mourad Gridach},
keywords = {Dilated convolution, Deep neural networks, Medical image segmentation, PyramiD Dilated Network},
abstract = {Medical image segmentation is an important step in many generic applications such as population analysis and, more accessible, can be made into a crucial tool in diagnosis and treatment planning. Previous approaches are based on two main architectures: fully convolutional networks and U-Net-based architecture. These methods rely on multiple pooling and striding layers leading to the loss of important spatial information and fail to capture details in medical images. In this paper, we propose a novel neural network called PyDiNet (Pyramid Dilated Network) to capture small and complex variations in medical images while preserving spatial information. To achieve this goal, PyDiNet uses a newly proposed pyramid dilated module (PDM), which consists of multiple dilated convolutions stacked in parallel. We combine several PDM modules to form the final PyDiNet architecture. We applied the proposed PyDiNet to different medical image segmentation tasks. Experimental results show that the proposed model achieves new state-of-the-art performance on three medical image segmentation benchmarks. Furthermore, PyDiNet was very competitive on the 2020 Endoscopic Artifact Detection challenge.}
}
@article{PANDA2021120,
title = {Implicit adversarial data augmentation and robustness with Noise-based Learning},
journal = {Neural Networks},
volume = {141},
pages = {120-132},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001350},
author = {Priyadarshini Panda and Kaushik Roy},
keywords = {Adversarial robustness, Deep learning, Principal Component Analysis},
abstract = {We introduce a Noise-based Learning (NoL) approach for training neural networks that are intrinsically robust to adversarial attacks. We find that the learning of random noise introduced with the input with the same loss function used during posterior maximization, improves a model’s adversarial resistance. We show that the learnt noise performs implicit adversarial data augmentation boosting a model’s adversary generalization capability. We evaluate our approach’s efficacy and provide a simplistic visualization tool for understanding adversarial data, using Principal Component Analysis. We conduct comprehensive experiments on prevailing benchmarks such as MNIST, CIFAR10, CIFAR100, Tiny ImageNet and show that our approach performs remarkably well against a wide range of attacks. Furthermore, combining NoL with state-of-the-art defense mechanisms, such as adversarial training, consistently outperforms prior techniques in both white-box and black-box attacks.}
}
@article{LI2021281,
title = {H∞ estimation for stochastic semi-Markovian switching CVNNs with missing measurements and mode-dependent delays},
journal = {Neural Networks},
volume = {141},
pages = {281-293},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001593},
author = {Qiang Li and Jinling Liang and Hong Qu},
keywords = {Complex-valued neural networks, Semi-Markovian switching, Missing measurements, Stochastic disturbances,  performance, Mode-dependent delay},
abstract = {This article is devoted to the H∞ estimation problem for stochastic semi-Markovian switching complex-valued neural networks subject to incomplete measurement outputs, where the time-varying delay also depends on another semi-Markov process. A sequence of random variables with known statistical property is introduced to depict the missing measurement phenomenon. Based on the generalized Itoˆ’s formula in complex form concerning with the semi-Markovian systems, complex-valued reciprocal convex inequality as well as intensive stochastic analysis method, some mode-dependent sufficient conditions are presented guaranteeing the estimation error system to be exponentially mean-square stable with a prespecified H∞ disturbance attenuation level. In addition, the mode-dependent estimator gain matrices are appropriately designed according to the feasible solutions of certain complex matrix inequalities. In the end, one numerical example is provided to illustrate effectiveness of the theoretical results.}
}
@article{RYAN202187,
title = {Real-time face & eye tracking and blink detection using event cameras},
journal = {Neural Networks},
volume = {141},
pages = {87-97},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001076},
author = {Cian Ryan and Brian O’Sullivan and Amr Elrasad and Aisling Cahill and Joe Lemley and Paul Kielty and Christoph Posch and Etienne Perot},
keywords = {Event cameras, Convolutional neural network, Driver monitoring system},
abstract = {Event cameras contain emerging, neuromorphic vision sensors that capture local-light​ intensity changes at each pixel, generating a stream of asynchronous events. This way of acquiring visual information constitutes a departure from traditional frame-based cameras and offers several significant advantages — low energy consumption, high temporal resolution, high dynamic range and low latency. Driver monitoring systems (DMS) are in-cabin safety systems designed to sense and understand a drivers physical and cognitive state. Event cameras are particularly suited to DMS due to their inherent advantages. This paper proposes a novel method to simultaneously detect and track faces and eyes for driver monitoring. A unique, fully convolutional recurrent neural network architecture is presented. To train this network, a synthetic event-based dataset is simulated with accurate bounding box annotations, called Neuromorphic-HELEN. Additionally, a method to detect and analyse drivers’ eye blinks is proposed, exploiting the high temporal resolution of event cameras. Behaviour of blinking provides greater insights into a driver level of fatigue or drowsiness. We show that blinks have a unique temporal signature that can be better captured by event cameras.}
}
@article{MIAO2021201,
title = {D-MONA: A dilated mixed-order non-local attention network for speaker and language recognition},
journal = {Neural Networks},
volume = {139},
pages = {201-211},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000940},
author = {Xiaoxiao Miao and Ian McLoughlin and Wenchao Wang and Pengyuan Zhang},
keywords = {Speaker/language recognition, Mixed-order attention, Non-local attention, Dilated network},
abstract = {Attention-based convolutional neural network (CNN) models are increasingly being adopted for speaker and language recognition (SR/LR) tasks. These include time, frequency, spatial and channel attention, which can focus on useful time frames, frequency bands, regions or channels while extracting features. However, these traditional attention methods lack the exploration of complex information and multi-scale long-range speech feature interactions, which can benefit SR/LR tasks. To address these issues, this paper firstly proposes mixed-order attention (MOA) for low frame-level speech features to gain the finest grain multi-order information at higher resolution. We then combine that with a non-local attention (NLA) mechanism and a dilated residual structure to balance fine grained local detail with convolution from multi-scale long-range time/frequency regions in feature space. The proposed dilated mixed-order non-local attention network (D-MONA) exploits the detail available from the first and the second-order feature attention analysis, but achieves this over a much wider context than purely local attention. Experiments are conducted on three datasets, including two SR tasks of Voxceleb and CN-celeb, and one LR task, NIST LRE 07. For SR, D-MONA improves on ResNet-34 results by at least 29% and 15% for Voxceleb1 and CN-celeb respectively. For the LR task, a large improvement is achieved over ResNet-34 of 21% for the challenging 3s utterance condition, 59% for the 10s condition and 67% for the 30s condition. It also outperforms the state-of-the-art deep bottleneck feature-DNN (DBF-DNN) x-vector system at all scales.}
}
@article{LING2021223,
title = {Stochastic quasi-synchronization of heterogeneous delayed impulsive dynamical networks via single impulsive control},
journal = {Neural Networks},
volume = {139},
pages = {223-236},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000915},
author = {Guang Ling and Ming-Feng Ge and Xinghua Liu and Gaoxi Xiao and Qingju Fan},
keywords = {Stochastic quasi-synchronization, Heterogeneous dynamical networks, Impulsive coupling, Time-varying delays, Single impulsive control},
abstract = {This paper investigates the quasi-synchronization problem of the stochastic heterogeneous complex dynamical networks with impulsive couplings and multiple time-varying delays. It is shown that this kind of dynamical networks can achieve exponential quasi-synchronization by exerting impulsive control added on only one chosen pinning node. By employing the Lyapunov stability theory, some sufficient criteria on quasi-synchronization for this dynamical network are established, revealing the relationship between the quasi-synchronization performance and the stochastic perturbations as well as the frequency and strength of impulsive coupling. Finally, some numerical examples are used to illustrate the effectiveness of the main results.}
}
@article{SHEN2021162,
title = {Multistability and associative memory of neural networks with Morita-like activation functions},
journal = {Neural Networks},
volume = {142},
pages = {162-170},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.035},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001726},
author = {Yuanchu Shen and Song Zhu and Xiaoyang Liu and Shiping Wen},
keywords = {Multistability, Neural networks, Morita-like functions, Associative memory},
abstract = {This paper presents the multistability analysis and associative memory of neural networks (NNs) with Morita-like activation functions. In order to seek larger memory capacity, this paper proposes Morita-like activation functions. In a weakened condition, this paper shows that the NNs with n-neurons have (2m+1)n equilibrium points (Eps) and (m+1)n of them are locally exponentially stable, where the parameter m depends on the Morita-like activation functions, called Morita parameter. Also the attraction basins are estimated based on the state space partition. Moreover, this paper applies these NNs into associative memories (AMs). Compared with the previous related works, the number of Eps and AM’s memory capacity are extensively increased. The simulation results are illustrated and some reliable associative memories examples are shown at the end of this paper.}
}
@article{ZIRKLE202130,
title = {Noise effect on the temporal patterns of neural synchrony},
journal = {Neural Networks},
volume = {141},
pages = {30-39},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001209},
author = {Joel Zirkle and Leonid L. Rubchinsky},
keywords = {Intermittency, Synchrony, Phase-locking, Neural oscillations, Stochasticity, Channel noise},
abstract = {Neural synchrony in the brain is often present in an intermittent fashion, i.e., there are intervals of synchronized activity interspersed with intervals of desynchronized activity. A series of experimental studies showed that this kind of temporal patterning of neural synchronization may be very specific and may be correlated with behaviour (even if the average synchrony strength is not changed). Prior studies showed that a network with many short desynchronized intervals may be functionally different from a network with few long desynchronized intervals as it may be more sensitive to synchronizing input signals. In this study, we investigated the effect of channel noise on the temporal patterns of neural synchronization. We employed a small network of conductance-based model neurons that were mutually connected via excitatory synapses. The resulting dynamics of the network was studied using the same time-series analysis methods as used in prior experimental and computational studies. While it is well known that synchrony strength generally degrades with noise, we found that noise also affects the temporal patterning of synchrony. Noise, at a sufficient intensity (yet too weak to substantially affect synchrony strength), promotes dynamics with predominantly short (although potentially very numerous) desynchronizations. Thus, channel noise may be one of the mechanisms contributing to the short desynchronization dynamics observed in multiple experimental studies.}
}
@article{ZHANG202177,
title = {Dense Residual Network: Enhancing global dense feature flow for character recognition},
journal = {Neural Networks},
volume = {139},
pages = {77-85},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000472},
author = {Zhao Zhang and Zemin Tang and Yang Wang and Zheng Zhang and Choujun Zhan and Zhengjun Zha and Meng Wang},
keywords = {Global dense block, Fast dense residual network, Down-sampling block, Global dense residual learning, Text image representation and recognition},
abstract = {Deep Convolutional Neural Networks (CNNs), such as Dense Convolutional Network (DenseNet), have achieved great success for image representation learning by capturing deep hierarchical features. However, most existing network architectures of simply stacking the convolutional layers fail to enable them to fully discover local and global feature information between layers. In this paper, we mainly investigate how to enhance the local and global feature learning abilities of DenseNet by fully exploiting the hierarchical features from all convolutional layers. Technically, we propose an effective convolutional deep model termed Dense Residual Network (DRN) for the task of optical character recognition. To define DRN, we propose a refined residual dense block (r-RDB) to retain the ability of local feature fusion and local residual learning of original RDB, which can reduce the computing efforts of inner layers at the same time. After fully capturing local residual dense features, we utilize the sum operation and several r-RDBs to construct a new block termed global dense block (GDB) by imitating the construction of dense blocks to adaptively learn global dense residual features in a holistic way. Finally, we use two convolutional layers to design a down-sampling block to reduce the global feature size and extract more informative deeper features. Extensive results show that our DRN can deliver enhanced results, compared with other related deep models.}
}
@article{HUANG2021344,
title = {Bifurcations in a fractional-order BAM neural network with four different delays},
journal = {Neural Networks},
volume = {141},
pages = {344-354},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001325},
author = {Chengdai Huang and Juan Wang and Xiaoping Chen and Jinde Cao},
keywords = {Multiple delays, Stability, Hopf bifurcation, Fractional-order BAM neural networks},
abstract = {This paper illuminates the issue of bifurcations for a fractional-order bidirectional associative memory neural network(FOBAMNN) with four different delays. On account of the affirmatory presumption, the developed FOBAMNN is firstly transformed into the one with two nonidentical delays. Then the critical values of Hopf bifurcations with respect to disparate delays are calculated quantitatively by establishing one delay and selecting remaining delay as a bifurcation parameter in the transformed model. It detects that the stability of the developed FOBAMNN with multiple delays can be fairly preserved if selecting lesser control delays, and Hopf bifurcation emerges once the control delays outnumber their critical values. The derived bifurcation results are numerically testified via the bifurcation graphs. The feasibility of theoretical analysis is ultimately corroborated in the light of simulation experiments. The analytic results available in this paper are beneficial to give impetus to resolve the issues of bifurcations of high-order FONNs with multiple delays.}
}
@article{GU2021385,
title = {CRaDLe: Deep code retrieval based on semantic Dependency Learning},
journal = {Neural Networks},
volume = {141},
pages = {385-394},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001568},
author = {Wenchao Gu and Zongjie Li and Cuiyun Gao and Chaozheng Wang and Hongyu Zhang and Zenglin Xu and Michael R. Lyu},
keywords = {Code retrieval, Semantic dependency, Dependency learning, Neural network},
abstract = {Code retrieval is a common practice for programmers to reuse existing code snippets in the open-source repositories. Given a user query (i.e., a natural language description), code retrieval aims at searching the most relevant ones from a set of code snippets. The main challenge of effective code retrieval lies in mitigating the semantic gap between natural language descriptions and code snippets. With the ever-increasing amount of available open-source code, recent studies resort to neural networks to learn the semantic matching relationships between the two sources. The statement-level dependency information, which highlights the dependency relations among the program statements during the execution, reflects the structural importance of one statement in the code, which is favorable for accurately capturing the code semantics but has never been explored for the code retrieval task. In this paper, we propose CRaDLe, a novel approach for Code Retrieval based on statement-level semantic Dependency Learning. Specifically, CRaDLe distills code representations through fusing both the dependency and semantic information at the statement level, and then learns a unified vector representation for each code and description pair for modeling the matching relationship. Comprehensive experiments and analysis on real-world datasets show that the proposed approach can accurately retrieve code snippets for a given query and significantly outperform the state-of-the-art approaches on the task.}
}
@article{LI2021130,
title = {Understanding the message passing in graph neural networks via power iteration clustering},
journal = {Neural Networks},
volume = {140},
pages = {130-135},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000757},
author = {Xue Li and Yuanzhi Cheng},
keywords = {Graph neural networks, Message passing, Power iteration, Subspace power iteration clustering},
abstract = {The mechanism of message passing in graph neural networks (GNNs) is still mysterious. Apart from convolutional neural networks, no theoretical origin for GNNs has been proposed. To our surprise, message passing can be best understood in terms of power iteration. By fully or partly removing activation functions and layer weights of GNNs, we propose subspace power iteration clustering (SPIC) models that iteratively learn with only one aggregator. Experiments show that our models extend GNNs and enhance their capability to process random featured networks. Moreover, we demonstrate the redundancy of some state-of-the-art GNNs in design and define a lower limit for model evaluation by a random aggregator of message passing. Our findings push the boundaries of the theoretical understanding of neural networks.}
}
@article{XIE2021168,
title = {Cross Knowledge-based Generative Zero-Shot Learning approach with Taxonomy Regularization},
journal = {Neural Networks},
volume = {139},
pages = {168-178},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000514},
author = {Cheng Xie and Hongxin Xiang and Ting Zeng and Yun Yang and Beibei Yu and Qing Liu},
keywords = {Zero-Shot Learning, Image recognition, Generative Adversarial Network, Knowledge engineering},
abstract = {Although zero-shot learning (ZSL) has an inferential capability of recognizing new classes that have never been seen before, it always faces two fundamental challenges of the cross modality and cross-domain challenges. In order to alleviate these problems, we develop a generative network-based ZSL approach equipped with the proposed Cross Knowledge Learning (CKL) scheme and Taxonomy Regularization (TR). In our approach, the semantic features are taken as inputs, and the output is the synthesized visual features generated from the corresponding semantic features. CKL enables more relevant semantic features to be trained for semantic-to-visual feature embedding in ZSL, while Taxonomy Regularization (TR) significantly improves the intersections with unseen images with more generalized visual features generated from generative network. Extensive experiments on several benchmark datasets (i.e., AwA1, AwA2, CUB, NAB and aPY) show that our approach is superior to these state-of-the-art methods in terms of ZSL image classification and retrieval.}
}
@article{NAKAMURA2021348,
title = {Block-cyclic stochastic coordinate descent for deep neural networks},
journal = {Neural Networks},
volume = {139},
pages = {348-357},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001283},
author = {Kensuke Nakamura and Stefano Soatto and Byung-Woo Hong},
keywords = {Coordinate descent, Deep neural network, Energy optimization, Stochastic gradient descent},
abstract = {We present a stochastic first-order optimization algorithm, named block-cyclic stochastic coordinate descent (BCSC), that adds a cyclic constraint to stochastic block-coordinate descent in the selection of both data and parameters. It uses different subsets of the data to update different subsets of the parameters, thus limiting the detrimental effect of outliers in the training set. Empirical tests in image classification benchmark datasets show that BCSC outperforms state-of-the-art optimization methods in generalization leading to higher accuracy within the same number of update iterations. The improvements are consistent across different architectures and datasets, and can be combined with other training techniques and regularizations.}
}
@article{MACIAG2021118,
title = {Unsupervised Anomaly Detection in Stream Data with Online Evolving Spiking Neural Networks},
journal = {Neural Networks},
volume = {139},
pages = {118-139},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000599},
author = {Piotr S. Maciąg and Marzena Kryszkiewicz and Robert Bembenik and Jesus L. Lobo and Javier {Del Ser}},
keywords = {Evolving Spiking Neural Networks, Outliers detection, Online learning, Time series data, Unsupervised anomaly detection, Stream data},
abstract = {Unsupervised anomaly discovery in stream data is a research topic with many practical applications. However, in many cases, it is not easy to collect enough training data with labeled anomalies for supervised learning of an anomaly detector in order to deploy it later for identification of real anomalies in streaming data. It is thus important to design anomalies detectors that can correctly detect anomalies without access to labeled training data. Our idea is to adapt the Online evolving Spiking Neural Network (OeSNN) classifier to the anomaly detection task. As a result, we offer an Online evolving Spiking Neural Network for Unsupervised Anomaly Detection algorithm (OeSNN-UAD), which, unlike OeSNN, works in an unsupervised way and does not separate output neurons into disjoint decision classes. OeSNN-UAD uses our proposed new two-step anomaly detection method. Also, we derive new theoretical properties of neuronal model and input layer encoding of OeSNN, which enable more effective and efficient detection of anomalies in our OeSNN-UAD approach. The proposed OeSNN-UAD detector was experimentally compared with state-of-the-art unsupervised and semi-supervised detectors of anomalies in stream data from the Numenta Anomaly Benchmark and Yahoo Anomaly Datasets repositories. Our approach outperforms the other solutions provided in the literature in the case of data streams from the Numenta Anomaly Benchmark repository. Also, in the case of real data files of the Yahoo Anomaly Benchmark repository, OeSNN-UAD outperforms other selected algorithms, whereas in the case of Yahoo Anomaly Benchmark synthetic data files, it provides competitive results to the results recently reported in the literature.}
}
@article{KIM2021148,
title = {Uncorrelated feature encoding for faster image style transfer},
journal = {Neural Networks},
volume = {140},
pages = {148-157},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000873},
author = {Minseong Kim and Hyun-Chul Choi},
keywords = {Uncorrelated feature encoding, Uncorrelation loss, Image style transfer, Convolutional neural networks, End-to-end learning, Redundant channel elimination},
abstract = {Recent image style transfer methods use a pre-trained convolutional neural network as their feature encoder. However, the pre-trained network is not optimal for image style transfer but rather for image classification. Furthermore, they require time-consuming feature alignment to consider the existing correlation among channels of the encoded feature map. In this paper, we propose an end-to-end learning method that optimizes both encoder and decoder networks for style transfer task and relieves the computational complexity of the existing correlation-aware feature alignment. First, we performed end-to-end learning that updates not only decoder but also encoder parameters for the task of image style transfer in the network training phase. Second, in addition to the previous style and content losses, we use uncorrelation loss, i.e., the total correlation coefficient among responses of encoder channels. Our uncorrelation loss allows the encoder network to generate a feature map of channels without correlation. Subsequently, our method results in faster forward processing with only a light-weighted transformer of correlation-unaware feature alignment. Moreover, our method drastically reduced the channel redundancy of the encoded feature during the network training process. This provides us a possibility to perform channel elimination with negligible degradation in generated style quality. Our method is applicable to multiple scaled style transfer by using the cascade network scheme and allows a user to control style strength through the usage of a content-style trade-off parameter.}
}
@article{WANG2021199,
title = {Modeling the grid cell activity on non-horizontal surfaces based on oscillatory interference modulated by gravity},
journal = {Neural Networks},
volume = {141},
pages = {199-210},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001441},
author = {Yihong Wang and Xuying Xu and Rubin Wang},
keywords = {Grid cell, Navigation, Neural encoding, Spatial cognition, Three-dimensional space},
abstract = {Internal representation of the space is a fundamental and crucial function of the animal’s brain. Grid cells in the medial entorhinal cortex are thought to provide an environment-invariant metric system for the navigation of the animal. Most experimental and theoretical studies have focused on the horizontal planar codes of grid cell, while how this metric coordinate system is configured in the actual three-dimensional space remains unclear. Evidence has implied the spatial cognition may not be fully volumetric. We proposed an oscillatory interference model with a novel gravity and body plane modulation to simulate grid cell activity in complex space for rodents. The animal can perceive the rotation of its body plane along the local surface by sensing the gravity, causing the modulation to the dendritic oscillations. The results not only reproduce the firing patterns of the grid cell recorded from known experiments, but also predict the grid codes in novel environments. It further demonstrates that the gravity signal is indispensable for the animal’s navigation, and supports the hypothesis that the periodic firing of the grid cell is intrinsically not a volumetric code in three-dimensional space. This will provide new insights to understand the spatial representation of the actual world in the brain.}
}
@article{DANG2021128,
title = {Why grid cells function as a metric for space},
journal = {Neural Networks},
volume = {142},
pages = {128-137},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001684},
author = {Suogui Dang and Yining Wu and Rui Yan and Huajin Tang},
keywords = {Grid cell, Place cell, Metric, Navigation},
abstract = {The brain is able to calculate the distance and direction to the desired position based on grid cells. Extensive neurophysiological studies of rodent navigation have postulated the grid cells function as a metric for space, and have inspired many computational studies to develop innovative navigation approaches. Furthermore, grid cells may provide a general encoding scheme for high-order nonspatial information. Built upon existing neuroscience and machine learning work, this paper provides theoretical clarity on that the grid cell population codes can be taken as a metric for space. The metric is generated by a shift-invariant positive definite kernel via kernel distance method and embeds isometrically in a Euclidean space, and the inner product of the grid cell population code exponentially converges to the kernel. We also provide a method to learn the distribution of grid cell population efficiently. Grid cells, as a scalable position encoding method, can encode the spatial relationships of places and enable grid cells to outperform place cells in navigation. Further, we extend the grid cell to images encoding and find that grid cells embed images into a mental map, where geometric relationships are conceptual relationships of images. The theoretical model and analysis would contribute to establishing the grid cell code as a generic coding scheme for both spatial and conceptual spaces, and is promising for a multitude of problems across spatial cognition, machine learning and semantic cognition.}
}
@article{DONG202140,
title = {Synchronization for stochastic coupled networks with Lévy noise via event-triggered control},
journal = {Neural Networks},
volume = {141},
pages = {40-51},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001167},
author = {Hailing Dong and Ming Luo and Mingqing Xiao},
keywords = {Almost sure synchronization, Markovian switching, Lévy noise, Event-triggered control},
abstract = {This paper addresses the realization of almost sure synchronization problem for a new array of stochastic networks associated with delay and Lévy noise via event-triggered control. The coupling structure of the network is governed by a continuous-time homogeneous Markov chain. The nodes in the networks communicate with each other and update their information only at discrete-time instants so that the network workload can be minimized. Under the framework of stochastic process including Markov chain and Lévy process, and the convergence theorem of non-negative semi-martingales, we show that the Markovian coupled networks can achieve the almost sure synchronization by event-triggered control methodology. The results are further extended to the directed topology, where the coupling structure can be asymmetric. Furthermore, we also proved that the Zeno behavior can be excluded under our proposed approach, indicating that our framework is practically feasible. Numerical simulations are provided to demonstrate the effectiveness of the obtained theoretical results.}
}
@article{LIU2021237,
title = {Keyword spotting techniques to improve the recognition accuracy of user-defined keywords},
journal = {Neural Networks},
volume = {139},
pages = {237-245},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000927},
author = {Li Liu and Mingxue Yang and Xinyi Gao and Qingsong Liu and Zhengxi Yuan and Jun Zhou},
keywords = {Keyword spotting, User-defined keywords, Incremental training},
abstract = {The existing keyword spotting (KWS) techniques can recognize pre-defined keywords well but have a poor recognition accuracy for user-defined keywords. In real use cases, there is a high demand for users to define their keywords for various reasons. To address the problem, in this work, three techniques have been proposed, including incremental training with revised loss function, data augmentation, and fine-grained training, to improve the accuracy for the user-defined keywords while maintaining high accuracy for pre-defined keywords. The proposed techniques are applied to a classical KWS model (cnn-trad-fpool3) and a state-of-the-art KWS model (res15) respectively. The experimental results show that the proposed techniques have better recognition accuracy than several existing methods for the recognition of use-defined keywords. With the proposed techniques, the recognition accuracy of user-defined keywords on cnn-trad-fpool3 and res15 are significantly improved by 21.78% and 24.42%, respectively.}
}
@article{DENG2021358,
title = {A noisy label and negative sample robust loss function for DNN-based distant supervised relation extraction},
journal = {Neural Networks},
volume = {139},
pages = {358-370},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001180},
author = {Lihui Deng and Bo Yang and Zhongfeng Kang and Shantian Yang and Shihu Wu},
keywords = {Loss function, Noisy label learning, Class imbalance, Distant supervised relation extraction, Gradient analysis},
abstract = {As a major method for relation extraction, distantly supervised relation extraction (DSRE) suffered from the noisy label problem and class imbalance problem (these two problems are also common for many other NLP tasks, e.g., text classification). However, there seems no existing research in DSRE or other NLP tasks that can simultaneously solve both problems, which is a significant insufficiency in related researches. In this paper, we propose a loss function which is robust to noisy label and efficient for the imbalanced class dataset. More specific, first we quantify the negative impacts of the noisy label and class imbalance problems. And then we construct a loss function that can minimize these negative impacts through a linear programming method. As far as we know, this seems to be the first attempt to address the noisy label problem and class imbalance problem simultaneously. We evaluated the constructed loss function on the distantly labeled dataset, our artificially noised dataset, human-annotated dataset of Docred, as well as the artificially noised dataset of CoNLL 2003. Experimental results indicate that a DNN model adopting the constructed loss function can outperform other models that adopt the state-of-the-art noisy label robust or negative sample robust loss functions.}
}
@article{TSANTEKIDIS2021193,
title = {Diversity-driven knowledge distillation for financial trading using Deep Reinforcement Learning},
journal = {Neural Networks},
volume = {140},
pages = {193-202},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000769},
author = {Avraam Tsantekidis and Nikolaos Passalis and Anastasios Tefas},
keywords = {Deep Reinforcement Learning, Financial markets, Trading},
abstract = {Deep Reinforcement Learning (RL) is increasingly used for developing financial trading agents for a wide range of tasks. However, optimizing deep RL agents is notoriously difficult and unstable, especially in noisy financial environments, significantly hindering the performance of trading agents. In this work, we present a novel method that improves the training reliability of DRL trading agents building upon the well-known approach of neural network distillation. In the proposed approach, teacher agents are trained in different subsets of RL environment, thus diversifying the policies they learn. Then student agents are trained using distillation from the trained teachers to guide the training process, allowing for better exploring the solution space, while “mimicking” an existing policy/trading strategy provided by the teacher model. The boost in effectiveness of the proposed method comes from the use of diversified ensembles of teachers trained to perform trading for different currencies. This enables us to transfer the common view regarding the most profitable policy to the student, further improving the training stability in noisy financial environments. In the conducted experiments we find that when applying distillation, constraining the teacher models to be diversified can significantly improve their performance of the final student agents. We demonstrate this by providing an extensive evaluation on various financial trading tasks. Furthermore, we also provide additional experiments in the separate domain of control in games using the Procgen environments in order to demonstrate the generality of the proposed method.}
}
@article{MORALA202157,
title = {Towards a mathematical framework to inform neural network modelling via polynomial regression},
journal = {Neural Networks},
volume = {142},
pages = {57-72},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001738},
author = {Pablo Morala and Jenny Alexandra Cifuentes and Rosa E. Lillo and Iñaki Ucar},
keywords = {Polynomial regression, Neural networks, Machine learning},
abstract = {Even when neural networks are widely used in a large number of applications, they are still considered as black boxes and present some difficulties for dimensioning or evaluating their prediction error. This has led to an increasing interest in the overlapping area between neural networks and more traditional statistical methods, which can help overcome those problems. In this article, a mathematical framework relating neural networks and polynomial regression is explored by building an explicit expression for the coefficients of a polynomial regression from the weights of a given neural network, using a Taylor expansion approach. This is achieved for single hidden layer neural networks in regression problems. The validity of the proposed method depends on different factors like the distribution of the synaptic potentials or the chosen activation function. The performance of this method is empirically tested via simulation of synthetic data generated from polynomials to train neural networks with different structures and hyperparameters, showing that almost identical predictions can be obtained when certain conditions are met. Lastly, when learning from polynomial generated data, the proposed method produces polynomials that approximate correctly the data locally.}
}
@article{CHEN2021238,
title = {A dual-stream deep attractor network with multi-domain learning for speech dereverberation and separation},
journal = {Neural Networks},
volume = {141},
pages = {238-248},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100160X},
author = {Hangting Chen and Pengyuan Zhang},
keywords = {Speech separation, Dereverberation, Deep attractor network, Time-domain network},
abstract = {Deep attractor networks (DANs) perform speech separation with discriminative embeddings and speaker attractors. Compared with methods based on the permutation invariant training (PIT), DANs define a deep embedding space and deliver a more elaborate representation on each time–frequency (T–F) bin. However, it has been observed that the DANs achieve limited improvement on the signal quality if directly deployed in a reverberant environment. Following the success of time-domain separation networks on the clean mixture speech, we propose a dual-stream DAN with multi-domain learning to efficiently perform both dereverberation and separation tasks under the condition of variable numbers of speakers. The speaker encoding stream (SES) of the dual-stream DAN is trained to model the speaker information in the embedding space defined with the Fourier transform kernels. The speech decoding stream (SDS) accepts speaker attractors from the SES and learns to estimate the early component of the sound in the time domain. Meanwhile, additional clustering losses are used to bridge the gap between the oracle and the estimated attractors. Experiments were conducted on the Spatialized Multi-Speaker Wall Street Journal (SMS-WSJ) dataset. After comparing with the anechoic and reverberant signals, the early component was chosen as the learning targets. The experimental results demonstrated that the dual-stream DAN achieved scale-invariant source-to-distortion ratio (SI-SDR) improvement of 9.8∕7.5 dB on the reverberant 2-/3-speaker evaluation set, exceeding the baseline DAN and convolutional time-domain audio separation network (Conv-TasNet) by 2.0∕0.7 dB and 1.0∕0.5 dB, respectively.}
}
@article{ZHOU2021213,
title = {Self-selective attention using correlation between instances for distant supervision relation extraction},
journal = {Neural Networks},
volume = {142},
pages = {213-220},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001696},
author = {Yanru Zhou and Limin Pan and Chongyou Bai and Senlin Luo and Zhouting Wu},
keywords = {Distant supervision relation extraction, Convolution neural network, Self-attention mechanism},
abstract = {Distant supervision relation extraction methods are widely used to extract relational facts in text. The traditional selective attention model regards instances in the bag as independent of each other, which makes insufficient use of correlation information between instances and supervision information of all correctly labeled instances, affecting the performance of relation extractor. Aiming at this problem, a distant supervision relation extraction method with self-selective attention is proposed. The method uses a layer of convolution and self-attention mechanism to encode instances to learn the better semantic vector representation of instances. The correlation between instances in the bag is used to assign a higher weight to all correctly labeled instances, and the weighted summation of instances in the bag is used to obtain a bag vector representation. Experiments on the NYT dataset show that the method can make full use of the information of all correctly labeled instances in the bag. The method can achieve better results as compared with baselines.}
}
@article{NALLANTHIGHAL2021211,
title = {Deep learning architectures for estimating breathing signal and respiratory parameters from speech recordings},
journal = {Neural Networks},
volume = {141},
pages = {211-224},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001179},
author = {Venkata Srikanth Nallanthighal and Zohreh Mostaani and Aki Härmä and Helmer Strik and Mathew Magimai-Doss},
keywords = {Speech breathing, Signal processing, Deep neural networks, Respiratory parameters, Speech technology},
abstract = {Respiration is an essential and primary mechanism for speech production. We first inhale and then produce speech while exhaling. When we run out of breath, we stop speaking and inhale. Though this process is involuntary, speech production involves a systematic outflow of air during exhalation characterized by linguistic content and prosodic factors of the utterance. Thus speech and respiration are closely related, and modeling this relationship makes sensing respiratory dynamics directly from the speech plausible, however is not well explored. In this article, we conduct a comprehensive study to explore techniques for sensing breathing signal and breathing parameters from speech using deep learning architectures and address the challenges involved in establishing the practical purpose of this technology. Estimating the breathing pattern from the speech would give us information about the respiratory parameters, thus enabling us to understand the respiratory health using one’s speech.}
}
@article{ZHAO2021100,
title = {Smoothing inertial neurodynamic approach for sparse signal reconstruction via Lp-norm minimization},
journal = {Neural Networks},
volume = {140},
pages = {100-112},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000484},
author = {You Zhao and Xiaofeng Liao and Xing He and Rongqiang Tang and Weiwei Deng},
keywords = {-norm minimization problem, Sparse signals reconstruction, Smoothing inertial neurodynamic approach, KKT condition},
abstract = {In this paper, we propose a smoothing inertial neurodynamic approach (SINA) which is used to deal with Lp-norm minimization problem to reconstruct sparse signals. Note that the considered optimization problem is nonsmooth, nonconvex and non-Lipschitz. First, the problem is transformed into a smooth optimization problem based on smoothing approximation method, and the Lipschitz property of gradient of the smooth objective function is discussed. Then, SINA based on Karush–Kuhn–Tucker (KKT) condition, smoothing approximation and inertial dynamical approach, is designed to handle smooth optimization problem. The existence, uniqueness, global convergence and optimality of the solution of the SINA are discussed by the Cauchy–Lipschitz–Picard theorem, energy function and KKT condition. In addition, for p=1, the SINA has a mean sublinear convergence rate O1∕t under some mild conditions. Finally, some numerical examples on sparse signal reconstruction and image restoration are given to illustrate the theoretical results and the efficiency of SINA.}
}
@article{TANG2021105,
title = {Probabilistic learning vector quantization on manifold of symmetric positive definite matrices},
journal = {Neural Networks},
volume = {142},
pages = {105-118},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001611},
author = {Fengzhen Tang and Haifeng Feng and Peter Tino and Bailu Si and Daxiong Ji},
keywords = {Probabilistic learning vector quantization, Learning vector quantization, Symmetric positive definite matrices, Riemannian geodesic distances, Riemannian manifold},
abstract = {In this paper, we develop a new classification method for manifold-valued data in the framework of probabilistic learning vector quantization. In many classification scenarios, the data can be naturally represented by symmetric positive definite matrices, which are inherently points that live on a curved Riemannian manifold. Due to the non-Euclidean geometry of Riemannian manifolds, traditional Euclidean machine learning algorithms yield poor results on such data. In this paper, we generalize the probabilistic learning vector quantization algorithm for data points living on the manifold of symmetric positive definite matrices equipped with Riemannian natural metric (affine-invariant metric). By exploiting the induced Riemannian distance, we derive the probabilistic learning Riemannian space quantization algorithm, obtaining the learning rule through Riemannian gradient descent. Empirical investigations on synthetic data, image data , and motor imagery electroencephalogram (EEG) data demonstrate the superior performance of the proposed method.}
}
@article{ALLAIRE2021184,
title = {Emulation of wildland fire spread simulation using deep learning},
journal = {Neural Networks},
volume = {141},
pages = {184-198},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001337},
author = {Frédéric Allaire and Vivien Mallet and Jean-Baptiste Filippi},
keywords = {Deep neural network, Hybrid architecture, Mixed inputs, Numerical simulation, Fire growth prediction, Corsica},
abstract = {Numerical simulation of wildland fire spread is useful to predict the locations that are likely to burn and to support decision in an operational context, notably for crisis situations and long-term planning. For short-term, the computational time of traditional simulators is too high to be tractable over large zones like a country or part of a country, especially for fire danger mapping. This issue is tackled by emulating the area of the burned surface returned after simulation of a fire igniting anywhere in Corsica island and spreading freely during one hour, with a wide range of possible environmental input conditions. A deep neural network with a hybrid architecture is used to account for two types of inputs: the spatial fields describing the surrounding landscape and the remaining scalar inputs. After training on a large simulation dataset, the network shows a satisfactory approximation error on a complementary test dataset with a MAPE of 32.8%. The convolutional part is pre-computed and the emulator is defined as the remaining part of the network, saving significant computational time. On a 32-core machine, the emulator has a speed-up factor of several thousands compared to the simulator and the overall relationship between its inputs and output is consistent with the expected physical behavior of fire spread. This reduction in computational time allows the computation of one-hour burned area map for the whole island of Corsica in less than a minute, opening new application in short-term fire danger mapping.}
}
@article{KOO2021113,
title = {Empirical strategy for stretching probability distribution in neural-network-based regression},
journal = {Neural Networks},
volume = {140},
pages = {113-120},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000800},
author = {Eunho Koo and Hyungjun Kim},
keywords = {Multilayer perceptron, Prediction error, Distribution, Loss function, Noisy input signal},
abstract = {In regression analysis under artificial neural networks, the prediction performance depends on determining the appropriate weights between layers. As randomly initialized weights are updated during back-propagation using the gradient descent procedure under a given loss function, the loss function structure can affect the performance significantly. In this study, we considered the distribution error, i.e., the inconsistency of two distributions (those of the predicted values and label), as the prediction error, and proposed weighted empirical stretching (WES) as a novel loss function to increase the overlap area of the two distributions. The function depends on the distribution of a given label, thus, it is applicable to any distribution shape. Moreover, it contains a scaling hyperparameter (β) such that the appropriate parameter value maximizes the common section of the two distributions. To test the function capability, we generated ideal distributed curves (unimodal, skewed unimodal, bimodal, and skewed bimodal) as the labels, and used the Fourier-extracted input data from the curves under a feedforward neural network. In general, WES outperformed loss functions in wide use, and the performance was robust to the various noise levels. The improved results in RMSE for the extreme domain (i.e., both tail regions of the distribution) are expected to be utilized for prediction of abnormal events in non-linear complex systems such as natural disaster and financial crisis.}
}
@article{BEGUS2021305,
title = {CiwGAN and fiwGAN: Encoding information in acoustic data to model lexical learning with Generative Adversarial Networks},
journal = {Neural Networks},
volume = {139},
pages = {305-325},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001052},
author = {Gašper Beguš},
keywords = {Artificial intelligence, Generative adversarial networks, Speech, Lexical learning, Neural network interpretability, Acoustic word embedding},
abstract = {How can deep neural networks encode information that corresponds to words in human speech into raw acoustic data? This paper proposes two neural network architectures for modeling unsupervised lexical learning from raw acoustic inputs: ciwGAN (Categorical InfoWaveGAN) and fiwGAN (Featural InfoWaveGAN). These combine Deep Convolutional GAN architecture for audio data (WaveGAN; Donahue et al., 2019) with the information theoretic extension of GAN – InfoGAN (Chen et al., 2016) – and propose a new latent space structure that can model featural learning simultaneously with a higher level classification and allows for a very low-dimension vector representation of lexical items. In addition to the Generator and Discriminator networks, the architectures introduce a network that learns to retrieve latent codes from generated audio outputs. Lexical learning is thus modeled as emergent from an architecture that forces a deep neural network to output data such that unique information is retrievable from its acoustic outputs. The networks trained on lexical items from the TIMIT corpus learn to encode unique information corresponding to lexical items in the form of categorical variables in their latent space. By manipulating these variables, the network outputs specific lexical items. The network occasionally outputs innovative lexical items that violate training data, but are linguistically interpretable and highly informative for cognitive modeling and neural network interpretability. Innovative outputs suggest that phonetic and phonological representations learned by the network can be productively recombined and directly paralleled to productivity in human speech: a fiwGAN network trained on suit and dark outputs innovative start, even though it never saw start or even a [st] sequence in the training data. We also argue that setting latent featural codes to values well beyond training range results in almost categorical generation of prototypical lexical items and reveals underlying values of each latent code. Probing deep neural networks trained on well understood dependencies in speech bears implications for latent space interpretability and understanding how deep neural networks learn meaningful representations, as well as potential for unsupervised text-to-speech generation in the GAN framework.}
}
@article{ZHAO2021326,
title = {End-to-end keyword search system based on attention mechanism and energy scorer for low resource languages},
journal = {Neural Networks},
volume = {139},
pages = {326-334},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001295},
author = {Zeyu Zhao and Wei-Qiang Zhang},
keywords = {Keyword search, End-to-end, Low resource language, Deep neural network},
abstract = {Keyword search (KWS) means searching for keywords given by the user from continuous speech. Conventional KWS systems are based on Automatic Speech Recognition (ASR), where the input speech has to be first processed by the ASR system before keyword searching. In the recent decade, as deep learning and deep neural networks (DNN) become increasingly popular, KWS systems can also be trained in an end-to-end (E2E) manner. The main advantage of E2E KWS is that there is no need for speech recognition, which makes the training and searching procedure much more straightforward than the traditional ones. This article proposes an E2E KWS model, which consists of four parts: speech encoder–decoder, query encoder–decoder, attention mechanism, and energy scorer. Firstly, the proposed model outperforms the baseline model. Secondly, we find that under various supervision, character or phoneme sequences, speech or query encoders can extract the corresponding information, resulting in different performances. Moreover, we introduce an attention mechanism and invent a novel energy scorer, where the former can help locate keywords. The latter can make final decisions by considering speech embeddings, query embeddings, and attention weights in parallel. We evaluate our model on low resource conditions with about 10-hour training data for four different languages. The experiment results prove that the proposed model can work well on low resource conditions.}
}
@article{HUSSEIN2021212,
title = {Semi-dilated convolutional neural networks for epileptic seizure prediction},
journal = {Neural Networks},
volume = {139},
pages = {212-222},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000885},
author = {Ramy Hussein and Soojin Lee and Rabab Ward and Martin J. McKeown},
keywords = {Epilepsy, Seizure prediction, EEG, Semi-dilated convolution, Wavelet transform},
abstract = {Epilepsy is a neurological brain disorder that affects ∼75 million people worldwide. Predicting epileptic seizures holds great potential for improving the quality of life of people with epilepsy, but seizure prediction solely from the Electroencephalogram (EEG) is challenging. Classical machine learning algorithms and a variety of feature engineering methods have become a mainstay in seizure prediction, yet performance has been variable. In this work, we first propose an efficient data pre-processing method that maps the time-series EEG signals into an image-like format (a “scalogram”) using continuous wavelet transform. We then develop a novel convolution module named “semi-dilated convolution” that better exploits the geometry of wavelet scalograms and nonsquare-shape images. Finally, we propose a neural network architecture named “semi-dilated convolutional network (SDCN)” that uses semi-dilated convolutions to solely expand the receptive field along the long dimension (image width) while maintaining high resolution along the short dimension (image height). Results demonstrate that the proposed SDCN architecture outperforms previous seizure prediction methods, achieving an average seizure prediction sensitivity of 98.90% for scalp EEG and 88.45–89.52% for invasive EEG.}
}
@article{LI2021335,
title = {Synchronization in finite time for variable-order fractional complex dynamic networks with multi-weights and discontinuous nodes based on sliding mode control strategy},
journal = {Neural Networks},
volume = {139},
pages = {335-347},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001210},
author = {Xia Li and Huaiqin Wu and Jinde Cao},
keywords = {Fractional complex dynamic networks, Global synchronization in finite time, Variable-order fractional derivative, Sliding mode control, Discontinuous nodes},
abstract = {This paper is concerned with the global synchronization in finite time for variable-order fractional complex dynamic networks with multi-weights, where the dynamic nodes are modeled to be discontinuous, and subject to the local Hölder nonlinear growth in a neighborhood of continuous points. Firstly, an inequality with respect to variable-order fractional derivative for convex functions is proposed. On the basis of the proposed inequality, a global convergence principle in finite time for absolutely continuous functions is developed. Secondly, based on proposed convergence principle in finite time, a new sliding mode surface is presented, and an appropriate sliding mode control law is designed to drive the trajectory of the error system to the prescribed sliding mode surface in finite time and remain on it forever. In addition, on the basis of differential inclusions theory and Lur’e Postnikov-type convex Lyapunov function approach, the sufficient conditions with respect to the global stability in finite time are established in terms of linear matrix inequalities for the error system on designed sliding mode surface. Moreover, the upper bound of the settling time is explicitly evaluated. Finally, the effectiveness and correction of synchronization strategies are illustrated through two simulation experiments.}
}
@article{CHEN2021249,
title = {A neuralized feature engineering method for entity relation extraction},
journal = {Neural Networks},
volume = {141},
pages = {249-260},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001453},
author = {Yanping Chen and Weizhe Yang and Kai Wang and Yongbin Qin and Ruizhang Huang and Qinghua Zheng},
keywords = {Feature engineering, Feature combination, Relation extraction},
abstract = {Making full use of semantic and structure information in a sentence is critical to support entity relation extraction. Neural networks use stacked neural layers to perform designated feature transformations and can automatically extract high-order abstract feature representations from raw inputs. However, because a sentence usually contains several pairs of named entities, the networks are weak when encoding semantic and structure information of a relation instance. In this paper, we propose a neuralized feature engineering approach for entity relation extraction. This approach enhances the neural network by manually designed features, which have the advantage of using prior knowledge and experience developed in feature-based models. Neuralized feature engineering encodes manually designed features into distributed representations to increase the discriminability of a neural network. Experiments show that this approach considerably improves the performance compared to that of neural networks or feature-based models alone, exceeding state-of-the-art performance by more than 8% and 16.5% in terms of F1-score on the ACE corpus and the Chinese literature text corpus, respectively.}
}
@article{YANG2021133,
title = {Residual wide-kernel deep convolutional auto-encoder for intelligent rotating machinery fault diagnosis with limited samples},
journal = {Neural Networks},
volume = {141},
pages = {133-144},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001301},
author = {Daoguang Yang and Hamid Reza Karimi and Kangkang Sun},
keywords = {Deep learning, Convolutional auto-encoder (CAE), Rotating machine fault diagnosis, Raw vibration signals, Residual learning, Limited samples},
abstract = {This paper deals with the development of a novel deep learning framework to achieve highly accurate rotating machinery fault diagnosis using residual wide-kernel deep convolutional auto-encoder. Unlike most existing methods, in which the input data is processed by fast Fourier transform (FFT) and wavelet transform, this paper aims to learn important features from limited raw vibration signals. Firstly, the wide-kernel convolutional layer is introduced in the convolutional auto-encoder that can ensure the model can learn effective features from the data without any signal processing. Secondly, the residual learning block is introduced in convolutional auto-encoder that can ensure the model with sufficient depth without gradient vanishing and overfitting problems. Thirdly, convolutional auto-encoder can learn constructive features without massive data. To evaluate the performance of the proposed model, Case Western Reserve University (CWRU) bearing dataset and Southeast University (SEU) gearbox dataset are used to test. The experiment results and comparisons verify the denoising and feature extraction ability of the proposed model in the case of very few training samples.}
}
@article{LI2021225,
title = {Deep neural network-based generalized sidelobe canceller for dual-channel far-field speech recognition},
journal = {Neural Networks},
volume = {141},
pages = {225-237},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001544},
author = {Guanjun Li and Shan Liang and Shuai Nie and Wenju Liu and Zhanlei Yang},
keywords = {Deep neural network, Generalized sidelobe canceller, Dual-channel, Far-field speech recognition},
abstract = {The traditional generalized sidelobe canceller (GSC) is a common speech enhancement front end to improve the noise robustness of automatic speech recognition (ASR) systems in the far-field cases. However, the traditional GSC is optimized based on the signal level criteria, causing it not to guarantee the optimal ASR performance. To address this issue, we propose a novel dual-channel deep neural network (DNN)-based GSC structure, called nnGSC, which is optimized by using the objective of maximizing the ASR performance. Our key idea is to make each module of the traditional GSC fully learnable and use the acoustic model to perform joint optimization with GSC. We use the coefficients of the traditional GSC to initialize nnGSC, so that both traditional signal processing knowledge and large amounts of data can be used to guide the network learning. In addition, nnGSC can automatically track the target direction-of-arrival (DOA) frame-by-frame without the need for additional localization algorithms. In the experiments, nnGSC achieves a relative character error rate (CER) improvement of 23.7% compared to the microphone observation, 13.5% compared to the oracle direction-based super-directive beamformer, 12.2% compared to the oracle direction-based traditional GSC and 5.9% compared to the oracle mask-based minimum variance distortionless response (MVDR) beamformer. Moreover, we can improve the robustness of nnGSC against array geometry mismatches by training with multi-geometry data.}
}
@article{JIANG2021340,
title = {Candidate region aware nested named entity recognition},
journal = {Neural Networks},
volume = {142},
pages = {340-350},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.019},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000691},
author = {Deng Jiang and Haopeng Ren and Yi Cai and Jingyun Xu and Yanxia Liu and Ho-fung Leung},
keywords = {Named entity recognition, Sequence labeling, Multi-task learning},
abstract = {Named entity recognition (NER) is crucial in various natural language processing (NLP) tasks. However, the nested entities which are common in practical corpus are often ignored in most of current NER models. To extract the nested entities, two categories of models (i.e., feature-based and neural network-based approaches) are proposed. However, the feature-based models suffer from the complicated feature engineering and often heavily rely on the external resources. Discarding the heavy feature engineering, recent neural network-based methods which treat the nested NER as a classification task are designed but still suffer from the heavy class imbalance issue and the high computational cost. To solve these problems, we propose a neural multi-task model with two modules: Binary Sequence Labeling and Candidate Region Classification to extract the nested entities. Extensive experiments are conducted on the public datasets. Comparing with recent neural network-based approaches, our proposed model achieves the better performance and obtains the higher efficiency.}
}
@article{LI202192,
title = {Flexible multi-view semi-supervised learning with unified graph},
journal = {Neural Networks},
volume = {142},
pages = {92-104},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.033},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001702},
author = {Zhongheng Li and Qianyao Qiang and Bin Zhang and Fei Wang and Feiping Nie},
keywords = {Multi-view semi-supervised learning, Unified pattern, Regression residual term, Multi-view combination},
abstract = {At present, the diversity of data acquisition boosts the growth of multi-view data and the lack of label information. Since manually labeling is expensive and impractical, it is practical to enhance learning performance with a small amount of labeled data and a large amount of unlabeled data. In this study, we propose a novel multi-view semi-supervised learning (MSEL) framework termed flexible MSEL (FMSEL) with unified graph. In this framework, two flexible regression residual terms are introduced. One is a linear penalty term, which adaptively weighs the diverse contributions of different views and properly learns a well structured unified graph. The other is a relaxation regularization term, which finds the optimal prediction and the linear regression function. Both the prediction of samples in the database and new-coming data are supported. Moreover, during the process, the unified graph learns depending on the data structure and dynamically updated label information. Further, we provide an alternating optimization algorithm to iteratively solve the resultant objective problem and theoretically analyze the corresponding complexities. Extensive experiments conducted on synthetic and public datasets demonstrate the superiority of FMSEL.}
}
@article{TAVAKOLI20211,
title = {SPLASH: Learnable activation functions for improving accuracy and adversarial robustness},
journal = {Neural Networks},
volume = {140},
pages = {1-12},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000733},
author = {Mohammadamin Tavakoli and Forest Agostinelli and Pierre Baldi},
keywords = {Activation, Neural networks, Accuracy, Robustness, Adversarial},
abstract = {We introduce SPLASH units, a class of learnable activation functions shown to simultaneously improve the accuracy of deep neural networks while also improving their robustness to adversarial attacks. SPLASH units have both a simple parameterization and maintain the ability to approximate a wide range of non-linear functions. SPLASH units are: (1) continuous; (2) grounded (f(0)=0); (3) use symmetric hinges; and (4) their hinges are placed at fixed locations which are derived from the data (i.e. no learning required). Compared to nine other learned and fixed activation functions, including ReLU and its variants, SPLASH units show superior performance across three datasets (MNIST, CIFAR-10, and CIFAR-100) and four architectures (LeNet5, All-CNN, ResNet-20, and Network-in-Network). Furthermore, we show that SPLASH units significantly increase the robustness of deep neural networks to adversarial attacks. Our experiments on both black-box and white-box adversarial attacks show that commonly-used architectures, namely LeNet5, All-CNN, Network-in-Network, and ResNet-20, can be up to 31% more robust to adversarial attacks by simply using SPLASH units instead of ReLUs. Finally, we show the benefits of using SPLASH activation functions in bigger architectures designed for non-trivial datasets such as ImageNet.}
}
@article{KIM202127,
title = {Exploring the spatial reasoning ability of neural models in human IQ tests},
journal = {Neural Networks},
volume = {140},
pages = {27-38},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100068X},
author = {Hyunjae Kim and Yookyung Koh and Jinheon Baek and Jaewoo Kang},
keywords = {Spatial reasoning, Human IQ test, Neural networks},
abstract = {Although neural models have performed impressively well on various tasks such as image recognition and question answering, their reasoning ability has been measured in only few studies. In this work, we focus on spatial reasoning and explore the spatial understanding of neural models. First, we describe the following two spatial reasoning IQ tests: rotation and shape composition. Using well-defined rules, we constructed datasets that consist of various complexity levels. We designed a variety of experiments in terms of generalization, and evaluated six different baseline models on the newly generated datasets. We provide an analysis of the results and factors that affect the generalization abilities of models. Also, we analyze how neural models solve spatial reasoning tests with visual aids. We hope that our work can encourage further research into human-level spatial reasoning and provide a new direction for future work.}
}
@article{YE202161,
title = {Reducing bias to source samples for unsupervised domain adaptation},
journal = {Neural Networks},
volume = {141},
pages = {61-71},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100109X},
author = {Yalan Ye and Ziwei Huang and Tongjie Pan and Jingjing Li and Heng Tao Shen},
keywords = {Domain adaptation, Transfer learning, Generative adversarial network},
abstract = {Unsupervised Domain Adaptation (UDA) makes predictions for the target domain data while labels are only available in the source domain. Lots of works in UDA focus on finding a common representation of the two domains via domain alignment, assuming that a classifier trained in the source domain can be generalized well to the target domain. Thus, most existing UDA methods only consider minimizing the domain discrepancy without enforcing any constraint on the classifier. However, due to the uniqueness of each domain, it is difficult to achieve a perfect common representation, especially when there is low similarity between the source domain and the target domain. As a consequence, the classifier is biased to the source domain features and makes incorrect predictions on the target domain. To address this issue, we propose a novel approach named reducing bias to source samples for unsupervised domain adaptation (RBDA) by jointly matching the distribution of the two domains and reducing the classifier’s bias to source samples. Specifically, RBDA first conditions the adversarial networks with the cross-covariance of learned features and classifier predictions to match the distribution of two domains. Then to reduce the classifier’s bias to source samples, RBDA is designed with three effective mechanisms: a mean teacher model to guide the training of the original model, a regularization term to regularize the model and an improved cross-entropy loss for better supervised information learning. Comprehensive experiments on several open benchmarks demonstrate that RBDA achieves state-of-the-art results, which show its effectiveness for unsupervised domain adaptation scenarios.}
}
@article{LI202172,
title = {Deep joint learning for language recognition},
journal = {Neural Networks},
volume = {141},
pages = {72-86},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001143},
author = {Lin Li and Zheng Li and Yan Liu and Qingyang Hong},
keywords = {Deep joint learning, Language recognition, Language identification, Multi-feature learning, Multi-task learning},
abstract = {Deep learning methods for language recognition have achieved promising performance. However, most of the studies focus on frameworks for single types of acoustic features and single tasks. In this paper, we propose the deep joint learning strategies based on the Multi-Feature (MF) and Multi-Task (MT) models. First, we investigate the efficiency of integrating multiple acoustic features and explore two kinds of training constraints, one is introducing auxiliary classification constraints with adaptive weights for loss functions in feature encoder sub-networks, and the other option is introducing the Canonical Correlation Analysis (CCA) constraint to maximize the correlation of different feature representations. Correlated speech tasks, such as phoneme recognition, are applied as auxiliary tasks in order to learn related information to enhance the performance of language recognition. We analyze phoneme-aware information from different learning strategies, like joint learning on the frame-level, adversarial learning on the segment-level, and the combination mode. In addition, we present the Language-Phoneme embedding extraction structure to learn and extract language and phoneme embedding representations simultaneously. We demonstrate the effectiveness of the proposed approaches with experiments on the Oriental Language Recognition (OLR) data sets. Experimental results indicate that joint learning on the multi-feature and multi-task models extracts instinct feature representations for language identities and improves the performance, especially in complex challenges, such as cross-channel or open-set conditions.}
}
@article{FARRELL2021330,
title = {Autoencoder networks extract latent variables and encode these variables in their connectomes},
journal = {Neural Networks},
volume = {141},
pages = {330-343},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000903},
author = {Matthew Farrell and Stefano Recanatesi and R. Clay Reid and Stefan Mihalas and Eric Shea-Brown},
keywords = {Autoencoder, Connectome, Dimensionality reduction, Identifiability, Latent variable encoding},
abstract = {Advances in electron microscopy and data processing techniques are leading to increasingly large and complete microscale connectomes. At the same time, advances in artificial neural networks have produced model systems that perform comparably rich computations with perfectly specified connectivity. This raises an exciting scientific opportunity for the study of both biological and artificial neural networks: to infer the underlying circuit function from the structure of its connectivity. A potential roadblock, however, is that – even with well constrained neural dynamics – there are in principle many different connectomes that could support a given computation. Here, we define a tractable setting in which the problem of inferring circuit function from circuit connectivity can be analyzed in detail: the function of input compression and reconstruction, in an autoencoder network with a single hidden layer. Here, in general there is substantial ambiguity in the weights that can produce the same circuit function, because largely arbitrary changes to input weights can be undone by applying the inverse modifications to the output weights. However, we use mathematical arguments and simulations to show that adding simple, biologically motivated regularization of connectivity resolves this ambiguity in an interesting way: weights are constrained such that the latent variable structure underlying the inputs can be extracted from the weights by using nonlinear dimensionality reduction methods.}
}
@article{XUE2021223,
title = {Cycle consistent network for end-to-end style transfer TTS training},
journal = {Neural Networks},
volume = {140},
pages = {223-236},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100085X},
author = {Liumeng Xue and Shifeng Pan and Lei He and Lei Xie and Frank K. Soong},
keywords = {Speech synthesis, End-to-end, Style transfer, Variational autoencoder, Cycle consistent},
abstract = {In this paper, we propose a cycle consistent network based end-to-end TTS for speaking style transfer, including intra-speaker, inter-speaker, and unseen speaker style transfer for both parallel and unparallel transfers. The proposed approach is built upon a multi-speaker Variational Autoencoder (VAE) TTS model. The model is usually trained in a paired manner, which means the reference speech is totally paired with the output including speaker identity, text, and style. To achieve a better quality for style transfer, which for most cases is in an unpaired manner, we augment the model with an unpaired path with a separated variational style encoder. The unpaired path takes as input an unpaired reference speech and yields an unpaired output. The unpaired output, which lacks direct ground-truth target, is then successfully constrained by a delicately designed cycle consistent network. Specifically, the unpaired output of the forward transfer is fed into the model again as an unpaired reference input, and after the backward transfer yields an output expected to be the same as the original unpaired reference speech. Ablation study shows the effectiveness of the unpaired path, separated style encoders and cycle consistent network in the proposed model. The final evaluation demonstrates the proposed approach significantly outperforms the Global Style Token (GST) and VAE based systems for all the six style transfer categories, in metrics of naturalness, speech quality, similarity of speaker identity, and similarity of speaking style.}
}
@article{ZHAO2021270,
title = {Learnable Heterogeneous Convolution: Learning both topology and strength},
journal = {Neural Networks},
volume = {141},
pages = {270-280},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.038},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100126X},
author = {Rongzhen Zhao and Zhenzhi Wu and Qikun Zhang},
keywords = {Convolution neural network, Efficiency & performance, Learning topology & strength, Fine-grained but structural, Hardware acceleration},
abstract = {Existing convolution techniques in artificial neural networks suffer from huge computation complexity, while the biological neural network works in a much more powerful yet efficient way. Inspired by the biological plasticity of dendritic topology and synaptic strength, our method, Learnable Heterogeneous Convolution, realizes joint learning of kernel shape and weights, which unifies existing handcrafted convolution techniques in a data-driven way. A model based on our method can converge with structural sparse weights and then be accelerated by devices of high parallelism. In the experiments, our method either reduces VGG16/19 and ResNet34/50 computation by nearly 5× on CIFAR10 and 2× on ImageNet without harming the performance, where the weights are compressed by 10× and 4× respectively; or improves the accuracy by up to 1.0% on CIFAR10 and 0.5% on ImageNet with slightly higher efficiency. The code will be available on www.github.com/Genera1Z/LearnableHeterogeneousConvolution.}
}
@article{FAN2021344,
title = {Learning dual-margin model for visual tracking},
journal = {Neural Networks},
volume = {140},
pages = {344-354},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001313},
author = {Nana Fan and Xin Li and Zikun Zhou and Qiao Liu and Zhenyu He},
keywords = {Visual tracking, Siamese network, Dual margin},
abstract = {Existing trackers usually exploit robust features or online updating mechanisms to deal with target variations which is a key challenge in visual tracking. However, the features being robust to variations remain little spatial information, and existing online updating methods are prone to overfitting. In this paper, we propose a dual-margin model for robust and accurate visual tracking. The dual-margin model comprises an intra-object margin between different target appearances and an inter-object margin between the target and the background. The proposed method is able to not only distinguish the target from the background but also perceive the target changes, which tracks target appearance changing and facilitates accurate target state estimation. In addition, to exploit rich off-line video data and learn general rules of target appearance variations, we train the dual-margin model on a large off-line video dataset. We perform tracking under a Siamese framework using the constructed appearance set as templates. The proposed method achieves accurate and robust tracking performance on five public datasets while running in real-time. The favorable performance against the state-of-the-art methods demonstrates the effectiveness of the proposed algorithm.}
}
@article{TURINICI2021294,
title = {Radon–Sobolev Variational Auto-Encoders},
journal = {Neural Networks},
volume = {141},
pages = {294-305},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001556},
author = {Gabriel Turinici},
keywords = {Variational Auto-Encoder, Generative model, Sobolev spaces, Radon–Sobolev Variational Auto-Encoder},
abstract = {The quality of generative models (such as Generative adversarial networks and Variational Auto-Encoders) depends heavily on the choice of a good probability distance. However some popular metrics like the Wasserstein or the Sliced Wasserstein distances, the Jensen–Shannon divergence, the Kullback–Leibler divergence, lack convenient properties such as (geodesic) convexity, fast evaluation and so on. To address these shortcomings, we introduce a class of distances that have built-in convexity. We investigate the relationship with some known paradigms (sliced distances – a synonym for Radon distances – reproducing kernel Hilbert spaces, energy distances). The distances are shown to possess fast implementations and are included in an adapted Variational Auto-Encoder termed Radon–Sobolev Variational Auto-Encoder (RS-VAE) which produces high quality results on standard generative datasets.}
}
@article{WANG202164,
title = {Synchronization criteria of delayed inertial neural networks with generally Markovian jumping},
journal = {Neural Networks},
volume = {139},
pages = {64-76},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000460},
author = {Junyi Wang and Zhanshan Wang and Xiangyong Chen and Jianlong Qiu},
keywords = {Inertial neural network, Generally Markovian jumping, Delay-dependent Lyapunov–Krasovskii functionals, Higher order polynomial based relaxed inequality},
abstract = {In this paper, the synchronization problem of inertial neural networks with time-varying delays and generally Markovian jumping is investigated. The second order differential equations are transformed into the first-order differential equations by utilizing the variable transformation method. The Markovian process in the systems is uncertain or partially known due to the delay of data transmission channel or the loss of data information, which is more general and practicable to consider generally Markovian jumping inertial neural networks. The synchronization criteria can be obtained by using the delay-dependent Lyapunov–Krasovskii functionals and higher order polynomial based relaxed inequality (HOPRII). In addition, the desired controllers are obtained by solving a set of linear matrix inequalities. Finally, the numerical examples are provided to demonstrate the effectiveness of the theoretical results.}
}
@article{TAHERI2021148,
title = {Statistical guarantees for regularized neural networks},
journal = {Neural Networks},
volume = {142},
pages = {148-161},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001714},
author = {Mahsa Taheri and Fang Xie and Johannes Lederer},
keywords = {Neural networks, Deep learning, Prediction guarantees, Regularization},
abstract = {Neural networks have become standard tools in the analysis of data, but they lack comprehensive mathematical theories. For example, there are very few statistical guarantees for learning neural networks from data, especially for classes of estimators that are used in practice or at least similar to such. In this paper, we develop a general statistical guarantee for estimators that consist of a least-squares term and a regularizer. We then exemplify this guarantee with ℓ1-regularization, showing that the corresponding prediction error increases at most logarithmically in the total number of parameters and can even decrease in the number of layers. Our results establish a mathematical basis for regularized estimation of neural networks, and they deepen our mathematical understanding of neural networks and deep learning more generally.}
}
@article{GUO2021107,
title = {Multi-periodicity of switched neural networks with time delays and periodic external inputs under stochastic disturbances},
journal = {Neural Networks},
volume = {141},
pages = {107-119},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.039},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001271},
author = {Zhenyuan Guo and Jingxuan Ci and Jun Wang},
keywords = {Multi-periodicity, Exponential stability in mean-square, Time delays, Switched neural networks, Stochastic disturbances},
abstract = {This paper presents new theoretical results on the multi-periodicity of recurrent neural networks with time delays evoked by periodic inputs under stochastic disturbances and state-dependent switching. Based on the geometric properties of activation function and switching threshold, the neuronal state space is partitioned into 5n regions in which 3n ones are shown to be positively invariant with probability one. Furthermore, by using Itô’s formula, Lyapunov functional method, and the contraction mapping theorem, two criteria are proposed to ascertain the existence and mean-square exponential stability of a periodic orbit in every positive invariant set. As a result, the number of mean-square exponentially stable periodic orbits increases to 3n from 2n in a neural network without switching. Two illustrative examples are elaborated to substantiate the efficacy and characteristics of the theoretical results.}
}
@article{BEISE2021121,
title = {On decision regions of narrow deep neural networks},
journal = {Neural Networks},
volume = {140},
pages = {121-129},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000745},
author = {Hans-Peter Beise and Steve {Dias Da Cruz} and Udo Schröder},
keywords = {Expressive power, Approximation by network functions, Neural networks, Decision regions, Width of neural networks},
abstract = {We show that for neural network functions that have width less or equal to the input dimension all connected components of decision regions are unbounded. The result holds for continuous and strictly monotonic activation functions as well as for the ReLU activation function. This complements recent results on approximation capabilities by Hanin and Sellke (2017) and connectivity of decision regions by Nguyen et al. (2018) for such narrow neural networks. Our results are illustrated by means of numerical experiments.}
}
@article{GUPTA2021105,
title = {Residual Neural Network precisely quantifies dysarthria severity-level based on short-duration speech segments},
journal = {Neural Networks},
volume = {139},
pages = {105-117},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000502},
author = {Siddhant Gupta and Ankur T. Patil and Mirali Purohit and Mihir Parmar and Maitreya Patel and Hemant A. Patil and Rodrigo Capobianco Guido},
keywords = {Dysarthria, Severity-level, Short-speech segments, CNN, ResNet},
abstract = {Recently, we have witnessed Deep Learning methodologies gaining significant attention for severity-based classification of dysarthric speech. Detecting dysarthria, quantifying its severity, are of paramount importance in various real-life applications, such as the assessment of patients’ progression in treatments, which includes an adequate planning of their therapy and the improvement of speech-based interactive systems in order to handle pathologically-affected voices automatically. Notably, current speech-powered tools often deal with short-duration speech segments and, consequently, are less efficient in dealing with impaired speech, even by using Convolutional Neural Networks (CNNs). Thus, detecting dysarthria severity-level based on short speech segments might help in improving the performance and applicability of those systems. To achieve this goal, we propose a novel Residual Network (ResNet)-based technique which receives short-duration speech segments as input. Statistically meaningful objective analysis of our experiments, reported over standard Universal Access corpus, exhibits average values of 21.35% and 22.48% improvement, compared to the baseline CNN, in terms of classification accuracy and F1-score, respectively. For additional comparisons, tests with Gaussian Mixture Models and Light CNNs were also performed. Overall, the values of 98.90% and 98.00% for classification accuracy and F1-score, respectively, were obtained with the proposed ResNet approach, confirming its efficacy and reassuring its practical applicability.}
}
@article{ZHANG202113,
title = {TigeCMN: On exploration of temporal interaction graph embedding via Coupled Memory Neural Networks},
journal = {Neural Networks},
volume = {140},
pages = {13-26},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000587},
author = {Zhen Zhang and Jiajun Bu and Zhao Li and Chengwei Yao and Can Wang and Jia Wu},
keywords = {Graph embedding, Temporal interaction graphs, Node classification, Recommendation, Visualization},
abstract = {With the increasing demand of mining rich knowledge in graph structured data, graph embedding has become one of the most popular research topics in both academic and industrial communities due to its powerful capability in learning effective representations. The majority of existing work overwhelmingly learn node embeddings in the context of static, plain or attributed, homogeneous graphs. However, many real-world applications frequently involve bipartite graphs with temporal and attributed interaction edges, named temporal interaction graphs. The temporal interactions usually imply different facets of interest and might even evolve over the time, thus putting forward huge challenges in learning effective node representations. Furthermore, most existing graph embedding models try to embed all the information of each node into a single vector representation, which is insufficient to characterize the node’s multifaceted properties. In this paper, we propose a novel framework named TigeCMN to learn node representations from a sequence of temporal interactions. Specifically, we devise two coupled memory networks to store and update node embeddings in the external matrices explicitly and dynamically, which forms deep matrix representations and thus could enhance the expressiveness of the node embeddings. Then, we generate node embedding from two parts: a static embedding that encodes its stationary properties and a dynamic embedding induced from memory matrix that models its temporal interaction patterns. We conduct extensive experiments on various real-world datasets covering the tasks of node classification, recommendation and visualization. The experimental results empirically demonstrate that TigeCMN can achieve significant gains compared with recent state-of-the-art baselines.}
}
@article{LI202173,
title = {Generalized two-dimensional linear discriminant analysis with regularization},
journal = {Neural Networks},
volume = {142},
pages = {73-91},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.030},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001672},
author = {Chun-Na Li and Yuan-Hai Shao and Wei-Jie Chen and Zhen Wang and Nai-Yang Deng},
keywords = {Linear discriminant analysis, Two-dimensional linear discriminant analysis, Regularization, Robust dimensionality reduction},
abstract = {Recent advances show that two-dimensional linear discriminant analysis (2DLDA) is a successful matrix based dimensionality reduction method. However, 2DLDA may encounter the singularity issue theoretically, and also is sensitive to outliers. In this paper, a generalized Lp-norm 2DLDA framework with regularization for an arbitrary p>0 is proposed, named G2DLDA. There are mainly two contributions of G2DLDA: one is G2DLDA model uses an arbitrary Lp-norm to measure the between-class and within-class scatter, and hence a proper p can be selected to achieve robustness. The other one is that the introduced regularization term makes G2DLDA enjoy better generalization performance and avoid singularity. In addition, an effective learning algorithm is designed for G2LDA, which can be solved through a series of convex problems with closed-form solutions. Its convergence can be guaranteed theoretically when 1≤p≤2. Preliminary experimental results on three contaminated human face databases show the effectiveness of the proposed G2DLDA.}
}
@article{PENG2021261,
title = {Multi-resolution modulation-filtered cochleagram feature for LSTM-based dimensional emotion recognition from speech},
journal = {Neural Networks},
volume = {140},
pages = {261-273},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001155},
author = {Zhichao Peng and Jianwu Dang and Masashi Unoki and Masato Akagi},
keywords = {Dimensional emotion, Temporal modulation, Multi-resolution modulation-filtered cochleagram, Parallel long short-term memory network},
abstract = {Continuous dimensional emotion recognition from speech helps robots or virtual agents capture the temporal dynamics of a speaker’s emotional state in natural human–robot interactions. Temporal modulation cues obtained directly from the time-domain model of auditory perception can better reflect temporal dynamics than the acoustic features usually processed in the frequency domain. Feature extraction, which can reflect temporal dynamics of emotion from temporal modulation cues, is challenging because of the complexity and diversity of the auditory perception model. A recent neuroscientific study suggests that human brains derive multi-resolution representations through temporal modulation analysis. This study investigates multi-resolution representations of an auditory perception model and proposes a novel feature called multi-resolution modulation-filtered cochleagram (MMCG) for predicting valence and arousal values of emotional primitives. The MMCG is constructed by combining four modulation-filtered cochleagrams at different resolutions to capture various temporal and contextual modulation information. In addition, to model the multi-temporal dependencies of the MMCG, we designed a parallel long short-term memory (LSTM) architecture. The results of extensive experiments on the RECOLA and SEWA datasets demonstrate that MMCG provides the best recognition performance in both datasets among all evaluated features. The results also show that the parallel LSTM can build multi-temporal dependencies from the MMCG features, and the performance on valence and arousal prediction is better than that of a plain LSTM method.}
}
@article{PANG2021203,
title = {Tumor attention networks: Better feature selection, better tumor segmentation},
journal = {Neural Networks},
volume = {140},
pages = {203-222},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000861},
author = {Shuchao Pang and Anan Du and Mehmet A. Orgun and Yunyun Wang and Zhenmei Yu},
keywords = {Liver tumor segmentation, Visual attention, Feature selection, Visualization, Neural networks, Medical image segmentation},
abstract = {Compared with the traditional analysis of computed tomography scans, automatic liver tumor segmentation can supply precise tumor volumes and reduce the inter-observer variability in estimating the tumor size and the tumor burden, which could further assist physicians to make better therapeutic choices for hepatic diseases and monitoring treatment. Among current mainstream segmentation approaches, multi-layer and multi-kernel convolutional neural networks (CNNs) have attracted much attention in diverse biomedical/medical image segmentation tasks with remarkable performance. However, an arbitrary stacking of feature maps makes CNNs quite inconsistent in imitating the cognition and the visual attention of human beings for a specific visual task. To mitigate the lack of a reasonable feature selection mechanism in CNNs, we exploit a novel and effective network architecture, called Tumor Attention Networks (TA-Net), for mining adaptive features by embedding Tumor Attention layers with multi-functional modules to assist the liver tumor segmentation task. In particular, each tumor attention layer can adaptively highlight valuable tumor features and suppress unrelated ones among feature maps from 3D and 2D perspectives. Moreover, an analysis of visualization results illustrates the effectiveness of our tumor attention modules and the interpretability of CNNs for liver tumor segmentation. Furthermore, we explore different arrangements of skip connections in information fusion. A deep ablation study is also conducted to illustrate the effects of different attention strategies for hepatic tumors. The results of extensive experiments demonstrate that the proposed TA-Net increases the liver tumor segmentation performance with a lower computation cost and a small parameter overhead over the state-of-the-art methods, under various evaluation metrics on clinical benchmark data. In addition, two additional medical image datasets are used to evaluate generalization capability of TA-Net, including the comparison with general semantic segmentation methods and a non-tumor segmentation task. All the program codes have been released at https://github.com/shuchao1212/TA-Net.}
}
@article{BURT2021145,
title = {Unsupervised foveal vision neural architecture with top-down attention},
journal = {Neural Networks},
volume = {141},
pages = {145-159},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000836},
author = {Ryan Burt and Nina N. Thigpen and Andreas Keil and Jose C. Principe},
keywords = {Unsupervised Learning, Foveal vision, Top-down saliency, Deep learning},
abstract = {Deep learning architectures are an extremely powerful tool for recognizing and classifying images. However, they require supervised learning and normally work on vectors of the size of image pixels and produce the best results when trained on millions of object images. To help mitigate these issues, we propose an end-to-end architecture that fuses bottom-up saliency and top-down attention with an object recognition module to focus on relevant data and learn important features that can later be fine-tuned for a specific task, employing only unsupervised learning. In addition, by utilizing a virtual fovea that focuses on relevant portions of the data, the training speed can be greatly improved. We test the performance of the proposed Gamma saliency technique on the Toronto and CAT 2000 databases, and the foveated vision in the large Street View House Numbers (SVHN) database. The results with foveated vision show that Gamma saliency performs at the same level as the best alternative algorithms while being computationally faster. The results in SVHN show that our unsupervised cognitive architecture is comparable to fully supervised methods and that saliency also improves CNN performance if desired. Finally, we develop and test a top-down attention mechanism based on the Gamma saliency applied to the top layer of CNNs to facilitate scene understanding in multi-object cluttered images. We show that the extra information from top-down saliency is capable of speeding up the extraction of digits in the cluttered multidigit MNIST data set, corroborating the important role of top down attention.}
}
@article{TANG2023575,
title = {Corrigendum to “Functional Connectivity Learning via Siamese-based SPD Matrix Representation of Brain Imaging Data” [Neural Networks 163 (2023) 272–285]},
journal = {Neural Networks},
volume = {164},
pages = {575},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023002563},
author = {Yunbo Tang and Dan Chen and Jia Wu and Weiping Tu and Jessica J.M. Monaghan and Paul Sowman and David Mcalpine}
}
@article{SALHA20211,
title = {FastGAE: Scalable graph autoencoders with stochastic subgraph decoding},
journal = {Neural Networks},
volume = {142},
pages = {1-19},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001520},
author = {Guillaume Salha and Romain Hennequin and Jean-Baptiste Remy and Manuel Moussallam and Michalis Vazirgiannis},
keywords = {Graph autoencoders, Graph variational autoencoders, Scalability, Graph convolutional networks, Link prediction, Node clustering},
abstract = {Graph autoencoders (AE) and variational autoencoders (VAE) are powerful node embedding methods, but suffer from scalability issues. In this paper, we introduce FastGAE, a general framework to scale graph AE and VAE to large graphs with millions of nodes and edges. Our strategy, based on an effective stochastic subgraph decoding scheme, significantly speeds up the training of graph AE and VAE while preserving or even improving performances. We demonstrate the effectiveness of FastGAE on various real-world graphs, outperforming the few existing approaches to scale graph AE and VAE by a wide margin.}
}
@article{ZHANG2021140,
title = {Knowledge graph embedding with shared latent semantic units},
journal = {Neural Networks},
volume = {139},
pages = {140-148},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000551},
author = {Zhao Zhang and Fuzhen Zhuang and Meng Qu and Zheng-Yu Niu and Hui Xiong and Qing He},
keywords = {Knowledge graph, Reinforcement learning, Embedding},
abstract = {Knowledge graph embedding (KGE) aims to project both entities and relations into a continuous low-dimensional space. However, for a given knowledge graph (KG), only a small number of entities and relations occur many times, while the vast majority of entities and relations occur less frequently. This data sparsity problem has largely been ignored by most of the existing KGE models. To this end, in this paper, we propose a general technique to enable knowledge transfer among semantically similar entities or relations. Specifically, we define latent semantic units (LSUs), which are the sub-components of entity and relation embeddings. Semantically similar entities or relations are supposed to share the same LSUs, and thus knowledge can be transferred among entities or relations. Finally, extensive experiments show that the proposed technique is able to enhance existing KGE models and can provide better representations of KGs.}
}
@article{ZHANG2021325,
title = {Multistability of delayed fractional-order competitive neural networks},
journal = {Neural Networks},
volume = {140},
pages = {325-335},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001246},
author = {Fanghai Zhang and Tingwen Huang and Qiujie Wu and Zhigang Zeng},
keywords = {Fractional-order competitive neural networks, Multistability, Attraction basins, Delays},
abstract = {This paper is concerned with the multistability of fractional-order competitive neural networks (FCNNs) with time-varying delays. Based on the division of state space, the equilibrium points (EPs) of FCNNs are given. Several sufficient conditions and criteria are proposed to ascertain the multiple O(t−α)-stability of delayed FCNNs. The O(t−α)-stability is the extension of Mittag-Leffler stability of fractional-order neural networks, which contains monostability and multistability. Moreover, the attraction basins of the stable EPs of FCNNs are estimated, which shows the attraction basins of the stable EPs can be larger than the divided subsets. These conditions and criteria supplement and improve the previous results. Finally, the results are illustrated by the simulation examples.}
}
@article{MILLAN202144,
title = {Growth strategy determines the memory and structural properties of brain networks},
journal = {Neural Networks},
volume = {142},
pages = {44-56},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001647},
author = {Ana P. Millán and Joaquín J. Torres and Samuel Johnson and J. Marro},
keywords = {Brain development, Co-evolving neural network, Associative memory, Complex networks, Temporal networks},
abstract = {The interplay between structure and function affects the emerging properties of many natural systems. Here we use an adaptive neural network model that couples activity and topological dynamics and reproduces the experimental temporal profiles of synaptic density observed in the brain. We prove that the existence of a transient period of relatively high synaptic connectivity is critical for the development of the system under noise circumstances, such that the resulting network can recover stored memories. Moreover, we show that intermediate synaptic densities provide optimal developmental paths with minimum energy consumption, and that ultimately it is the transient heterogeneity in the network that determines its evolution. These results could explain why the pruning curves observed in actual brain areas present their characteristic temporal profiles and they also suggest new design strategies to build biologically inspired neural networks with particular information processing capabilities.}
}
@article{YANG2021265,
title = {IHG-MA: Inductive heterogeneous graph multi-agent reinforcement learning for multi-intersection traffic signal control},
journal = {Neural Networks},
volume = {139},
pages = {265-277},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000952},
author = {Shantian Yang and Bo Yang and Zhongfeng Kang and Lihui Deng},
keywords = {Heterogeneous graph neural network, Inductive heterogeneous graph representation learning, Multi-agent reinforcement learning, Transfer learning, Cooperative traffic signal control},
abstract = {Multi-agent deep reinforcement learning (MDRL) has been widely applied in multi-intersection traffic signal control. The MDRL algorithms produce the decentralized cooperative traffic-signal policies via specialized multi-agent settings in certain traffic networks. However, the state-of-the-art MDRL algorithms seem to have some drawbacks. (1) It is desirable that the traffic-signal policies can be smoothly transferred to diverse traffic networks, however, the adopted specialized multi-agent settings hinder the traffic-signal policies to transfer and generalize to new traffic networks. (2) Existing MDRL algorithms which are based on deep neural networks cannot flexibly tackle a time-varying number of vehicles traversing the traffic networks. (3) Existing MDRL algorithms which are based on homogeneous graph neural networks fail to capture the heterogeneous features of objects in traffic networks. Motivated by the above observations, in this paper, we propose an algorithm, referred to as Inductive Heterogeneous Graph Multi-agent Actor–critic (IHG-MA) algorithm, for multi-intersection traffic signal control. The proposed IHG-MA algorithm has two features: (1) It conducts representation learning using a proposed inductive heterogeneous graph neural network (IHG), which is an inductive algorithm. The proposed IHG algorithm can generate embeddings for previously unseen nodes (e.g., new entry vehicles) and new graphs (e.g., new traffic networks). But unlike the algorithms based on the homogeneous graph neural network, IHG algorithm not only encodes heterogeneous features of each node, but also encodes heterogeneous structural (graph) information. (2) It also conducts policy learning using a proposed multi-agent actor–critic(MA), which is a decentralized cooperative framework. The proposed MA framework employs the final embeddings to compute the Q-value and policy, and then optimizes the whole algorithm via the Q-value and policy loss. Experimental results on different traffic datasets illustrate that IHG-MA algorithm outperforms the state-of-the-art algorithms in terms of multiple traffic metrics, which seems to be a new promising algorithm for multi-intersection traffic signal control.}
}
@article{KIM2021158,
title = {Visual question answering based on local-scene-aware referring expression generation},
journal = {Neural Networks},
volume = {139},
pages = {158-167},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000435},
author = {Jung-Jun Kim and Dong-Gyu Lee and Jialin Wu and Hong-Gyu Jung and Seong-Whan Lee},
keywords = {Visual question answering, Joint-embedding multi-head attention, Referring expression generation},
abstract = {Visual question answering requires a deep understanding of both images and natural language. However, most methods mainly focus on visual concept; such as the relationships between various objects. The limited use of object categories combined with their relationships or simple question embedding is insufficient for representing complex scenes and explaining decisions. To address this limitation, we propose the use of text expressions generated for images, because such expressions have few structural constraints and can provide richer descriptions of images. The generated expressions can be incorporated with visual features and question embedding to obtain the question-relevant answer. A joint-embedding multi-head attention network is also proposed to model three different information modalities with co-attention. We quantitatively and qualitatively evaluated the proposed method on the VQA v2 dataset and compared it with state-of-the-art methods in terms of answer prediction. The quality of the generated expressions was also evaluated on the RefCOCO, RefCOCO+, and RefCOCOg datasets. Experimental results demonstrate the effectiveness of the proposed method and reveal that it outperformed all of the competing methods in terms of both quantitative and qualitative results.}
}
@article{DEVARAJAN2021309,
title = {A statistical framework for non-negative matrix factorization based on generalized dual divergence},
journal = {Neural Networks},
volume = {140},
pages = {309-324},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.020},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001088},
author = {Karthik Devarajan},
keywords = {Nonnegative matrix factorization, Dual Kullback–Leibler divergence, -divergence, Unsupervised learning, Deep learning, Cancer genomics},
abstract = {A statistical framework for non-negative matrix factorization based on generalized dual Kullback–Leibler divergence, which includes members of the exponential family of models, is proposed. A family of algorithms is developed using this framework, including under sparsity constraints, and its convergence proven using the Expectation–Maximization algorithm. The framework generalizes some existing methods for different noise structures and contrasts with the recently developed quasi-likelihood approach, thus providing a useful alternative for non-negative matrix factorization. A measure to evaluate the goodness-of-fit of the resulting factorization is described. The performance of the proposed methods is evaluated extensively using real life and simulated data and their utility in unsupervised and semi-supervised learning is illustrated using an application in cancer genomics. This framework can be viewed from the perspective of reinforcement learning, and can be adapted to incorporate discriminant functions and multi-layered neural networks within a deep learning paradigm.}
}
@article{ZHOU2021255,
title = {Synchronization of memristive neural networks with unknown parameters via event-triggered adaptive control},
journal = {Neural Networks},
volume = {139},
pages = {255-264},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000794},
author = {Yufeng Zhou and Hao Zhang and Zhigang Zeng},
keywords = {Event-triggered adaptive control, Synchronization, Memristive neural networks, Distributed delays, Unbounded discrete delays},
abstract = {This paper considers the drive-response synchronization of memristive neural networks (MNNs) with unknown parameters, where the unbounded discrete and bounded distributed time-varying delays are involved. Aiming at the unknown parameters of MNNs, the updating law of weight in response system and the gain of adaptive controller are proposed to realize the synchronization of delayed MNNs. In view of the limited communication and bandwidth, the event-triggered mechanism is introduced to adaptive control, which not only decreases the times of controller update and the amount of data sending out but also enables synchronization when parameters of MNNs are unknown. In addition, a relative threshold strategy, which is relative to fixed threshold strategy, is proposed to increase the inter-execution intervals and to improve the control effect. When the parameters of MNNs are known, the algebraic criteria of synchronization are established via event-triggered state feedback control by exploiting inequality techniques and calculus theorems. Finally, one simulation is presented to validate the effectiveness of the proposed results.}
}
@article{ESFANDIARI202133,
title = {A fast saddle-point dynamical system approach to robust deep learning},
journal = {Neural Networks},
volume = {139},
pages = {33-44},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.021},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100071X},
author = {Yasaman Esfandiari and Aditya Balu and Keivan Ebrahimi and Umesh Vaidya and Nicola Elia and Soumik Sarkar},
keywords = {Adversarial training, Robust deep learning, Robust optimization},
abstract = {Recent focus on robustness to adversarial attacks for deep neural networks produced a large variety of algorithms for training robust models. Most of the effective algorithms involve solving the min–max optimization problem for training robust models (min step) under worst-case attacks (max step). However, they often suffer from high computational cost from running several inner maximization iterations (to find an optimal attack) inside every outer minimization iteration. Therefore, it becomes difficult to readily apply such algorithms for moderate to large size real world data sets. To alleviate this, we explore the effectiveness of iterative descent–ascent algorithms where the maximization and minimization steps are executed in an alternate fashion to simultaneously obtain the worst-case attack and the corresponding robust model. Specifically, we propose a novel discrete-time dynamical system-based algorithm that aims to find the saddle point of a min–max optimization problem in the presence of uncertainties. Under the assumptions that the cost function is convex and uncertainties enter concavely in the robust learning problem, we analytically show that our algorithm converges asymptotically to the robust optimal solution under a general adversarial budget constraints as induced by ℓp norm, for 1≤p≤∞. Based on our proposed analysis, we devise a fast robust training algorithm for deep neural networks. Although such training involves highly non-convex robust optimization problems, empirical results show that the algorithm can achieve significant robustness compared to other state-of-the-art robust models on benchmark data sets.}
}
@article{BAI202165,
title = {Speaker recognition based on deep learning: An overview},
journal = {Neural Networks},
volume = {140},
pages = {65-99},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000848},
author = {Zhongxin Bai and Xiao-Lei Zhang},
keywords = {Speaker recognition, Speaker verification, Speaker identification, Speaker diarization, Robust speaker recognition, Deep learning},
abstract = {Speaker recognition is a task of identifying persons from their voices. Recently, deep learning has dramatically revolutionized speaker recognition. However, there is lack of comprehensive reviews on the exciting progress. In this paper, we review several major subtasks of speaker recognition, including speaker verification, identification, diarization, and robust speaker recognition, with a focus on deep-learning-based methods. Because the major advantage of deep learning over conventional methods is its representation ability, which is able to produce highly abstract embedding features from utterances, we first pay close attention to deep-learning-based speaker feature extraction, including the inputs, network structures, temporal pooling strategies, and objective functions respectively, which are the fundamental components of many speaker recognition subtasks. Then, we make an overview of speaker diarization, with an emphasis of recent supervised, end-to-end, and online diarization. Finally, we survey robust speaker recognition from the perspectives of domain adaptation and speech enhancement, which are two major approaches of dealing with domain mismatch and noise problems. Popular and recently released corpora are listed at the end of the paper.}
}
@article{LIU2021306,
title = {FastTalker: A neural text-to-speech architecture with shallow and group autoregression},
journal = {Neural Networks},
volume = {141},
pages = {306-314},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001532},
author = {Rui Liu and Berrak Sisman and Yixing Lin and Haizhou Li},
keywords = {Neural text-to-speech synthesis, Shallow autoregressive, Group autoregressive, Temporal dependency},
abstract = {Non-autoregressive architecture for neural text-to-speech (TTS) allows for parallel implementation, thus reduces inference time over its autoregressive counterpart. However, such system architecture does not explicitly model temporal dependency of acoustic signal as it generates individual acoustic frames independently. The lack of temporal modeling often adversely impacts speech continuity, thus voice quality. In this paper, we propose a novel neural TTS model that is denoted as FastTalker. We study two strategies for high-quality speech synthesis at low computational cost. First, we add a shallow autoregressive acoustic decoder on top of the non-autoregressive context decoder to retrieve the temporal information of the acoustic signal. Second, we further implement group autoregression to accelerate the inference of the autoregressive acoustic decoder. The group-based autoregression acoustic decoder generates acoustic features as a sequence of groups instead of frames, each group having multiple consecutive frames. Within a group, the acoustic features are generated in parallel. With the shallow and group autoregression, FastTalker retrieves the temporal information of the acoustic signal, while keeping the fast-decoding property. The proposed FastTalker achieves a good balance between speech quality and inference speed. Experiments show that, in terms of voice quality and naturalness, FastTalker outperforms the non-autoregressive FastSpeech baseline significantly, and is on par with the autoregressive baselines. It also shows a considerable inference speedup over Tacotron2 and Transformer TTS.}
}
@article{STABINGER2021171,
title = {Arguments for the unsuitability of convolutional neural networks for non-local tasks},
journal = {Neural Networks},
volume = {142},
pages = {171-179},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001775},
author = {Sebastian Stabinger and David Peer and Antonio Rodríguez-Sánchez},
keywords = {Convolutional neural networks, Sorting networks, Relational reasoning, Attention, Locality},
abstract = {Convolutional neural networks have established themselves over the past years as the state of the art method for image classification, and for many datasets, they even surpass humans in categorizing images. Unfortunately, the same architectures perform much worse when they have to compare parts of an image to each other to correctly classify this image. Until now, no well-formed theoretical argument has been presented to explain this deficiency. In this paper, we will argue that convolutional layers are of little use for such problems, since comparison tasks are global by nature, but convolutional layers are local by design. We will use this insight to reformulate a comparison task into a sorting task and use findings on sorting networks to propose a lower bound for the number of parameters a neural network needs to solve comparison tasks in a generalizable way. We will use this lower bound to argue that attention, as well as iterative/recurrent processing, is needed to prevent a combinatorial explosion.}
}
@article{ZHANG20211,
title = {Deep ANC: A deep learning approach to active noise control},
journal = {Neural Networks},
volume = {141},
pages = {1-10},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.037},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001258},
author = {Hao Zhang and DeLiang Wang},
keywords = {Active noise control, Deep learning, Deep ANC, Loudspeaker nonlinearity, Quiet zone},
abstract = {Traditional active noise control (ANC) methods are based on adaptive signal processing with the least mean square algorithm as the foundation. They are linear systems and do not perform satisfactorily in the presence of nonlinear distortions. In this paper, we formulate ANC as a supervised learning problem and propose a deep learning approach, called deep ANC, to address the nonlinear ANC problem. The main idea is to employ deep learning to encode the optimal control parameters corresponding to different noises and environments. A convolutional recurrent network (CRN) is trained to estimate the real and imaginary spectrograms of the canceling signal from the reference signal so that the corresponding anti-noise can eliminate or attenuate the primary noise in the ANC system. Large-scale multi-condition training is employed to achieve good generalization and robustness against a variety of noises. The deep ANC method can be trained to achieve active noise cancellation no matter whether the reference signal is noise or noisy speech. In addition, a delay-compensated strategy is introduced to solve the potential latency problem of ANC systems. Experimental results show that deep ANC is effective for wideband noise reduction and generalizes well to untrained noises. Moreover, the proposed method can achieve ANC within a quiet zone and is robust against variations in reference signals.}
}
@article{KONG2021246,
title = {Detecting slender objects with uncertainty based on keypoint-displacement representation},
journal = {Neural Networks},
volume = {139},
pages = {246-254},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.024},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100112X},
author = {Zelong Kong and Nian Zhang and Xinping Guan and Xinyi Le},
keywords = {Deep learning, Object detection, Uncertainty prediction, Quality evaluation},
abstract = {Slender objects are long and thin objects. Existing object detection networks are not specially designed for detecting slender objects. We propose a method to detect slender objects. We represent slender objects with a keypoint-displacement pattern instead of using axis-aligned bounding boxes, avoiding problems like orientation confusion and wrong elimination. In our network, three parallel branches predict keypoint heatmaps, displacement vector field, and displacement uncertainty heatmap respectively. We add the uncertainty branch to enable our network to give uncertainty together with detection results. The predicted uncertainty provides a continuous criterion to evaluate whether detection results are reliable. In addition, the uncertainty branch can lower the weight of ambiguous training samples, leading to more accurate detection results. We employ our proposed method in two typical practical applications. Edges of electrode sheets and pins of electronic chips are correctly detected as slender objects. Manufacturing quality is evaluated through analyzing the detection results, including keypoint number, displacement property, and uncertainty value.}
}
@article{ZHANG2021351,
title = {Capturing the grouping and compactness of high-level semantic feature for saliency detection},
journal = {Neural Networks},
volume = {142},
pages = {351-362},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001659},
author = {Ying Ying Zhang and HongJuan Wang and XiaoDong Lv and Ping Zhang},
keywords = {Saliency detection, High-level semantic feature, The grouping and compactness characteristics, Elastic net based hypergraph, The spatial distribution, Saliency propagation},
abstract = {Saliency detection is an important and challenging research topic due to the variety and complexity of the background and saliency regions. In this paper, we present a novel unsupervised saliency detection approach by exploiting the grouping and compactness characteristics of the high-level semantic features. First, for the high-level semantic feature, the elastic net based hypergraph model is adopted to discover the group structure relationships of salient regional points, and the calculation of the spatial distribution is constructed to detect the compactness of the saliency regions. Next, the grouping-based and compactness-based saliency maps are improved by a propagation algorithm. The propagation process uses an enhanced similarity matrix, which fuses the low-level deep feature and the high-level semantic feature through cross diffusion. Results on four benchmark datasets with pixel-wise accurate labeling demonstrate the effectiveness of the proposed method. Particularly, the proposed unsupervised method achieves competitive performance with deep learning-based methods.}
}
@article{CAO2021237,
title = {Bidirectional stochastic configuration network for regression problems},
journal = {Neural Networks},
volume = {140},
pages = {237-246},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000964},
author = {Weipeng Cao and Zhongwu Xie and Jianqiang Li and Zhiwu Xu and Zhong Ming and Xizhao Wang},
keywords = {Stochastic configuration network, Random vector functional link network, Randomized algorithms, Neural networks with random weights, Constructive neural networks},
abstract = {To adapt to the reality of limited computing resources of various terminal devices in industrial applications, a randomized neural network called stochastic configuration network (SCN), which can conduct effective training without GPU, was proposed. SCN uses a supervisory random mechanism to assign its input weights and hidden biases, which makes it more stable than other randomized algorithms but also leads to time-consuming model training. To alleviate this problem, we propose a novel bidirectional SCN algorithm (BSCN) in this paper, which divides the way of adding hidden nodes into two modes: forward learning and backward learning. In the forward learning mode, BSCN still uses the supervisory mechanism to configure the parameters of the newly added nodes, which is the same as SCN. In the backward learning mode, BSCN calculates the parameters at one time based on the residual error feedback of the current model. The two learning modes are performed iteratively until the prediction error of the model reaches an acceptable level or the number of hidden nodes reaches its maximum value. This semi-random learning mechanism greatly speeds up the training efficiency of the BSCN model and significantly improves the quality of the hidden nodes. Extensive experiments on ten benchmark regression problems, two real-life air pollution prediction problems, and a classical image processing problem show that BSCN can achieve faster training speed, higher stability, and better generalization ability than SCN.}
}
@article{HUANG2021184,
title = {Dual self-paced multi-view clustering},
journal = {Neural Networks},
volume = {140},
pages = {184-192},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000721},
author = {Zongmo Huang and Yazhou Ren and Xiaorong Pu and Lili Pan and Dezhong Yao and Guoxian Yu},
keywords = {Multi-view clustering, Self-paced learning, Soft-weighting, Feature selection},
abstract = {By utilizing the complementary information from multiple views, multi-view clustering (MVC) algorithms typically achieve much better clustering performance than conventional single-view methods. Although in this field, great progresses have been made in past few years, most existing multi-view clustering methods still suffer the following shortcomings: (1) most MVC methods are non-convex and thus are easily stuck into suboptimal local minima; (2) the effectiveness of these methods is sensitive to the existence of noises or outliers; and (3) the qualities of different features and views are usually ignored, which can also influence the clustering result. To address these issues, we propose dual self-paced multi-view clustering (DSMVC) in this paper. Specifically, DSMVC takes advantage of self-paced learning to tackle the non-convex issue. By applying a soft-weighting scheme of self-paced learning for instances, the negative impact caused by noises and outliers can be significantly reduced. Moreover, to alleviate the feature and view quality issues, we develop a novel feature selection approach in a self-paced manner and a weighting term for views. Experimental results on real-world data sets demonstrate the effectiveness of the proposed method.}
}
@article{ZHU202111,
title = {Automatic, dynamic, and nearly optimal learning rate specification via local quadratic approximation},
journal = {Neural Networks},
volume = {141},
pages = {11-29},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021001131},
author = {Yingqiu Zhu and Danyang Huang and Yuan Gao and Rui Wu and Yu Chen and Bo Zhang and Hansheng Wang},
keywords = {Neural networks, Gradient descent, Learning rate, Machine learning, Local quadratic approximation, Gradient-based optimization},
abstract = {In deep learning tasks, the update step size determined by the learning rate at each iteration plays a critical role in gradient-based optimization. However, determining the appropriate learning rate in practice typically relies on subjective judgment. In this work, we propose a novel optimization method based on local quadratic approximation (LQA). In each update step, we locally approximate the loss function along the gradient direction by using a standard quadratic function of the learning rate. Subsequently, we propose an approximation step to obtain a nearly optimal learning rate in a computationally efficient manner. The proposed LQA method has three important features. First, the learning rate is automatically determined in each update step. Second, it is dynamically adjusted according to the current loss function value and parameter estimates. Third, with the gradient direction fixed, the proposed method attains a nearly maximum reduction in the loss function. Extensive experiments were conducted to prove the effectiveness of the proposed LQA method.}
}
@article{YANG2021149,
title = {An effective SteinGLM initialization scheme for training multi-layer feedforward sigmoidal neural networks},
journal = {Neural Networks},
volume = {139},
pages = {149-157},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021000563},
author = {Zebin Yang and Hengtao Zhang and Agus Sudjianto and Aijun Zhang},
keywords = {Multi-layer feedforward neural network, Initialization scheme, Stein’s identity, Multi-index model, Generalized linear model},
abstract = {Network initialization is the first and critical step for training neural networks. In this paper, we propose a novel network initialization scheme based on the celebrated Stein’s identity. By viewing multi-layer feedforward sigmoidal neural networks as cascades of multi-index models, the projection weights to the first hidden layer are initialized using eigenvectors of the cross-moment matrix between the input’s second-order score function and the response. The input data is then forward propagated to the next layer and such a procedure can be repeated until all the hidden layers are initialized. Finally, the weights for the output layer are initialized by generalized linear modeling. Such a proposed SteinGLM method is shown through extensive numerical results to be much faster and more accurate than other popular methods commonly used for training neural networks.}
}